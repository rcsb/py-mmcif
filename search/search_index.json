{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"mmCIF Core Access Library Introduction This module includes a native Python mmCIF API for data files and dictionaries along with pybind11 wrappers for the PDB C++ Core mmCIF Library. Installation Download the library source software from the project repository: git clone --recurse-submodules https://github.com/rcsb/py-mmcif.git Optionally, run test suite using the Tox test runner. The C++ library bindings have been tested on Centos 7/Ubuntu 20.04 Linux with GCC/G++ > 4.8.5 and MacOS (10.15) with > clang-900.0.39.2 using Python versions 2.7.18 and 3.9.4. tox Installation is via the program pip . pip install mmcif or from the local repository: pip install . To generate API documentation using Sphinx : cd scripts # Check Sphinx dependencies in the introductory comments to the following script. ./initdocs.sh A command-line script is provided as a preprocessor for modular dictionaries that include definition and data content using categories pdbx_include_dictionary, pdbx_include_category and pdbx_include_item. build_dict_cli --help usage: build_dict_cli [ -h ] --op OP --input_dict_path INPUT_DICT_PATH [ --output_dict_path OUTPUT_DICT_PATH ] [ --cleanup ] optional arguments: -h, --help show this help message and exit --op OP Operation ( build | get_version ) --input_dict_path INPUT_DICT_PATH Path to dictionary generator file --output_dict_path OUTPUT_DICT_PATH Path to output dictionary text file --cleanup Remove include instruction categories after processing ________________________________________________________________________________","title":"Overview"},{"location":"#mmcif-core-access-library","text":"","title":"mmCIF Core Access Library"},{"location":"#introduction","text":"This module includes a native Python mmCIF API for data files and dictionaries along with pybind11 wrappers for the PDB C++ Core mmCIF Library.","title":"Introduction"},{"location":"#installation","text":"Download the library source software from the project repository: git clone --recurse-submodules https://github.com/rcsb/py-mmcif.git Optionally, run test suite using the Tox test runner. The C++ library bindings have been tested on Centos 7/Ubuntu 20.04 Linux with GCC/G++ > 4.8.5 and MacOS (10.15) with > clang-900.0.39.2 using Python versions 2.7.18 and 3.9.4. tox Installation is via the program pip . pip install mmcif or from the local repository: pip install . To generate API documentation using Sphinx : cd scripts # Check Sphinx dependencies in the introductory comments to the following script. ./initdocs.sh A command-line script is provided as a preprocessor for modular dictionaries that include definition and data content using categories pdbx_include_dictionary, pdbx_include_category and pdbx_include_item. build_dict_cli --help usage: build_dict_cli [ -h ] --op OP --input_dict_path INPUT_DICT_PATH [ --output_dict_path OUTPUT_DICT_PATH ] [ --cleanup ] optional arguments: -h, --help show this help message and exit --op OP Operation ( build | get_version ) --input_dict_path INPUT_DICT_PATH Path to dictionary generator file --output_dict_path OUTPUT_DICT_PATH Path to output dictionary text file --cleanup Remove include instruction categories after processing ________________________________________________________________________________","title":"Installation"},{"location":"api_reference/","text":"","title":"Overview"},{"location":"api_reference/BinaryCifReader/","text":"mmcif.io.BinaryCifReader.BinaryCifReader Reader methods for the binary CIF format. Source code in mmcif/io/BinaryCifReader.py class BinaryCifReader ( object ): \"\"\"Reader methods for the binary CIF format.\"\"\" def __init__ ( self , storeStringsAsBytes = False , defaultStringEncoding = \"utf-8\" ): \"\"\"Create an instance of the binary CIF reader class. Args: storeStringsAsBytes (bool, optional): strings are stored as lists of bytes. Defaults to False. defaultStringEncoding (str, optional): default encoding for string data. Defaults to \"utf-8\". \"\"\" self . __storeStringsAsBytes = storeStringsAsBytes self . __defaultStringEncoding = defaultStringEncoding def deserialize ( self , locator ): \"\"\"Deserialize the input binary CIF file stored in the file/URL locator path. Args: locator (str): input file path or URL Returns: list: list DataContainer objects \"\"\" cL = [] try : if self . __isLocal ( locator ): with gzip . open ( locator , mode = \"rb\" ) if locator [ - 3 :] == \".gz\" else open ( locator , \"rb\" ) as fh : cL = self . __deserialize ( fh , storeStringsAsBytes = self . __storeStringsAsBytes ) else : if locator . endswith ( \".gz\" ): customHeader = { \"Accept-Encoding\" : \"gzip\" } with closing ( requests . get ( locator , headers = customHeader )) as fh : ufh = gzip . GzipFile ( fileobj = io . BytesIO ( fh . content )) cL = self . __deserialize ( ufh , storeStringsAsBytes = self . __storeStringsAsBytes ) else : with closing ( requests . get ( locator )) as fh : cL = self . __deserialize ( io . BytesIO ( fh . content ), storeStringsAsBytes = self . __storeStringsAsBytes ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return cL def __deserialize ( self , fh , storeStringsAsBytes = False ): cL = [] try : dec = BinaryCifDecoders ( storeStringsAsBytes = storeStringsAsBytes ) bD = msgpack . unpack ( fh ) # logger . debug ( \"bD.keys() %r \" , bD . keys ()) logger . debug ( \"bD['dataBlocks'] %s \" , bD [ self . __toBytes ( \"dataBlocks\" )]) # for dataBlock in bD [ self . __toBytes ( \"dataBlocks\" )]: header = self . __fromBytes ( dataBlock [ self . __toBytes ( \"header\" )]) if self . __toBytes ( \"header\" ) in dataBlock else None logger . debug ( \"header %r \" , header ) logger . debug ( \"dataBlock %r \" , dataBlock ) # dc = DataContainer ( header ) categoryList = dataBlock [ self . __toBytes ( \"categories\" )] if self . __toBytes ( \"categories\" ) in dataBlock else [] for category in categoryList : catName = self . __fromBytes ( category [ self . __toBytes ( \"name\" )])[ 1 :] colList = category [ self . __toBytes ( \"columns\" )] logger . debug ( \"catName %r columns %r \" , catName , colList ) colD = OrderedDict () atNameList = [] for col in colList : logger . debug ( \"col.keys() %r \" , col . keys ()) atName = self . __fromBytes ( col [ self . __toBytes ( \"name\" )]) atData = col [ self . __toBytes ( \"data\" )] logger . debug ( \"atData encoding ( %d ) data ( %d )\" , len ( atData [ self . __toBytes ( \"encoding\" )]), len ( atData [ self . __toBytes ( \"data\" )])) atMask = col [ self . __toBytes ( \"mask\" )] logger . debug ( \"catName %r atName %r \" , catName , atName ) logger . debug ( \" >atData.data %r \" , atData [ self . __toBytes ( \"data\" )]) logger . debug ( \" >atData.encoding ( %d ) %r \" , len ( atData [ self . __toBytes ( \"encoding\" )]), atData [ self . __toBytes ( \"encoding\" )]) logger . debug ( \" >mask %r \" , atMask ) tVal = dec . decode ( col [ self . __toBytes ( \"data\" )][ self . __toBytes ( \"data\" )], col [ self . __toBytes ( \"data\" )][ self . __toBytes ( \"encoding\" )]) if col [ self . __toBytes ( \"mask\" )]: mVal = dec . decode ( col [ self . __toBytes ( \"mask\" )][ self . __toBytes ( \"data\" )], col [ self . __toBytes ( \"mask\" )][ self . __toBytes ( \"encoding\" )]) tVal = [ \"?\" if m == 2 else \".\" if m == 1 else d for d , m in zip ( tVal , mVal )] colD [ atName ] = tVal atNameList . append ( atName ) # cObj = DataCategory ( catName , attributeNameList = atNameList ) genL = [ colGen for colGen in colD . values ()] for row in zip ( * genL ): logger . debug ( \"row %r \" , row ) cObj . append ( row ) # dc . append ( cObj ) cL . append ( dc ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return cL def __isLocal ( self , locator ): \"\"\"Returns true if input string can be interpreted as a local file path. Args: locator (str): url or path string Returns: bool: True if locator is a local path \"\"\" try : locSp = urlsplit ( locator ) return locSp . scheme in [ \"\" , \"file\" ] except Exception as e : logger . exception ( \"For locator %r failing with %s \" , locator , str ( e )) return None def __toBytes ( self , strVal ): \"\"\"Optional conversion of the input string to bytes according to the class setting (storeStringsAsBytes). Args: strVal (string): input string Returns: string or bytes: optionally converted string. \"\"\" try : return strVal . encode ( self . __defaultStringEncoding ) if self . __storeStringsAsBytes else strVal except ( UnicodeDecodeError , AttributeError ): logger . exception ( \"Bad type for %r \" , strVal ) return strVal def __fromBytes ( self , byteVal ): \"\"\"Optional conversion of the input value according to the class setting (storeStringsAsBytes). Args: byteVal (string): input byte object Returns: string: optionally converted input value \"\"\" try : return byteVal . decode ( self . __defaultStringEncoding ) if self . __storeStringsAsBytes else byteVal except ( UnicodeDecodeError , AttributeError ): logger . exception ( \"Bad type for %r \" , byteVal ) return byteVal Methods __init__ ( self , storeStringsAsBytes = False , defaultStringEncoding = 'utf-8' ) special Create an instance of the binary CIF reader class. Parameters: Name Type Description Default storeStringsAsBytes bool strings are stored as lists of bytes. Defaults to False. False defaultStringEncoding str default encoding for string data. Defaults to \"utf-8\". 'utf-8' Source code in mmcif/io/BinaryCifReader.py def __init__ ( self , storeStringsAsBytes = False , defaultStringEncoding = \"utf-8\" ): \"\"\"Create an instance of the binary CIF reader class. Args: storeStringsAsBytes (bool, optional): strings are stored as lists of bytes. Defaults to False. defaultStringEncoding (str, optional): default encoding for string data. Defaults to \"utf-8\". \"\"\" self . __storeStringsAsBytes = storeStringsAsBytes self . __defaultStringEncoding = defaultStringEncoding deserialize ( self , locator ) Deserialize the input binary CIF file stored in the file/URL locator path. Parameters: Name Type Description Default locator str input file path or URL required Returns: Type Description list list DataContainer objects Source code in mmcif/io/BinaryCifReader.py def deserialize ( self , locator ): \"\"\"Deserialize the input binary CIF file stored in the file/URL locator path. Args: locator (str): input file path or URL Returns: list: list DataContainer objects \"\"\" cL = [] try : if self . __isLocal ( locator ): with gzip . open ( locator , mode = \"rb\" ) if locator [ - 3 :] == \".gz\" else open ( locator , \"rb\" ) as fh : cL = self . __deserialize ( fh , storeStringsAsBytes = self . __storeStringsAsBytes ) else : if locator . endswith ( \".gz\" ): customHeader = { \"Accept-Encoding\" : \"gzip\" } with closing ( requests . get ( locator , headers = customHeader )) as fh : ufh = gzip . GzipFile ( fileobj = io . BytesIO ( fh . content )) cL = self . __deserialize ( ufh , storeStringsAsBytes = self . __storeStringsAsBytes ) else : with closing ( requests . get ( locator )) as fh : cL = self . __deserialize ( io . BytesIO ( fh . content ), storeStringsAsBytes = self . __storeStringsAsBytes ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return cL mmcif.io.BinaryCifReader.BinaryCifDecoders Column oriented Binary CIF decoders implementing StringArray, ByteArray, IntegerPacking, Delta, RunLength, FixedPoint, and IntervalQuantization from the BinaryCIF specification described in: Sehnal D, Bittrich S, Velankar S, Koca J, Svobodova R, Burley SK, Rose AS. BinaryCIF and CIFTools-Lightweight, efficient and extensible macromolecular data management. PLoS Comput Biol. 2020 Oct 19;16(10):e1008247. doi: 10.1371/journal.pcbi.1008247. PMID: 33075050; PMCID: PMC7595629. and in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md and from the I/HM Python implementation at https://github.com/ihmwg/python-ihm[summary ] Source code in mmcif/io/BinaryCifReader.py class BinaryCifDecoders ( object ): \"\"\"Column oriented Binary CIF decoders implementing StringArray, ByteArray, IntegerPacking, Delta, RunLength, FixedPoint, and IntervalQuantization from the BinaryCIF specification described in: Sehnal D, Bittrich S, Velankar S, Koca J, Svobodova R, Burley SK, Rose AS. BinaryCIF and CIFTools-Lightweight, efficient and extensible macromolecular data management. PLoS Comput Biol. 2020 Oct 19;16(10):e1008247. doi: 10.1371/journal.pcbi.1008247. PMID: 33075050; PMCID: PMC7595629. and in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md and from the I/HM Python implementation at https://github.com/ihmwg/python-ihm[summary] \"\"\" bCifCodeTypeD = { 1 : \"integer_8\" , 2 : \"integer_16\" , 3 : \"integer_32\" , 4 : \"unsigned_integer_8\" , 5 : \"unsigned_integer_16\" , 6 : \"unsigned_integer_32\" , 32 : \"float_32\" , 33 : \"float_64\" } \"\"\"Binary CIF protocol internal data type codes to integer and float types \"\"\" bCifTypeD = { \"integer_8\" : { \"struct_format_code\" : \"b\" , \"min\" : - 0x7F - 1 , \"max\" : 0x7F }, \"integer_16\" : { \"struct_format_code\" : \"h\" , \"min\" : - 0x7FFF - 1 , \"max\" : 0x7FFF }, \"integer_32\" : { \"struct_format_code\" : \"i\" , \"min\" : - 0x7FFFFFFF - 1 , \"max\" : 0x7FFFFFFF }, \"unsigned_integer_8\" : { \"struct_format_code\" : \"B\" , \"min\" : 0 , \"max\" : 0xFF }, \"unsigned_integer_16\" : { \"struct_format_code\" : \"H\" , \"min\" : 0 , \"max\" : 0xFFFF }, \"unsigned_integer_32\" : { \"struct_format_code\" : \"I\" , \"min\" : 0 , \"max\" : 0xFFFFFFFF }, \"float_32\" : { \"struct_format_code\" : \"f\" , \"min\" : 1.175494351e-38 , \"max\" : 3.402823466e38 }, \"float_64\" : { \"struct_format_code\" : \"d\" , \"min\" : 2.2250738585072014e-308 , \"max\" : 1.7976931348623158e308 }, } \"\"\"Binary CIF data type feature dictionary \"\"\" def __init__ ( self , storeStringsAsBytes = False , defaultStringEncoding = \"utf-8\" , verbose = False ): \"\"\"Create an instance of the binary CIF encoder class. Args: storeStringsAsBytes (bool, optional): express keys and strings as byte types otherwise follow the default encoding. Defaults to False. defaultStringEncoding (str, optional): default encoding for string types. Defaults to \"utf-8\". verbose(bool, optional): provide tracking of type conversion issues. Defaults to False. \"\"\" self . __storeStringsAsBytes = storeStringsAsBytes self . __defaultStringEncoding = defaultStringEncoding self . __verbose = verbose # self . __encodersMethodD = { \"StringArray\" : self . stringArrayDecoder , \"ByteArray\" : self . byteArrayDecoder , \"IntegerPacking\" : self . integerPackingDecoder , \"Delta\" : self . deltaDecoder , \"RunLength\" : self . runLengthDecoder , \"FixedPoint\" : self . fixedPointDecoder , \"IntervalQuantization\" : self . intervalQuantizationDecoder , } def decode ( self , colDataList , encodingDictList ): \"\"\"Return the decoded input data column using the input list of encodings Args: colDataList (list): column of data to be decoded encodingDictList (list): list of dictionary holding binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of column data \"\"\" for encoding in reversed ( encodingDictList ): encType = self . __fromBytes ( encoding [ self . __toBytes ( \"kind\" )]) colDataList = self . __encodersMethodD [ encType ]( colDataList , encoding ) return colDataList def stringArrayDecoder ( self , colDataList , encodingDict ): \"\"\"Decode an array of strings stored as a concatenation of all unique strings, a list of offsets to construct the unique substrings, and indices into the offset array. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of string data \"\"\" offsetList = list ( self . decode ( encodingDict [ self . __toBytes ( \"offsets\" )], encodingDict [ self . __toBytes ( \"offsetEncoding\" )])) lookupIndexIt = self . decode ( colDataList , encodingDict [ self . __toBytes ( \"dataEncoding\" )]) stringData = self . __fromBytes ( encodingDict [ self . __toBytes ( \"stringData\" )]) uniqueStringList = [] for iBegin , iEnd in zip ( offsetList , offsetList [ 1 :]): uniqueStringList . append ( stringData [ iBegin : iEnd ]) logger . debug ( \"iBegin %d iEnd %d %r \" , iBegin , iEnd , stringData [ iBegin : iEnd ]) for ii in lookupIndexIt : yield uniqueStringList [ ii ] if ii >= 0 else None def byteArrayDecoder ( self , colDataList , encodingDict ): \"\"\"Decode input byte list into a list of integers/floats Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer/float data \"\"\" structKey = self . bCifCodeTypeD [ encodingDict [ self . __toBytes ( \"type\" )]] structFormatCode = self . bCifTypeD [ structKey ][ \"struct_format_code\" ] count = len ( colDataList ) // struct . calcsize ( structFormatCode ) # struct.unpack() format string for little-endian = < format_string code * counts return struct . unpack ( \"<\" + structFormatCode * count , colDataList ) def __unsignedDecode ( self , colDataList , encodingDict ): upperLimit = self . bCifTypeD [ \"unsigned_integer_8\" ][ \"max\" ] if encodingDict [ self . __toBytes ( \"byteCount\" )] == 1 else self . bCifTypeD [ \"unsigned_integer_16\" ][ \"max\" ] ii = 0 while ii < len ( colDataList ): value = 0 tVal = colDataList [ ii ] while tVal == upperLimit : value += tVal ii += 1 tVal = colDataList [ ii ] yield value + tVal ii += 1 def __signedDecode ( self , colDataList , encodingDict ): upperLimit = self . bCifTypeD [ \"integer_8\" ][ \"max\" ] if encodingDict [ self . __toBytes ( \"byteCount\" )] == 1 else self . bCifTypeD [ \"integer_16\" ][ \"max\" ] lowerLimit = self . bCifTypeD [ \"integer_8\" ][ \"min\" ] if encodingDict [ self . __toBytes ( \"byteCount\" )] == 1 else self . bCifTypeD [ \"integer_16\" ][ \"min\" ] ii = 0 while ii < len ( colDataList ): value = 0 tVal = colDataList [ ii ] while tVal == upperLimit or tVal == lowerLimit : value += tVal ii += 1 tVal = colDataList [ ii ] yield value + tVal ii += 1 def integerPackingDecoder ( self , colDataList , encodingDict ): \"\"\"Decode a (32-bit) integer list packed into 8- or 16-bit values. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer data \"\"\" if encodingDict [ self . __toBytes ( \"isUnsigned\" )]: return self . __unsignedDecode ( colDataList , encodingDict ) else : return self . __signedDecode ( colDataList , encodingDict ) def deltaDecoder ( self , colDataList , encodingDict ): \"\"\"Decode an integer list stored as a list of consecutive differences. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer data \"\"\" val = encodingDict [ self . __toBytes ( \"origin\" )] for diff in colDataList : val += diff yield val def runLengthDecoder ( self , colDataList , encodingDict ): \"\"\"Decode an integer list stored as pairs of (value, number of repeats). Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer data \"\"\" _ = encodingDict colDataList = list ( colDataList ) for ii in range ( 0 , len ( colDataList ), 2 ): for _ in range ( colDataList [ ii + 1 ]): yield colDataList [ ii ] def fixedPointDecoder ( self , colDataList , encodingDict ): \"\"\"Decode a floating point list stored as integers and a multiplicative factor. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of float data \"\"\" factor = float ( encodingDict [ self . __toBytes ( \"factor\" )]) for val in colDataList : yield float ( val ) / factor def intervalQuantizationDecoder ( self , colDataList , encodingDict ): \"\"\"Decode a list of 32-bit integers quantized within a given interval into a list of floats. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of float data \"\"\" delta = float ( encodingDict [ self . __toBytes ( \"max\" )] - encodingDict [ self . __toBytes ( \"min\" )]) / float ( encodingDict [ self . __toBytes ( \"numSteps\" )] - 1.0 ) minVal = encodingDict [ self . __toBytes ( \"min\" )] for val in colDataList : yield minVal + delta * val def __toBytes ( self , strVal ): \"\"\"Optional conversion of the input string to bytes according to the class setting (storeStringsAsBytes). Args: strVal (string): input string Returns: string or bytes: optionally converted string. \"\"\" try : return strVal . encode ( self . __defaultStringEncoding ) if self . __storeStringsAsBytes else strVal except ( UnicodeDecodeError , AttributeError ): if self . __verbose : logger . exception ( \"Bad type for %r \" , strVal ) return strVal def __fromBytes ( self , byteVal ): \"\"\"Optional conversion of the input value according to the class setting (storeStringsAsBytes). Args: byteVal (string): input byte object Returns: string: optionally converted input value \"\"\" try : return byteVal . decode ( self . __defaultStringEncoding ) if self . __storeStringsAsBytes else byteVal except ( UnicodeDecodeError , AttributeError ): if self . __verbose : logger . exception ( \"Bad type for %r \" , byteVal ) return byteVal Attributes bCifCodeTypeD Binary CIF protocol internal data type codes to integer and float types bCifTypeD Binary CIF data type feature dictionary Methods __init__ ( self , storeStringsAsBytes = False , defaultStringEncoding = 'utf-8' , verbose = False ) special Create an instance of the binary CIF encoder class. Parameters: Name Type Description Default storeStringsAsBytes bool express keys and strings as byte types otherwise follow the default encoding. Defaults to False. False defaultStringEncoding str default encoding for string types. Defaults to \"utf-8\". 'utf-8' verbose(bool, optional provide tracking of type conversion issues. Defaults to False. required Source code in mmcif/io/BinaryCifReader.py def __init__ ( self , storeStringsAsBytes = False , defaultStringEncoding = \"utf-8\" , verbose = False ): \"\"\"Create an instance of the binary CIF encoder class. Args: storeStringsAsBytes (bool, optional): express keys and strings as byte types otherwise follow the default encoding. Defaults to False. defaultStringEncoding (str, optional): default encoding for string types. Defaults to \"utf-8\". verbose(bool, optional): provide tracking of type conversion issues. Defaults to False. \"\"\" self . __storeStringsAsBytes = storeStringsAsBytes self . __defaultStringEncoding = defaultStringEncoding self . __verbose = verbose # self . __encodersMethodD = { \"StringArray\" : self . stringArrayDecoder , \"ByteArray\" : self . byteArrayDecoder , \"IntegerPacking\" : self . integerPackingDecoder , \"Delta\" : self . deltaDecoder , \"RunLength\" : self . runLengthDecoder , \"FixedPoint\" : self . fixedPointDecoder , \"IntervalQuantization\" : self . intervalQuantizationDecoder , } byteArrayDecoder ( self , colDataList , encodingDict ) Decode input byte list into a list of integers/floats Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of integer/float data Source code in mmcif/io/BinaryCifReader.py def byteArrayDecoder ( self , colDataList , encodingDict ): \"\"\"Decode input byte list into a list of integers/floats Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer/float data \"\"\" structKey = self . bCifCodeTypeD [ encodingDict [ self . __toBytes ( \"type\" )]] structFormatCode = self . bCifTypeD [ structKey ][ \"struct_format_code\" ] count = len ( colDataList ) // struct . calcsize ( structFormatCode ) # struct.unpack() format string for little-endian = < format_string code * counts return struct . unpack ( \"<\" + structFormatCode * count , colDataList ) decode ( self , colDataList , encodingDictList ) Return the decoded input data column using the input list of encodings Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDictList list list of dictionary holding binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of column data Source code in mmcif/io/BinaryCifReader.py def decode ( self , colDataList , encodingDictList ): \"\"\"Return the decoded input data column using the input list of encodings Args: colDataList (list): column of data to be decoded encodingDictList (list): list of dictionary holding binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of column data \"\"\" for encoding in reversed ( encodingDictList ): encType = self . __fromBytes ( encoding [ self . __toBytes ( \"kind\" )]) colDataList = self . __encodersMethodD [ encType ]( colDataList , encoding ) return colDataList deltaDecoder ( self , colDataList , encodingDict ) Decode an integer list stored as a list of consecutive differences. Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of integer data Source code in mmcif/io/BinaryCifReader.py def deltaDecoder ( self , colDataList , encodingDict ): \"\"\"Decode an integer list stored as a list of consecutive differences. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer data \"\"\" val = encodingDict [ self . __toBytes ( \"origin\" )] for diff in colDataList : val += diff yield val fixedPointDecoder ( self , colDataList , encodingDict ) Decode a floating point list stored as integers and a multiplicative factor. Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of float data Source code in mmcif/io/BinaryCifReader.py def fixedPointDecoder ( self , colDataList , encodingDict ): \"\"\"Decode a floating point list stored as integers and a multiplicative factor. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of float data \"\"\" factor = float ( encodingDict [ self . __toBytes ( \"factor\" )]) for val in colDataList : yield float ( val ) / factor integerPackingDecoder ( self , colDataList , encodingDict ) Decode a (32-bit) integer list packed into 8- or 16-bit values. Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of integer data Source code in mmcif/io/BinaryCifReader.py def integerPackingDecoder ( self , colDataList , encodingDict ): \"\"\"Decode a (32-bit) integer list packed into 8- or 16-bit values. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer data \"\"\" if encodingDict [ self . __toBytes ( \"isUnsigned\" )]: return self . __unsignedDecode ( colDataList , encodingDict ) else : return self . __signedDecode ( colDataList , encodingDict ) intervalQuantizationDecoder ( self , colDataList , encodingDict ) Decode a list of 32-bit integers quantized within a given interval into a list of floats. Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of float data Source code in mmcif/io/BinaryCifReader.py def intervalQuantizationDecoder ( self , colDataList , encodingDict ): \"\"\"Decode a list of 32-bit integers quantized within a given interval into a list of floats. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of float data \"\"\" delta = float ( encodingDict [ self . __toBytes ( \"max\" )] - encodingDict [ self . __toBytes ( \"min\" )]) / float ( encodingDict [ self . __toBytes ( \"numSteps\" )] - 1.0 ) minVal = encodingDict [ self . __toBytes ( \"min\" )] for val in colDataList : yield minVal + delta * val runLengthDecoder ( self , colDataList , encodingDict ) Decode an integer list stored as pairs of (value, number of repeats). Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of integer data Source code in mmcif/io/BinaryCifReader.py def runLengthDecoder ( self , colDataList , encodingDict ): \"\"\"Decode an integer list stored as pairs of (value, number of repeats). Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer data \"\"\" _ = encodingDict colDataList = list ( colDataList ) for ii in range ( 0 , len ( colDataList ), 2 ): for _ in range ( colDataList [ ii + 1 ]): yield colDataList [ ii ] stringArrayDecoder ( self , colDataList , encodingDict ) Decode an array of strings stored as a concatenation of all unique strings, a list of offsets to construct the unique substrings, and indices into the offset array. Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of string data Source code in mmcif/io/BinaryCifReader.py def stringArrayDecoder ( self , colDataList , encodingDict ): \"\"\"Decode an array of strings stored as a concatenation of all unique strings, a list of offsets to construct the unique substrings, and indices into the offset array. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of string data \"\"\" offsetList = list ( self . decode ( encodingDict [ self . __toBytes ( \"offsets\" )], encodingDict [ self . __toBytes ( \"offsetEncoding\" )])) lookupIndexIt = self . decode ( colDataList , encodingDict [ self . __toBytes ( \"dataEncoding\" )]) stringData = self . __fromBytes ( encodingDict [ self . __toBytes ( \"stringData\" )]) uniqueStringList = [] for iBegin , iEnd in zip ( offsetList , offsetList [ 1 :]): uniqueStringList . append ( stringData [ iBegin : iEnd ]) logger . debug ( \"iBegin %d iEnd %d %r \" , iBegin , iEnd , stringData [ iBegin : iEnd ]) for ii in lookupIndexIt : yield uniqueStringList [ ii ] if ii >= 0 else None","title":"BinaryCifReader"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifReader","text":"Reader methods for the binary CIF format. Source code in mmcif/io/BinaryCifReader.py class BinaryCifReader ( object ): \"\"\"Reader methods for the binary CIF format.\"\"\" def __init__ ( self , storeStringsAsBytes = False , defaultStringEncoding = \"utf-8\" ): \"\"\"Create an instance of the binary CIF reader class. Args: storeStringsAsBytes (bool, optional): strings are stored as lists of bytes. Defaults to False. defaultStringEncoding (str, optional): default encoding for string data. Defaults to \"utf-8\". \"\"\" self . __storeStringsAsBytes = storeStringsAsBytes self . __defaultStringEncoding = defaultStringEncoding def deserialize ( self , locator ): \"\"\"Deserialize the input binary CIF file stored in the file/URL locator path. Args: locator (str): input file path or URL Returns: list: list DataContainer objects \"\"\" cL = [] try : if self . __isLocal ( locator ): with gzip . open ( locator , mode = \"rb\" ) if locator [ - 3 :] == \".gz\" else open ( locator , \"rb\" ) as fh : cL = self . __deserialize ( fh , storeStringsAsBytes = self . __storeStringsAsBytes ) else : if locator . endswith ( \".gz\" ): customHeader = { \"Accept-Encoding\" : \"gzip\" } with closing ( requests . get ( locator , headers = customHeader )) as fh : ufh = gzip . GzipFile ( fileobj = io . BytesIO ( fh . content )) cL = self . __deserialize ( ufh , storeStringsAsBytes = self . __storeStringsAsBytes ) else : with closing ( requests . get ( locator )) as fh : cL = self . __deserialize ( io . BytesIO ( fh . content ), storeStringsAsBytes = self . __storeStringsAsBytes ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return cL def __deserialize ( self , fh , storeStringsAsBytes = False ): cL = [] try : dec = BinaryCifDecoders ( storeStringsAsBytes = storeStringsAsBytes ) bD = msgpack . unpack ( fh ) # logger . debug ( \"bD.keys() %r \" , bD . keys ()) logger . debug ( \"bD['dataBlocks'] %s \" , bD [ self . __toBytes ( \"dataBlocks\" )]) # for dataBlock in bD [ self . __toBytes ( \"dataBlocks\" )]: header = self . __fromBytes ( dataBlock [ self . __toBytes ( \"header\" )]) if self . __toBytes ( \"header\" ) in dataBlock else None logger . debug ( \"header %r \" , header ) logger . debug ( \"dataBlock %r \" , dataBlock ) # dc = DataContainer ( header ) categoryList = dataBlock [ self . __toBytes ( \"categories\" )] if self . __toBytes ( \"categories\" ) in dataBlock else [] for category in categoryList : catName = self . __fromBytes ( category [ self . __toBytes ( \"name\" )])[ 1 :] colList = category [ self . __toBytes ( \"columns\" )] logger . debug ( \"catName %r columns %r \" , catName , colList ) colD = OrderedDict () atNameList = [] for col in colList : logger . debug ( \"col.keys() %r \" , col . keys ()) atName = self . __fromBytes ( col [ self . __toBytes ( \"name\" )]) atData = col [ self . __toBytes ( \"data\" )] logger . debug ( \"atData encoding ( %d ) data ( %d )\" , len ( atData [ self . __toBytes ( \"encoding\" )]), len ( atData [ self . __toBytes ( \"data\" )])) atMask = col [ self . __toBytes ( \"mask\" )] logger . debug ( \"catName %r atName %r \" , catName , atName ) logger . debug ( \" >atData.data %r \" , atData [ self . __toBytes ( \"data\" )]) logger . debug ( \" >atData.encoding ( %d ) %r \" , len ( atData [ self . __toBytes ( \"encoding\" )]), atData [ self . __toBytes ( \"encoding\" )]) logger . debug ( \" >mask %r \" , atMask ) tVal = dec . decode ( col [ self . __toBytes ( \"data\" )][ self . __toBytes ( \"data\" )], col [ self . __toBytes ( \"data\" )][ self . __toBytes ( \"encoding\" )]) if col [ self . __toBytes ( \"mask\" )]: mVal = dec . decode ( col [ self . __toBytes ( \"mask\" )][ self . __toBytes ( \"data\" )], col [ self . __toBytes ( \"mask\" )][ self . __toBytes ( \"encoding\" )]) tVal = [ \"?\" if m == 2 else \".\" if m == 1 else d for d , m in zip ( tVal , mVal )] colD [ atName ] = tVal atNameList . append ( atName ) # cObj = DataCategory ( catName , attributeNameList = atNameList ) genL = [ colGen for colGen in colD . values ()] for row in zip ( * genL ): logger . debug ( \"row %r \" , row ) cObj . append ( row ) # dc . append ( cObj ) cL . append ( dc ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return cL def __isLocal ( self , locator ): \"\"\"Returns true if input string can be interpreted as a local file path. Args: locator (str): url or path string Returns: bool: True if locator is a local path \"\"\" try : locSp = urlsplit ( locator ) return locSp . scheme in [ \"\" , \"file\" ] except Exception as e : logger . exception ( \"For locator %r failing with %s \" , locator , str ( e )) return None def __toBytes ( self , strVal ): \"\"\"Optional conversion of the input string to bytes according to the class setting (storeStringsAsBytes). Args: strVal (string): input string Returns: string or bytes: optionally converted string. \"\"\" try : return strVal . encode ( self . __defaultStringEncoding ) if self . __storeStringsAsBytes else strVal except ( UnicodeDecodeError , AttributeError ): logger . exception ( \"Bad type for %r \" , strVal ) return strVal def __fromBytes ( self , byteVal ): \"\"\"Optional conversion of the input value according to the class setting (storeStringsAsBytes). Args: byteVal (string): input byte object Returns: string: optionally converted input value \"\"\" try : return byteVal . decode ( self . __defaultStringEncoding ) if self . __storeStringsAsBytes else byteVal except ( UnicodeDecodeError , AttributeError ): logger . exception ( \"Bad type for %r \" , byteVal ) return byteVal","title":"BinaryCifReader"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifReader-methods","text":"","title":"Methods"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifReader.__init__","text":"Create an instance of the binary CIF reader class. Parameters: Name Type Description Default storeStringsAsBytes bool strings are stored as lists of bytes. Defaults to False. False defaultStringEncoding str default encoding for string data. Defaults to \"utf-8\". 'utf-8' Source code in mmcif/io/BinaryCifReader.py def __init__ ( self , storeStringsAsBytes = False , defaultStringEncoding = \"utf-8\" ): \"\"\"Create an instance of the binary CIF reader class. Args: storeStringsAsBytes (bool, optional): strings are stored as lists of bytes. Defaults to False. defaultStringEncoding (str, optional): default encoding for string data. Defaults to \"utf-8\". \"\"\" self . __storeStringsAsBytes = storeStringsAsBytes self . __defaultStringEncoding = defaultStringEncoding","title":"__init__()"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifReader.deserialize","text":"Deserialize the input binary CIF file stored in the file/URL locator path. Parameters: Name Type Description Default locator str input file path or URL required Returns: Type Description list list DataContainer objects Source code in mmcif/io/BinaryCifReader.py def deserialize ( self , locator ): \"\"\"Deserialize the input binary CIF file stored in the file/URL locator path. Args: locator (str): input file path or URL Returns: list: list DataContainer objects \"\"\" cL = [] try : if self . __isLocal ( locator ): with gzip . open ( locator , mode = \"rb\" ) if locator [ - 3 :] == \".gz\" else open ( locator , \"rb\" ) as fh : cL = self . __deserialize ( fh , storeStringsAsBytes = self . __storeStringsAsBytes ) else : if locator . endswith ( \".gz\" ): customHeader = { \"Accept-Encoding\" : \"gzip\" } with closing ( requests . get ( locator , headers = customHeader )) as fh : ufh = gzip . GzipFile ( fileobj = io . BytesIO ( fh . content )) cL = self . __deserialize ( ufh , storeStringsAsBytes = self . __storeStringsAsBytes ) else : with closing ( requests . get ( locator )) as fh : cL = self . __deserialize ( io . BytesIO ( fh . content ), storeStringsAsBytes = self . __storeStringsAsBytes ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return cL","title":"deserialize()"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders","text":"Column oriented Binary CIF decoders implementing StringArray, ByteArray, IntegerPacking, Delta, RunLength, FixedPoint, and IntervalQuantization from the BinaryCIF specification described in: Sehnal D, Bittrich S, Velankar S, Koca J, Svobodova R, Burley SK, Rose AS. BinaryCIF and CIFTools-Lightweight, efficient and extensible macromolecular data management. PLoS Comput Biol. 2020 Oct 19;16(10):e1008247. doi: 10.1371/journal.pcbi.1008247. PMID: 33075050; PMCID: PMC7595629. and in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md and from the I/HM Python implementation at https://github.com/ihmwg/python-ihm[summary ] Source code in mmcif/io/BinaryCifReader.py class BinaryCifDecoders ( object ): \"\"\"Column oriented Binary CIF decoders implementing StringArray, ByteArray, IntegerPacking, Delta, RunLength, FixedPoint, and IntervalQuantization from the BinaryCIF specification described in: Sehnal D, Bittrich S, Velankar S, Koca J, Svobodova R, Burley SK, Rose AS. BinaryCIF and CIFTools-Lightweight, efficient and extensible macromolecular data management. PLoS Comput Biol. 2020 Oct 19;16(10):e1008247. doi: 10.1371/journal.pcbi.1008247. PMID: 33075050; PMCID: PMC7595629. and in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md and from the I/HM Python implementation at https://github.com/ihmwg/python-ihm[summary] \"\"\" bCifCodeTypeD = { 1 : \"integer_8\" , 2 : \"integer_16\" , 3 : \"integer_32\" , 4 : \"unsigned_integer_8\" , 5 : \"unsigned_integer_16\" , 6 : \"unsigned_integer_32\" , 32 : \"float_32\" , 33 : \"float_64\" } \"\"\"Binary CIF protocol internal data type codes to integer and float types \"\"\" bCifTypeD = { \"integer_8\" : { \"struct_format_code\" : \"b\" , \"min\" : - 0x7F - 1 , \"max\" : 0x7F }, \"integer_16\" : { \"struct_format_code\" : \"h\" , \"min\" : - 0x7FFF - 1 , \"max\" : 0x7FFF }, \"integer_32\" : { \"struct_format_code\" : \"i\" , \"min\" : - 0x7FFFFFFF - 1 , \"max\" : 0x7FFFFFFF }, \"unsigned_integer_8\" : { \"struct_format_code\" : \"B\" , \"min\" : 0 , \"max\" : 0xFF }, \"unsigned_integer_16\" : { \"struct_format_code\" : \"H\" , \"min\" : 0 , \"max\" : 0xFFFF }, \"unsigned_integer_32\" : { \"struct_format_code\" : \"I\" , \"min\" : 0 , \"max\" : 0xFFFFFFFF }, \"float_32\" : { \"struct_format_code\" : \"f\" , \"min\" : 1.175494351e-38 , \"max\" : 3.402823466e38 }, \"float_64\" : { \"struct_format_code\" : \"d\" , \"min\" : 2.2250738585072014e-308 , \"max\" : 1.7976931348623158e308 }, } \"\"\"Binary CIF data type feature dictionary \"\"\" def __init__ ( self , storeStringsAsBytes = False , defaultStringEncoding = \"utf-8\" , verbose = False ): \"\"\"Create an instance of the binary CIF encoder class. Args: storeStringsAsBytes (bool, optional): express keys and strings as byte types otherwise follow the default encoding. Defaults to False. defaultStringEncoding (str, optional): default encoding for string types. Defaults to \"utf-8\". verbose(bool, optional): provide tracking of type conversion issues. Defaults to False. \"\"\" self . __storeStringsAsBytes = storeStringsAsBytes self . __defaultStringEncoding = defaultStringEncoding self . __verbose = verbose # self . __encodersMethodD = { \"StringArray\" : self . stringArrayDecoder , \"ByteArray\" : self . byteArrayDecoder , \"IntegerPacking\" : self . integerPackingDecoder , \"Delta\" : self . deltaDecoder , \"RunLength\" : self . runLengthDecoder , \"FixedPoint\" : self . fixedPointDecoder , \"IntervalQuantization\" : self . intervalQuantizationDecoder , } def decode ( self , colDataList , encodingDictList ): \"\"\"Return the decoded input data column using the input list of encodings Args: colDataList (list): column of data to be decoded encodingDictList (list): list of dictionary holding binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of column data \"\"\" for encoding in reversed ( encodingDictList ): encType = self . __fromBytes ( encoding [ self . __toBytes ( \"kind\" )]) colDataList = self . __encodersMethodD [ encType ]( colDataList , encoding ) return colDataList def stringArrayDecoder ( self , colDataList , encodingDict ): \"\"\"Decode an array of strings stored as a concatenation of all unique strings, a list of offsets to construct the unique substrings, and indices into the offset array. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of string data \"\"\" offsetList = list ( self . decode ( encodingDict [ self . __toBytes ( \"offsets\" )], encodingDict [ self . __toBytes ( \"offsetEncoding\" )])) lookupIndexIt = self . decode ( colDataList , encodingDict [ self . __toBytes ( \"dataEncoding\" )]) stringData = self . __fromBytes ( encodingDict [ self . __toBytes ( \"stringData\" )]) uniqueStringList = [] for iBegin , iEnd in zip ( offsetList , offsetList [ 1 :]): uniqueStringList . append ( stringData [ iBegin : iEnd ]) logger . debug ( \"iBegin %d iEnd %d %r \" , iBegin , iEnd , stringData [ iBegin : iEnd ]) for ii in lookupIndexIt : yield uniqueStringList [ ii ] if ii >= 0 else None def byteArrayDecoder ( self , colDataList , encodingDict ): \"\"\"Decode input byte list into a list of integers/floats Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer/float data \"\"\" structKey = self . bCifCodeTypeD [ encodingDict [ self . __toBytes ( \"type\" )]] structFormatCode = self . bCifTypeD [ structKey ][ \"struct_format_code\" ] count = len ( colDataList ) // struct . calcsize ( structFormatCode ) # struct.unpack() format string for little-endian = < format_string code * counts return struct . unpack ( \"<\" + structFormatCode * count , colDataList ) def __unsignedDecode ( self , colDataList , encodingDict ): upperLimit = self . bCifTypeD [ \"unsigned_integer_8\" ][ \"max\" ] if encodingDict [ self . __toBytes ( \"byteCount\" )] == 1 else self . bCifTypeD [ \"unsigned_integer_16\" ][ \"max\" ] ii = 0 while ii < len ( colDataList ): value = 0 tVal = colDataList [ ii ] while tVal == upperLimit : value += tVal ii += 1 tVal = colDataList [ ii ] yield value + tVal ii += 1 def __signedDecode ( self , colDataList , encodingDict ): upperLimit = self . bCifTypeD [ \"integer_8\" ][ \"max\" ] if encodingDict [ self . __toBytes ( \"byteCount\" )] == 1 else self . bCifTypeD [ \"integer_16\" ][ \"max\" ] lowerLimit = self . bCifTypeD [ \"integer_8\" ][ \"min\" ] if encodingDict [ self . __toBytes ( \"byteCount\" )] == 1 else self . bCifTypeD [ \"integer_16\" ][ \"min\" ] ii = 0 while ii < len ( colDataList ): value = 0 tVal = colDataList [ ii ] while tVal == upperLimit or tVal == lowerLimit : value += tVal ii += 1 tVal = colDataList [ ii ] yield value + tVal ii += 1 def integerPackingDecoder ( self , colDataList , encodingDict ): \"\"\"Decode a (32-bit) integer list packed into 8- or 16-bit values. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer data \"\"\" if encodingDict [ self . __toBytes ( \"isUnsigned\" )]: return self . __unsignedDecode ( colDataList , encodingDict ) else : return self . __signedDecode ( colDataList , encodingDict ) def deltaDecoder ( self , colDataList , encodingDict ): \"\"\"Decode an integer list stored as a list of consecutive differences. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer data \"\"\" val = encodingDict [ self . __toBytes ( \"origin\" )] for diff in colDataList : val += diff yield val def runLengthDecoder ( self , colDataList , encodingDict ): \"\"\"Decode an integer list stored as pairs of (value, number of repeats). Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer data \"\"\" _ = encodingDict colDataList = list ( colDataList ) for ii in range ( 0 , len ( colDataList ), 2 ): for _ in range ( colDataList [ ii + 1 ]): yield colDataList [ ii ] def fixedPointDecoder ( self , colDataList , encodingDict ): \"\"\"Decode a floating point list stored as integers and a multiplicative factor. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of float data \"\"\" factor = float ( encodingDict [ self . __toBytes ( \"factor\" )]) for val in colDataList : yield float ( val ) / factor def intervalQuantizationDecoder ( self , colDataList , encodingDict ): \"\"\"Decode a list of 32-bit integers quantized within a given interval into a list of floats. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of float data \"\"\" delta = float ( encodingDict [ self . __toBytes ( \"max\" )] - encodingDict [ self . __toBytes ( \"min\" )]) / float ( encodingDict [ self . __toBytes ( \"numSteps\" )] - 1.0 ) minVal = encodingDict [ self . __toBytes ( \"min\" )] for val in colDataList : yield minVal + delta * val def __toBytes ( self , strVal ): \"\"\"Optional conversion of the input string to bytes according to the class setting (storeStringsAsBytes). Args: strVal (string): input string Returns: string or bytes: optionally converted string. \"\"\" try : return strVal . encode ( self . __defaultStringEncoding ) if self . __storeStringsAsBytes else strVal except ( UnicodeDecodeError , AttributeError ): if self . __verbose : logger . exception ( \"Bad type for %r \" , strVal ) return strVal def __fromBytes ( self , byteVal ): \"\"\"Optional conversion of the input value according to the class setting (storeStringsAsBytes). Args: byteVal (string): input byte object Returns: string: optionally converted input value \"\"\" try : return byteVal . decode ( self . __defaultStringEncoding ) if self . __storeStringsAsBytes else byteVal except ( UnicodeDecodeError , AttributeError ): if self . __verbose : logger . exception ( \"Bad type for %r \" , byteVal ) return byteVal","title":"BinaryCifDecoders"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders-attributes","text":"","title":"Attributes"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders.bCifCodeTypeD","text":"Binary CIF protocol internal data type codes to integer and float types","title":"bCifCodeTypeD"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders.bCifTypeD","text":"Binary CIF data type feature dictionary","title":"bCifTypeD"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders-methods","text":"","title":"Methods"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders.__init__","text":"Create an instance of the binary CIF encoder class. Parameters: Name Type Description Default storeStringsAsBytes bool express keys and strings as byte types otherwise follow the default encoding. Defaults to False. False defaultStringEncoding str default encoding for string types. Defaults to \"utf-8\". 'utf-8' verbose(bool, optional provide tracking of type conversion issues. Defaults to False. required Source code in mmcif/io/BinaryCifReader.py def __init__ ( self , storeStringsAsBytes = False , defaultStringEncoding = \"utf-8\" , verbose = False ): \"\"\"Create an instance of the binary CIF encoder class. Args: storeStringsAsBytes (bool, optional): express keys and strings as byte types otherwise follow the default encoding. Defaults to False. defaultStringEncoding (str, optional): default encoding for string types. Defaults to \"utf-8\". verbose(bool, optional): provide tracking of type conversion issues. Defaults to False. \"\"\" self . __storeStringsAsBytes = storeStringsAsBytes self . __defaultStringEncoding = defaultStringEncoding self . __verbose = verbose # self . __encodersMethodD = { \"StringArray\" : self . stringArrayDecoder , \"ByteArray\" : self . byteArrayDecoder , \"IntegerPacking\" : self . integerPackingDecoder , \"Delta\" : self . deltaDecoder , \"RunLength\" : self . runLengthDecoder , \"FixedPoint\" : self . fixedPointDecoder , \"IntervalQuantization\" : self . intervalQuantizationDecoder , }","title":"__init__()"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders.byteArrayDecoder","text":"Decode input byte list into a list of integers/floats Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of integer/float data Source code in mmcif/io/BinaryCifReader.py def byteArrayDecoder ( self , colDataList , encodingDict ): \"\"\"Decode input byte list into a list of integers/floats Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer/float data \"\"\" structKey = self . bCifCodeTypeD [ encodingDict [ self . __toBytes ( \"type\" )]] structFormatCode = self . bCifTypeD [ structKey ][ \"struct_format_code\" ] count = len ( colDataList ) // struct . calcsize ( structFormatCode ) # struct.unpack() format string for little-endian = < format_string code * counts return struct . unpack ( \"<\" + structFormatCode * count , colDataList )","title":"byteArrayDecoder()"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders.decode","text":"Return the decoded input data column using the input list of encodings Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDictList list list of dictionary holding binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of column data Source code in mmcif/io/BinaryCifReader.py def decode ( self , colDataList , encodingDictList ): \"\"\"Return the decoded input data column using the input list of encodings Args: colDataList (list): column of data to be decoded encodingDictList (list): list of dictionary holding binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of column data \"\"\" for encoding in reversed ( encodingDictList ): encType = self . __fromBytes ( encoding [ self . __toBytes ( \"kind\" )]) colDataList = self . __encodersMethodD [ encType ]( colDataList , encoding ) return colDataList","title":"decode()"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders.deltaDecoder","text":"Decode an integer list stored as a list of consecutive differences. Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of integer data Source code in mmcif/io/BinaryCifReader.py def deltaDecoder ( self , colDataList , encodingDict ): \"\"\"Decode an integer list stored as a list of consecutive differences. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer data \"\"\" val = encodingDict [ self . __toBytes ( \"origin\" )] for diff in colDataList : val += diff yield val","title":"deltaDecoder()"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders.fixedPointDecoder","text":"Decode a floating point list stored as integers and a multiplicative factor. Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of float data Source code in mmcif/io/BinaryCifReader.py def fixedPointDecoder ( self , colDataList , encodingDict ): \"\"\"Decode a floating point list stored as integers and a multiplicative factor. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of float data \"\"\" factor = float ( encodingDict [ self . __toBytes ( \"factor\" )]) for val in colDataList : yield float ( val ) / factor","title":"fixedPointDecoder()"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders.integerPackingDecoder","text":"Decode a (32-bit) integer list packed into 8- or 16-bit values. Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of integer data Source code in mmcif/io/BinaryCifReader.py def integerPackingDecoder ( self , colDataList , encodingDict ): \"\"\"Decode a (32-bit) integer list packed into 8- or 16-bit values. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer data \"\"\" if encodingDict [ self . __toBytes ( \"isUnsigned\" )]: return self . __unsignedDecode ( colDataList , encodingDict ) else : return self . __signedDecode ( colDataList , encodingDict )","title":"integerPackingDecoder()"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders.intervalQuantizationDecoder","text":"Decode a list of 32-bit integers quantized within a given interval into a list of floats. Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of float data Source code in mmcif/io/BinaryCifReader.py def intervalQuantizationDecoder ( self , colDataList , encodingDict ): \"\"\"Decode a list of 32-bit integers quantized within a given interval into a list of floats. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of float data \"\"\" delta = float ( encodingDict [ self . __toBytes ( \"max\" )] - encodingDict [ self . __toBytes ( \"min\" )]) / float ( encodingDict [ self . __toBytes ( \"numSteps\" )] - 1.0 ) minVal = encodingDict [ self . __toBytes ( \"min\" )] for val in colDataList : yield minVal + delta * val","title":"intervalQuantizationDecoder()"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders.runLengthDecoder","text":"Decode an integer list stored as pairs of (value, number of repeats). Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of integer data Source code in mmcif/io/BinaryCifReader.py def runLengthDecoder ( self , colDataList , encodingDict ): \"\"\"Decode an integer list stored as pairs of (value, number of repeats). Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of integer data \"\"\" _ = encodingDict colDataList = list ( colDataList ) for ii in range ( 0 , len ( colDataList ), 2 ): for _ in range ( colDataList [ ii + 1 ]): yield colDataList [ ii ]","title":"runLengthDecoder()"},{"location":"api_reference/BinaryCifReader/#mmcif.io.BinaryCifReader.BinaryCifDecoders.stringArrayDecoder","text":"Decode an array of strings stored as a concatenation of all unique strings, a list of offsets to construct the unique substrings, and indices into the offset array. Parameters: Name Type Description Default colDataList list column of data to be decoded required encodingDict dict dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md required Yields: Type Description list decoded list of string data Source code in mmcif/io/BinaryCifReader.py def stringArrayDecoder ( self , colDataList , encodingDict ): \"\"\"Decode an array of strings stored as a concatenation of all unique strings, a list of offsets to construct the unique substrings, and indices into the offset array. Args: colDataList (list): column of data to be decoded encodingDict (dict): dictionary of binary CIF encoding details elements described in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md Yields: list: decoded list of string data \"\"\" offsetList = list ( self . decode ( encodingDict [ self . __toBytes ( \"offsets\" )], encodingDict [ self . __toBytes ( \"offsetEncoding\" )])) lookupIndexIt = self . decode ( colDataList , encodingDict [ self . __toBytes ( \"dataEncoding\" )]) stringData = self . __fromBytes ( encodingDict [ self . __toBytes ( \"stringData\" )]) uniqueStringList = [] for iBegin , iEnd in zip ( offsetList , offsetList [ 1 :]): uniqueStringList . append ( stringData [ iBegin : iEnd ]) logger . debug ( \"iBegin %d iEnd %d %r \" , iBegin , iEnd , stringData [ iBegin : iEnd ]) for ii in lookupIndexIt : yield uniqueStringList [ ii ] if ii >= 0 else None","title":"stringArrayDecoder()"},{"location":"api_reference/BinaryCifWriter/","text":"mmcif.io.BinaryCifWriter.BinaryCifWriter Writer methods for the binary CIF format. Source code in mmcif/io/BinaryCifWriter.py class BinaryCifWriter ( object ): \"\"\"Writer methods for the binary CIF format.\"\"\" def __init__ ( self , dictionaryApi , storeStringsAsBytes = False , defaultStringEncoding = \"utf-8\" , applyTypes = True , useStringTypes = False , useFloat64 = False ): \"\"\"Create an instance of the binary CIF writer class. Args: dictionaryApi (object): DictionaryApi object instance storeStringsAsBytes (bool, optional): strings are stored as lists of bytes. Defaults to False. defaultStringEncoding (str, optional): default encoding for string data. Defaults to \"utf-8\". applyTypes (bool, optional): apply explicit data typing before encoding. Defaults to True. useStringTypes (bool, optional): assume all types are string. Defaults to False. useFloat64 (bool, optional): store floats with 64 bit precision. Defaults to False. \"\"\" self . __version = \"0.01\" self . __storeStringsAsBytes = storeStringsAsBytes self . __defaultStringEncoding = defaultStringEncoding self . __applyTypes = applyTypes self . __useStringTypes = useStringTypes self . __useFloat64 = useFloat64 self . __dApi = dictionaryApi def serialize ( self , filePath , containerList ): \"\"\"Serialize the input container list in binary CIF and store these data in the input file path. Args: filePath (str): output file path containerList (list): list of DataContainer objects \"\"\" try : blocks = [] for container in containerList : name = container . getName () block = { self . __toBytes ( \"header\" ): self . __toBytes ( name ), self . __toBytes ( \"categories\" ): []} categories = block [ self . __toBytes ( \"categories\" )] blocks . append ( block ) for catName in container . getObjNameList (): cObj = container . getObj ( catName ) if self . __applyTypes : cObj = DataCategoryTyped ( cObj , dictionaryApi = self . __dApi , copyInputData = False ) # rowCount = cObj . getRowCount () # cols = [] for ii , atName in enumerate ( cObj . getAttributeList ()): colDataList = cObj . getColumn ( ii ) dataType = self . __getAttributeType ( cObj , atName ) if not self . __useStringTypes else \"string\" logger . debug ( \"catName %r atName %r dataType %r \" , catName , atName , dataType ) colMaskDict , encodedColDataList , encodingDictL = self . __encodeColumnData ( colDataList , dataType ) cols . append ( { self . __toBytes ( \"name\" ): self . __toBytes ( atName ), self . __toBytes ( \"mask\" ): colMaskDict , self . __toBytes ( \"data\" ): { self . __toBytes ( \"data\" ): encodedColDataList , self . __toBytes ( \"encoding\" ): encodingDictL }, } ) categories . append ({ self . __toBytes ( \"name\" ): self . __toBytes ( \"_\" + catName ), self . __toBytes ( \"columns\" ): cols , self . __toBytes ( \"rowCount\" ): rowCount }) # data = { self . __toBytes ( \"version\" ): self . __toBytes ( self . __version ), self . __toBytes ( \"encoder\" ): self . __toBytes ( \"python-mmcif library\" ), self . __toBytes ( \"dataBlocks\" ): blocks , } with open ( filePath , \"wb\" ) as ofh : msgpack . pack ( data , ofh ) return True except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return False def __encodeColumnData ( self , colDataList , dataType ): colMaskDict = {} enc = BinaryCifEncoders ( defaultStringEncoding = self . __defaultStringEncoding , storeStringsAsBytes = self . __storeStringsAsBytes , useFloat64 = self . __useFloat64 ) # maskEncoderList = [ \"Delta\" , \"RunLength\" , \"ByteArray\" ] typeEncoderD = { \"string\" : \"StringArrayMasked\" , \"integer\" : \"IntArrayMasked\" , \"float\" : \"FloatArrayMasked\" } colMaskList = enc . getMask ( colDataList ) dataEncType = typeEncoderD [ dataType ] colDataEncoded , colDataEncodingDictL = enc . encodeWithMask ( colDataList , colMaskList , dataEncType ) if colMaskList : maskEncoded , maskEncodingDictL = enc . encode ( colMaskList , maskEncoderList , \"integer\" ) colMaskDict = { self . __toBytes ( \"data\" ): maskEncoded , self . __toBytes ( \"encoding\" ): maskEncodingDictL } return colMaskDict , colDataEncoded , colDataEncodingDictL def __toBytes ( self , strVal ): \"\"\"Optional conversion of the input string to bytes according to the class setting (storeStringsAsBytes). Args: strVal (string): input string Returns: string or bytes: optionally converted string. \"\"\" try : return strVal . encode ( self . __defaultStringEncoding ) if self . __storeStringsAsBytes else strVal except ( UnicodeDecodeError , AttributeError ): logger . exception ( \"Bad type for %r \" , strVal ) return strVal def __getAttributeType ( self , dObj , atName ): \"\"\"Get attribute data type (string, integer, or float) and optionality Args: atName (str): attribute name Returns: (string): data type (string, integer or float) \"\"\" cifDataType = self . __dApi . getTypeCode ( dObj . getName (), atName ) cifPrimitiveType = self . __dApi . getTypePrimitive ( dObj . getName (), atName ) dataType = \"integer\" if \"int\" in cifDataType else \"float\" if cifPrimitiveType == \"numb\" else \"string\" return dataType Methods __init__ ( self , dictionaryApi , storeStringsAsBytes = False , defaultStringEncoding = 'utf-8' , applyTypes = True , useStringTypes = False , useFloat64 = False ) special Create an instance of the binary CIF writer class. Parameters: Name Type Description Default dictionaryApi object DictionaryApi object instance required storeStringsAsBytes bool strings are stored as lists of bytes. Defaults to False. False defaultStringEncoding str default encoding for string data. Defaults to \"utf-8\". 'utf-8' applyTypes bool apply explicit data typing before encoding. Defaults to True. True useStringTypes bool assume all types are string. Defaults to False. False useFloat64 bool store floats with 64 bit precision. Defaults to False. False Source code in mmcif/io/BinaryCifWriter.py def __init__ ( self , dictionaryApi , storeStringsAsBytes = False , defaultStringEncoding = \"utf-8\" , applyTypes = True , useStringTypes = False , useFloat64 = False ): \"\"\"Create an instance of the binary CIF writer class. Args: dictionaryApi (object): DictionaryApi object instance storeStringsAsBytes (bool, optional): strings are stored as lists of bytes. Defaults to False. defaultStringEncoding (str, optional): default encoding for string data. Defaults to \"utf-8\". applyTypes (bool, optional): apply explicit data typing before encoding. Defaults to True. useStringTypes (bool, optional): assume all types are string. Defaults to False. useFloat64 (bool, optional): store floats with 64 bit precision. Defaults to False. \"\"\" self . __version = \"0.01\" self . __storeStringsAsBytes = storeStringsAsBytes self . __defaultStringEncoding = defaultStringEncoding self . __applyTypes = applyTypes self . __useStringTypes = useStringTypes self . __useFloat64 = useFloat64 self . __dApi = dictionaryApi serialize ( self , filePath , containerList ) Serialize the input container list in binary CIF and store these data in the input file path. Parameters: Name Type Description Default filePath str output file path required containerList list list of DataContainer objects required Source code in mmcif/io/BinaryCifWriter.py def serialize ( self , filePath , containerList ): \"\"\"Serialize the input container list in binary CIF and store these data in the input file path. Args: filePath (str): output file path containerList (list): list of DataContainer objects \"\"\" try : blocks = [] for container in containerList : name = container . getName () block = { self . __toBytes ( \"header\" ): self . __toBytes ( name ), self . __toBytes ( \"categories\" ): []} categories = block [ self . __toBytes ( \"categories\" )] blocks . append ( block ) for catName in container . getObjNameList (): cObj = container . getObj ( catName ) if self . __applyTypes : cObj = DataCategoryTyped ( cObj , dictionaryApi = self . __dApi , copyInputData = False ) # rowCount = cObj . getRowCount () # cols = [] for ii , atName in enumerate ( cObj . getAttributeList ()): colDataList = cObj . getColumn ( ii ) dataType = self . __getAttributeType ( cObj , atName ) if not self . __useStringTypes else \"string\" logger . debug ( \"catName %r atName %r dataType %r \" , catName , atName , dataType ) colMaskDict , encodedColDataList , encodingDictL = self . __encodeColumnData ( colDataList , dataType ) cols . append ( { self . __toBytes ( \"name\" ): self . __toBytes ( atName ), self . __toBytes ( \"mask\" ): colMaskDict , self . __toBytes ( \"data\" ): { self . __toBytes ( \"data\" ): encodedColDataList , self . __toBytes ( \"encoding\" ): encodingDictL }, } ) categories . append ({ self . __toBytes ( \"name\" ): self . __toBytes ( \"_\" + catName ), self . __toBytes ( \"columns\" ): cols , self . __toBytes ( \"rowCount\" ): rowCount }) # data = { self . __toBytes ( \"version\" ): self . __toBytes ( self . __version ), self . __toBytes ( \"encoder\" ): self . __toBytes ( \"python-mmcif library\" ), self . __toBytes ( \"dataBlocks\" ): blocks , } with open ( filePath , \"wb\" ) as ofh : msgpack . pack ( data , ofh ) return True except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return False mmcif.io.BinaryCifWriter.BinaryCifEncoders Column oriented Binary CIF encoders implementing StringArray, ByteArray, IntegerPacking, Delta, RunLength, and FixedPoint encoders from the BinaryCIF specification described in: Sehnal D, Bittrich S, Velankar S, Koca J, Svobodova R, Burley SK, Rose AS. BinaryCIF and CIFTools-Lightweight, efficient and extensible macromolecular data management. PLoS Comput Biol. 2020 Oct 19;16(10):e1008247. doi: 10.1371/journal.pcbi.1008247. PMID: 33075050; PMCID: PMC7595629. and in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md and from the I/HM Python implementation at https://github.com/ihmwg/python-ihm Source code in mmcif/io/BinaryCifWriter.py class BinaryCifEncoders ( object ): \"\"\"Column oriented Binary CIF encoders implementing StringArray, ByteArray, IntegerPacking, Delta, RunLength, and FixedPoint encoders from the BinaryCIF specification described in: Sehnal D, Bittrich S, Velankar S, Koca J, Svobodova R, Burley SK, Rose AS. BinaryCIF and CIFTools-Lightweight, efficient and extensible macromolecular data management. PLoS Comput Biol. 2020 Oct 19;16(10):e1008247. doi: 10.1371/journal.pcbi.1008247. PMID: 33075050; PMCID: PMC7595629. and in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md and from the I/HM Python implementation at https://github.com/ihmwg/python-ihm \"\"\" def __init__ ( self , defaultStringEncoding = \"utf-8\" , storeStringsAsBytes = True , useFloat64 = False ): \"\"\"Instantiate the binary CIF encoder class. Args: defaultStringEncoding (str, optional): default encoding for string data . Defaults to \"utf-8\". storeStringsAsBytes (bool, optional): strings are stored as bytes. Defaults to True. useFloat64 (bool, optional): store floats in 64 bit precision. Defaults to True. \"\"\" self . __unknown = [ \".\" , \"?\" ] self . __defaultStringEncoding = defaultStringEncoding self . __storeStringsAsBytes = storeStringsAsBytes self . __useFloat64 = useFloat64 self . __bCifTypeCodeD = { v : k for k , v in BinaryCifDecoders . bCifCodeTypeD . items ()} def encode ( self , colDataList , encodingTypeList , dataType ): \"\"\"Encode the data using the input list of encoding types returning encoded data and encoding instructions. Args: colDataList (list): input data to be encoded encodingTypeList (list): list of encoding types (ByteArray, Delta, or RunLength) dataType (string): column input data type (string, integer, float) Returns: (list, list ): encoded data column, list of encoding instructions \"\"\" encodingDictL = [] for encType in encodingTypeList : if encType == \"ByteArray\" : colDataList , encDict = self . byteArrayEncoder ( colDataList , dataType ) elif encType == \"Delta\" : colDataList , encDict = self . deltaEncoder ( colDataList ) elif encType == \"RunLength\" : colDataList , encDict = self . runLengthEncoder ( colDataList ) else : logger . info ( \"unsupported encoding %r \" , encType ) if encDict is not None : encodingDictL . append ( encDict ) return colDataList , encodingDictL def encodeWithMask ( self , colDataList , colMaskList , encodingType ): \"\"\"Encode the data using the input mask and encoding type returning encoded data and encoding instructions. Args: colDataList (string): input data column colMaskList (list): incompleteness mask for the input data column encodingType (string): encoding type to apply (StringArrayMask, IntArrayMasked, FloatArrayMasked) Returns: (list, list ): encoded data column, list of encoding instructions \"\"\" encodedColDataList = [] encodingDictL = [] if encodingType == \"StringArrayMasked\" : encodedColDataList , encodingDictL = self . stringArrayMaskedEncoder ( colDataList , colMaskList ) elif encodingType == \"IntArrayMasked\" : encodedColDataList , encodingDictL = self . intArrayMaskedEncoder ( colDataList , colMaskList ) elif encodingType == \"FloatArrayMasked\" : encodedColDataList , encodingDictL = self . floatArrayMaskedEncoder ( colDataList , colMaskList ) else : logger . info ( \"unsupported masked encoding %r \" , encodingType ) return encodedColDataList , encodingDictL def __getIntegerPackingType ( self , colDataList ): \"\"\"Determine the integer packing type of the input integer data list\"\"\" try : minV = min ( colDataList ) maxV = max ( colDataList ) if minV >= 0 : # Unsigned types for typeName in [ \"unsigned_integer_8\" , \"unsigned_integer_16\" , \"unsigned_integer_32\" ]: byteArrayType = self . __bCifTypeCodeD [ typeName ] upperLimit = BinaryCifDecoders . bCifTypeD [ typeName ][ \"max\" ] if maxV <= upperLimit : return byteArrayType else : # Signed types for typeName in [ \"integer_8\" , \"integer_16\" , \"integer_32\" ]: byteArrayType = self . __bCifTypeCodeD [ typeName ] upperLimit = BinaryCifDecoders . bCifTypeD [ typeName ][ \"max\" ] lowerLimit = BinaryCifDecoders . bCifTypeD [ typeName ][ \"min\" ] if minV >= lowerLimit and maxV <= upperLimit : return byteArrayType except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) raise TypeError ( \"Cannot determine interger packing type\" ) def byteArrayEncoder ( self , colDataList , dataType ): \"\"\"Encode integer or float list in a packed byte array. Args: data (list): list of integer or float data dataType (str): data type (integer|float) Returns: bytes: byte encoded packed data \"\"\" if dataType == \"float\" : byteArrayType = self . __bCifTypeCodeD [ \"float_64\" ] if self . __useFloat64 else self . __bCifTypeCodeD [ \"float_32\" ] else : byteArrayType = self . __getIntegerPackingType ( colDataList ) encodingD = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"ByteArray\" ), self . __toBytes ( \"type\" ): byteArrayType } fmt = BinaryCifDecoders . bCifTypeD [ BinaryCifDecoders . bCifCodeTypeD [ byteArrayType ]][ \"struct_format_code\" ] # Data are encoded little-endian '<' return struct . pack ( \"<\" + fmt * len ( colDataList ), * colDataList ), encodingD def deltaEncoder ( self , colDataList , minLen = 40 ): \"\"\"Encode an integer list as a list of consecutive differences. Args: colDataList (list): list of integer data minLen (int, optional): minimum list length to apply encoder. Defaults to 40. Returns: list: delta encoded integer list \"\"\" if len ( colDataList ) <= minLen : return colDataList , None byteArrayType = self . __getIntegerPackingType ( colDataList ) encodingD = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"Delta\" ), self . __toBytes ( \"origin\" ): colDataList [ 0 ], self . __toBytes ( \"srcType\" ): byteArrayType } encodedColDataList = [ 0 ] + [ colDataList [ i ] - colDataList [ i - 1 ] for i in range ( 1 , len ( colDataList ))] return encodedColDataList , encodingD def runLengthEncoder ( self , colDataList , minLen = 40 ): \"\"\"Encode an integer array as pairs of (value, number of repeats) Args: colDataList (list): list of integer data minLen (int, optional): minimum list length to apply encoder. Defaults to 40. Returns: list: runlength encoded integer list \"\"\" if len ( colDataList ) <= minLen : return colDataList , None byteArrayType = self . __getIntegerPackingType ( colDataList ) encodingD = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"RunLength\" ), self . __toBytes ( \"srcType\" ): byteArrayType , self . __toBytes ( \"srcSize\" ): len ( colDataList )} encodedColDataList = [] val = None repeat = 1 for colVal in colDataList : if colVal != val : if val is not None : encodedColDataList . extend (( val , repeat )) val = colVal repeat = 1 else : repeat += 1 encodedColDataList . extend (( val , repeat )) # Check for any gains and possibly retreat if len ( encodedColDataList ) > len ( colDataList ): return colDataList , None else : return encodedColDataList , encodingD def stringArrayMaskedEncoder ( self , colDataList , colMaskList ): \"\"\"Encode the input data column (string) along with the incompleteness mask. Args: colDataList (list): input data column (string) colMaskList (list): incompleteness mask Returns: (list, list): encoded data column, list of encoding instructions \"\"\" integerEncoderList = [ \"Delta\" , \"RunLength\" , \"ByteArray\" ] uniqStringIndex = {} # keys are substrings, values indices uniqStringList = [] indexList = [] for i , strVal in enumerate ( colDataList ): if colMaskList is not None and colMaskList [ i ]: indexList . append ( - 1 ) else : tS = strVal tS = str ( tS ) if tS not in uniqStringIndex : uniqStringIndex [ tS ] = len ( uniqStringIndex ) uniqStringList . append ( tS ) indexList . append ( uniqStringIndex [ tS ]) offsetList = [ 0 ] runningLen = 0 for tS in uniqStringList : runningLen += len ( tS ) offsetList . append ( runningLen ) encodedOffsetList , offsetEncodingDictL = self . encode ( offsetList , integerEncoderList , \"integer\" ) encodedIndexList , indexEncodingDictL = self . encode ( indexList , integerEncoderList , \"integer\" ) encodingDict = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"StringArray\" ), self . __toBytes ( \"dataEncoding\" ): indexEncodingDictL , self . __toBytes ( \"stringData\" ): self . __toBytes ( \"\" . join ( uniqStringList )), self . __toBytes ( \"offsetEncoding\" ): offsetEncodingDictL , self . __toBytes ( \"offsets\" ): encodedOffsetList , } return encodedIndexList , [ encodingDict ] def intArrayMaskedEncoder ( self , colDataList , colMaskList ): \"\"\"Encode the input data column (integer) along with the incompleteness mask. Args: colDataList (list): input data column (string) colMaskList (list): incompleteness mask Returns: (list, list): encoded data column, list of encoding instructions \"\"\" integerEncoderList = [ \"Delta\" , \"RunLength\" , \"ByteArray\" ] if colMaskList : maskedColDataList = [ - 1 if m else d for m , d in zip ( colMaskList , colDataList )] else : maskedColDataList = colDataList encodedColDataList , encodingDictL = self . encode ( maskedColDataList , integerEncoderList , \"integer\" ) return encodedColDataList , encodingDictL def floatArrayMaskedEncoder ( self , colDataList , colMaskList ): \"\"\"Encode the input data column (float) along with the incompleteness mask. Args: colDataList (list): input data column (string) colMaskList (list): incompleteness mask Returns: (list, list): encoded data column, list of encoding instructions \"\"\" floatEncoderList = [ \"ByteArray\" ] if colMaskList : maskedColDataList = [ 0.0 if m else d for m , d in zip ( colMaskList , colDataList )] else : maskedColDataList = colDataList encodedColDataList , encodingDictL = self . encode ( maskedColDataList , floatEncoderList , \"float\" ) return encodedColDataList , encodingDictL def getMask ( self , colDataList ): \"\"\"Create an incompleteness mask list identifying missing/omitted values in the input data column. The mask is assigned: 0 = Value is present, 1 = '.' (value not specified), and 2 = '?' (value unknown). Args: colDataList (list): input data column Returns: list or None: mask list or None if the column contains no missing values \"\"\" mask = None for ii , colVal in enumerate ( colDataList ): if colVal is not None and colVal not in self . __unknown : continue if not mask : mask = [ 0 ] * len ( colDataList ) mask [ ii ] = 2 if colVal is None or colVal == \"?\" else 1 return mask def __toBytes ( self , strVal ): \"\"\"Optional conversion of the input string to bytes according to the class setting (storeStringsAsBytes). Args: strVal (string): input string Returns: string or bytes: optionally converted string. \"\"\" try : return strVal . encode ( self . __defaultStringEncoding ) if self . __storeStringsAsBytes else strVal except ( UnicodeDecodeError , AttributeError ): logger . exception ( \"Bad type for %r \" , strVal ) return strVal Methods __init__ ( self , defaultStringEncoding = 'utf-8' , storeStringsAsBytes = True , useFloat64 = False ) special Instantiate the binary CIF encoder class. Parameters: Name Type Description Default defaultStringEncoding str default encoding for string data . Defaults to \"utf-8\". 'utf-8' storeStringsAsBytes bool strings are stored as bytes. Defaults to True. True useFloat64 bool store floats in 64 bit precision. Defaults to True. False Source code in mmcif/io/BinaryCifWriter.py def __init__ ( self , defaultStringEncoding = \"utf-8\" , storeStringsAsBytes = True , useFloat64 = False ): \"\"\"Instantiate the binary CIF encoder class. Args: defaultStringEncoding (str, optional): default encoding for string data . Defaults to \"utf-8\". storeStringsAsBytes (bool, optional): strings are stored as bytes. Defaults to True. useFloat64 (bool, optional): store floats in 64 bit precision. Defaults to True. \"\"\" self . __unknown = [ \".\" , \"?\" ] self . __defaultStringEncoding = defaultStringEncoding self . __storeStringsAsBytes = storeStringsAsBytes self . __useFloat64 = useFloat64 self . __bCifTypeCodeD = { v : k for k , v in BinaryCifDecoders . bCifCodeTypeD . items ()} byteArrayEncoder ( self , colDataList , dataType ) Encode integer or float list in a packed byte array. Parameters: Name Type Description Default data list list of integer or float data required dataType str data type (integer|float) required Returns: Type Description bytes byte encoded packed data Source code in mmcif/io/BinaryCifWriter.py def byteArrayEncoder ( self , colDataList , dataType ): \"\"\"Encode integer or float list in a packed byte array. Args: data (list): list of integer or float data dataType (str): data type (integer|float) Returns: bytes: byte encoded packed data \"\"\" if dataType == \"float\" : byteArrayType = self . __bCifTypeCodeD [ \"float_64\" ] if self . __useFloat64 else self . __bCifTypeCodeD [ \"float_32\" ] else : byteArrayType = self . __getIntegerPackingType ( colDataList ) encodingD = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"ByteArray\" ), self . __toBytes ( \"type\" ): byteArrayType } fmt = BinaryCifDecoders . bCifTypeD [ BinaryCifDecoders . bCifCodeTypeD [ byteArrayType ]][ \"struct_format_code\" ] # Data are encoded little-endian '<' return struct . pack ( \"<\" + fmt * len ( colDataList ), * colDataList ), encodingD deltaEncoder ( self , colDataList , minLen = 40 ) Encode an integer list as a list of consecutive differences. Parameters: Name Type Description Default colDataList list list of integer data required minLen int minimum list length to apply encoder. Defaults to 40. 40 Returns: Type Description list delta encoded integer list Source code in mmcif/io/BinaryCifWriter.py def deltaEncoder ( self , colDataList , minLen = 40 ): \"\"\"Encode an integer list as a list of consecutive differences. Args: colDataList (list): list of integer data minLen (int, optional): minimum list length to apply encoder. Defaults to 40. Returns: list: delta encoded integer list \"\"\" if len ( colDataList ) <= minLen : return colDataList , None byteArrayType = self . __getIntegerPackingType ( colDataList ) encodingD = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"Delta\" ), self . __toBytes ( \"origin\" ): colDataList [ 0 ], self . __toBytes ( \"srcType\" ): byteArrayType } encodedColDataList = [ 0 ] + [ colDataList [ i ] - colDataList [ i - 1 ] for i in range ( 1 , len ( colDataList ))] return encodedColDataList , encodingD encode ( self , colDataList , encodingTypeList , dataType ) Encode the data using the input list of encoding types returning encoded data and encoding instructions. Parameters: Name Type Description Default colDataList list input data to be encoded required encodingTypeList list list of encoding types (ByteArray, Delta, or RunLength) required dataType string column input data type (string, integer, float) required Returns: Type Description (list, list ) encoded data column, list of encoding instructions Source code in mmcif/io/BinaryCifWriter.py def encode ( self , colDataList , encodingTypeList , dataType ): \"\"\"Encode the data using the input list of encoding types returning encoded data and encoding instructions. Args: colDataList (list): input data to be encoded encodingTypeList (list): list of encoding types (ByteArray, Delta, or RunLength) dataType (string): column input data type (string, integer, float) Returns: (list, list ): encoded data column, list of encoding instructions \"\"\" encodingDictL = [] for encType in encodingTypeList : if encType == \"ByteArray\" : colDataList , encDict = self . byteArrayEncoder ( colDataList , dataType ) elif encType == \"Delta\" : colDataList , encDict = self . deltaEncoder ( colDataList ) elif encType == \"RunLength\" : colDataList , encDict = self . runLengthEncoder ( colDataList ) else : logger . info ( \"unsupported encoding %r \" , encType ) if encDict is not None : encodingDictL . append ( encDict ) return colDataList , encodingDictL encodeWithMask ( self , colDataList , colMaskList , encodingType ) Encode the data using the input mask and encoding type returning encoded data and encoding instructions. Parameters: Name Type Description Default colDataList string input data column required colMaskList list incompleteness mask for the input data column required encodingType string encoding type to apply (StringArrayMask, IntArrayMasked, FloatArrayMasked) required Returns: Type Description (list, list ) encoded data column, list of encoding instructions Source code in mmcif/io/BinaryCifWriter.py def encodeWithMask ( self , colDataList , colMaskList , encodingType ): \"\"\"Encode the data using the input mask and encoding type returning encoded data and encoding instructions. Args: colDataList (string): input data column colMaskList (list): incompleteness mask for the input data column encodingType (string): encoding type to apply (StringArrayMask, IntArrayMasked, FloatArrayMasked) Returns: (list, list ): encoded data column, list of encoding instructions \"\"\" encodedColDataList = [] encodingDictL = [] if encodingType == \"StringArrayMasked\" : encodedColDataList , encodingDictL = self . stringArrayMaskedEncoder ( colDataList , colMaskList ) elif encodingType == \"IntArrayMasked\" : encodedColDataList , encodingDictL = self . intArrayMaskedEncoder ( colDataList , colMaskList ) elif encodingType == \"FloatArrayMasked\" : encodedColDataList , encodingDictL = self . floatArrayMaskedEncoder ( colDataList , colMaskList ) else : logger . info ( \"unsupported masked encoding %r \" , encodingType ) return encodedColDataList , encodingDictL floatArrayMaskedEncoder ( self , colDataList , colMaskList ) Encode the input data column (float) along with the incompleteness mask. Parameters: Name Type Description Default colDataList list input data column (string) required colMaskList list incompleteness mask required Returns: Type Description (list, list) encoded data column, list of encoding instructions Source code in mmcif/io/BinaryCifWriter.py def floatArrayMaskedEncoder ( self , colDataList , colMaskList ): \"\"\"Encode the input data column (float) along with the incompleteness mask. Args: colDataList (list): input data column (string) colMaskList (list): incompleteness mask Returns: (list, list): encoded data column, list of encoding instructions \"\"\" floatEncoderList = [ \"ByteArray\" ] if colMaskList : maskedColDataList = [ 0.0 if m else d for m , d in zip ( colMaskList , colDataList )] else : maskedColDataList = colDataList encodedColDataList , encodingDictL = self . encode ( maskedColDataList , floatEncoderList , \"float\" ) return encodedColDataList , encodingDictL getMask ( self , colDataList ) Create an incompleteness mask list identifying missing/omitted values in the input data column. The mask is assigned: 0 = Value is present, 1 = '.' (value not specified), and 2 = '?' (value unknown). Parameters: Name Type Description Default colDataList list input data column required Returns: Type Description list or None mask list or None if the column contains no missing values Source code in mmcif/io/BinaryCifWriter.py def getMask ( self , colDataList ): \"\"\"Create an incompleteness mask list identifying missing/omitted values in the input data column. The mask is assigned: 0 = Value is present, 1 = '.' (value not specified), and 2 = '?' (value unknown). Args: colDataList (list): input data column Returns: list or None: mask list or None if the column contains no missing values \"\"\" mask = None for ii , colVal in enumerate ( colDataList ): if colVal is not None and colVal not in self . __unknown : continue if not mask : mask = [ 0 ] * len ( colDataList ) mask [ ii ] = 2 if colVal is None or colVal == \"?\" else 1 return mask intArrayMaskedEncoder ( self , colDataList , colMaskList ) Encode the input data column (integer) along with the incompleteness mask. Parameters: Name Type Description Default colDataList list input data column (string) required colMaskList list incompleteness mask required Returns: Type Description (list, list) encoded data column, list of encoding instructions Source code in mmcif/io/BinaryCifWriter.py def intArrayMaskedEncoder ( self , colDataList , colMaskList ): \"\"\"Encode the input data column (integer) along with the incompleteness mask. Args: colDataList (list): input data column (string) colMaskList (list): incompleteness mask Returns: (list, list): encoded data column, list of encoding instructions \"\"\" integerEncoderList = [ \"Delta\" , \"RunLength\" , \"ByteArray\" ] if colMaskList : maskedColDataList = [ - 1 if m else d for m , d in zip ( colMaskList , colDataList )] else : maskedColDataList = colDataList encodedColDataList , encodingDictL = self . encode ( maskedColDataList , integerEncoderList , \"integer\" ) return encodedColDataList , encodingDictL runLengthEncoder ( self , colDataList , minLen = 40 ) Encode an integer array as pairs of (value, number of repeats) Parameters: Name Type Description Default colDataList list list of integer data required minLen int minimum list length to apply encoder. Defaults to 40. 40 Returns: Type Description list runlength encoded integer list Source code in mmcif/io/BinaryCifWriter.py def runLengthEncoder ( self , colDataList , minLen = 40 ): \"\"\"Encode an integer array as pairs of (value, number of repeats) Args: colDataList (list): list of integer data minLen (int, optional): minimum list length to apply encoder. Defaults to 40. Returns: list: runlength encoded integer list \"\"\" if len ( colDataList ) <= minLen : return colDataList , None byteArrayType = self . __getIntegerPackingType ( colDataList ) encodingD = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"RunLength\" ), self . __toBytes ( \"srcType\" ): byteArrayType , self . __toBytes ( \"srcSize\" ): len ( colDataList )} encodedColDataList = [] val = None repeat = 1 for colVal in colDataList : if colVal != val : if val is not None : encodedColDataList . extend (( val , repeat )) val = colVal repeat = 1 else : repeat += 1 encodedColDataList . extend (( val , repeat )) # Check for any gains and possibly retreat if len ( encodedColDataList ) > len ( colDataList ): return colDataList , None else : return encodedColDataList , encodingD stringArrayMaskedEncoder ( self , colDataList , colMaskList ) Encode the input data column (string) along with the incompleteness mask. Parameters: Name Type Description Default colDataList list input data column (string) required colMaskList list incompleteness mask required Returns: Type Description (list, list) encoded data column, list of encoding instructions Source code in mmcif/io/BinaryCifWriter.py def stringArrayMaskedEncoder ( self , colDataList , colMaskList ): \"\"\"Encode the input data column (string) along with the incompleteness mask. Args: colDataList (list): input data column (string) colMaskList (list): incompleteness mask Returns: (list, list): encoded data column, list of encoding instructions \"\"\" integerEncoderList = [ \"Delta\" , \"RunLength\" , \"ByteArray\" ] uniqStringIndex = {} # keys are substrings, values indices uniqStringList = [] indexList = [] for i , strVal in enumerate ( colDataList ): if colMaskList is not None and colMaskList [ i ]: indexList . append ( - 1 ) else : tS = strVal tS = str ( tS ) if tS not in uniqStringIndex : uniqStringIndex [ tS ] = len ( uniqStringIndex ) uniqStringList . append ( tS ) indexList . append ( uniqStringIndex [ tS ]) offsetList = [ 0 ] runningLen = 0 for tS in uniqStringList : runningLen += len ( tS ) offsetList . append ( runningLen ) encodedOffsetList , offsetEncodingDictL = self . encode ( offsetList , integerEncoderList , \"integer\" ) encodedIndexList , indexEncodingDictL = self . encode ( indexList , integerEncoderList , \"integer\" ) encodingDict = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"StringArray\" ), self . __toBytes ( \"dataEncoding\" ): indexEncodingDictL , self . __toBytes ( \"stringData\" ): self . __toBytes ( \"\" . join ( uniqStringList )), self . __toBytes ( \"offsetEncoding\" ): offsetEncodingDictL , self . __toBytes ( \"offsets\" ): encodedOffsetList , } return encodedIndexList , [ encodingDict ]","title":"BinaryCifWriter"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifWriter","text":"Writer methods for the binary CIF format. Source code in mmcif/io/BinaryCifWriter.py class BinaryCifWriter ( object ): \"\"\"Writer methods for the binary CIF format.\"\"\" def __init__ ( self , dictionaryApi , storeStringsAsBytes = False , defaultStringEncoding = \"utf-8\" , applyTypes = True , useStringTypes = False , useFloat64 = False ): \"\"\"Create an instance of the binary CIF writer class. Args: dictionaryApi (object): DictionaryApi object instance storeStringsAsBytes (bool, optional): strings are stored as lists of bytes. Defaults to False. defaultStringEncoding (str, optional): default encoding for string data. Defaults to \"utf-8\". applyTypes (bool, optional): apply explicit data typing before encoding. Defaults to True. useStringTypes (bool, optional): assume all types are string. Defaults to False. useFloat64 (bool, optional): store floats with 64 bit precision. Defaults to False. \"\"\" self . __version = \"0.01\" self . __storeStringsAsBytes = storeStringsAsBytes self . __defaultStringEncoding = defaultStringEncoding self . __applyTypes = applyTypes self . __useStringTypes = useStringTypes self . __useFloat64 = useFloat64 self . __dApi = dictionaryApi def serialize ( self , filePath , containerList ): \"\"\"Serialize the input container list in binary CIF and store these data in the input file path. Args: filePath (str): output file path containerList (list): list of DataContainer objects \"\"\" try : blocks = [] for container in containerList : name = container . getName () block = { self . __toBytes ( \"header\" ): self . __toBytes ( name ), self . __toBytes ( \"categories\" ): []} categories = block [ self . __toBytes ( \"categories\" )] blocks . append ( block ) for catName in container . getObjNameList (): cObj = container . getObj ( catName ) if self . __applyTypes : cObj = DataCategoryTyped ( cObj , dictionaryApi = self . __dApi , copyInputData = False ) # rowCount = cObj . getRowCount () # cols = [] for ii , atName in enumerate ( cObj . getAttributeList ()): colDataList = cObj . getColumn ( ii ) dataType = self . __getAttributeType ( cObj , atName ) if not self . __useStringTypes else \"string\" logger . debug ( \"catName %r atName %r dataType %r \" , catName , atName , dataType ) colMaskDict , encodedColDataList , encodingDictL = self . __encodeColumnData ( colDataList , dataType ) cols . append ( { self . __toBytes ( \"name\" ): self . __toBytes ( atName ), self . __toBytes ( \"mask\" ): colMaskDict , self . __toBytes ( \"data\" ): { self . __toBytes ( \"data\" ): encodedColDataList , self . __toBytes ( \"encoding\" ): encodingDictL }, } ) categories . append ({ self . __toBytes ( \"name\" ): self . __toBytes ( \"_\" + catName ), self . __toBytes ( \"columns\" ): cols , self . __toBytes ( \"rowCount\" ): rowCount }) # data = { self . __toBytes ( \"version\" ): self . __toBytes ( self . __version ), self . __toBytes ( \"encoder\" ): self . __toBytes ( \"python-mmcif library\" ), self . __toBytes ( \"dataBlocks\" ): blocks , } with open ( filePath , \"wb\" ) as ofh : msgpack . pack ( data , ofh ) return True except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return False def __encodeColumnData ( self , colDataList , dataType ): colMaskDict = {} enc = BinaryCifEncoders ( defaultStringEncoding = self . __defaultStringEncoding , storeStringsAsBytes = self . __storeStringsAsBytes , useFloat64 = self . __useFloat64 ) # maskEncoderList = [ \"Delta\" , \"RunLength\" , \"ByteArray\" ] typeEncoderD = { \"string\" : \"StringArrayMasked\" , \"integer\" : \"IntArrayMasked\" , \"float\" : \"FloatArrayMasked\" } colMaskList = enc . getMask ( colDataList ) dataEncType = typeEncoderD [ dataType ] colDataEncoded , colDataEncodingDictL = enc . encodeWithMask ( colDataList , colMaskList , dataEncType ) if colMaskList : maskEncoded , maskEncodingDictL = enc . encode ( colMaskList , maskEncoderList , \"integer\" ) colMaskDict = { self . __toBytes ( \"data\" ): maskEncoded , self . __toBytes ( \"encoding\" ): maskEncodingDictL } return colMaskDict , colDataEncoded , colDataEncodingDictL def __toBytes ( self , strVal ): \"\"\"Optional conversion of the input string to bytes according to the class setting (storeStringsAsBytes). Args: strVal (string): input string Returns: string or bytes: optionally converted string. \"\"\" try : return strVal . encode ( self . __defaultStringEncoding ) if self . __storeStringsAsBytes else strVal except ( UnicodeDecodeError , AttributeError ): logger . exception ( \"Bad type for %r \" , strVal ) return strVal def __getAttributeType ( self , dObj , atName ): \"\"\"Get attribute data type (string, integer, or float) and optionality Args: atName (str): attribute name Returns: (string): data type (string, integer or float) \"\"\" cifDataType = self . __dApi . getTypeCode ( dObj . getName (), atName ) cifPrimitiveType = self . __dApi . getTypePrimitive ( dObj . getName (), atName ) dataType = \"integer\" if \"int\" in cifDataType else \"float\" if cifPrimitiveType == \"numb\" else \"string\" return dataType","title":"BinaryCifWriter"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifWriter-methods","text":"","title":"Methods"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifWriter.__init__","text":"Create an instance of the binary CIF writer class. Parameters: Name Type Description Default dictionaryApi object DictionaryApi object instance required storeStringsAsBytes bool strings are stored as lists of bytes. Defaults to False. False defaultStringEncoding str default encoding for string data. Defaults to \"utf-8\". 'utf-8' applyTypes bool apply explicit data typing before encoding. Defaults to True. True useStringTypes bool assume all types are string. Defaults to False. False useFloat64 bool store floats with 64 bit precision. Defaults to False. False Source code in mmcif/io/BinaryCifWriter.py def __init__ ( self , dictionaryApi , storeStringsAsBytes = False , defaultStringEncoding = \"utf-8\" , applyTypes = True , useStringTypes = False , useFloat64 = False ): \"\"\"Create an instance of the binary CIF writer class. Args: dictionaryApi (object): DictionaryApi object instance storeStringsAsBytes (bool, optional): strings are stored as lists of bytes. Defaults to False. defaultStringEncoding (str, optional): default encoding for string data. Defaults to \"utf-8\". applyTypes (bool, optional): apply explicit data typing before encoding. Defaults to True. useStringTypes (bool, optional): assume all types are string. Defaults to False. useFloat64 (bool, optional): store floats with 64 bit precision. Defaults to False. \"\"\" self . __version = \"0.01\" self . __storeStringsAsBytes = storeStringsAsBytes self . __defaultStringEncoding = defaultStringEncoding self . __applyTypes = applyTypes self . __useStringTypes = useStringTypes self . __useFloat64 = useFloat64 self . __dApi = dictionaryApi","title":"__init__()"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifWriter.serialize","text":"Serialize the input container list in binary CIF and store these data in the input file path. Parameters: Name Type Description Default filePath str output file path required containerList list list of DataContainer objects required Source code in mmcif/io/BinaryCifWriter.py def serialize ( self , filePath , containerList ): \"\"\"Serialize the input container list in binary CIF and store these data in the input file path. Args: filePath (str): output file path containerList (list): list of DataContainer objects \"\"\" try : blocks = [] for container in containerList : name = container . getName () block = { self . __toBytes ( \"header\" ): self . __toBytes ( name ), self . __toBytes ( \"categories\" ): []} categories = block [ self . __toBytes ( \"categories\" )] blocks . append ( block ) for catName in container . getObjNameList (): cObj = container . getObj ( catName ) if self . __applyTypes : cObj = DataCategoryTyped ( cObj , dictionaryApi = self . __dApi , copyInputData = False ) # rowCount = cObj . getRowCount () # cols = [] for ii , atName in enumerate ( cObj . getAttributeList ()): colDataList = cObj . getColumn ( ii ) dataType = self . __getAttributeType ( cObj , atName ) if not self . __useStringTypes else \"string\" logger . debug ( \"catName %r atName %r dataType %r \" , catName , atName , dataType ) colMaskDict , encodedColDataList , encodingDictL = self . __encodeColumnData ( colDataList , dataType ) cols . append ( { self . __toBytes ( \"name\" ): self . __toBytes ( atName ), self . __toBytes ( \"mask\" ): colMaskDict , self . __toBytes ( \"data\" ): { self . __toBytes ( \"data\" ): encodedColDataList , self . __toBytes ( \"encoding\" ): encodingDictL }, } ) categories . append ({ self . __toBytes ( \"name\" ): self . __toBytes ( \"_\" + catName ), self . __toBytes ( \"columns\" ): cols , self . __toBytes ( \"rowCount\" ): rowCount }) # data = { self . __toBytes ( \"version\" ): self . __toBytes ( self . __version ), self . __toBytes ( \"encoder\" ): self . __toBytes ( \"python-mmcif library\" ), self . __toBytes ( \"dataBlocks\" ): blocks , } with open ( filePath , \"wb\" ) as ofh : msgpack . pack ( data , ofh ) return True except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return False","title":"serialize()"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifEncoders","text":"Column oriented Binary CIF encoders implementing StringArray, ByteArray, IntegerPacking, Delta, RunLength, and FixedPoint encoders from the BinaryCIF specification described in: Sehnal D, Bittrich S, Velankar S, Koca J, Svobodova R, Burley SK, Rose AS. BinaryCIF and CIFTools-Lightweight, efficient and extensible macromolecular data management. PLoS Comput Biol. 2020 Oct 19;16(10):e1008247. doi: 10.1371/journal.pcbi.1008247. PMID: 33075050; PMCID: PMC7595629. and in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md and from the I/HM Python implementation at https://github.com/ihmwg/python-ihm Source code in mmcif/io/BinaryCifWriter.py class BinaryCifEncoders ( object ): \"\"\"Column oriented Binary CIF encoders implementing StringArray, ByteArray, IntegerPacking, Delta, RunLength, and FixedPoint encoders from the BinaryCIF specification described in: Sehnal D, Bittrich S, Velankar S, Koca J, Svobodova R, Burley SK, Rose AS. BinaryCIF and CIFTools-Lightweight, efficient and extensible macromolecular data management. PLoS Comput Biol. 2020 Oct 19;16(10):e1008247. doi: 10.1371/journal.pcbi.1008247. PMID: 33075050; PMCID: PMC7595629. and in the specification at https://github.com/molstar/BinaryCIF/blob/master/encoding.md and from the I/HM Python implementation at https://github.com/ihmwg/python-ihm \"\"\" def __init__ ( self , defaultStringEncoding = \"utf-8\" , storeStringsAsBytes = True , useFloat64 = False ): \"\"\"Instantiate the binary CIF encoder class. Args: defaultStringEncoding (str, optional): default encoding for string data . Defaults to \"utf-8\". storeStringsAsBytes (bool, optional): strings are stored as bytes. Defaults to True. useFloat64 (bool, optional): store floats in 64 bit precision. Defaults to True. \"\"\" self . __unknown = [ \".\" , \"?\" ] self . __defaultStringEncoding = defaultStringEncoding self . __storeStringsAsBytes = storeStringsAsBytes self . __useFloat64 = useFloat64 self . __bCifTypeCodeD = { v : k for k , v in BinaryCifDecoders . bCifCodeTypeD . items ()} def encode ( self , colDataList , encodingTypeList , dataType ): \"\"\"Encode the data using the input list of encoding types returning encoded data and encoding instructions. Args: colDataList (list): input data to be encoded encodingTypeList (list): list of encoding types (ByteArray, Delta, or RunLength) dataType (string): column input data type (string, integer, float) Returns: (list, list ): encoded data column, list of encoding instructions \"\"\" encodingDictL = [] for encType in encodingTypeList : if encType == \"ByteArray\" : colDataList , encDict = self . byteArrayEncoder ( colDataList , dataType ) elif encType == \"Delta\" : colDataList , encDict = self . deltaEncoder ( colDataList ) elif encType == \"RunLength\" : colDataList , encDict = self . runLengthEncoder ( colDataList ) else : logger . info ( \"unsupported encoding %r \" , encType ) if encDict is not None : encodingDictL . append ( encDict ) return colDataList , encodingDictL def encodeWithMask ( self , colDataList , colMaskList , encodingType ): \"\"\"Encode the data using the input mask and encoding type returning encoded data and encoding instructions. Args: colDataList (string): input data column colMaskList (list): incompleteness mask for the input data column encodingType (string): encoding type to apply (StringArrayMask, IntArrayMasked, FloatArrayMasked) Returns: (list, list ): encoded data column, list of encoding instructions \"\"\" encodedColDataList = [] encodingDictL = [] if encodingType == \"StringArrayMasked\" : encodedColDataList , encodingDictL = self . stringArrayMaskedEncoder ( colDataList , colMaskList ) elif encodingType == \"IntArrayMasked\" : encodedColDataList , encodingDictL = self . intArrayMaskedEncoder ( colDataList , colMaskList ) elif encodingType == \"FloatArrayMasked\" : encodedColDataList , encodingDictL = self . floatArrayMaskedEncoder ( colDataList , colMaskList ) else : logger . info ( \"unsupported masked encoding %r \" , encodingType ) return encodedColDataList , encodingDictL def __getIntegerPackingType ( self , colDataList ): \"\"\"Determine the integer packing type of the input integer data list\"\"\" try : minV = min ( colDataList ) maxV = max ( colDataList ) if minV >= 0 : # Unsigned types for typeName in [ \"unsigned_integer_8\" , \"unsigned_integer_16\" , \"unsigned_integer_32\" ]: byteArrayType = self . __bCifTypeCodeD [ typeName ] upperLimit = BinaryCifDecoders . bCifTypeD [ typeName ][ \"max\" ] if maxV <= upperLimit : return byteArrayType else : # Signed types for typeName in [ \"integer_8\" , \"integer_16\" , \"integer_32\" ]: byteArrayType = self . __bCifTypeCodeD [ typeName ] upperLimit = BinaryCifDecoders . bCifTypeD [ typeName ][ \"max\" ] lowerLimit = BinaryCifDecoders . bCifTypeD [ typeName ][ \"min\" ] if minV >= lowerLimit and maxV <= upperLimit : return byteArrayType except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) raise TypeError ( \"Cannot determine interger packing type\" ) def byteArrayEncoder ( self , colDataList , dataType ): \"\"\"Encode integer or float list in a packed byte array. Args: data (list): list of integer or float data dataType (str): data type (integer|float) Returns: bytes: byte encoded packed data \"\"\" if dataType == \"float\" : byteArrayType = self . __bCifTypeCodeD [ \"float_64\" ] if self . __useFloat64 else self . __bCifTypeCodeD [ \"float_32\" ] else : byteArrayType = self . __getIntegerPackingType ( colDataList ) encodingD = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"ByteArray\" ), self . __toBytes ( \"type\" ): byteArrayType } fmt = BinaryCifDecoders . bCifTypeD [ BinaryCifDecoders . bCifCodeTypeD [ byteArrayType ]][ \"struct_format_code\" ] # Data are encoded little-endian '<' return struct . pack ( \"<\" + fmt * len ( colDataList ), * colDataList ), encodingD def deltaEncoder ( self , colDataList , minLen = 40 ): \"\"\"Encode an integer list as a list of consecutive differences. Args: colDataList (list): list of integer data minLen (int, optional): minimum list length to apply encoder. Defaults to 40. Returns: list: delta encoded integer list \"\"\" if len ( colDataList ) <= minLen : return colDataList , None byteArrayType = self . __getIntegerPackingType ( colDataList ) encodingD = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"Delta\" ), self . __toBytes ( \"origin\" ): colDataList [ 0 ], self . __toBytes ( \"srcType\" ): byteArrayType } encodedColDataList = [ 0 ] + [ colDataList [ i ] - colDataList [ i - 1 ] for i in range ( 1 , len ( colDataList ))] return encodedColDataList , encodingD def runLengthEncoder ( self , colDataList , minLen = 40 ): \"\"\"Encode an integer array as pairs of (value, number of repeats) Args: colDataList (list): list of integer data minLen (int, optional): minimum list length to apply encoder. Defaults to 40. Returns: list: runlength encoded integer list \"\"\" if len ( colDataList ) <= minLen : return colDataList , None byteArrayType = self . __getIntegerPackingType ( colDataList ) encodingD = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"RunLength\" ), self . __toBytes ( \"srcType\" ): byteArrayType , self . __toBytes ( \"srcSize\" ): len ( colDataList )} encodedColDataList = [] val = None repeat = 1 for colVal in colDataList : if colVal != val : if val is not None : encodedColDataList . extend (( val , repeat )) val = colVal repeat = 1 else : repeat += 1 encodedColDataList . extend (( val , repeat )) # Check for any gains and possibly retreat if len ( encodedColDataList ) > len ( colDataList ): return colDataList , None else : return encodedColDataList , encodingD def stringArrayMaskedEncoder ( self , colDataList , colMaskList ): \"\"\"Encode the input data column (string) along with the incompleteness mask. Args: colDataList (list): input data column (string) colMaskList (list): incompleteness mask Returns: (list, list): encoded data column, list of encoding instructions \"\"\" integerEncoderList = [ \"Delta\" , \"RunLength\" , \"ByteArray\" ] uniqStringIndex = {} # keys are substrings, values indices uniqStringList = [] indexList = [] for i , strVal in enumerate ( colDataList ): if colMaskList is not None and colMaskList [ i ]: indexList . append ( - 1 ) else : tS = strVal tS = str ( tS ) if tS not in uniqStringIndex : uniqStringIndex [ tS ] = len ( uniqStringIndex ) uniqStringList . append ( tS ) indexList . append ( uniqStringIndex [ tS ]) offsetList = [ 0 ] runningLen = 0 for tS in uniqStringList : runningLen += len ( tS ) offsetList . append ( runningLen ) encodedOffsetList , offsetEncodingDictL = self . encode ( offsetList , integerEncoderList , \"integer\" ) encodedIndexList , indexEncodingDictL = self . encode ( indexList , integerEncoderList , \"integer\" ) encodingDict = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"StringArray\" ), self . __toBytes ( \"dataEncoding\" ): indexEncodingDictL , self . __toBytes ( \"stringData\" ): self . __toBytes ( \"\" . join ( uniqStringList )), self . __toBytes ( \"offsetEncoding\" ): offsetEncodingDictL , self . __toBytes ( \"offsets\" ): encodedOffsetList , } return encodedIndexList , [ encodingDict ] def intArrayMaskedEncoder ( self , colDataList , colMaskList ): \"\"\"Encode the input data column (integer) along with the incompleteness mask. Args: colDataList (list): input data column (string) colMaskList (list): incompleteness mask Returns: (list, list): encoded data column, list of encoding instructions \"\"\" integerEncoderList = [ \"Delta\" , \"RunLength\" , \"ByteArray\" ] if colMaskList : maskedColDataList = [ - 1 if m else d for m , d in zip ( colMaskList , colDataList )] else : maskedColDataList = colDataList encodedColDataList , encodingDictL = self . encode ( maskedColDataList , integerEncoderList , \"integer\" ) return encodedColDataList , encodingDictL def floatArrayMaskedEncoder ( self , colDataList , colMaskList ): \"\"\"Encode the input data column (float) along with the incompleteness mask. Args: colDataList (list): input data column (string) colMaskList (list): incompleteness mask Returns: (list, list): encoded data column, list of encoding instructions \"\"\" floatEncoderList = [ \"ByteArray\" ] if colMaskList : maskedColDataList = [ 0.0 if m else d for m , d in zip ( colMaskList , colDataList )] else : maskedColDataList = colDataList encodedColDataList , encodingDictL = self . encode ( maskedColDataList , floatEncoderList , \"float\" ) return encodedColDataList , encodingDictL def getMask ( self , colDataList ): \"\"\"Create an incompleteness mask list identifying missing/omitted values in the input data column. The mask is assigned: 0 = Value is present, 1 = '.' (value not specified), and 2 = '?' (value unknown). Args: colDataList (list): input data column Returns: list or None: mask list or None if the column contains no missing values \"\"\" mask = None for ii , colVal in enumerate ( colDataList ): if colVal is not None and colVal not in self . __unknown : continue if not mask : mask = [ 0 ] * len ( colDataList ) mask [ ii ] = 2 if colVal is None or colVal == \"?\" else 1 return mask def __toBytes ( self , strVal ): \"\"\"Optional conversion of the input string to bytes according to the class setting (storeStringsAsBytes). Args: strVal (string): input string Returns: string or bytes: optionally converted string. \"\"\" try : return strVal . encode ( self . __defaultStringEncoding ) if self . __storeStringsAsBytes else strVal except ( UnicodeDecodeError , AttributeError ): logger . exception ( \"Bad type for %r \" , strVal ) return strVal","title":"BinaryCifEncoders"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifEncoders-methods","text":"","title":"Methods"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifEncoders.__init__","text":"Instantiate the binary CIF encoder class. Parameters: Name Type Description Default defaultStringEncoding str default encoding for string data . Defaults to \"utf-8\". 'utf-8' storeStringsAsBytes bool strings are stored as bytes. Defaults to True. True useFloat64 bool store floats in 64 bit precision. Defaults to True. False Source code in mmcif/io/BinaryCifWriter.py def __init__ ( self , defaultStringEncoding = \"utf-8\" , storeStringsAsBytes = True , useFloat64 = False ): \"\"\"Instantiate the binary CIF encoder class. Args: defaultStringEncoding (str, optional): default encoding for string data . Defaults to \"utf-8\". storeStringsAsBytes (bool, optional): strings are stored as bytes. Defaults to True. useFloat64 (bool, optional): store floats in 64 bit precision. Defaults to True. \"\"\" self . __unknown = [ \".\" , \"?\" ] self . __defaultStringEncoding = defaultStringEncoding self . __storeStringsAsBytes = storeStringsAsBytes self . __useFloat64 = useFloat64 self . __bCifTypeCodeD = { v : k for k , v in BinaryCifDecoders . bCifCodeTypeD . items ()}","title":"__init__()"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifEncoders.byteArrayEncoder","text":"Encode integer or float list in a packed byte array. Parameters: Name Type Description Default data list list of integer or float data required dataType str data type (integer|float) required Returns: Type Description bytes byte encoded packed data Source code in mmcif/io/BinaryCifWriter.py def byteArrayEncoder ( self , colDataList , dataType ): \"\"\"Encode integer or float list in a packed byte array. Args: data (list): list of integer or float data dataType (str): data type (integer|float) Returns: bytes: byte encoded packed data \"\"\" if dataType == \"float\" : byteArrayType = self . __bCifTypeCodeD [ \"float_64\" ] if self . __useFloat64 else self . __bCifTypeCodeD [ \"float_32\" ] else : byteArrayType = self . __getIntegerPackingType ( colDataList ) encodingD = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"ByteArray\" ), self . __toBytes ( \"type\" ): byteArrayType } fmt = BinaryCifDecoders . bCifTypeD [ BinaryCifDecoders . bCifCodeTypeD [ byteArrayType ]][ \"struct_format_code\" ] # Data are encoded little-endian '<' return struct . pack ( \"<\" + fmt * len ( colDataList ), * colDataList ), encodingD","title":"byteArrayEncoder()"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifEncoders.deltaEncoder","text":"Encode an integer list as a list of consecutive differences. Parameters: Name Type Description Default colDataList list list of integer data required minLen int minimum list length to apply encoder. Defaults to 40. 40 Returns: Type Description list delta encoded integer list Source code in mmcif/io/BinaryCifWriter.py def deltaEncoder ( self , colDataList , minLen = 40 ): \"\"\"Encode an integer list as a list of consecutive differences. Args: colDataList (list): list of integer data minLen (int, optional): minimum list length to apply encoder. Defaults to 40. Returns: list: delta encoded integer list \"\"\" if len ( colDataList ) <= minLen : return colDataList , None byteArrayType = self . __getIntegerPackingType ( colDataList ) encodingD = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"Delta\" ), self . __toBytes ( \"origin\" ): colDataList [ 0 ], self . __toBytes ( \"srcType\" ): byteArrayType } encodedColDataList = [ 0 ] + [ colDataList [ i ] - colDataList [ i - 1 ] for i in range ( 1 , len ( colDataList ))] return encodedColDataList , encodingD","title":"deltaEncoder()"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifEncoders.encode","text":"Encode the data using the input list of encoding types returning encoded data and encoding instructions. Parameters: Name Type Description Default colDataList list input data to be encoded required encodingTypeList list list of encoding types (ByteArray, Delta, or RunLength) required dataType string column input data type (string, integer, float) required Returns: Type Description (list, list ) encoded data column, list of encoding instructions Source code in mmcif/io/BinaryCifWriter.py def encode ( self , colDataList , encodingTypeList , dataType ): \"\"\"Encode the data using the input list of encoding types returning encoded data and encoding instructions. Args: colDataList (list): input data to be encoded encodingTypeList (list): list of encoding types (ByteArray, Delta, or RunLength) dataType (string): column input data type (string, integer, float) Returns: (list, list ): encoded data column, list of encoding instructions \"\"\" encodingDictL = [] for encType in encodingTypeList : if encType == \"ByteArray\" : colDataList , encDict = self . byteArrayEncoder ( colDataList , dataType ) elif encType == \"Delta\" : colDataList , encDict = self . deltaEncoder ( colDataList ) elif encType == \"RunLength\" : colDataList , encDict = self . runLengthEncoder ( colDataList ) else : logger . info ( \"unsupported encoding %r \" , encType ) if encDict is not None : encodingDictL . append ( encDict ) return colDataList , encodingDictL","title":"encode()"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifEncoders.encodeWithMask","text":"Encode the data using the input mask and encoding type returning encoded data and encoding instructions. Parameters: Name Type Description Default colDataList string input data column required colMaskList list incompleteness mask for the input data column required encodingType string encoding type to apply (StringArrayMask, IntArrayMasked, FloatArrayMasked) required Returns: Type Description (list, list ) encoded data column, list of encoding instructions Source code in mmcif/io/BinaryCifWriter.py def encodeWithMask ( self , colDataList , colMaskList , encodingType ): \"\"\"Encode the data using the input mask and encoding type returning encoded data and encoding instructions. Args: colDataList (string): input data column colMaskList (list): incompleteness mask for the input data column encodingType (string): encoding type to apply (StringArrayMask, IntArrayMasked, FloatArrayMasked) Returns: (list, list ): encoded data column, list of encoding instructions \"\"\" encodedColDataList = [] encodingDictL = [] if encodingType == \"StringArrayMasked\" : encodedColDataList , encodingDictL = self . stringArrayMaskedEncoder ( colDataList , colMaskList ) elif encodingType == \"IntArrayMasked\" : encodedColDataList , encodingDictL = self . intArrayMaskedEncoder ( colDataList , colMaskList ) elif encodingType == \"FloatArrayMasked\" : encodedColDataList , encodingDictL = self . floatArrayMaskedEncoder ( colDataList , colMaskList ) else : logger . info ( \"unsupported masked encoding %r \" , encodingType ) return encodedColDataList , encodingDictL","title":"encodeWithMask()"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifEncoders.floatArrayMaskedEncoder","text":"Encode the input data column (float) along with the incompleteness mask. Parameters: Name Type Description Default colDataList list input data column (string) required colMaskList list incompleteness mask required Returns: Type Description (list, list) encoded data column, list of encoding instructions Source code in mmcif/io/BinaryCifWriter.py def floatArrayMaskedEncoder ( self , colDataList , colMaskList ): \"\"\"Encode the input data column (float) along with the incompleteness mask. Args: colDataList (list): input data column (string) colMaskList (list): incompleteness mask Returns: (list, list): encoded data column, list of encoding instructions \"\"\" floatEncoderList = [ \"ByteArray\" ] if colMaskList : maskedColDataList = [ 0.0 if m else d for m , d in zip ( colMaskList , colDataList )] else : maskedColDataList = colDataList encodedColDataList , encodingDictL = self . encode ( maskedColDataList , floatEncoderList , \"float\" ) return encodedColDataList , encodingDictL","title":"floatArrayMaskedEncoder()"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifEncoders.getMask","text":"Create an incompleteness mask list identifying missing/omitted values in the input data column. The mask is assigned: 0 = Value is present, 1 = '.' (value not specified), and 2 = '?' (value unknown). Parameters: Name Type Description Default colDataList list input data column required Returns: Type Description list or None mask list or None if the column contains no missing values Source code in mmcif/io/BinaryCifWriter.py def getMask ( self , colDataList ): \"\"\"Create an incompleteness mask list identifying missing/omitted values in the input data column. The mask is assigned: 0 = Value is present, 1 = '.' (value not specified), and 2 = '?' (value unknown). Args: colDataList (list): input data column Returns: list or None: mask list or None if the column contains no missing values \"\"\" mask = None for ii , colVal in enumerate ( colDataList ): if colVal is not None and colVal not in self . __unknown : continue if not mask : mask = [ 0 ] * len ( colDataList ) mask [ ii ] = 2 if colVal is None or colVal == \"?\" else 1 return mask","title":"getMask()"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifEncoders.intArrayMaskedEncoder","text":"Encode the input data column (integer) along with the incompleteness mask. Parameters: Name Type Description Default colDataList list input data column (string) required colMaskList list incompleteness mask required Returns: Type Description (list, list) encoded data column, list of encoding instructions Source code in mmcif/io/BinaryCifWriter.py def intArrayMaskedEncoder ( self , colDataList , colMaskList ): \"\"\"Encode the input data column (integer) along with the incompleteness mask. Args: colDataList (list): input data column (string) colMaskList (list): incompleteness mask Returns: (list, list): encoded data column, list of encoding instructions \"\"\" integerEncoderList = [ \"Delta\" , \"RunLength\" , \"ByteArray\" ] if colMaskList : maskedColDataList = [ - 1 if m else d for m , d in zip ( colMaskList , colDataList )] else : maskedColDataList = colDataList encodedColDataList , encodingDictL = self . encode ( maskedColDataList , integerEncoderList , \"integer\" ) return encodedColDataList , encodingDictL","title":"intArrayMaskedEncoder()"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifEncoders.runLengthEncoder","text":"Encode an integer array as pairs of (value, number of repeats) Parameters: Name Type Description Default colDataList list list of integer data required minLen int minimum list length to apply encoder. Defaults to 40. 40 Returns: Type Description list runlength encoded integer list Source code in mmcif/io/BinaryCifWriter.py def runLengthEncoder ( self , colDataList , minLen = 40 ): \"\"\"Encode an integer array as pairs of (value, number of repeats) Args: colDataList (list): list of integer data minLen (int, optional): minimum list length to apply encoder. Defaults to 40. Returns: list: runlength encoded integer list \"\"\" if len ( colDataList ) <= minLen : return colDataList , None byteArrayType = self . __getIntegerPackingType ( colDataList ) encodingD = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"RunLength\" ), self . __toBytes ( \"srcType\" ): byteArrayType , self . __toBytes ( \"srcSize\" ): len ( colDataList )} encodedColDataList = [] val = None repeat = 1 for colVal in colDataList : if colVal != val : if val is not None : encodedColDataList . extend (( val , repeat )) val = colVal repeat = 1 else : repeat += 1 encodedColDataList . extend (( val , repeat )) # Check for any gains and possibly retreat if len ( encodedColDataList ) > len ( colDataList ): return colDataList , None else : return encodedColDataList , encodingD","title":"runLengthEncoder()"},{"location":"api_reference/BinaryCifWriter/#mmcif.io.BinaryCifWriter.BinaryCifEncoders.stringArrayMaskedEncoder","text":"Encode the input data column (string) along with the incompleteness mask. Parameters: Name Type Description Default colDataList list input data column (string) required colMaskList list incompleteness mask required Returns: Type Description (list, list) encoded data column, list of encoding instructions Source code in mmcif/io/BinaryCifWriter.py def stringArrayMaskedEncoder ( self , colDataList , colMaskList ): \"\"\"Encode the input data column (string) along with the incompleteness mask. Args: colDataList (list): input data column (string) colMaskList (list): incompleteness mask Returns: (list, list): encoded data column, list of encoding instructions \"\"\" integerEncoderList = [ \"Delta\" , \"RunLength\" , \"ByteArray\" ] uniqStringIndex = {} # keys are substrings, values indices uniqStringList = [] indexList = [] for i , strVal in enumerate ( colDataList ): if colMaskList is not None and colMaskList [ i ]: indexList . append ( - 1 ) else : tS = strVal tS = str ( tS ) if tS not in uniqStringIndex : uniqStringIndex [ tS ] = len ( uniqStringIndex ) uniqStringList . append ( tS ) indexList . append ( uniqStringIndex [ tS ]) offsetList = [ 0 ] runningLen = 0 for tS in uniqStringList : runningLen += len ( tS ) offsetList . append ( runningLen ) encodedOffsetList , offsetEncodingDictL = self . encode ( offsetList , integerEncoderList , \"integer\" ) encodedIndexList , indexEncodingDictL = self . encode ( indexList , integerEncoderList , \"integer\" ) encodingDict = { self . __toBytes ( \"kind\" ): self . __toBytes ( \"StringArray\" ), self . __toBytes ( \"dataEncoding\" ): indexEncodingDictL , self . __toBytes ( \"stringData\" ): self . __toBytes ( \"\" . join ( uniqStringList )), self . __toBytes ( \"offsetEncoding\" ): offsetEncodingDictL , self . __toBytes ( \"offsets\" ): encodedOffsetList , } return encodedIndexList , [ encodingDict ]","title":"stringArrayMaskedEncoder()"},{"location":"api_reference/CifFile/","text":"mmcif.io.CifFile.CifFile CifFile New method prototype -- CifFile* ParseCifSimple(const std::string& fileName, const bool verbose = false, const unsigned int intCaseSense = 0, const unsigned int maxLineLength = CifFile::STD_CIF_LINE_LENGTH, const std::string& nullValue = CifString::UnknownValue, const std::string& parseLogFileName = std::string()); Source code in mmcif/io/CifFile.py class CifFile ( object ): \"\"\" CifFile New method prototype -- CifFile* ParseCifSimple(const std::string& fileName, const bool verbose = false, const unsigned int intCaseSense = 0, const unsigned int maxLineLength = CifFile::STD_CIF_LINE_LENGTH, const std::string& nullValue = CifString::UnknownValue, const std::string& parseLogFileName = std::string()); \"\"\" def __init__ ( self , fileName , parseLogFileName = None ): self . __fileName = fileName if parseLogFileName is None : self . __cifFile = ParseCifSimple ( self . __fileName , False , 0 , 255 , \"?\" , \"\" ) else : self . __cifFile = ParseCifSimple ( self . __fileName , False , 0 , 255 , \"?\" , parseLogFileName ) def getCifFile ( self ): return self . __cifFile @classmethod def getFileExt ( cls ): return \"cif\" def write ( self , fileName ): self . __cifFile . Write ( fileName ) @classmethod def read ( cls , fileName ): return cls ( fileName ) __init__ ( self , fileName , parseLogFileName = None ) special Source code in mmcif/io/CifFile.py def __init__ ( self , fileName , parseLogFileName = None ): self . __fileName = fileName if parseLogFileName is None : self . __cifFile = ParseCifSimple ( self . __fileName , False , 0 , 255 , \"?\" , \"\" ) else : self . __cifFile = ParseCifSimple ( self . __fileName , False , 0 , 255 , \"?\" , parseLogFileName ) getCifFile ( self ) Source code in mmcif/io/CifFile.py def getCifFile ( self ): return self . __cifFile getFileExt () classmethod Source code in mmcif/io/CifFile.py @classmethod def getFileExt ( cls ): return \"cif\" read ( fileName ) classmethod Source code in mmcif/io/CifFile.py @classmethod def read ( cls , fileName ): return cls ( fileName ) write ( self , fileName ) Source code in mmcif/io/CifFile.py def write ( self , fileName ): self . __cifFile . Write ( fileName )","title":"CifFile"},{"location":"api_reference/CifFile/#mmcif.io.CifFile.CifFile","text":"CifFile New method prototype -- CifFile* ParseCifSimple(const std::string& fileName, const bool verbose = false, const unsigned int intCaseSense = 0, const unsigned int maxLineLength = CifFile::STD_CIF_LINE_LENGTH, const std::string& nullValue = CifString::UnknownValue, const std::string& parseLogFileName = std::string()); Source code in mmcif/io/CifFile.py class CifFile ( object ): \"\"\" CifFile New method prototype -- CifFile* ParseCifSimple(const std::string& fileName, const bool verbose = false, const unsigned int intCaseSense = 0, const unsigned int maxLineLength = CifFile::STD_CIF_LINE_LENGTH, const std::string& nullValue = CifString::UnknownValue, const std::string& parseLogFileName = std::string()); \"\"\" def __init__ ( self , fileName , parseLogFileName = None ): self . __fileName = fileName if parseLogFileName is None : self . __cifFile = ParseCifSimple ( self . __fileName , False , 0 , 255 , \"?\" , \"\" ) else : self . __cifFile = ParseCifSimple ( self . __fileName , False , 0 , 255 , \"?\" , parseLogFileName ) def getCifFile ( self ): return self . __cifFile @classmethod def getFileExt ( cls ): return \"cif\" def write ( self , fileName ): self . __cifFile . Write ( fileName ) @classmethod def read ( cls , fileName ): return cls ( fileName )","title":"CifFile"},{"location":"api_reference/CifFile/#mmcif.io.CifFile.CifFile.__init__","text":"Source code in mmcif/io/CifFile.py def __init__ ( self , fileName , parseLogFileName = None ): self . __fileName = fileName if parseLogFileName is None : self . __cifFile = ParseCifSimple ( self . __fileName , False , 0 , 255 , \"?\" , \"\" ) else : self . __cifFile = ParseCifSimple ( self . __fileName , False , 0 , 255 , \"?\" , parseLogFileName )","title":"__init__()"},{"location":"api_reference/CifFile/#mmcif.io.CifFile.CifFile.getCifFile","text":"Source code in mmcif/io/CifFile.py def getCifFile ( self ): return self . __cifFile","title":"getCifFile()"},{"location":"api_reference/CifFile/#mmcif.io.CifFile.CifFile.getFileExt","text":"Source code in mmcif/io/CifFile.py @classmethod def getFileExt ( cls ): return \"cif\"","title":"getFileExt()"},{"location":"api_reference/CifFile/#mmcif.io.CifFile.CifFile.read","text":"Source code in mmcif/io/CifFile.py @classmethod def read ( cls , fileName ): return cls ( fileName )","title":"read()"},{"location":"api_reference/CifFile/#mmcif.io.CifFile.CifFile.write","text":"Source code in mmcif/io/CifFile.py def write ( self , fileName ): self . __cifFile . Write ( fileName )","title":"write()"},{"location":"api_reference/DataCategory/","text":"mmcif.api.DataCategory.DataCategory ( DataCategoryBase ) Methods for creating, accessing, and formatting PDBx/mmCif data categories. Source code in mmcif/api/DataCategory.py class DataCategory ( DataCategoryBase ): \"\"\"Methods for creating, accessing, and formatting PDBx/mmCif data categories.\"\"\" def __init__ ( self , name , attributeNameList = None , rowList = None , raiseExceptions = True , copyInputData = True ): \"\"\"Summary Args: name (str): Category name attributeNameList (None, optional): Initial attribute names rowList (None, optional): Initial category data organized in rows corresponding to the attribute name list raiseExceptions (bool, optional): Flag to control if expections are raised or handled internally copyInputData (bool, optional): Copy rather than reference input data \"\"\" super ( DataCategory , self ) . __init__ ( name , attributeNameList , rowList , raiseExceptions = raiseExceptions , copyInputData = copyInputData ) # self . __verbose = False self . _currentRowIndex = 0 self . __currentAttribute = None # def setVerboseMode ( self , boolVal ): self . __verbose = boolVal def getCurrentAttribute ( self ): return self . __currentAttribute def getRowIndex ( self ): return self . _currentRowIndex def getFullRow ( self , index ): \"\"\"Return a full row based on the length of the the attribute list or a row initialized with missing values\"\"\" try : if len ( self . data [ index ]) < self . _numAttributes : for _ in range ( self . _numAttributes - len ( self . data [ index ])): self . data [ index ] . append ( \"?\" ) return self . data [ index ] except Exception as e : logger . debug ( \"Returning an empty row at %d ( %s )\" , index , str ( e )) return [ \"?\" for ii in range ( self . _numAttributes )] def getAttributeListWithOrder ( self ): oL = [] for ii , att in enumerate ( self . _attributeNameList ): oL . append (( att , ii )) return oL def appendAttributeExtendRows ( self , attributeName , defaultValue = \"?\" ): attributeNameLC = attributeName . lower () if attributeNameLC in self . _catalog : i = self . _attributeNameList . index ( self . _catalog [ attributeNameLC ]) self . _attributeNameList [ i ] = attributeName self . _catalog [ attributeNameLC ] = attributeName logger . info ( \"Appending existing attribute %s \" , attributeName ) else : self . _attributeNameList . append ( attributeName ) self . _catalog [ attributeNameLC ] = attributeName # add a placeholder to any existing rows for the new attribute. if self . data : for row in self . data : row . append ( defaultValue ) # self . _numAttributes = len ( self . _attributeNameList ) return self . _numAttributes def getValue ( self , attributeName = None , rowIndex = None ): if attributeName is None : attribute = self . __currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ): try : return self . data [ rowI ][ self . _attributeNameList . index ( attribute )] except IndexError : if self . _raiseExceptions : raise IndexError if self . _raiseExceptions : raise IndexError ( attribute ) else : return None def getValueOrDefault ( self , attributeName = None , rowIndex = None , defaultValue = \"\" ): \"\"\"Within the current category return the value of input attribute in the input rowIndex [0-based]. On error or if the value missing or null return the default value. Empty values returned as is. Exceptions on for unknown attributeNames and out-of-range indices. \"\"\" if attributeName is None : attribute = self . __currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ): try : tV = self . data [ rowI ][ self . _attributeNameList . index ( attribute )] if ( tV is None ) or ( tV in [ \".\" , \"?\" ]): return defaultValue else : return tV except Exception as e : logger . debug ( \"Failing attributeName %s rowIndex %r defaultValue %r with %s \" , attributeName , rowIndex , defaultValue , str ( e )) # if self._raiseExceptions: # raise e # Returning default -- no exception else : if self . _raiseExceptions : raise ValueError # return defaultValue def getFirstValueOrDefault ( self , attributeNameList , rowIndex = 0 , defaultValue = \"\" ): \"\"\"Return the value from the first non-null attribute found in the input attribute list from the row (rowIndex) in the current category object. \"\"\" try : for at in attributeNameList : if self . hasAttribute ( at ): tV = self . getValue ( at , rowIndex ) if ( tV is None ) or ( tV in [ \"\" , \".\" , \"?\" ]): continue else : return tV except Exception as e : logger . debug ( \"Failing with %s \" , str ( e )) # if self._raiseExceptions: # raise e return defaultValue def setValue ( self , value , attributeName = None , rowIndex = None ): \"\"\"Set the value of an existing attribute. rowIndex values >=0, where the category will be extended in length as needed. \"\"\" if attributeName is None : attribute = self . __currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ) and ( rowI >= 0 ): try : ind = - 2 # if row index is out of range - add the rows - for ii in range ( rowI + 1 - len ( self . data )): self . data . append ( self . __emptyRow ()) # self.data[rowI][attribute]=value ll = len ( self . data [ rowI ]) ind = self . _attributeNameList . index ( attribute ) # extend the list if needed - if ind >= ll : self . data [ rowI ] . extend ([ None for ii in range ( ind - ( ll - 1 ))]) self . data [ rowI ][ ind ] = value return True except IndexError : if self . __verbose : logger . exception ( \"DataCategory(setvalue) index error category %s attribute %s row index %d col %d rowlen %d value %r \" , self . _name , attribute , rowI , ind , len ( self . data [ rowI ]), value , ) logger . debug ( \"DataCategory(setvalue) attribute %r length attribute list %d \" , attribute , len ( self . _attributeNameList )) for ii , aV in enumerate ( self . _attributeNameList ): logger . debug ( \"DataCategory(setvalue) %d attributeName %r \" , ii , aV ) if self . _raiseExceptions : raise IndexError except ValueError : if self . __verbose : logger . exception ( \"DataCategory(setvalue) value error category %s attribute %s row index %d value %r \" , self . _name , attribute , rowI , value ) if self . _raiseExceptions : raise ValueError else : if self . _raiseExceptions : raise ValueError return False def __emptyRow ( self ): return [ None for ii in range ( len ( self . _attributeNameList ))] def replaceValue ( self , oldValue , newValue , attributeName ): try : numReplace = 0 if attributeName not in self . _attributeNameList : return numReplace ind = self . _attributeNameList . index ( attributeName ) for row in self . data : if row [ ind ] == oldValue : row [ ind ] = newValue numReplace += 1 return numReplace except Exception as e : if self . _raiseExceptions : raise e return numReplace def replaceSubstring ( self , oldValue , newValue , attributeName ): try : numReplace = 0 if attributeName not in self . _attributeNameList : return numReplace ind = self . _attributeNameList . index ( attributeName ) for row in self . data : val = row [ ind ] row [ ind ] = val . replace ( oldValue , newValue ) if val != row [ ind ]: numReplace += 1 return numReplace except Exception as e : if self . _raiseExceptions : raise e return numReplace def selectIndices ( self , attributeValue , attributeName ): try : rL = [] if attributeName not in self . _attributeNameList : return rL ind = self . _attributeNameList . index ( attributeName ) for ii , row in enumerate ( self . data ): if attributeValue == row [ ind ]: rL . append ( ii ) return rL except Exception as e : if self . _raiseExceptions : raise e return rL def selectIndicesFromList ( self , attributeValueList , attributeNameList ): rL = [] try : indList = [] for at in attributeNameList : indList . append ( self . _attributeNameList . index ( at )) indValList = list ( zip ( indList , attributeValueList )) # numList = len ( indValList ) for ii , row in enumerate ( self . data ): nMatch = 0 for ind , tVal in indValList : if tVal == row [ ind ]: nMatch += 1 if nMatch == numList : rL . append ( ii ) except Exception as e : if self . __verbose : logger . exception ( \"Selection/index failure for values %r \" , attributeValueList ) if self . _raiseExceptions : raise e return rL def selectValuesWhere ( self , attributeName , attributeValueWhere , attributeNameWhere , returnCount = 0 ): rL = [] try : iCount = 0 ind = self . _attributeNameList . index ( attributeName ) indWhere = self . _attributeNameList . index ( attributeNameWhere ) for row in self . data : if attributeValueWhere == row [ indWhere ]: rL . append ( row [ ind ]) iCount += 1 if returnCount and ( iCount >= returnCount ): break except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return rL def selectValueListWhere ( self , attributeNameList , attributeValueWhere , attributeNameWhere , returnCount = 0 ): \"\"\"Return a list of lists containing the values of input attributeNameList satisfying the attribute value where condition. \"\"\" rL = [] try : iCount = 0 indList = [] for at in attributeNameList : indList . append ( self . _attributeNameList . index ( at )) indWhere = self . _attributeNameList . index ( attributeNameWhere ) for row in self . data : if attributeValueWhere == row [ indWhere ]: rL . append ([ row [ jj ] for jj in indList ]) iCount += 1 if returnCount and ( iCount >= returnCount ): break except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return rL def selectValuesWhereConditions ( self , attributeName , conditionsD , returnCount = 0 ): rL = [] try : iCount = 0 ind = self . _attributeNameList . index ( attributeName ) idxD = { k : self . _attributeNameList . index ( k ) for k , v in conditionsD . items ()} # # for row in self . data : ok = True for k , v in conditionsD . items (): ok = ( v == row [ idxD [ k ]]) and ok if ok : rL . append ( row [ ind ]) iCount += 1 if returnCount and ( iCount >= returnCount ): break except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return rL def countValuesWhereConditions ( self , conditionsD ): \"\"\"Count row instances subject to input equivalence conditions Args: conditionsD (dict): {'atName': value, ....} Raises: e: any failure Returns: int: count of instances satisfying input conditions \"\"\" try : iCount = 0 idxD = { k : self . _attributeNameList . index ( k ) for k , v in conditionsD . items ()} # for row in self . data : ok = True for k , v in conditionsD . items (): ok = ( v == row [ idxD [ k ]]) and ok if ok : iCount += 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return iCount def countValuesWhereOpConditions ( self , conditionTupleList ): \"\"\"Count row instances subject to input condition list Args: conditionTupleList (list): (attributeName, op, value) where (op = 'eq', 'gt(int)', 'lt(int)', 'in', 'ne', 'not in') Raises: e: any failure Returns: int: count of instances satisfying input conditions \"\"\" try : iCount = 0 idxD = { atName : self . _attributeNameList . index ( atName ) for ( atName , op , value ) in conditionTupleList } # for row in self . data : ok = True for ( atName , op , v ) in conditionTupleList : if op == \"eq\" : ok = ( v == row [ idxD [ atName ]]) and ok elif op == \"ne\" : ok = ( v != row [ idxD [ atName ]]) and ok elif op == \"lt(int)\" : ok = ( int ( row [ idxD [ atName ]]) < v ) and ok elif op == \"gt(int)\" : ok = ( int ( row [ idxD [ atName ]]) > v ) and ok elif op == \"in\" : ok = ( row [ idxD [ atName ]] in v ) and ok elif op == \"not in\" : ok = ( row [ idxD [ atName ]] not in v ) and ok if ok : iCount += 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return iCount # def getCombinationCounts ( self , attributeList ): \"\"\"Count the value occurrences of the input attributeList in the category. Args: attributeList (list): target list of attribute names Returns: cD[(attribute value, ... )] = count \"\"\" cD = {} try : idxL = [ self . _attributeNameList . index ( atName ) for atName in attributeList ] # for row in self . data : ky = tuple ([ row [ jj ] for jj in idxL ]) cD [ ky ] = cD [ ky ] + 1 if ky in cD else 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return cD def getCombinationCountsWithConditions ( self , attributeList , conditionTupleList ): \"\"\"Count the value occurrences of the input attributeList in the category. Args: attributeList (list): target list of attribute names conditionTupleList (list): (attributeName, op, value) where (op = 'eq', 'gt(int)', 'lt(int)', 'in', 'ne', 'not in') Returns: cD[(attribute value, ... )] = count \"\"\" cD = {} try : idxL = [ self . _attributeNameList . index ( atName ) for atName in attributeList ] idxD = { atName : self . _attributeNameList . index ( atName ) for ( atName , op , value ) in conditionTupleList } # for row in self . data : ok = True for ( atName , op , v ) in conditionTupleList : if op == \"eq\" : ok = ( v == row [ idxD [ atName ]]) and ok elif op == \"ne\" : ok = ( v != row [ idxD [ atName ]]) and ok elif op == \"lt(int)\" : ok = ( int ( row [ idxD [ atName ]]) < v ) and ok elif op == \"gt(int)\" : ok = ( int ( row [ idxD [ atName ]]) > v ) and ok elif op == \"in\" : ok = ( row [ idxD [ atName ]] in v ) and ok elif op == \"not in\" : ok = ( row [ idxD [ atName ]] not in v ) and ok if ok : ky = tuple ([ row [ jj ] for jj in idxL ]) cD [ ky ] = cD [ ky ] + 1 if ky in cD else 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return cD def invokeAttributeMethod ( self , attributeName , mType , method , db ): _ = mType _ = db self . _currentRowIndex = 0 self . __currentAttribute = attributeName self . appendAttribute ( attributeName ) currentRowIndex = self . _currentRowIndex # pylint: disable=possibly-unused-variable # ind = self . _attributeNameList . index ( attributeName ) if not self . data : row = [ None for ii in range ( len ( self . _attributeNameList ) * 2 )] row [ ind ] = None self . data . append ( row ) for row in self . data : ll = len ( row ) if ind >= ll : row . extend ([ None for ii in range ( 2 * ind - ll )]) row [ ind ] = None exec ( method . getInline (), globals (), locals ()) # pylint: disable=exec-used self . _currentRowIndex += 1 currentRowIndex = self . _currentRowIndex def invokeCategoryMethod ( self , mType , method , db ): _ = mType _ = db self . _currentRowIndex = 0 exec ( method . getInline (), globals (), locals ()) # pylint: disable=exec-used def printIt ( self , fh = sys . stdout ): fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \" Category: %s attribute list length: %d \\n \" % ( self . _name , len ( self . _attributeNameList ))) for at in self . _attributeNameList : fh . write ( \" Category: %s attribute: %s \\n \" % ( self . _name , at )) fh . write ( \" Row value list length: %d \\n \" % len ( self . data )) # for row in self . data [: 2 ]: # if len ( row ) == len ( self . _attributeNameList ): for ii , v in enumerate ( row ): fh . write ( \" %30s : %s ... \\n \" % ( self . _attributeNameList [ ii ], str ( v )[: 30 ])) else : fh . write ( \"+WARNING - %s data length %d attribute name length %s mismatched \\n \" % ( self . _name , len ( row ), len ( self . _attributeNameList ))) def dumpIt ( self , fh = sys . stdout ): fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \" Category: %s attribute list length: %d \\n \" % ( self . _name , len ( self . _attributeNameList ))) for at in self . _attributeNameList : fh . write ( \" Category: %s attribute: %s \\n \" % ( self . _name , at )) fh . write ( \" Value list length: %d \\n \" % len ( self . data )) for jj , row in enumerate ( self . data ): for ii , v in enumerate ( row ): fh . write ( \" %4d %30s : %s \\n \" % ( jj , self . _attributeNameList [ ii ], v )) Methods __init__ ( self , name , attributeNameList = None , rowList = None , raiseExceptions = True , copyInputData = True ) special Summary Parameters: Name Type Description Default name str Category name required attributeNameList None Initial attribute names None rowList None Initial category data organized in rows corresponding to the attribute name list None raiseExceptions bool Flag to control if expections are raised or handled internally True copyInputData bool Copy rather than reference input data True Source code in mmcif/api/DataCategory.py def __init__ ( self , name , attributeNameList = None , rowList = None , raiseExceptions = True , copyInputData = True ): \"\"\"Summary Args: name (str): Category name attributeNameList (None, optional): Initial attribute names rowList (None, optional): Initial category data organized in rows corresponding to the attribute name list raiseExceptions (bool, optional): Flag to control if expections are raised or handled internally copyInputData (bool, optional): Copy rather than reference input data \"\"\" super ( DataCategory , self ) . __init__ ( name , attributeNameList , rowList , raiseExceptions = raiseExceptions , copyInputData = copyInputData ) # self . __verbose = False self . _currentRowIndex = 0 self . __currentAttribute = None # appendAttributeExtendRows ( self , attributeName , defaultValue = '?' ) Source code in mmcif/api/DataCategory.py def appendAttributeExtendRows ( self , attributeName , defaultValue = \"?\" ): attributeNameLC = attributeName . lower () if attributeNameLC in self . _catalog : i = self . _attributeNameList . index ( self . _catalog [ attributeNameLC ]) self . _attributeNameList [ i ] = attributeName self . _catalog [ attributeNameLC ] = attributeName logger . info ( \"Appending existing attribute %s \" , attributeName ) else : self . _attributeNameList . append ( attributeName ) self . _catalog [ attributeNameLC ] = attributeName # add a placeholder to any existing rows for the new attribute. if self . data : for row in self . data : row . append ( defaultValue ) # self . _numAttributes = len ( self . _attributeNameList ) return self . _numAttributes countValuesWhereConditions ( self , conditionsD ) Count row instances subject to input equivalence conditions Parameters: Name Type Description Default conditionsD dict {'atName': value, ....} required Exceptions: Type Description e any failure Returns: Type Description int count of instances satisfying input conditions Source code in mmcif/api/DataCategory.py def countValuesWhereConditions ( self , conditionsD ): \"\"\"Count row instances subject to input equivalence conditions Args: conditionsD (dict): {'atName': value, ....} Raises: e: any failure Returns: int: count of instances satisfying input conditions \"\"\" try : iCount = 0 idxD = { k : self . _attributeNameList . index ( k ) for k , v in conditionsD . items ()} # for row in self . data : ok = True for k , v in conditionsD . items (): ok = ( v == row [ idxD [ k ]]) and ok if ok : iCount += 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return iCount countValuesWhereOpConditions ( self , conditionTupleList ) Count row instances subject to input condition list Parameters: Name Type Description Default conditionTupleList list (attributeName, op, value) where (op = 'eq', 'gt(int)', 'lt(int)', 'in', 'ne', 'not in') required Exceptions: Type Description e any failure Returns: Type Description int count of instances satisfying input conditions Source code in mmcif/api/DataCategory.py def countValuesWhereOpConditions ( self , conditionTupleList ): \"\"\"Count row instances subject to input condition list Args: conditionTupleList (list): (attributeName, op, value) where (op = 'eq', 'gt(int)', 'lt(int)', 'in', 'ne', 'not in') Raises: e: any failure Returns: int: count of instances satisfying input conditions \"\"\" try : iCount = 0 idxD = { atName : self . _attributeNameList . index ( atName ) for ( atName , op , value ) in conditionTupleList } # for row in self . data : ok = True for ( atName , op , v ) in conditionTupleList : if op == \"eq\" : ok = ( v == row [ idxD [ atName ]]) and ok elif op == \"ne\" : ok = ( v != row [ idxD [ atName ]]) and ok elif op == \"lt(int)\" : ok = ( int ( row [ idxD [ atName ]]) < v ) and ok elif op == \"gt(int)\" : ok = ( int ( row [ idxD [ atName ]]) > v ) and ok elif op == \"in\" : ok = ( row [ idxD [ atName ]] in v ) and ok elif op == \"not in\" : ok = ( row [ idxD [ atName ]] not in v ) and ok if ok : iCount += 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return iCount dumpIt ( self , fh =< _io . StringIO object at 0x106062280 > ) Source code in mmcif/api/DataCategory.py def dumpIt ( self , fh = sys . stdout ): fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \" Category: %s attribute list length: %d \\n \" % ( self . _name , len ( self . _attributeNameList ))) for at in self . _attributeNameList : fh . write ( \" Category: %s attribute: %s \\n \" % ( self . _name , at )) fh . write ( \" Value list length: %d \\n \" % len ( self . data )) for jj , row in enumerate ( self . data ): for ii , v in enumerate ( row ): fh . write ( \" %4d %30s : %s \\n \" % ( jj , self . _attributeNameList [ ii ], v )) getAttributeListWithOrder ( self ) Source code in mmcif/api/DataCategory.py def getAttributeListWithOrder ( self ): oL = [] for ii , att in enumerate ( self . _attributeNameList ): oL . append (( att , ii )) return oL getCombinationCounts ( self , attributeList ) Count the value occurrences of the input attributeList in the category. Parameters: Name Type Description Default attributeList list target list of attribute names required Returns: Type Description cD[(attribute value, ... )] = count Source code in mmcif/api/DataCategory.py def getCombinationCounts ( self , attributeList ): \"\"\"Count the value occurrences of the input attributeList in the category. Args: attributeList (list): target list of attribute names Returns: cD[(attribute value, ... )] = count \"\"\" cD = {} try : idxL = [ self . _attributeNameList . index ( atName ) for atName in attributeList ] # for row in self . data : ky = tuple ([ row [ jj ] for jj in idxL ]) cD [ ky ] = cD [ ky ] + 1 if ky in cD else 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return cD getCombinationCountsWithConditions ( self , attributeList , conditionTupleList ) Count the value occurrences of the input attributeList in the category. Parameters: Name Type Description Default attributeList list target list of attribute names required conditionTupleList list (attributeName, op, value) where (op = 'eq', 'gt(int)', 'lt(int)', 'in', 'ne', 'not in') required Returns: Type Description cD[(attribute value, ... )] = count Source code in mmcif/api/DataCategory.py def getCombinationCountsWithConditions ( self , attributeList , conditionTupleList ): \"\"\"Count the value occurrences of the input attributeList in the category. Args: attributeList (list): target list of attribute names conditionTupleList (list): (attributeName, op, value) where (op = 'eq', 'gt(int)', 'lt(int)', 'in', 'ne', 'not in') Returns: cD[(attribute value, ... )] = count \"\"\" cD = {} try : idxL = [ self . _attributeNameList . index ( atName ) for atName in attributeList ] idxD = { atName : self . _attributeNameList . index ( atName ) for ( atName , op , value ) in conditionTupleList } # for row in self . data : ok = True for ( atName , op , v ) in conditionTupleList : if op == \"eq\" : ok = ( v == row [ idxD [ atName ]]) and ok elif op == \"ne\" : ok = ( v != row [ idxD [ atName ]]) and ok elif op == \"lt(int)\" : ok = ( int ( row [ idxD [ atName ]]) < v ) and ok elif op == \"gt(int)\" : ok = ( int ( row [ idxD [ atName ]]) > v ) and ok elif op == \"in\" : ok = ( row [ idxD [ atName ]] in v ) and ok elif op == \"not in\" : ok = ( row [ idxD [ atName ]] not in v ) and ok if ok : ky = tuple ([ row [ jj ] for jj in idxL ]) cD [ ky ] = cD [ ky ] + 1 if ky in cD else 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return cD getCurrentAttribute ( self ) Source code in mmcif/api/DataCategory.py def getCurrentAttribute ( self ): return self . __currentAttribute getFirstValueOrDefault ( self , attributeNameList , rowIndex = 0 , defaultValue = '' ) Return the value from the first non-null attribute found in the input attribute list from the row (rowIndex) in the current category object. Source code in mmcif/api/DataCategory.py def getFirstValueOrDefault ( self , attributeNameList , rowIndex = 0 , defaultValue = \"\" ): \"\"\"Return the value from the first non-null attribute found in the input attribute list from the row (rowIndex) in the current category object. \"\"\" try : for at in attributeNameList : if self . hasAttribute ( at ): tV = self . getValue ( at , rowIndex ) if ( tV is None ) or ( tV in [ \"\" , \".\" , \"?\" ]): continue else : return tV except Exception as e : logger . debug ( \"Failing with %s \" , str ( e )) # if self._raiseExceptions: # raise e return defaultValue getFullRow ( self , index ) Return a full row based on the length of the the attribute list or a row initialized with missing values Source code in mmcif/api/DataCategory.py def getFullRow ( self , index ): \"\"\"Return a full row based on the length of the the attribute list or a row initialized with missing values\"\"\" try : if len ( self . data [ index ]) < self . _numAttributes : for _ in range ( self . _numAttributes - len ( self . data [ index ])): self . data [ index ] . append ( \"?\" ) return self . data [ index ] except Exception as e : logger . debug ( \"Returning an empty row at %d ( %s )\" , index , str ( e )) return [ \"?\" for ii in range ( self . _numAttributes )] getRowIndex ( self ) Source code in mmcif/api/DataCategory.py def getRowIndex ( self ): return self . _currentRowIndex getValue ( self , attributeName = None , rowIndex = None ) Source code in mmcif/api/DataCategory.py def getValue ( self , attributeName = None , rowIndex = None ): if attributeName is None : attribute = self . __currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ): try : return self . data [ rowI ][ self . _attributeNameList . index ( attribute )] except IndexError : if self . _raiseExceptions : raise IndexError if self . _raiseExceptions : raise IndexError ( attribute ) else : return None getValueOrDefault ( self , attributeName = None , rowIndex = None , defaultValue = '' ) Within the current category return the value of input attribute in the input rowIndex [0-based]. On error or if the value missing or null return the default value. Empty values returned as is. Exceptions on for unknown attributeNames and out-of-range indices. Source code in mmcif/api/DataCategory.py def getValueOrDefault ( self , attributeName = None , rowIndex = None , defaultValue = \"\" ): \"\"\"Within the current category return the value of input attribute in the input rowIndex [0-based]. On error or if the value missing or null return the default value. Empty values returned as is. Exceptions on for unknown attributeNames and out-of-range indices. \"\"\" if attributeName is None : attribute = self . __currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ): try : tV = self . data [ rowI ][ self . _attributeNameList . index ( attribute )] if ( tV is None ) or ( tV in [ \".\" , \"?\" ]): return defaultValue else : return tV except Exception as e : logger . debug ( \"Failing attributeName %s rowIndex %r defaultValue %r with %s \" , attributeName , rowIndex , defaultValue , str ( e )) # if self._raiseExceptions: # raise e # Returning default -- no exception else : if self . _raiseExceptions : raise ValueError # return defaultValue invokeAttributeMethod ( self , attributeName , mType , method , db ) Source code in mmcif/api/DataCategory.py def invokeAttributeMethod ( self , attributeName , mType , method , db ): _ = mType _ = db self . _currentRowIndex = 0 self . __currentAttribute = attributeName self . appendAttribute ( attributeName ) currentRowIndex = self . _currentRowIndex # pylint: disable=possibly-unused-variable # ind = self . _attributeNameList . index ( attributeName ) if not self . data : row = [ None for ii in range ( len ( self . _attributeNameList ) * 2 )] row [ ind ] = None self . data . append ( row ) for row in self . data : ll = len ( row ) if ind >= ll : row . extend ([ None for ii in range ( 2 * ind - ll )]) row [ ind ] = None exec ( method . getInline (), globals (), locals ()) # pylint: disable=exec-used self . _currentRowIndex += 1 currentRowIndex = self . _currentRowIndex invokeCategoryMethod ( self , mType , method , db ) Source code in mmcif/api/DataCategory.py def invokeCategoryMethod ( self , mType , method , db ): _ = mType _ = db self . _currentRowIndex = 0 exec ( method . getInline (), globals (), locals ()) # pylint: disable=exec-used printIt ( self , fh =< _io . StringIO object at 0x106062280 > ) Source code in mmcif/api/DataCategory.py def printIt ( self , fh = sys . stdout ): fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \" Category: %s attribute list length: %d \\n \" % ( self . _name , len ( self . _attributeNameList ))) for at in self . _attributeNameList : fh . write ( \" Category: %s attribute: %s \\n \" % ( self . _name , at )) fh . write ( \" Row value list length: %d \\n \" % len ( self . data )) # for row in self . data [: 2 ]: # if len ( row ) == len ( self . _attributeNameList ): for ii , v in enumerate ( row ): fh . write ( \" %30s : %s ... \\n \" % ( self . _attributeNameList [ ii ], str ( v )[: 30 ])) else : fh . write ( \"+WARNING - %s data length %d attribute name length %s mismatched \\n \" % ( self . _name , len ( row ), len ( self . _attributeNameList ))) replaceSubstring ( self , oldValue , newValue , attributeName ) Source code in mmcif/api/DataCategory.py def replaceSubstring ( self , oldValue , newValue , attributeName ): try : numReplace = 0 if attributeName not in self . _attributeNameList : return numReplace ind = self . _attributeNameList . index ( attributeName ) for row in self . data : val = row [ ind ] row [ ind ] = val . replace ( oldValue , newValue ) if val != row [ ind ]: numReplace += 1 return numReplace except Exception as e : if self . _raiseExceptions : raise e return numReplace replaceValue ( self , oldValue , newValue , attributeName ) Source code in mmcif/api/DataCategory.py def replaceValue ( self , oldValue , newValue , attributeName ): try : numReplace = 0 if attributeName not in self . _attributeNameList : return numReplace ind = self . _attributeNameList . index ( attributeName ) for row in self . data : if row [ ind ] == oldValue : row [ ind ] = newValue numReplace += 1 return numReplace except Exception as e : if self . _raiseExceptions : raise e return numReplace selectIndices ( self , attributeValue , attributeName ) Source code in mmcif/api/DataCategory.py def selectIndices ( self , attributeValue , attributeName ): try : rL = [] if attributeName not in self . _attributeNameList : return rL ind = self . _attributeNameList . index ( attributeName ) for ii , row in enumerate ( self . data ): if attributeValue == row [ ind ]: rL . append ( ii ) return rL except Exception as e : if self . _raiseExceptions : raise e return rL selectIndicesFromList ( self , attributeValueList , attributeNameList ) Source code in mmcif/api/DataCategory.py def selectIndicesFromList ( self , attributeValueList , attributeNameList ): rL = [] try : indList = [] for at in attributeNameList : indList . append ( self . _attributeNameList . index ( at )) indValList = list ( zip ( indList , attributeValueList )) # numList = len ( indValList ) for ii , row in enumerate ( self . data ): nMatch = 0 for ind , tVal in indValList : if tVal == row [ ind ]: nMatch += 1 if nMatch == numList : rL . append ( ii ) except Exception as e : if self . __verbose : logger . exception ( \"Selection/index failure for values %r \" , attributeValueList ) if self . _raiseExceptions : raise e return rL selectValueListWhere ( self , attributeNameList , attributeValueWhere , attributeNameWhere , returnCount = 0 ) Return a list of lists containing the values of input attributeNameList satisfying the attribute value where condition. Source code in mmcif/api/DataCategory.py def selectValueListWhere ( self , attributeNameList , attributeValueWhere , attributeNameWhere , returnCount = 0 ): \"\"\"Return a list of lists containing the values of input attributeNameList satisfying the attribute value where condition. \"\"\" rL = [] try : iCount = 0 indList = [] for at in attributeNameList : indList . append ( self . _attributeNameList . index ( at )) indWhere = self . _attributeNameList . index ( attributeNameWhere ) for row in self . data : if attributeValueWhere == row [ indWhere ]: rL . append ([ row [ jj ] for jj in indList ]) iCount += 1 if returnCount and ( iCount >= returnCount ): break except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return rL selectValuesWhere ( self , attributeName , attributeValueWhere , attributeNameWhere , returnCount = 0 ) Source code in mmcif/api/DataCategory.py def selectValuesWhere ( self , attributeName , attributeValueWhere , attributeNameWhere , returnCount = 0 ): rL = [] try : iCount = 0 ind = self . _attributeNameList . index ( attributeName ) indWhere = self . _attributeNameList . index ( attributeNameWhere ) for row in self . data : if attributeValueWhere == row [ indWhere ]: rL . append ( row [ ind ]) iCount += 1 if returnCount and ( iCount >= returnCount ): break except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return rL selectValuesWhereConditions ( self , attributeName , conditionsD , returnCount = 0 ) Source code in mmcif/api/DataCategory.py def selectValuesWhereConditions ( self , attributeName , conditionsD , returnCount = 0 ): rL = [] try : iCount = 0 ind = self . _attributeNameList . index ( attributeName ) idxD = { k : self . _attributeNameList . index ( k ) for k , v in conditionsD . items ()} # # for row in self . data : ok = True for k , v in conditionsD . items (): ok = ( v == row [ idxD [ k ]]) and ok if ok : rL . append ( row [ ind ]) iCount += 1 if returnCount and ( iCount >= returnCount ): break except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return rL setValue ( self , value , attributeName = None , rowIndex = None ) Set the value of an existing attribute. rowIndex values >=0, where the category will be extended in length as needed. Source code in mmcif/api/DataCategory.py def setValue ( self , value , attributeName = None , rowIndex = None ): \"\"\"Set the value of an existing attribute. rowIndex values >=0, where the category will be extended in length as needed. \"\"\" if attributeName is None : attribute = self . __currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ) and ( rowI >= 0 ): try : ind = - 2 # if row index is out of range - add the rows - for ii in range ( rowI + 1 - len ( self . data )): self . data . append ( self . __emptyRow ()) # self.data[rowI][attribute]=value ll = len ( self . data [ rowI ]) ind = self . _attributeNameList . index ( attribute ) # extend the list if needed - if ind >= ll : self . data [ rowI ] . extend ([ None for ii in range ( ind - ( ll - 1 ))]) self . data [ rowI ][ ind ] = value return True except IndexError : if self . __verbose : logger . exception ( \"DataCategory(setvalue) index error category %s attribute %s row index %d col %d rowlen %d value %r \" , self . _name , attribute , rowI , ind , len ( self . data [ rowI ]), value , ) logger . debug ( \"DataCategory(setvalue) attribute %r length attribute list %d \" , attribute , len ( self . _attributeNameList )) for ii , aV in enumerate ( self . _attributeNameList ): logger . debug ( \"DataCategory(setvalue) %d attributeName %r \" , ii , aV ) if self . _raiseExceptions : raise IndexError except ValueError : if self . __verbose : logger . exception ( \"DataCategory(setvalue) value error category %s attribute %s row index %d value %r \" , self . _name , attribute , rowI , value ) if self . _raiseExceptions : raise ValueError else : if self . _raiseExceptions : raise ValueError return False setVerboseMode ( self , boolVal ) Source code in mmcif/api/DataCategory.py def setVerboseMode ( self , boolVal ): self . __verbose = boolVal","title":"DataCategory"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory","text":"Methods for creating, accessing, and formatting PDBx/mmCif data categories. Source code in mmcif/api/DataCategory.py class DataCategory ( DataCategoryBase ): \"\"\"Methods for creating, accessing, and formatting PDBx/mmCif data categories.\"\"\" def __init__ ( self , name , attributeNameList = None , rowList = None , raiseExceptions = True , copyInputData = True ): \"\"\"Summary Args: name (str): Category name attributeNameList (None, optional): Initial attribute names rowList (None, optional): Initial category data organized in rows corresponding to the attribute name list raiseExceptions (bool, optional): Flag to control if expections are raised or handled internally copyInputData (bool, optional): Copy rather than reference input data \"\"\" super ( DataCategory , self ) . __init__ ( name , attributeNameList , rowList , raiseExceptions = raiseExceptions , copyInputData = copyInputData ) # self . __verbose = False self . _currentRowIndex = 0 self . __currentAttribute = None # def setVerboseMode ( self , boolVal ): self . __verbose = boolVal def getCurrentAttribute ( self ): return self . __currentAttribute def getRowIndex ( self ): return self . _currentRowIndex def getFullRow ( self , index ): \"\"\"Return a full row based on the length of the the attribute list or a row initialized with missing values\"\"\" try : if len ( self . data [ index ]) < self . _numAttributes : for _ in range ( self . _numAttributes - len ( self . data [ index ])): self . data [ index ] . append ( \"?\" ) return self . data [ index ] except Exception as e : logger . debug ( \"Returning an empty row at %d ( %s )\" , index , str ( e )) return [ \"?\" for ii in range ( self . _numAttributes )] def getAttributeListWithOrder ( self ): oL = [] for ii , att in enumerate ( self . _attributeNameList ): oL . append (( att , ii )) return oL def appendAttributeExtendRows ( self , attributeName , defaultValue = \"?\" ): attributeNameLC = attributeName . lower () if attributeNameLC in self . _catalog : i = self . _attributeNameList . index ( self . _catalog [ attributeNameLC ]) self . _attributeNameList [ i ] = attributeName self . _catalog [ attributeNameLC ] = attributeName logger . info ( \"Appending existing attribute %s \" , attributeName ) else : self . _attributeNameList . append ( attributeName ) self . _catalog [ attributeNameLC ] = attributeName # add a placeholder to any existing rows for the new attribute. if self . data : for row in self . data : row . append ( defaultValue ) # self . _numAttributes = len ( self . _attributeNameList ) return self . _numAttributes def getValue ( self , attributeName = None , rowIndex = None ): if attributeName is None : attribute = self . __currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ): try : return self . data [ rowI ][ self . _attributeNameList . index ( attribute )] except IndexError : if self . _raiseExceptions : raise IndexError if self . _raiseExceptions : raise IndexError ( attribute ) else : return None def getValueOrDefault ( self , attributeName = None , rowIndex = None , defaultValue = \"\" ): \"\"\"Within the current category return the value of input attribute in the input rowIndex [0-based]. On error or if the value missing or null return the default value. Empty values returned as is. Exceptions on for unknown attributeNames and out-of-range indices. \"\"\" if attributeName is None : attribute = self . __currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ): try : tV = self . data [ rowI ][ self . _attributeNameList . index ( attribute )] if ( tV is None ) or ( tV in [ \".\" , \"?\" ]): return defaultValue else : return tV except Exception as e : logger . debug ( \"Failing attributeName %s rowIndex %r defaultValue %r with %s \" , attributeName , rowIndex , defaultValue , str ( e )) # if self._raiseExceptions: # raise e # Returning default -- no exception else : if self . _raiseExceptions : raise ValueError # return defaultValue def getFirstValueOrDefault ( self , attributeNameList , rowIndex = 0 , defaultValue = \"\" ): \"\"\"Return the value from the first non-null attribute found in the input attribute list from the row (rowIndex) in the current category object. \"\"\" try : for at in attributeNameList : if self . hasAttribute ( at ): tV = self . getValue ( at , rowIndex ) if ( tV is None ) or ( tV in [ \"\" , \".\" , \"?\" ]): continue else : return tV except Exception as e : logger . debug ( \"Failing with %s \" , str ( e )) # if self._raiseExceptions: # raise e return defaultValue def setValue ( self , value , attributeName = None , rowIndex = None ): \"\"\"Set the value of an existing attribute. rowIndex values >=0, where the category will be extended in length as needed. \"\"\" if attributeName is None : attribute = self . __currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ) and ( rowI >= 0 ): try : ind = - 2 # if row index is out of range - add the rows - for ii in range ( rowI + 1 - len ( self . data )): self . data . append ( self . __emptyRow ()) # self.data[rowI][attribute]=value ll = len ( self . data [ rowI ]) ind = self . _attributeNameList . index ( attribute ) # extend the list if needed - if ind >= ll : self . data [ rowI ] . extend ([ None for ii in range ( ind - ( ll - 1 ))]) self . data [ rowI ][ ind ] = value return True except IndexError : if self . __verbose : logger . exception ( \"DataCategory(setvalue) index error category %s attribute %s row index %d col %d rowlen %d value %r \" , self . _name , attribute , rowI , ind , len ( self . data [ rowI ]), value , ) logger . debug ( \"DataCategory(setvalue) attribute %r length attribute list %d \" , attribute , len ( self . _attributeNameList )) for ii , aV in enumerate ( self . _attributeNameList ): logger . debug ( \"DataCategory(setvalue) %d attributeName %r \" , ii , aV ) if self . _raiseExceptions : raise IndexError except ValueError : if self . __verbose : logger . exception ( \"DataCategory(setvalue) value error category %s attribute %s row index %d value %r \" , self . _name , attribute , rowI , value ) if self . _raiseExceptions : raise ValueError else : if self . _raiseExceptions : raise ValueError return False def __emptyRow ( self ): return [ None for ii in range ( len ( self . _attributeNameList ))] def replaceValue ( self , oldValue , newValue , attributeName ): try : numReplace = 0 if attributeName not in self . _attributeNameList : return numReplace ind = self . _attributeNameList . index ( attributeName ) for row in self . data : if row [ ind ] == oldValue : row [ ind ] = newValue numReplace += 1 return numReplace except Exception as e : if self . _raiseExceptions : raise e return numReplace def replaceSubstring ( self , oldValue , newValue , attributeName ): try : numReplace = 0 if attributeName not in self . _attributeNameList : return numReplace ind = self . _attributeNameList . index ( attributeName ) for row in self . data : val = row [ ind ] row [ ind ] = val . replace ( oldValue , newValue ) if val != row [ ind ]: numReplace += 1 return numReplace except Exception as e : if self . _raiseExceptions : raise e return numReplace def selectIndices ( self , attributeValue , attributeName ): try : rL = [] if attributeName not in self . _attributeNameList : return rL ind = self . _attributeNameList . index ( attributeName ) for ii , row in enumerate ( self . data ): if attributeValue == row [ ind ]: rL . append ( ii ) return rL except Exception as e : if self . _raiseExceptions : raise e return rL def selectIndicesFromList ( self , attributeValueList , attributeNameList ): rL = [] try : indList = [] for at in attributeNameList : indList . append ( self . _attributeNameList . index ( at )) indValList = list ( zip ( indList , attributeValueList )) # numList = len ( indValList ) for ii , row in enumerate ( self . data ): nMatch = 0 for ind , tVal in indValList : if tVal == row [ ind ]: nMatch += 1 if nMatch == numList : rL . append ( ii ) except Exception as e : if self . __verbose : logger . exception ( \"Selection/index failure for values %r \" , attributeValueList ) if self . _raiseExceptions : raise e return rL def selectValuesWhere ( self , attributeName , attributeValueWhere , attributeNameWhere , returnCount = 0 ): rL = [] try : iCount = 0 ind = self . _attributeNameList . index ( attributeName ) indWhere = self . _attributeNameList . index ( attributeNameWhere ) for row in self . data : if attributeValueWhere == row [ indWhere ]: rL . append ( row [ ind ]) iCount += 1 if returnCount and ( iCount >= returnCount ): break except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return rL def selectValueListWhere ( self , attributeNameList , attributeValueWhere , attributeNameWhere , returnCount = 0 ): \"\"\"Return a list of lists containing the values of input attributeNameList satisfying the attribute value where condition. \"\"\" rL = [] try : iCount = 0 indList = [] for at in attributeNameList : indList . append ( self . _attributeNameList . index ( at )) indWhere = self . _attributeNameList . index ( attributeNameWhere ) for row in self . data : if attributeValueWhere == row [ indWhere ]: rL . append ([ row [ jj ] for jj in indList ]) iCount += 1 if returnCount and ( iCount >= returnCount ): break except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return rL def selectValuesWhereConditions ( self , attributeName , conditionsD , returnCount = 0 ): rL = [] try : iCount = 0 ind = self . _attributeNameList . index ( attributeName ) idxD = { k : self . _attributeNameList . index ( k ) for k , v in conditionsD . items ()} # # for row in self . data : ok = True for k , v in conditionsD . items (): ok = ( v == row [ idxD [ k ]]) and ok if ok : rL . append ( row [ ind ]) iCount += 1 if returnCount and ( iCount >= returnCount ): break except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return rL def countValuesWhereConditions ( self , conditionsD ): \"\"\"Count row instances subject to input equivalence conditions Args: conditionsD (dict): {'atName': value, ....} Raises: e: any failure Returns: int: count of instances satisfying input conditions \"\"\" try : iCount = 0 idxD = { k : self . _attributeNameList . index ( k ) for k , v in conditionsD . items ()} # for row in self . data : ok = True for k , v in conditionsD . items (): ok = ( v == row [ idxD [ k ]]) and ok if ok : iCount += 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return iCount def countValuesWhereOpConditions ( self , conditionTupleList ): \"\"\"Count row instances subject to input condition list Args: conditionTupleList (list): (attributeName, op, value) where (op = 'eq', 'gt(int)', 'lt(int)', 'in', 'ne', 'not in') Raises: e: any failure Returns: int: count of instances satisfying input conditions \"\"\" try : iCount = 0 idxD = { atName : self . _attributeNameList . index ( atName ) for ( atName , op , value ) in conditionTupleList } # for row in self . data : ok = True for ( atName , op , v ) in conditionTupleList : if op == \"eq\" : ok = ( v == row [ idxD [ atName ]]) and ok elif op == \"ne\" : ok = ( v != row [ idxD [ atName ]]) and ok elif op == \"lt(int)\" : ok = ( int ( row [ idxD [ atName ]]) < v ) and ok elif op == \"gt(int)\" : ok = ( int ( row [ idxD [ atName ]]) > v ) and ok elif op == \"in\" : ok = ( row [ idxD [ atName ]] in v ) and ok elif op == \"not in\" : ok = ( row [ idxD [ atName ]] not in v ) and ok if ok : iCount += 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return iCount # def getCombinationCounts ( self , attributeList ): \"\"\"Count the value occurrences of the input attributeList in the category. Args: attributeList (list): target list of attribute names Returns: cD[(attribute value, ... )] = count \"\"\" cD = {} try : idxL = [ self . _attributeNameList . index ( atName ) for atName in attributeList ] # for row in self . data : ky = tuple ([ row [ jj ] for jj in idxL ]) cD [ ky ] = cD [ ky ] + 1 if ky in cD else 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return cD def getCombinationCountsWithConditions ( self , attributeList , conditionTupleList ): \"\"\"Count the value occurrences of the input attributeList in the category. Args: attributeList (list): target list of attribute names conditionTupleList (list): (attributeName, op, value) where (op = 'eq', 'gt(int)', 'lt(int)', 'in', 'ne', 'not in') Returns: cD[(attribute value, ... )] = count \"\"\" cD = {} try : idxL = [ self . _attributeNameList . index ( atName ) for atName in attributeList ] idxD = { atName : self . _attributeNameList . index ( atName ) for ( atName , op , value ) in conditionTupleList } # for row in self . data : ok = True for ( atName , op , v ) in conditionTupleList : if op == \"eq\" : ok = ( v == row [ idxD [ atName ]]) and ok elif op == \"ne\" : ok = ( v != row [ idxD [ atName ]]) and ok elif op == \"lt(int)\" : ok = ( int ( row [ idxD [ atName ]]) < v ) and ok elif op == \"gt(int)\" : ok = ( int ( row [ idxD [ atName ]]) > v ) and ok elif op == \"in\" : ok = ( row [ idxD [ atName ]] in v ) and ok elif op == \"not in\" : ok = ( row [ idxD [ atName ]] not in v ) and ok if ok : ky = tuple ([ row [ jj ] for jj in idxL ]) cD [ ky ] = cD [ ky ] + 1 if ky in cD else 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return cD def invokeAttributeMethod ( self , attributeName , mType , method , db ): _ = mType _ = db self . _currentRowIndex = 0 self . __currentAttribute = attributeName self . appendAttribute ( attributeName ) currentRowIndex = self . _currentRowIndex # pylint: disable=possibly-unused-variable # ind = self . _attributeNameList . index ( attributeName ) if not self . data : row = [ None for ii in range ( len ( self . _attributeNameList ) * 2 )] row [ ind ] = None self . data . append ( row ) for row in self . data : ll = len ( row ) if ind >= ll : row . extend ([ None for ii in range ( 2 * ind - ll )]) row [ ind ] = None exec ( method . getInline (), globals (), locals ()) # pylint: disable=exec-used self . _currentRowIndex += 1 currentRowIndex = self . _currentRowIndex def invokeCategoryMethod ( self , mType , method , db ): _ = mType _ = db self . _currentRowIndex = 0 exec ( method . getInline (), globals (), locals ()) # pylint: disable=exec-used def printIt ( self , fh = sys . stdout ): fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \" Category: %s attribute list length: %d \\n \" % ( self . _name , len ( self . _attributeNameList ))) for at in self . _attributeNameList : fh . write ( \" Category: %s attribute: %s \\n \" % ( self . _name , at )) fh . write ( \" Row value list length: %d \\n \" % len ( self . data )) # for row in self . data [: 2 ]: # if len ( row ) == len ( self . _attributeNameList ): for ii , v in enumerate ( row ): fh . write ( \" %30s : %s ... \\n \" % ( self . _attributeNameList [ ii ], str ( v )[: 30 ])) else : fh . write ( \"+WARNING - %s data length %d attribute name length %s mismatched \\n \" % ( self . _name , len ( row ), len ( self . _attributeNameList ))) def dumpIt ( self , fh = sys . stdout ): fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \" Category: %s attribute list length: %d \\n \" % ( self . _name , len ( self . _attributeNameList ))) for at in self . _attributeNameList : fh . write ( \" Category: %s attribute: %s \\n \" % ( self . _name , at )) fh . write ( \" Value list length: %d \\n \" % len ( self . data )) for jj , row in enumerate ( self . data ): for ii , v in enumerate ( row ): fh . write ( \" %4d %30s : %s \\n \" % ( jj , self . _attributeNameList [ ii ], v ))","title":"DataCategory"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory-methods","text":"","title":"Methods"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.__init__","text":"Summary Parameters: Name Type Description Default name str Category name required attributeNameList None Initial attribute names None rowList None Initial category data organized in rows corresponding to the attribute name list None raiseExceptions bool Flag to control if expections are raised or handled internally True copyInputData bool Copy rather than reference input data True Source code in mmcif/api/DataCategory.py def __init__ ( self , name , attributeNameList = None , rowList = None , raiseExceptions = True , copyInputData = True ): \"\"\"Summary Args: name (str): Category name attributeNameList (None, optional): Initial attribute names rowList (None, optional): Initial category data organized in rows corresponding to the attribute name list raiseExceptions (bool, optional): Flag to control if expections are raised or handled internally copyInputData (bool, optional): Copy rather than reference input data \"\"\" super ( DataCategory , self ) . __init__ ( name , attributeNameList , rowList , raiseExceptions = raiseExceptions , copyInputData = copyInputData ) # self . __verbose = False self . _currentRowIndex = 0 self . __currentAttribute = None #","title":"__init__()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.appendAttributeExtendRows","text":"Source code in mmcif/api/DataCategory.py def appendAttributeExtendRows ( self , attributeName , defaultValue = \"?\" ): attributeNameLC = attributeName . lower () if attributeNameLC in self . _catalog : i = self . _attributeNameList . index ( self . _catalog [ attributeNameLC ]) self . _attributeNameList [ i ] = attributeName self . _catalog [ attributeNameLC ] = attributeName logger . info ( \"Appending existing attribute %s \" , attributeName ) else : self . _attributeNameList . append ( attributeName ) self . _catalog [ attributeNameLC ] = attributeName # add a placeholder to any existing rows for the new attribute. if self . data : for row in self . data : row . append ( defaultValue ) # self . _numAttributes = len ( self . _attributeNameList ) return self . _numAttributes","title":"appendAttributeExtendRows()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.countValuesWhereConditions","text":"Count row instances subject to input equivalence conditions Parameters: Name Type Description Default conditionsD dict {'atName': value, ....} required Exceptions: Type Description e any failure Returns: Type Description int count of instances satisfying input conditions Source code in mmcif/api/DataCategory.py def countValuesWhereConditions ( self , conditionsD ): \"\"\"Count row instances subject to input equivalence conditions Args: conditionsD (dict): {'atName': value, ....} Raises: e: any failure Returns: int: count of instances satisfying input conditions \"\"\" try : iCount = 0 idxD = { k : self . _attributeNameList . index ( k ) for k , v in conditionsD . items ()} # for row in self . data : ok = True for k , v in conditionsD . items (): ok = ( v == row [ idxD [ k ]]) and ok if ok : iCount += 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return iCount","title":"countValuesWhereConditions()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.countValuesWhereOpConditions","text":"Count row instances subject to input condition list Parameters: Name Type Description Default conditionTupleList list (attributeName, op, value) where (op = 'eq', 'gt(int)', 'lt(int)', 'in', 'ne', 'not in') required Exceptions: Type Description e any failure Returns: Type Description int count of instances satisfying input conditions Source code in mmcif/api/DataCategory.py def countValuesWhereOpConditions ( self , conditionTupleList ): \"\"\"Count row instances subject to input condition list Args: conditionTupleList (list): (attributeName, op, value) where (op = 'eq', 'gt(int)', 'lt(int)', 'in', 'ne', 'not in') Raises: e: any failure Returns: int: count of instances satisfying input conditions \"\"\" try : iCount = 0 idxD = { atName : self . _attributeNameList . index ( atName ) for ( atName , op , value ) in conditionTupleList } # for row in self . data : ok = True for ( atName , op , v ) in conditionTupleList : if op == \"eq\" : ok = ( v == row [ idxD [ atName ]]) and ok elif op == \"ne\" : ok = ( v != row [ idxD [ atName ]]) and ok elif op == \"lt(int)\" : ok = ( int ( row [ idxD [ atName ]]) < v ) and ok elif op == \"gt(int)\" : ok = ( int ( row [ idxD [ atName ]]) > v ) and ok elif op == \"in\" : ok = ( row [ idxD [ atName ]] in v ) and ok elif op == \"not in\" : ok = ( row [ idxD [ atName ]] not in v ) and ok if ok : iCount += 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return iCount","title":"countValuesWhereOpConditions()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.dumpIt","text":"Source code in mmcif/api/DataCategory.py def dumpIt ( self , fh = sys . stdout ): fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \" Category: %s attribute list length: %d \\n \" % ( self . _name , len ( self . _attributeNameList ))) for at in self . _attributeNameList : fh . write ( \" Category: %s attribute: %s \\n \" % ( self . _name , at )) fh . write ( \" Value list length: %d \\n \" % len ( self . data )) for jj , row in enumerate ( self . data ): for ii , v in enumerate ( row ): fh . write ( \" %4d %30s : %s \\n \" % ( jj , self . _attributeNameList [ ii ], v ))","title":"dumpIt()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.getAttributeListWithOrder","text":"Source code in mmcif/api/DataCategory.py def getAttributeListWithOrder ( self ): oL = [] for ii , att in enumerate ( self . _attributeNameList ): oL . append (( att , ii )) return oL","title":"getAttributeListWithOrder()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.getCombinationCounts","text":"Count the value occurrences of the input attributeList in the category. Parameters: Name Type Description Default attributeList list target list of attribute names required Returns: Type Description cD[(attribute value, ... )] = count Source code in mmcif/api/DataCategory.py def getCombinationCounts ( self , attributeList ): \"\"\"Count the value occurrences of the input attributeList in the category. Args: attributeList (list): target list of attribute names Returns: cD[(attribute value, ... )] = count \"\"\" cD = {} try : idxL = [ self . _attributeNameList . index ( atName ) for atName in attributeList ] # for row in self . data : ky = tuple ([ row [ jj ] for jj in idxL ]) cD [ ky ] = cD [ ky ] + 1 if ky in cD else 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return cD","title":"getCombinationCounts()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.getCombinationCountsWithConditions","text":"Count the value occurrences of the input attributeList in the category. Parameters: Name Type Description Default attributeList list target list of attribute names required conditionTupleList list (attributeName, op, value) where (op = 'eq', 'gt(int)', 'lt(int)', 'in', 'ne', 'not in') required Returns: Type Description cD[(attribute value, ... )] = count Source code in mmcif/api/DataCategory.py def getCombinationCountsWithConditions ( self , attributeList , conditionTupleList ): \"\"\"Count the value occurrences of the input attributeList in the category. Args: attributeList (list): target list of attribute names conditionTupleList (list): (attributeName, op, value) where (op = 'eq', 'gt(int)', 'lt(int)', 'in', 'ne', 'not in') Returns: cD[(attribute value, ... )] = count \"\"\" cD = {} try : idxL = [ self . _attributeNameList . index ( atName ) for atName in attributeList ] idxD = { atName : self . _attributeNameList . index ( atName ) for ( atName , op , value ) in conditionTupleList } # for row in self . data : ok = True for ( atName , op , v ) in conditionTupleList : if op == \"eq\" : ok = ( v == row [ idxD [ atName ]]) and ok elif op == \"ne\" : ok = ( v != row [ idxD [ atName ]]) and ok elif op == \"lt(int)\" : ok = ( int ( row [ idxD [ atName ]]) < v ) and ok elif op == \"gt(int)\" : ok = ( int ( row [ idxD [ atName ]]) > v ) and ok elif op == \"in\" : ok = ( row [ idxD [ atName ]] in v ) and ok elif op == \"not in\" : ok = ( row [ idxD [ atName ]] not in v ) and ok if ok : ky = tuple ([ row [ jj ] for jj in idxL ]) cD [ ky ] = cD [ ky ] + 1 if ky in cD else 1 except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return cD","title":"getCombinationCountsWithConditions()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.getCurrentAttribute","text":"Source code in mmcif/api/DataCategory.py def getCurrentAttribute ( self ): return self . __currentAttribute","title":"getCurrentAttribute()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.getFirstValueOrDefault","text":"Return the value from the first non-null attribute found in the input attribute list from the row (rowIndex) in the current category object. Source code in mmcif/api/DataCategory.py def getFirstValueOrDefault ( self , attributeNameList , rowIndex = 0 , defaultValue = \"\" ): \"\"\"Return the value from the first non-null attribute found in the input attribute list from the row (rowIndex) in the current category object. \"\"\" try : for at in attributeNameList : if self . hasAttribute ( at ): tV = self . getValue ( at , rowIndex ) if ( tV is None ) or ( tV in [ \"\" , \".\" , \"?\" ]): continue else : return tV except Exception as e : logger . debug ( \"Failing with %s \" , str ( e )) # if self._raiseExceptions: # raise e return defaultValue","title":"getFirstValueOrDefault()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.getFullRow","text":"Return a full row based on the length of the the attribute list or a row initialized with missing values Source code in mmcif/api/DataCategory.py def getFullRow ( self , index ): \"\"\"Return a full row based on the length of the the attribute list or a row initialized with missing values\"\"\" try : if len ( self . data [ index ]) < self . _numAttributes : for _ in range ( self . _numAttributes - len ( self . data [ index ])): self . data [ index ] . append ( \"?\" ) return self . data [ index ] except Exception as e : logger . debug ( \"Returning an empty row at %d ( %s )\" , index , str ( e )) return [ \"?\" for ii in range ( self . _numAttributes )]","title":"getFullRow()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.getRowIndex","text":"Source code in mmcif/api/DataCategory.py def getRowIndex ( self ): return self . _currentRowIndex","title":"getRowIndex()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.getValue","text":"Source code in mmcif/api/DataCategory.py def getValue ( self , attributeName = None , rowIndex = None ): if attributeName is None : attribute = self . __currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ): try : return self . data [ rowI ][ self . _attributeNameList . index ( attribute )] except IndexError : if self . _raiseExceptions : raise IndexError if self . _raiseExceptions : raise IndexError ( attribute ) else : return None","title":"getValue()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.getValueOrDefault","text":"Within the current category return the value of input attribute in the input rowIndex [0-based]. On error or if the value missing or null return the default value. Empty values returned as is. Exceptions on for unknown attributeNames and out-of-range indices. Source code in mmcif/api/DataCategory.py def getValueOrDefault ( self , attributeName = None , rowIndex = None , defaultValue = \"\" ): \"\"\"Within the current category return the value of input attribute in the input rowIndex [0-based]. On error or if the value missing or null return the default value. Empty values returned as is. Exceptions on for unknown attributeNames and out-of-range indices. \"\"\" if attributeName is None : attribute = self . __currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ): try : tV = self . data [ rowI ][ self . _attributeNameList . index ( attribute )] if ( tV is None ) or ( tV in [ \".\" , \"?\" ]): return defaultValue else : return tV except Exception as e : logger . debug ( \"Failing attributeName %s rowIndex %r defaultValue %r with %s \" , attributeName , rowIndex , defaultValue , str ( e )) # if self._raiseExceptions: # raise e # Returning default -- no exception else : if self . _raiseExceptions : raise ValueError # return defaultValue","title":"getValueOrDefault()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.invokeAttributeMethod","text":"Source code in mmcif/api/DataCategory.py def invokeAttributeMethod ( self , attributeName , mType , method , db ): _ = mType _ = db self . _currentRowIndex = 0 self . __currentAttribute = attributeName self . appendAttribute ( attributeName ) currentRowIndex = self . _currentRowIndex # pylint: disable=possibly-unused-variable # ind = self . _attributeNameList . index ( attributeName ) if not self . data : row = [ None for ii in range ( len ( self . _attributeNameList ) * 2 )] row [ ind ] = None self . data . append ( row ) for row in self . data : ll = len ( row ) if ind >= ll : row . extend ([ None for ii in range ( 2 * ind - ll )]) row [ ind ] = None exec ( method . getInline (), globals (), locals ()) # pylint: disable=exec-used self . _currentRowIndex += 1 currentRowIndex = self . _currentRowIndex","title":"invokeAttributeMethod()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.invokeCategoryMethod","text":"Source code in mmcif/api/DataCategory.py def invokeCategoryMethod ( self , mType , method , db ): _ = mType _ = db self . _currentRowIndex = 0 exec ( method . getInline (), globals (), locals ()) # pylint: disable=exec-used","title":"invokeCategoryMethod()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.printIt","text":"Source code in mmcif/api/DataCategory.py def printIt ( self , fh = sys . stdout ): fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \" Category: %s attribute list length: %d \\n \" % ( self . _name , len ( self . _attributeNameList ))) for at in self . _attributeNameList : fh . write ( \" Category: %s attribute: %s \\n \" % ( self . _name , at )) fh . write ( \" Row value list length: %d \\n \" % len ( self . data )) # for row in self . data [: 2 ]: # if len ( row ) == len ( self . _attributeNameList ): for ii , v in enumerate ( row ): fh . write ( \" %30s : %s ... \\n \" % ( self . _attributeNameList [ ii ], str ( v )[: 30 ])) else : fh . write ( \"+WARNING - %s data length %d attribute name length %s mismatched \\n \" % ( self . _name , len ( row ), len ( self . _attributeNameList )))","title":"printIt()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.replaceSubstring","text":"Source code in mmcif/api/DataCategory.py def replaceSubstring ( self , oldValue , newValue , attributeName ): try : numReplace = 0 if attributeName not in self . _attributeNameList : return numReplace ind = self . _attributeNameList . index ( attributeName ) for row in self . data : val = row [ ind ] row [ ind ] = val . replace ( oldValue , newValue ) if val != row [ ind ]: numReplace += 1 return numReplace except Exception as e : if self . _raiseExceptions : raise e return numReplace","title":"replaceSubstring()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.replaceValue","text":"Source code in mmcif/api/DataCategory.py def replaceValue ( self , oldValue , newValue , attributeName ): try : numReplace = 0 if attributeName not in self . _attributeNameList : return numReplace ind = self . _attributeNameList . index ( attributeName ) for row in self . data : if row [ ind ] == oldValue : row [ ind ] = newValue numReplace += 1 return numReplace except Exception as e : if self . _raiseExceptions : raise e return numReplace","title":"replaceValue()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.selectIndices","text":"Source code in mmcif/api/DataCategory.py def selectIndices ( self , attributeValue , attributeName ): try : rL = [] if attributeName not in self . _attributeNameList : return rL ind = self . _attributeNameList . index ( attributeName ) for ii , row in enumerate ( self . data ): if attributeValue == row [ ind ]: rL . append ( ii ) return rL except Exception as e : if self . _raiseExceptions : raise e return rL","title":"selectIndices()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.selectIndicesFromList","text":"Source code in mmcif/api/DataCategory.py def selectIndicesFromList ( self , attributeValueList , attributeNameList ): rL = [] try : indList = [] for at in attributeNameList : indList . append ( self . _attributeNameList . index ( at )) indValList = list ( zip ( indList , attributeValueList )) # numList = len ( indValList ) for ii , row in enumerate ( self . data ): nMatch = 0 for ind , tVal in indValList : if tVal == row [ ind ]: nMatch += 1 if nMatch == numList : rL . append ( ii ) except Exception as e : if self . __verbose : logger . exception ( \"Selection/index failure for values %r \" , attributeValueList ) if self . _raiseExceptions : raise e return rL","title":"selectIndicesFromList()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.selectValueListWhere","text":"Return a list of lists containing the values of input attributeNameList satisfying the attribute value where condition. Source code in mmcif/api/DataCategory.py def selectValueListWhere ( self , attributeNameList , attributeValueWhere , attributeNameWhere , returnCount = 0 ): \"\"\"Return a list of lists containing the values of input attributeNameList satisfying the attribute value where condition. \"\"\" rL = [] try : iCount = 0 indList = [] for at in attributeNameList : indList . append ( self . _attributeNameList . index ( at )) indWhere = self . _attributeNameList . index ( attributeNameWhere ) for row in self . data : if attributeValueWhere == row [ indWhere ]: rL . append ([ row [ jj ] for jj in indList ]) iCount += 1 if returnCount and ( iCount >= returnCount ): break except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return rL","title":"selectValueListWhere()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.selectValuesWhere","text":"Source code in mmcif/api/DataCategory.py def selectValuesWhere ( self , attributeName , attributeValueWhere , attributeNameWhere , returnCount = 0 ): rL = [] try : iCount = 0 ind = self . _attributeNameList . index ( attributeName ) indWhere = self . _attributeNameList . index ( attributeNameWhere ) for row in self . data : if attributeValueWhere == row [ indWhere ]: rL . append ( row [ ind ]) iCount += 1 if returnCount and ( iCount >= returnCount ): break except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return rL","title":"selectValuesWhere()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.selectValuesWhereConditions","text":"Source code in mmcif/api/DataCategory.py def selectValuesWhereConditions ( self , attributeName , conditionsD , returnCount = 0 ): rL = [] try : iCount = 0 ind = self . _attributeNameList . index ( attributeName ) idxD = { k : self . _attributeNameList . index ( k ) for k , v in conditionsD . items ()} # # for row in self . data : ok = True for k , v in conditionsD . items (): ok = ( v == row [ idxD [ k ]]) and ok if ok : rL . append ( row [ ind ]) iCount += 1 if returnCount and ( iCount >= returnCount ): break except Exception as e : if self . __verbose : logger . exception ( \"Selection failure\" ) if self . _raiseExceptions : raise e return rL","title":"selectValuesWhereConditions()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.setValue","text":"Set the value of an existing attribute. rowIndex values >=0, where the category will be extended in length as needed. Source code in mmcif/api/DataCategory.py def setValue ( self , value , attributeName = None , rowIndex = None ): \"\"\"Set the value of an existing attribute. rowIndex values >=0, where the category will be extended in length as needed. \"\"\" if attributeName is None : attribute = self . __currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ) and ( rowI >= 0 ): try : ind = - 2 # if row index is out of range - add the rows - for ii in range ( rowI + 1 - len ( self . data )): self . data . append ( self . __emptyRow ()) # self.data[rowI][attribute]=value ll = len ( self . data [ rowI ]) ind = self . _attributeNameList . index ( attribute ) # extend the list if needed - if ind >= ll : self . data [ rowI ] . extend ([ None for ii in range ( ind - ( ll - 1 ))]) self . data [ rowI ][ ind ] = value return True except IndexError : if self . __verbose : logger . exception ( \"DataCategory(setvalue) index error category %s attribute %s row index %d col %d rowlen %d value %r \" , self . _name , attribute , rowI , ind , len ( self . data [ rowI ]), value , ) logger . debug ( \"DataCategory(setvalue) attribute %r length attribute list %d \" , attribute , len ( self . _attributeNameList )) for ii , aV in enumerate ( self . _attributeNameList ): logger . debug ( \"DataCategory(setvalue) %d attributeName %r \" , ii , aV ) if self . _raiseExceptions : raise IndexError except ValueError : if self . __verbose : logger . exception ( \"DataCategory(setvalue) value error category %s attribute %s row index %d value %r \" , self . _name , attribute , rowI , value ) if self . _raiseExceptions : raise ValueError else : if self . _raiseExceptions : raise ValueError return False","title":"setValue()"},{"location":"api_reference/DataCategory/#mmcif.api.DataCategory.DataCategory.setVerboseMode","text":"Source code in mmcif/api/DataCategory.py def setVerboseMode ( self , boolVal ): self . __verbose = boolVal","title":"setVerboseMode()"},{"location":"api_reference/DataCategoryBase/","text":"mmcif.api.DataCategoryBase.DataCategoryBase ( UserList ) Base object definition for a data category - This class subclasses UserList and implements many list-like features for row data managed by this class. Source code in mmcif/api/DataCategoryBase.py class DataCategoryBase ( UserList ): \"\"\"Base object definition for a data category - This class subclasses UserList and implements many list-like features for row data managed by this class. \"\"\" def __init__ ( self , name , attributeNameList = None , rowList = None , raiseExceptions = True , copyInputData = True ): self . _name = name if copyInputData : self . _attributeNameList = copy . deepcopy ( attributeNameList ) if attributeNameList is not None else [] # self.data = copy.deepcopy(rowList) if rowList is not None else [] else : self . _attributeNameList = attributeNameList if attributeNameList is not None else [] # self.data = rowList if rowList is not None else [] # # ------- if rowList is None or ( isinstance ( rowList , list ) and not rowList ): self . data = [] elif isinstance ( rowList , list ) and rowList : if isinstance ( rowList [ 0 ], ( list , tuple )): if copyInputData : self . data = copy . deepcopy ( rowList ) if rowList is not None else [] else : self . data = rowList if rowList is not None else [] elif isinstance ( rowList [ 0 ], dict ): rL = [] for rowD in rowList : rL . append ([ rowD [ k ] if k in rowD else None for k in self . _attributeNameList ]) if copyInputData : self . data = copy . deepcopy ( rL ) else : self . data = rL else : if raiseExceptions : raise ValueError else : logger . error ( \"Initialization failure\" ) else : if raiseExceptions : raise ValueError else : logger . error ( \"Initialization failure\" ) # ------- # self . _itemNameList = [] self . __mappingType = \"DATA\" self . _raiseExceptions = raiseExceptions self . _copyInputData = copyInputData # super ( DataCategoryBase , self ) . __init__ ( self . data ) # # Derived class data - # self . _catalog = {} self . _numAttributes = 0 # self . _stringTypes = basestring self . __setup () def __setup ( self ): self . _numAttributes = len ( self . _attributeNameList ) self . _catalog = {} for attributeName in self . _attributeNameList : attributeNameLC = attributeName . lower () self . _catalog [ attributeNameLC ] = attributeName self . __updateItemLabels () # Add append/extend methods to accept row lists and dictionaries - # def append ( self , row ): if isinstance ( row , ( list , tuple )): self . data . append ( row ) return True elif isinstance ( row , dict ): try : # - self . data . append ([ row [ k ] if k in row else None for k in self . _attributeNameList ]) return False except Exception as e : if self . _raiseExceptions : raise e else : logger . error ( \"Row processing failing with %s \" , str ( e )) else : if self . _raiseExceptions : raise ValueError else : logger . error ( \"Unsupported row type\" ) return False def extend ( self , rowList ): if isinstance ( rowList , list ) and rowList : if isinstance ( rowList [ 0 ], ( list , tuple )): if self . _copyInputData : self . data . extend ( copy . deepcopy ( rowList )) else : self . data . extend ( rowList ) return True elif isinstance ( rowList [ 0 ], dict ): rL = [] for rowD in rowList : # - rL . append ([ rowD [ k ] if k in rowD else None for k in self . _attributeNameList ]) if self . _copyInputData : self . data . extend ( copy . deepcopy ( rL )) else : self . data . extend ( rL ) return True else : if self . _raiseExceptions : raise ValueError else : logger . error ( \"unexpected row data type\" ) else : logger . error ( \"unexpected input data type\" ) return False # # Setters/appenders # def setName ( self , name ): self . _name = name def setRowList ( self , rowList ): if self . _copyInputData : self . data = copy . deepcopy ( rowList ) else : self . data = rowList def setAttributeNameList ( self , attributeNameList ): if self . _copyInputData : self . _attributeNameList = copy . deepcopy ( attributeNameList ) else : self . _attributeNameList = attributeNameList self . __setup () def appendAttribute ( self , attributeName ): attributeNameLC = attributeName . lower () if attributeNameLC in self . _catalog : i = self . _attributeNameList . index ( self . _catalog [ attributeNameLC ]) self . _attributeNameList [ i ] = attributeName self . _catalog [ attributeNameLC ] = attributeName else : self . _attributeNameList . append ( attributeName ) self . _catalog [ attributeNameLC ] = attributeName # self . _numAttributes = len ( self . _attributeNameList ) return self . _numAttributes def renameAttributes ( self , mapDict ): \"\"\"Rename attributes according to mapping information in the input mapping dictionary {oldName: newName}\"\"\" atL = [] for atName in self . _attributeNameList : atL . append ( mapDict [ atName ] if atName in mapDict else atName ) self . _attributeNameList = atL self . __setup () return True ## # Getters ## def get ( self ): return ( self . _name , self . _attributeNameList , self . data ) def getName ( self ): return self . _name def getAttributeList ( self ): return self . _attributeNameList def getAttributeCount ( self ): return len ( self . _attributeNameList ) def getAttributeIndex ( self , attributeName ): try : return self . _attributeNameList . index ( attributeName ) except Exception as e : logger . debug ( \"Fails for %s with %s \" , attributeName , str ( e )) return - 1 def getAttributeIndexDict ( self ): rD = {} for ii , attributeName in enumerate ( self . _attributeNameList ): rD [ attributeName ] = ii return rD def getIndex ( self , attributeName ): return self . getAttributeIndex ( attributeName ) def hasAttribute ( self , attributeName ): return attributeName in self . _attributeNameList def getItemNameList ( self ): return self . __updateItemLabels () def getRowList ( self ): return self . data def getRowCount ( self ): return len ( self . data ) def getRow ( self , index ): try : return self . data [ index ] except Exception as e : if self . _raiseExceptions : raise e return [] def getColumn ( self , index ): try : return [ row [ index ] for row in self . data ] except Exception as e : if self . _raiseExceptions : raise e return [] def getRowAttributeDict ( self , index ): rD = {} try : for ii , v in enumerate ( self . data [ index ]): rD [ self . _attributeNameList [ ii ]] = v return rD except Exception as e : if self . _raiseExceptions : raise e return rD def getRowItemDict ( self , index ): rD = {} try : self . __updateItemLabels () for ii , v in enumerate ( self . data [ index ]): rD [ self . _itemNameList [ ii ]] = v return rD except Exception as e : if self . _raiseExceptions : raise e return rD def getAttributeValueList ( self , attributeName ): \"\"\"Return a list of attribute values.\"\"\" rL = [] try : idx = self . getAttributeIndex ( attributeName ) rL = [ row [ idx ] for row in self . data ] return rL except Exception as e : if self . _raiseExceptions : raise e return rL def getAttributeUniqueValueList ( self , attributeName ): \"\"\"Return a sorted list of unique attribute values.\"\"\" rL = [] try : rD = {} idx = self . getAttributeIndex ( attributeName ) rD = { row [ idx ]: True for row in self . data } return sorted ( rD . keys ()) except Exception as e : if self . _raiseExceptions : raise e return rL def removeRow ( self , index ): try : del self . data [ index ] return True except Exception as e : if self . _raiseExceptions : raise e return False def removeRows ( self , indexList ): try : iL = sorted ( indexList , reverse = True ) for i in iL : del self . data [ i ] return True except Exception as e : if self . _raiseExceptions : raise e return False def removeDuplicateRows ( self ): \"\"\"Remove duplicate rows from the category Raises: e: any exception Returns: bool: True for success or False otherwise \"\"\" try : filteredL = [] for row in self . data : if row not in filteredL : filteredL . append ( row ) self . data = filteredL return True except Exception as e : if self . _raiseExceptions : raise e return False def removeAttribute ( self , attributeName ): \"\"\"Remove the attribute from the attribute list along with any corresponding row data. \"\"\" idx = self . getAttributeIndex ( attributeName ) if idx != - 1 : try : del self . _attributeNameList [ idx ] for row in self . data : try : del row [ idx ] except Exception : pass self . __setup () return True except Exception : return False ## ## ## def __updateItemLabels ( self ): \"\"\"Internal method to create mmCIF style item names for the current attribute list. \"\"\" self . _itemNameList = [] for atName in self . _attributeNameList : self . _itemNameList . append ( \"_\" + str ( self . _name ) + \".\" + atName ) # return self . _itemNameList def __alignLabels ( self , row ): \"\"\"Internal method which aligns the list of input attributes with row data. If there are fewer labels than data elements in a row, then placeholder labels are created (e.g. \"unlabeled_#\") \"\"\" if len ( row ) > len ( self . _attributeNameList ): for i in range ( len ( self . _attributeNameList ), len ( row ) - 1 ): self . _attributeNameList . insert ( i , \"unlabeled_\" + str ( i )) if self . __mappingType == \"ITEM\" : self . __updateItemLabels () def setMapping ( self , mType ): \"\"\"Controls the manner in which this class returns data when accessed by index or in the context of an iterator: DATA = list of row data elements as these were input. [default] ATTRIBUTE = row returned as a dictionary with attribute key ITEM = row returned as a dictionary with item key \"\"\" if mType in [ \"DATA\" , \"ATTRIBUTE\" , \"ITEM\" ]: self . __mappingType = mType return True else : return False def __str__ ( self ): ans = \"name: %r \\n attrbuteList: %r \\n Data: %r \\n \" % ( self . _name , self . _attributeNameList , list ( self . data )) return ans def __repr__ ( self ): return self . __class__ . __name__ + \"(\" + str ( self ) + \")\" def __iter__ ( self ): for dD in self . data : yield self . __applyMapping ( dD ) def __getitem__ ( self , idx ): return self . __applyMapping ( self . data [ idx ]) def __setitem__ ( self , idx , value ): dL = self . __extractMapping ( value ) self . data [ idx ] = dL def __applyMapping ( self , dD ): if self . __mappingType == \"DATA\" : return dD elif self . __mappingType == \"ATTRIBUTE\" : self . __alignLabels ( dD ) return dict ( list ( zip ( self . _attributeNameList , dD ))) elif self . __mappingType == \"ITEM\" : self . __alignLabels ( dD ) self . __updateItemLabels () return dict ( list ( zip ( self . _itemNameList , dD ))) def __extractMapping ( self , dD ): try : if self . __mappingType == \"DATA\" : return dD elif self . __mappingType == \"ATTRIBUTE\" : rL = [] for k , v in dD . items (): rL . insert ( self . _attributeNameList . index ( k ), v ) return rL elif self . __mappingType == \"ITEM\" : rL = [] for k , v in dD . items (): rL . insert ( self . _itemNameList . index ( k ), v ) return rL except Exception : if self . _raiseExceptions : raise IndexError return None def cmpAttributeNames ( self , dcObj ): \"\"\"Compare the attributeNameList in current data category (dca) and input data category . Return: (current attributes not in dcObj), (attributes common to both), (attributes in dcObj not in current data category) \"\"\" sa = set ( self . getAttributeList ()) sb = set ( dcObj . getAttributeList ()) return tuple ( sa - sb ), tuple ( sa & sb ), tuple ( sb - sa ) def cmpAttributeValues ( self , dcObj , ignoreOrder = True , ** kwargs ): \"\"\"Compare the values by attribute for current data category (dca) and input data category. The comparison is performed independently for the values of corresponding attributes. Length differences are treated inequality out of hand. Return: [(attributeName, values equal flag (bool)), (attributeName, values equal flag (bool), ...] \"\"\" rL = [] try : _ = kwargs sa = set ( self . getAttributeList ()) sb = set ( dcObj . getAttributeList ()) atComList = list ( sa & sb ) # lenEq = self . getRowCount () == dcObj . getRowCount () for at in atComList : if lenEq : if ignoreOrder : same = sorted ( self . getAttributeValueList ( at )) == sorted ( dcObj . getAttributeValueList ( at )) else : same = self . getAttributeValueList ( at ) == dcObj . getAttributeValueList ( at ) else : same = False rL . append (( at , same )) return rL except Exception as e : if self . _raiseExceptions : raise e return rL def __eq__ ( self , other ): \"\"\"Override the default Equals behavior\"\"\" if isinstance ( other , self . __class__ ): return self . __dict__ == other . __dict__ return NotImplemented def __ne__ ( self , other ): \"\"\"Define a non-equality test\"\"\" if isinstance ( other , self . __class__ ): return not self . __eq__ ( other ) return NotImplemented def __hash__ ( self ): \"\"\"Override the default hash behavior (that returns the id or the object)\"\"\" # return hash(tuple(sorted(self.__dict__.items()))) return hash (( self . _name , tuple ( self . _attributeNameList ), tuple ( tuple ( x ) for x in self . data ))) # Methods __eq__ ( self , other ) special Override the default Equals behavior Source code in mmcif/api/DataCategoryBase.py def __eq__ ( self , other ): \"\"\"Override the default Equals behavior\"\"\" if isinstance ( other , self . __class__ ): return self . __dict__ == other . __dict__ return NotImplemented __getitem__ ( self , idx ) special Source code in mmcif/api/DataCategoryBase.py def __getitem__ ( self , idx ): return self . __applyMapping ( self . data [ idx ]) __hash__ ( self ) special Override the default hash behavior (that returns the id or the object) Source code in mmcif/api/DataCategoryBase.py def __hash__ ( self ): \"\"\"Override the default hash behavior (that returns the id or the object)\"\"\" # return hash(tuple(sorted(self.__dict__.items()))) return hash (( self . _name , tuple ( self . _attributeNameList ), tuple ( tuple ( x ) for x in self . data ))) __init__ ( self , name , attributeNameList = None , rowList = None , raiseExceptions = True , copyInputData = True ) special Source code in mmcif/api/DataCategoryBase.py def __init__ ( self , name , attributeNameList = None , rowList = None , raiseExceptions = True , copyInputData = True ): self . _name = name if copyInputData : self . _attributeNameList = copy . deepcopy ( attributeNameList ) if attributeNameList is not None else [] # self.data = copy.deepcopy(rowList) if rowList is not None else [] else : self . _attributeNameList = attributeNameList if attributeNameList is not None else [] # self.data = rowList if rowList is not None else [] # # ------- if rowList is None or ( isinstance ( rowList , list ) and not rowList ): self . data = [] elif isinstance ( rowList , list ) and rowList : if isinstance ( rowList [ 0 ], ( list , tuple )): if copyInputData : self . data = copy . deepcopy ( rowList ) if rowList is not None else [] else : self . data = rowList if rowList is not None else [] elif isinstance ( rowList [ 0 ], dict ): rL = [] for rowD in rowList : rL . append ([ rowD [ k ] if k in rowD else None for k in self . _attributeNameList ]) if copyInputData : self . data = copy . deepcopy ( rL ) else : self . data = rL else : if raiseExceptions : raise ValueError else : logger . error ( \"Initialization failure\" ) else : if raiseExceptions : raise ValueError else : logger . error ( \"Initialization failure\" ) # ------- # self . _itemNameList = [] self . __mappingType = \"DATA\" self . _raiseExceptions = raiseExceptions self . _copyInputData = copyInputData # super ( DataCategoryBase , self ) . __init__ ( self . data ) # # Derived class data - # self . _catalog = {} self . _numAttributes = 0 # self . _stringTypes = basestring self . __setup () __iter__ ( self ) special Source code in mmcif/api/DataCategoryBase.py def __iter__ ( self ): for dD in self . data : yield self . __applyMapping ( dD ) __ne__ ( self , other ) special Define a non-equality test Source code in mmcif/api/DataCategoryBase.py def __ne__ ( self , other ): \"\"\"Define a non-equality test\"\"\" if isinstance ( other , self . __class__ ): return not self . __eq__ ( other ) return NotImplemented __repr__ ( self ) special Source code in mmcif/api/DataCategoryBase.py def __repr__ ( self ): return self . __class__ . __name__ + \"(\" + str ( self ) + \")\" __setitem__ ( self , idx , value ) special Source code in mmcif/api/DataCategoryBase.py def __setitem__ ( self , idx , value ): dL = self . __extractMapping ( value ) self . data [ idx ] = dL __str__ ( self ) special Source code in mmcif/api/DataCategoryBase.py def __str__ ( self ): ans = \"name: %r \\n attrbuteList: %r \\n Data: %r \\n \" % ( self . _name , self . _attributeNameList , list ( self . data )) return ans append ( self , row ) S.append(value) -- append value to the end of the sequence Source code in mmcif/api/DataCategoryBase.py def append ( self , row ): if isinstance ( row , ( list , tuple )): self . data . append ( row ) return True elif isinstance ( row , dict ): try : # - self . data . append ([ row [ k ] if k in row else None for k in self . _attributeNameList ]) return False except Exception as e : if self . _raiseExceptions : raise e else : logger . error ( \"Row processing failing with %s \" , str ( e )) else : if self . _raiseExceptions : raise ValueError else : logger . error ( \"Unsupported row type\" ) return False appendAttribute ( self , attributeName ) Source code in mmcif/api/DataCategoryBase.py def appendAttribute ( self , attributeName ): attributeNameLC = attributeName . lower () if attributeNameLC in self . _catalog : i = self . _attributeNameList . index ( self . _catalog [ attributeNameLC ]) self . _attributeNameList [ i ] = attributeName self . _catalog [ attributeNameLC ] = attributeName else : self . _attributeNameList . append ( attributeName ) self . _catalog [ attributeNameLC ] = attributeName # self . _numAttributes = len ( self . _attributeNameList ) return self . _numAttributes cmpAttributeNames ( self , dcObj ) Compare the attributeNameList in current data category (dca) and input data category . Return: (current attributes not in dcObj), (attributes common to both), (attributes in dcObj not in current data category) Source code in mmcif/api/DataCategoryBase.py def cmpAttributeNames ( self , dcObj ): \"\"\"Compare the attributeNameList in current data category (dca) and input data category . Return: (current attributes not in dcObj), (attributes common to both), (attributes in dcObj not in current data category) \"\"\" sa = set ( self . getAttributeList ()) sb = set ( dcObj . getAttributeList ()) return tuple ( sa - sb ), tuple ( sa & sb ), tuple ( sb - sa ) cmpAttributeValues ( self , dcObj , ignoreOrder = True , ** kwargs ) Compare the values by attribute for current data category (dca) and input data category. The comparison is performed independently for the values of corresponding attributes. Length differences are treated inequality out of hand. Return: [(attributeName, values equal flag (bool)), (attributeName, values equal flag (bool), ...] Source code in mmcif/api/DataCategoryBase.py def cmpAttributeValues ( self , dcObj , ignoreOrder = True , ** kwargs ): \"\"\"Compare the values by attribute for current data category (dca) and input data category. The comparison is performed independently for the values of corresponding attributes. Length differences are treated inequality out of hand. Return: [(attributeName, values equal flag (bool)), (attributeName, values equal flag (bool), ...] \"\"\" rL = [] try : _ = kwargs sa = set ( self . getAttributeList ()) sb = set ( dcObj . getAttributeList ()) atComList = list ( sa & sb ) # lenEq = self . getRowCount () == dcObj . getRowCount () for at in atComList : if lenEq : if ignoreOrder : same = sorted ( self . getAttributeValueList ( at )) == sorted ( dcObj . getAttributeValueList ( at )) else : same = self . getAttributeValueList ( at ) == dcObj . getAttributeValueList ( at ) else : same = False rL . append (( at , same )) return rL except Exception as e : if self . _raiseExceptions : raise e return rL extend ( self , rowList ) S.extend(iterable) -- extend sequence by appending elements from the iterable Source code in mmcif/api/DataCategoryBase.py def extend ( self , rowList ): if isinstance ( rowList , list ) and rowList : if isinstance ( rowList [ 0 ], ( list , tuple )): if self . _copyInputData : self . data . extend ( copy . deepcopy ( rowList )) else : self . data . extend ( rowList ) return True elif isinstance ( rowList [ 0 ], dict ): rL = [] for rowD in rowList : # - rL . append ([ rowD [ k ] if k in rowD else None for k in self . _attributeNameList ]) if self . _copyInputData : self . data . extend ( copy . deepcopy ( rL )) else : self . data . extend ( rL ) return True else : if self . _raiseExceptions : raise ValueError else : logger . error ( \"unexpected row data type\" ) else : logger . error ( \"unexpected input data type\" ) return False get ( self ) Source code in mmcif/api/DataCategoryBase.py def get ( self ): return ( self . _name , self . _attributeNameList , self . data ) getAttributeCount ( self ) Source code in mmcif/api/DataCategoryBase.py def getAttributeCount ( self ): return len ( self . _attributeNameList ) getAttributeIndex ( self , attributeName ) Source code in mmcif/api/DataCategoryBase.py def getAttributeIndex ( self , attributeName ): try : return self . _attributeNameList . index ( attributeName ) except Exception as e : logger . debug ( \"Fails for %s with %s \" , attributeName , str ( e )) return - 1 getAttributeIndexDict ( self ) Source code in mmcif/api/DataCategoryBase.py def getAttributeIndexDict ( self ): rD = {} for ii , attributeName in enumerate ( self . _attributeNameList ): rD [ attributeName ] = ii return rD getAttributeList ( self ) Source code in mmcif/api/DataCategoryBase.py def getAttributeList ( self ): return self . _attributeNameList getAttributeUniqueValueList ( self , attributeName ) Return a sorted list of unique attribute values. Source code in mmcif/api/DataCategoryBase.py def getAttributeUniqueValueList ( self , attributeName ): \"\"\"Return a sorted list of unique attribute values.\"\"\" rL = [] try : rD = {} idx = self . getAttributeIndex ( attributeName ) rD = { row [ idx ]: True for row in self . data } return sorted ( rD . keys ()) except Exception as e : if self . _raiseExceptions : raise e return rL getAttributeValueList ( self , attributeName ) Return a list of attribute values. Source code in mmcif/api/DataCategoryBase.py def getAttributeValueList ( self , attributeName ): \"\"\"Return a list of attribute values.\"\"\" rL = [] try : idx = self . getAttributeIndex ( attributeName ) rL = [ row [ idx ] for row in self . data ] return rL except Exception as e : if self . _raiseExceptions : raise e return rL getColumn ( self , index ) Source code in mmcif/api/DataCategoryBase.py def getColumn ( self , index ): try : return [ row [ index ] for row in self . data ] except Exception as e : if self . _raiseExceptions : raise e return [] getIndex ( self , attributeName ) Source code in mmcif/api/DataCategoryBase.py def getIndex ( self , attributeName ): return self . getAttributeIndex ( attributeName ) getItemNameList ( self ) Source code in mmcif/api/DataCategoryBase.py def getItemNameList ( self ): return self . __updateItemLabels () getName ( self ) Source code in mmcif/api/DataCategoryBase.py def getName ( self ): return self . _name getRow ( self , index ) Source code in mmcif/api/DataCategoryBase.py def getRow ( self , index ): try : return self . data [ index ] except Exception as e : if self . _raiseExceptions : raise e return [] getRowAttributeDict ( self , index ) Source code in mmcif/api/DataCategoryBase.py def getRowAttributeDict ( self , index ): rD = {} try : for ii , v in enumerate ( self . data [ index ]): rD [ self . _attributeNameList [ ii ]] = v return rD except Exception as e : if self . _raiseExceptions : raise e return rD getRowCount ( self ) Source code in mmcif/api/DataCategoryBase.py def getRowCount ( self ): return len ( self . data ) getRowItemDict ( self , index ) Source code in mmcif/api/DataCategoryBase.py def getRowItemDict ( self , index ): rD = {} try : self . __updateItemLabels () for ii , v in enumerate ( self . data [ index ]): rD [ self . _itemNameList [ ii ]] = v return rD except Exception as e : if self . _raiseExceptions : raise e return rD getRowList ( self ) Source code in mmcif/api/DataCategoryBase.py def getRowList ( self ): return self . data hasAttribute ( self , attributeName ) Source code in mmcif/api/DataCategoryBase.py def hasAttribute ( self , attributeName ): return attributeName in self . _attributeNameList removeAttribute ( self , attributeName ) Remove the attribute from the attribute list along with any corresponding row data. Source code in mmcif/api/DataCategoryBase.py def removeAttribute ( self , attributeName ): \"\"\"Remove the attribute from the attribute list along with any corresponding row data. \"\"\" idx = self . getAttributeIndex ( attributeName ) if idx != - 1 : try : del self . _attributeNameList [ idx ] for row in self . data : try : del row [ idx ] except Exception : pass self . __setup () return True except Exception : return False removeDuplicateRows ( self ) Remove duplicate rows from the category Exceptions: Type Description e any exception Returns: Type Description bool True for success or False otherwise Source code in mmcif/api/DataCategoryBase.py def removeDuplicateRows ( self ): \"\"\"Remove duplicate rows from the category Raises: e: any exception Returns: bool: True for success or False otherwise \"\"\" try : filteredL = [] for row in self . data : if row not in filteredL : filteredL . append ( row ) self . data = filteredL return True except Exception as e : if self . _raiseExceptions : raise e return False removeRow ( self , index ) Source code in mmcif/api/DataCategoryBase.py def removeRow ( self , index ): try : del self . data [ index ] return True except Exception as e : if self . _raiseExceptions : raise e return False removeRows ( self , indexList ) Source code in mmcif/api/DataCategoryBase.py def removeRows ( self , indexList ): try : iL = sorted ( indexList , reverse = True ) for i in iL : del self . data [ i ] return True except Exception as e : if self . _raiseExceptions : raise e return False renameAttributes ( self , mapDict ) Rename attributes according to mapping information in the input mapping dictionary {oldName: newName} Source code in mmcif/api/DataCategoryBase.py def renameAttributes ( self , mapDict ): \"\"\"Rename attributes according to mapping information in the input mapping dictionary {oldName: newName}\"\"\" atL = [] for atName in self . _attributeNameList : atL . append ( mapDict [ atName ] if atName in mapDict else atName ) self . _attributeNameList = atL self . __setup () return True setAttributeNameList ( self , attributeNameList ) Source code in mmcif/api/DataCategoryBase.py def setAttributeNameList ( self , attributeNameList ): if self . _copyInputData : self . _attributeNameList = copy . deepcopy ( attributeNameList ) else : self . _attributeNameList = attributeNameList self . __setup () setMapping ( self , mType ) Controls the manner in which this class returns data when accessed by index or in the context of an iterator: DATA = list of row data elements as these were input. [default] ATTRIBUTE = row returned as a dictionary with attribute key ITEM = row returned as a dictionary with item key Source code in mmcif/api/DataCategoryBase.py def setMapping ( self , mType ): \"\"\"Controls the manner in which this class returns data when accessed by index or in the context of an iterator: DATA = list of row data elements as these were input. [default] ATTRIBUTE = row returned as a dictionary with attribute key ITEM = row returned as a dictionary with item key \"\"\" if mType in [ \"DATA\" , \"ATTRIBUTE\" , \"ITEM\" ]: self . __mappingType = mType return True else : return False setName ( self , name ) Source code in mmcif/api/DataCategoryBase.py def setName ( self , name ): self . _name = name setRowList ( self , rowList ) Source code in mmcif/api/DataCategoryBase.py def setRowList ( self , rowList ): if self . _copyInputData : self . data = copy . deepcopy ( rowList ) else : self . data = rowList","title":"DataCategoryBase"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase","text":"Base object definition for a data category - This class subclasses UserList and implements many list-like features for row data managed by this class. Source code in mmcif/api/DataCategoryBase.py class DataCategoryBase ( UserList ): \"\"\"Base object definition for a data category - This class subclasses UserList and implements many list-like features for row data managed by this class. \"\"\" def __init__ ( self , name , attributeNameList = None , rowList = None , raiseExceptions = True , copyInputData = True ): self . _name = name if copyInputData : self . _attributeNameList = copy . deepcopy ( attributeNameList ) if attributeNameList is not None else [] # self.data = copy.deepcopy(rowList) if rowList is not None else [] else : self . _attributeNameList = attributeNameList if attributeNameList is not None else [] # self.data = rowList if rowList is not None else [] # # ------- if rowList is None or ( isinstance ( rowList , list ) and not rowList ): self . data = [] elif isinstance ( rowList , list ) and rowList : if isinstance ( rowList [ 0 ], ( list , tuple )): if copyInputData : self . data = copy . deepcopy ( rowList ) if rowList is not None else [] else : self . data = rowList if rowList is not None else [] elif isinstance ( rowList [ 0 ], dict ): rL = [] for rowD in rowList : rL . append ([ rowD [ k ] if k in rowD else None for k in self . _attributeNameList ]) if copyInputData : self . data = copy . deepcopy ( rL ) else : self . data = rL else : if raiseExceptions : raise ValueError else : logger . error ( \"Initialization failure\" ) else : if raiseExceptions : raise ValueError else : logger . error ( \"Initialization failure\" ) # ------- # self . _itemNameList = [] self . __mappingType = \"DATA\" self . _raiseExceptions = raiseExceptions self . _copyInputData = copyInputData # super ( DataCategoryBase , self ) . __init__ ( self . data ) # # Derived class data - # self . _catalog = {} self . _numAttributes = 0 # self . _stringTypes = basestring self . __setup () def __setup ( self ): self . _numAttributes = len ( self . _attributeNameList ) self . _catalog = {} for attributeName in self . _attributeNameList : attributeNameLC = attributeName . lower () self . _catalog [ attributeNameLC ] = attributeName self . __updateItemLabels () # Add append/extend methods to accept row lists and dictionaries - # def append ( self , row ): if isinstance ( row , ( list , tuple )): self . data . append ( row ) return True elif isinstance ( row , dict ): try : # - self . data . append ([ row [ k ] if k in row else None for k in self . _attributeNameList ]) return False except Exception as e : if self . _raiseExceptions : raise e else : logger . error ( \"Row processing failing with %s \" , str ( e )) else : if self . _raiseExceptions : raise ValueError else : logger . error ( \"Unsupported row type\" ) return False def extend ( self , rowList ): if isinstance ( rowList , list ) and rowList : if isinstance ( rowList [ 0 ], ( list , tuple )): if self . _copyInputData : self . data . extend ( copy . deepcopy ( rowList )) else : self . data . extend ( rowList ) return True elif isinstance ( rowList [ 0 ], dict ): rL = [] for rowD in rowList : # - rL . append ([ rowD [ k ] if k in rowD else None for k in self . _attributeNameList ]) if self . _copyInputData : self . data . extend ( copy . deepcopy ( rL )) else : self . data . extend ( rL ) return True else : if self . _raiseExceptions : raise ValueError else : logger . error ( \"unexpected row data type\" ) else : logger . error ( \"unexpected input data type\" ) return False # # Setters/appenders # def setName ( self , name ): self . _name = name def setRowList ( self , rowList ): if self . _copyInputData : self . data = copy . deepcopy ( rowList ) else : self . data = rowList def setAttributeNameList ( self , attributeNameList ): if self . _copyInputData : self . _attributeNameList = copy . deepcopy ( attributeNameList ) else : self . _attributeNameList = attributeNameList self . __setup () def appendAttribute ( self , attributeName ): attributeNameLC = attributeName . lower () if attributeNameLC in self . _catalog : i = self . _attributeNameList . index ( self . _catalog [ attributeNameLC ]) self . _attributeNameList [ i ] = attributeName self . _catalog [ attributeNameLC ] = attributeName else : self . _attributeNameList . append ( attributeName ) self . _catalog [ attributeNameLC ] = attributeName # self . _numAttributes = len ( self . _attributeNameList ) return self . _numAttributes def renameAttributes ( self , mapDict ): \"\"\"Rename attributes according to mapping information in the input mapping dictionary {oldName: newName}\"\"\" atL = [] for atName in self . _attributeNameList : atL . append ( mapDict [ atName ] if atName in mapDict else atName ) self . _attributeNameList = atL self . __setup () return True ## # Getters ## def get ( self ): return ( self . _name , self . _attributeNameList , self . data ) def getName ( self ): return self . _name def getAttributeList ( self ): return self . _attributeNameList def getAttributeCount ( self ): return len ( self . _attributeNameList ) def getAttributeIndex ( self , attributeName ): try : return self . _attributeNameList . index ( attributeName ) except Exception as e : logger . debug ( \"Fails for %s with %s \" , attributeName , str ( e )) return - 1 def getAttributeIndexDict ( self ): rD = {} for ii , attributeName in enumerate ( self . _attributeNameList ): rD [ attributeName ] = ii return rD def getIndex ( self , attributeName ): return self . getAttributeIndex ( attributeName ) def hasAttribute ( self , attributeName ): return attributeName in self . _attributeNameList def getItemNameList ( self ): return self . __updateItemLabels () def getRowList ( self ): return self . data def getRowCount ( self ): return len ( self . data ) def getRow ( self , index ): try : return self . data [ index ] except Exception as e : if self . _raiseExceptions : raise e return [] def getColumn ( self , index ): try : return [ row [ index ] for row in self . data ] except Exception as e : if self . _raiseExceptions : raise e return [] def getRowAttributeDict ( self , index ): rD = {} try : for ii , v in enumerate ( self . data [ index ]): rD [ self . _attributeNameList [ ii ]] = v return rD except Exception as e : if self . _raiseExceptions : raise e return rD def getRowItemDict ( self , index ): rD = {} try : self . __updateItemLabels () for ii , v in enumerate ( self . data [ index ]): rD [ self . _itemNameList [ ii ]] = v return rD except Exception as e : if self . _raiseExceptions : raise e return rD def getAttributeValueList ( self , attributeName ): \"\"\"Return a list of attribute values.\"\"\" rL = [] try : idx = self . getAttributeIndex ( attributeName ) rL = [ row [ idx ] for row in self . data ] return rL except Exception as e : if self . _raiseExceptions : raise e return rL def getAttributeUniqueValueList ( self , attributeName ): \"\"\"Return a sorted list of unique attribute values.\"\"\" rL = [] try : rD = {} idx = self . getAttributeIndex ( attributeName ) rD = { row [ idx ]: True for row in self . data } return sorted ( rD . keys ()) except Exception as e : if self . _raiseExceptions : raise e return rL def removeRow ( self , index ): try : del self . data [ index ] return True except Exception as e : if self . _raiseExceptions : raise e return False def removeRows ( self , indexList ): try : iL = sorted ( indexList , reverse = True ) for i in iL : del self . data [ i ] return True except Exception as e : if self . _raiseExceptions : raise e return False def removeDuplicateRows ( self ): \"\"\"Remove duplicate rows from the category Raises: e: any exception Returns: bool: True for success or False otherwise \"\"\" try : filteredL = [] for row in self . data : if row not in filteredL : filteredL . append ( row ) self . data = filteredL return True except Exception as e : if self . _raiseExceptions : raise e return False def removeAttribute ( self , attributeName ): \"\"\"Remove the attribute from the attribute list along with any corresponding row data. \"\"\" idx = self . getAttributeIndex ( attributeName ) if idx != - 1 : try : del self . _attributeNameList [ idx ] for row in self . data : try : del row [ idx ] except Exception : pass self . __setup () return True except Exception : return False ## ## ## def __updateItemLabels ( self ): \"\"\"Internal method to create mmCIF style item names for the current attribute list. \"\"\" self . _itemNameList = [] for atName in self . _attributeNameList : self . _itemNameList . append ( \"_\" + str ( self . _name ) + \".\" + atName ) # return self . _itemNameList def __alignLabels ( self , row ): \"\"\"Internal method which aligns the list of input attributes with row data. If there are fewer labels than data elements in a row, then placeholder labels are created (e.g. \"unlabeled_#\") \"\"\" if len ( row ) > len ( self . _attributeNameList ): for i in range ( len ( self . _attributeNameList ), len ( row ) - 1 ): self . _attributeNameList . insert ( i , \"unlabeled_\" + str ( i )) if self . __mappingType == \"ITEM\" : self . __updateItemLabels () def setMapping ( self , mType ): \"\"\"Controls the manner in which this class returns data when accessed by index or in the context of an iterator: DATA = list of row data elements as these were input. [default] ATTRIBUTE = row returned as a dictionary with attribute key ITEM = row returned as a dictionary with item key \"\"\" if mType in [ \"DATA\" , \"ATTRIBUTE\" , \"ITEM\" ]: self . __mappingType = mType return True else : return False def __str__ ( self ): ans = \"name: %r \\n attrbuteList: %r \\n Data: %r \\n \" % ( self . _name , self . _attributeNameList , list ( self . data )) return ans def __repr__ ( self ): return self . __class__ . __name__ + \"(\" + str ( self ) + \")\" def __iter__ ( self ): for dD in self . data : yield self . __applyMapping ( dD ) def __getitem__ ( self , idx ): return self . __applyMapping ( self . data [ idx ]) def __setitem__ ( self , idx , value ): dL = self . __extractMapping ( value ) self . data [ idx ] = dL def __applyMapping ( self , dD ): if self . __mappingType == \"DATA\" : return dD elif self . __mappingType == \"ATTRIBUTE\" : self . __alignLabels ( dD ) return dict ( list ( zip ( self . _attributeNameList , dD ))) elif self . __mappingType == \"ITEM\" : self . __alignLabels ( dD ) self . __updateItemLabels () return dict ( list ( zip ( self . _itemNameList , dD ))) def __extractMapping ( self , dD ): try : if self . __mappingType == \"DATA\" : return dD elif self . __mappingType == \"ATTRIBUTE\" : rL = [] for k , v in dD . items (): rL . insert ( self . _attributeNameList . index ( k ), v ) return rL elif self . __mappingType == \"ITEM\" : rL = [] for k , v in dD . items (): rL . insert ( self . _itemNameList . index ( k ), v ) return rL except Exception : if self . _raiseExceptions : raise IndexError return None def cmpAttributeNames ( self , dcObj ): \"\"\"Compare the attributeNameList in current data category (dca) and input data category . Return: (current attributes not in dcObj), (attributes common to both), (attributes in dcObj not in current data category) \"\"\" sa = set ( self . getAttributeList ()) sb = set ( dcObj . getAttributeList ()) return tuple ( sa - sb ), tuple ( sa & sb ), tuple ( sb - sa ) def cmpAttributeValues ( self , dcObj , ignoreOrder = True , ** kwargs ): \"\"\"Compare the values by attribute for current data category (dca) and input data category. The comparison is performed independently for the values of corresponding attributes. Length differences are treated inequality out of hand. Return: [(attributeName, values equal flag (bool)), (attributeName, values equal flag (bool), ...] \"\"\" rL = [] try : _ = kwargs sa = set ( self . getAttributeList ()) sb = set ( dcObj . getAttributeList ()) atComList = list ( sa & sb ) # lenEq = self . getRowCount () == dcObj . getRowCount () for at in atComList : if lenEq : if ignoreOrder : same = sorted ( self . getAttributeValueList ( at )) == sorted ( dcObj . getAttributeValueList ( at )) else : same = self . getAttributeValueList ( at ) == dcObj . getAttributeValueList ( at ) else : same = False rL . append (( at , same )) return rL except Exception as e : if self . _raiseExceptions : raise e return rL def __eq__ ( self , other ): \"\"\"Override the default Equals behavior\"\"\" if isinstance ( other , self . __class__ ): return self . __dict__ == other . __dict__ return NotImplemented def __ne__ ( self , other ): \"\"\"Define a non-equality test\"\"\" if isinstance ( other , self . __class__ ): return not self . __eq__ ( other ) return NotImplemented def __hash__ ( self ): \"\"\"Override the default hash behavior (that returns the id or the object)\"\"\" # return hash(tuple(sorted(self.__dict__.items()))) return hash (( self . _name , tuple ( self . _attributeNameList ), tuple ( tuple ( x ) for x in self . data ))) #","title":"DataCategoryBase"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase-methods","text":"","title":"Methods"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.__eq__","text":"Override the default Equals behavior Source code in mmcif/api/DataCategoryBase.py def __eq__ ( self , other ): \"\"\"Override the default Equals behavior\"\"\" if isinstance ( other , self . __class__ ): return self . __dict__ == other . __dict__ return NotImplemented","title":"__eq__()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.__getitem__","text":"Source code in mmcif/api/DataCategoryBase.py def __getitem__ ( self , idx ): return self . __applyMapping ( self . data [ idx ])","title":"__getitem__()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.__hash__","text":"Override the default hash behavior (that returns the id or the object) Source code in mmcif/api/DataCategoryBase.py def __hash__ ( self ): \"\"\"Override the default hash behavior (that returns the id or the object)\"\"\" # return hash(tuple(sorted(self.__dict__.items()))) return hash (( self . _name , tuple ( self . _attributeNameList ), tuple ( tuple ( x ) for x in self . data )))","title":"__hash__()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.__init__","text":"Source code in mmcif/api/DataCategoryBase.py def __init__ ( self , name , attributeNameList = None , rowList = None , raiseExceptions = True , copyInputData = True ): self . _name = name if copyInputData : self . _attributeNameList = copy . deepcopy ( attributeNameList ) if attributeNameList is not None else [] # self.data = copy.deepcopy(rowList) if rowList is not None else [] else : self . _attributeNameList = attributeNameList if attributeNameList is not None else [] # self.data = rowList if rowList is not None else [] # # ------- if rowList is None or ( isinstance ( rowList , list ) and not rowList ): self . data = [] elif isinstance ( rowList , list ) and rowList : if isinstance ( rowList [ 0 ], ( list , tuple )): if copyInputData : self . data = copy . deepcopy ( rowList ) if rowList is not None else [] else : self . data = rowList if rowList is not None else [] elif isinstance ( rowList [ 0 ], dict ): rL = [] for rowD in rowList : rL . append ([ rowD [ k ] if k in rowD else None for k in self . _attributeNameList ]) if copyInputData : self . data = copy . deepcopy ( rL ) else : self . data = rL else : if raiseExceptions : raise ValueError else : logger . error ( \"Initialization failure\" ) else : if raiseExceptions : raise ValueError else : logger . error ( \"Initialization failure\" ) # ------- # self . _itemNameList = [] self . __mappingType = \"DATA\" self . _raiseExceptions = raiseExceptions self . _copyInputData = copyInputData # super ( DataCategoryBase , self ) . __init__ ( self . data ) # # Derived class data - # self . _catalog = {} self . _numAttributes = 0 # self . _stringTypes = basestring self . __setup ()","title":"__init__()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.__iter__","text":"Source code in mmcif/api/DataCategoryBase.py def __iter__ ( self ): for dD in self . data : yield self . __applyMapping ( dD )","title":"__iter__()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.__ne__","text":"Define a non-equality test Source code in mmcif/api/DataCategoryBase.py def __ne__ ( self , other ): \"\"\"Define a non-equality test\"\"\" if isinstance ( other , self . __class__ ): return not self . __eq__ ( other ) return NotImplemented","title":"__ne__()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.__repr__","text":"Source code in mmcif/api/DataCategoryBase.py def __repr__ ( self ): return self . __class__ . __name__ + \"(\" + str ( self ) + \")\"","title":"__repr__()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.__setitem__","text":"Source code in mmcif/api/DataCategoryBase.py def __setitem__ ( self , idx , value ): dL = self . __extractMapping ( value ) self . data [ idx ] = dL","title":"__setitem__()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.__str__","text":"Source code in mmcif/api/DataCategoryBase.py def __str__ ( self ): ans = \"name: %r \\n attrbuteList: %r \\n Data: %r \\n \" % ( self . _name , self . _attributeNameList , list ( self . data )) return ans","title":"__str__()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.append","text":"S.append(value) -- append value to the end of the sequence Source code in mmcif/api/DataCategoryBase.py def append ( self , row ): if isinstance ( row , ( list , tuple )): self . data . append ( row ) return True elif isinstance ( row , dict ): try : # - self . data . append ([ row [ k ] if k in row else None for k in self . _attributeNameList ]) return False except Exception as e : if self . _raiseExceptions : raise e else : logger . error ( \"Row processing failing with %s \" , str ( e )) else : if self . _raiseExceptions : raise ValueError else : logger . error ( \"Unsupported row type\" ) return False","title":"append()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.appendAttribute","text":"Source code in mmcif/api/DataCategoryBase.py def appendAttribute ( self , attributeName ): attributeNameLC = attributeName . lower () if attributeNameLC in self . _catalog : i = self . _attributeNameList . index ( self . _catalog [ attributeNameLC ]) self . _attributeNameList [ i ] = attributeName self . _catalog [ attributeNameLC ] = attributeName else : self . _attributeNameList . append ( attributeName ) self . _catalog [ attributeNameLC ] = attributeName # self . _numAttributes = len ( self . _attributeNameList ) return self . _numAttributes","title":"appendAttribute()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.cmpAttributeNames","text":"Compare the attributeNameList in current data category (dca) and input data category . Return: (current attributes not in dcObj), (attributes common to both), (attributes in dcObj not in current data category) Source code in mmcif/api/DataCategoryBase.py def cmpAttributeNames ( self , dcObj ): \"\"\"Compare the attributeNameList in current data category (dca) and input data category . Return: (current attributes not in dcObj), (attributes common to both), (attributes in dcObj not in current data category) \"\"\" sa = set ( self . getAttributeList ()) sb = set ( dcObj . getAttributeList ()) return tuple ( sa - sb ), tuple ( sa & sb ), tuple ( sb - sa )","title":"cmpAttributeNames()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.cmpAttributeValues","text":"Compare the values by attribute for current data category (dca) and input data category. The comparison is performed independently for the values of corresponding attributes. Length differences are treated inequality out of hand. Return: [(attributeName, values equal flag (bool)), (attributeName, values equal flag (bool), ...] Source code in mmcif/api/DataCategoryBase.py def cmpAttributeValues ( self , dcObj , ignoreOrder = True , ** kwargs ): \"\"\"Compare the values by attribute for current data category (dca) and input data category. The comparison is performed independently for the values of corresponding attributes. Length differences are treated inequality out of hand. Return: [(attributeName, values equal flag (bool)), (attributeName, values equal flag (bool), ...] \"\"\" rL = [] try : _ = kwargs sa = set ( self . getAttributeList ()) sb = set ( dcObj . getAttributeList ()) atComList = list ( sa & sb ) # lenEq = self . getRowCount () == dcObj . getRowCount () for at in atComList : if lenEq : if ignoreOrder : same = sorted ( self . getAttributeValueList ( at )) == sorted ( dcObj . getAttributeValueList ( at )) else : same = self . getAttributeValueList ( at ) == dcObj . getAttributeValueList ( at ) else : same = False rL . append (( at , same )) return rL except Exception as e : if self . _raiseExceptions : raise e return rL","title":"cmpAttributeValues()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.extend","text":"S.extend(iterable) -- extend sequence by appending elements from the iterable Source code in mmcif/api/DataCategoryBase.py def extend ( self , rowList ): if isinstance ( rowList , list ) and rowList : if isinstance ( rowList [ 0 ], ( list , tuple )): if self . _copyInputData : self . data . extend ( copy . deepcopy ( rowList )) else : self . data . extend ( rowList ) return True elif isinstance ( rowList [ 0 ], dict ): rL = [] for rowD in rowList : # - rL . append ([ rowD [ k ] if k in rowD else None for k in self . _attributeNameList ]) if self . _copyInputData : self . data . extend ( copy . deepcopy ( rL )) else : self . data . extend ( rL ) return True else : if self . _raiseExceptions : raise ValueError else : logger . error ( \"unexpected row data type\" ) else : logger . error ( \"unexpected input data type\" ) return False","title":"extend()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.get","text":"Source code in mmcif/api/DataCategoryBase.py def get ( self ): return ( self . _name , self . _attributeNameList , self . data )","title":"get()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getAttributeCount","text":"Source code in mmcif/api/DataCategoryBase.py def getAttributeCount ( self ): return len ( self . _attributeNameList )","title":"getAttributeCount()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getAttributeIndex","text":"Source code in mmcif/api/DataCategoryBase.py def getAttributeIndex ( self , attributeName ): try : return self . _attributeNameList . index ( attributeName ) except Exception as e : logger . debug ( \"Fails for %s with %s \" , attributeName , str ( e )) return - 1","title":"getAttributeIndex()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getAttributeIndexDict","text":"Source code in mmcif/api/DataCategoryBase.py def getAttributeIndexDict ( self ): rD = {} for ii , attributeName in enumerate ( self . _attributeNameList ): rD [ attributeName ] = ii return rD","title":"getAttributeIndexDict()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getAttributeList","text":"Source code in mmcif/api/DataCategoryBase.py def getAttributeList ( self ): return self . _attributeNameList","title":"getAttributeList()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getAttributeUniqueValueList","text":"Return a sorted list of unique attribute values. Source code in mmcif/api/DataCategoryBase.py def getAttributeUniqueValueList ( self , attributeName ): \"\"\"Return a sorted list of unique attribute values.\"\"\" rL = [] try : rD = {} idx = self . getAttributeIndex ( attributeName ) rD = { row [ idx ]: True for row in self . data } return sorted ( rD . keys ()) except Exception as e : if self . _raiseExceptions : raise e return rL","title":"getAttributeUniqueValueList()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getAttributeValueList","text":"Return a list of attribute values. Source code in mmcif/api/DataCategoryBase.py def getAttributeValueList ( self , attributeName ): \"\"\"Return a list of attribute values.\"\"\" rL = [] try : idx = self . getAttributeIndex ( attributeName ) rL = [ row [ idx ] for row in self . data ] return rL except Exception as e : if self . _raiseExceptions : raise e return rL","title":"getAttributeValueList()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getColumn","text":"Source code in mmcif/api/DataCategoryBase.py def getColumn ( self , index ): try : return [ row [ index ] for row in self . data ] except Exception as e : if self . _raiseExceptions : raise e return []","title":"getColumn()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getIndex","text":"Source code in mmcif/api/DataCategoryBase.py def getIndex ( self , attributeName ): return self . getAttributeIndex ( attributeName )","title":"getIndex()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getItemNameList","text":"Source code in mmcif/api/DataCategoryBase.py def getItemNameList ( self ): return self . __updateItemLabels ()","title":"getItemNameList()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getName","text":"Source code in mmcif/api/DataCategoryBase.py def getName ( self ): return self . _name","title":"getName()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getRow","text":"Source code in mmcif/api/DataCategoryBase.py def getRow ( self , index ): try : return self . data [ index ] except Exception as e : if self . _raiseExceptions : raise e return []","title":"getRow()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getRowAttributeDict","text":"Source code in mmcif/api/DataCategoryBase.py def getRowAttributeDict ( self , index ): rD = {} try : for ii , v in enumerate ( self . data [ index ]): rD [ self . _attributeNameList [ ii ]] = v return rD except Exception as e : if self . _raiseExceptions : raise e return rD","title":"getRowAttributeDict()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getRowCount","text":"Source code in mmcif/api/DataCategoryBase.py def getRowCount ( self ): return len ( self . data )","title":"getRowCount()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getRowItemDict","text":"Source code in mmcif/api/DataCategoryBase.py def getRowItemDict ( self , index ): rD = {} try : self . __updateItemLabels () for ii , v in enumerate ( self . data [ index ]): rD [ self . _itemNameList [ ii ]] = v return rD except Exception as e : if self . _raiseExceptions : raise e return rD","title":"getRowItemDict()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.getRowList","text":"Source code in mmcif/api/DataCategoryBase.py def getRowList ( self ): return self . data","title":"getRowList()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.hasAttribute","text":"Source code in mmcif/api/DataCategoryBase.py def hasAttribute ( self , attributeName ): return attributeName in self . _attributeNameList","title":"hasAttribute()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.removeAttribute","text":"Remove the attribute from the attribute list along with any corresponding row data. Source code in mmcif/api/DataCategoryBase.py def removeAttribute ( self , attributeName ): \"\"\"Remove the attribute from the attribute list along with any corresponding row data. \"\"\" idx = self . getAttributeIndex ( attributeName ) if idx != - 1 : try : del self . _attributeNameList [ idx ] for row in self . data : try : del row [ idx ] except Exception : pass self . __setup () return True except Exception : return False","title":"removeAttribute()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.removeDuplicateRows","text":"Remove duplicate rows from the category Exceptions: Type Description e any exception Returns: Type Description bool True for success or False otherwise Source code in mmcif/api/DataCategoryBase.py def removeDuplicateRows ( self ): \"\"\"Remove duplicate rows from the category Raises: e: any exception Returns: bool: True for success or False otherwise \"\"\" try : filteredL = [] for row in self . data : if row not in filteredL : filteredL . append ( row ) self . data = filteredL return True except Exception as e : if self . _raiseExceptions : raise e return False","title":"removeDuplicateRows()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.removeRow","text":"Source code in mmcif/api/DataCategoryBase.py def removeRow ( self , index ): try : del self . data [ index ] return True except Exception as e : if self . _raiseExceptions : raise e return False","title":"removeRow()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.removeRows","text":"Source code in mmcif/api/DataCategoryBase.py def removeRows ( self , indexList ): try : iL = sorted ( indexList , reverse = True ) for i in iL : del self . data [ i ] return True except Exception as e : if self . _raiseExceptions : raise e return False","title":"removeRows()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.renameAttributes","text":"Rename attributes according to mapping information in the input mapping dictionary {oldName: newName} Source code in mmcif/api/DataCategoryBase.py def renameAttributes ( self , mapDict ): \"\"\"Rename attributes according to mapping information in the input mapping dictionary {oldName: newName}\"\"\" atL = [] for atName in self . _attributeNameList : atL . append ( mapDict [ atName ] if atName in mapDict else atName ) self . _attributeNameList = atL self . __setup () return True","title":"renameAttributes()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.setAttributeNameList","text":"Source code in mmcif/api/DataCategoryBase.py def setAttributeNameList ( self , attributeNameList ): if self . _copyInputData : self . _attributeNameList = copy . deepcopy ( attributeNameList ) else : self . _attributeNameList = attributeNameList self . __setup ()","title":"setAttributeNameList()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.setMapping","text":"Controls the manner in which this class returns data when accessed by index or in the context of an iterator: DATA = list of row data elements as these were input. [default] ATTRIBUTE = row returned as a dictionary with attribute key ITEM = row returned as a dictionary with item key Source code in mmcif/api/DataCategoryBase.py def setMapping ( self , mType ): \"\"\"Controls the manner in which this class returns data when accessed by index or in the context of an iterator: DATA = list of row data elements as these were input. [default] ATTRIBUTE = row returned as a dictionary with attribute key ITEM = row returned as a dictionary with item key \"\"\" if mType in [ \"DATA\" , \"ATTRIBUTE\" , \"ITEM\" ]: self . __mappingType = mType return True else : return False","title":"setMapping()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.setName","text":"Source code in mmcif/api/DataCategoryBase.py def setName ( self , name ): self . _name = name","title":"setName()"},{"location":"api_reference/DataCategoryBase/#mmcif.api.DataCategoryBase.DataCategoryBase.setRowList","text":"Source code in mmcif/api/DataCategoryBase.py def setRowList ( self , rowList ): if self . _copyInputData : self . data = copy . deepcopy ( rowList ) else : self . data = rowList","title":"setRowList()"},{"location":"api_reference/DataCategoryFormatted/","text":"mmcif.api.DataCategoryFormatted.DataCategoryFormatted ( DataCategory ) A subclass of DataCategory including additional formatting methods. Source code in mmcif/api/DataCategoryFormatted.py class DataCategoryFormatted ( DataCategory ): \"\"\"A subclass of DataCategory including additional formatting methods.\"\"\" def __init__ ( self , dataCategoryObj , preferDoubleQuotes = True ): self . __dcObj = dataCategoryObj super ( DataCategoryFormatted , self ) . __init__ ( self . __dcObj . getName (), self . __dcObj . getAttributeList (), self . __dcObj . data ) # self . _currentRowIndex = 0 self . _currentAttribute = None # self . __avoidEmbeddedQuoting = False self . __preferDoubleQuotes = preferDoubleQuotes # # -------------------------------------------------------------------- # any whitespace self . __wsRe = re . compile ( r \"\\s\" ) # self.__wsAndQuotesRe=re.compile(r\"[\\s'\\\"]\") self . __wsAndQuotesRe = re . compile ( r \"[\\s' \\\" #]\" ) # any newline or carriage control self . __nlRe = re . compile ( r \"[\\n\\r]\" ) # # single quote self . __sqRe = re . compile ( r \"[']\" ) # self . __sqWsRe = re . compile ( r \"('\\s)|(\\s')\" ) # double quote self . __dqRe = re . compile ( r '[\"]' ) self . __dqWsRe = re . compile ( r '(\"\\s)|(\\s\")' ) # self . __intRe = re . compile ( r \"^[0-9]+$\" ) self . __floatRe = re . compile ( r \"^-?(([0-9]+)[.]?|([0-9]*[.][0-9]+))([(][0-9]+[)])?([eE][+-]?[0-9]+)?$\" ) # self . __dataTypeList = [ \"DT_NULL_VALUE\" , \"DT_INTEGER\" , \"DT_FLOAT\" , \"DT_UNQUOTED_STRING\" , \"DT_ITEM_NAME\" , \"DT_DOUBLE_QUOTED_STRING\" , \"DT_SINGLE_QUOTED_STRING\" , \"DT_MULTI_LINE_STRING\" , ] self . __formatTypeList = [ \"FT_NULL_VALUE\" , \"FT_NUMBER\" , \"FT_NUMBER\" , \"FT_UNQUOTED_STRING\" , \"FT_QUOTED_STRING\" , \"FT_QUOTED_STRING\" , \"FT_QUOTED_STRING\" , \"FT_MULTI_LINE_STRING\" , ] # # try: # basestring # except NameError: # basestring = str # # self.__string_types = basestring def __formatPdbx ( self , inp ): \"\"\"Format input data following PDBx quoting rules -\"\"\" try : if inp is None : return ( \"?\" , \"DT_NULL_VALUE\" ) # pure numerical values are returned as unquoted strings # if (isinstance(inp, int) or self.__intRe.search(str(inp))): # try : if isinstance ( inp , int ) or self . __intRe . search ( inp ): return ([ str ( inp )], \"DT_INTEGER\" ) except Exception : pass # if (isinstance(inp, float) or self.__floatRe.search(str(inp))): try : if isinstance ( inp , float ) or self . __floatRe . search ( inp ): return ([ str ( inp )], \"DT_FLOAT\" ) except Exception : pass # null value handling - if inp == \".\" or inp == \"?\" : return ([ inp ], \"DT_NULL_VALUE\" ) if inp == \"\" : return ([ \".\" ], \"DT_NULL_VALUE\" ) # Contains white space or quotes ? if not self . __wsAndQuotesRe . search ( inp ): # if inp.startswith(\"_\"): if inp [ 0 ] in [ \"_\" ]: return ( self . __doubleQuotedList ( inp ), \"DT_ITEM_NAME\" ) elif inp [ 0 ] in [ \"[\" , \"]\" , \"$\" , \"#\" , \";\" ]: return ( self . __doubleQuotedList ( inp ), \"DT_DOUBLE_QUOTED_STRING\" ) elif inp [: 5 ] . lower () in [ \"data_\" , \"loop_\" , \"save_\" ]: return ( self . __doubleQuotedList ( inp ), \"DT_DOUBLE_QUOTED_STRING\" ) else : return ([ str ( inp )], \"DT_UNQUOTED_STRING\" ) else : if self . __nlRe . search ( inp ): return ( self . __semiColonQuotedList ( inp ), \"DT_MULTI_LINE_STRING\" ) else : if self . __preferDoubleQuotes : if self . __avoidEmbeddedQuoting : # change priority to choose double quoting where possible. if not self . __dqRe . search ( inp ) and not self . __sqWsRe . search ( inp ): return ( self . __doubleQuotedList ( inp ), \"DT_DOUBLE_QUOTED_STRING\" ) elif not self . __sqRe . search ( inp ) and not self . __dqWsRe . search ( inp ): return ( self . __singleQuotedList ( inp ), \"DT_SINGLE_QUOTED_STRING\" ) else : return ( self . __semiColonQuotedList ( inp ), \"DT_MULTI_LINE_STRING\" ) else : # change priority to choose double quoting where possible. if not self . __dqRe . search ( inp ): return ( self . __doubleQuotedList ( inp ), \"DT_DOUBLE_QUOTED_STRING\" ) elif not self . __sqRe . search ( inp ): return ( self . __singleQuotedList ( inp ), \"DT_SINGLE_QUOTED_STRING\" ) else : return ( self . __semiColonQuotedList ( inp ), \"DT_MULTI_LINE_STRING\" ) else : if self . __avoidEmbeddedQuoting : # change priority to choose double quoting where possible. if not self . __sqRe . search ( inp ) and not self . __dqWsRe . search ( inp ): return ( self . __singleQuotedList ( inp ), \"DT_SINGLE_QUOTED_STRING\" ) elif not self . __dqRe . search ( inp ) and not self . __sqWsRe . search ( inp ): return ( self . __doubleQuotedList ( inp ), \"DT_DOUBLE_QUOTED_STRING\" ) else : return ( self . __semiColonQuotedList ( inp ), \"DT_MULTI_LINE_STRING\" ) else : # change priority to choose double quoting where possible. if not self . __sqRe . search ( inp ): return ( self . __singleQuotedList ( inp ), \"DT_SINGLE_QUOTED_STRING\" ) elif not self . __dqRe . search ( inp ): return ( self . __doubleQuotedList ( inp ), \"DT_DOUBLE_QUOTED_STRING\" ) else : return ( self . __semiColonQuotedList ( inp ), \"DT_MULTI_LINE_STRING\" ) except Exception as e : logger . exception ( \"Failing with %s on input %r %r \" , str ( e ), inp , type ( inp )) return ( \"?\" , \"DT_NULL_VALUE\" ) def __dataTypePdbx ( self , inp ): \"\"\"Detect the PDBx data type -\"\"\" if inp is None : return \"DT_NULL_VALUE\" # pure numerical values are returned as unquoted strings # if isinstance(inp, int) or self.__intRe.search(str(inp)): if isinstance ( inp , int ) or ( isinstance ( inp , string_types ) and self . __intRe . search ( inp )): return \"DT_INTEGER\" # if isinstance(inp, float) or self.__floatRe.search(str(inp)): if isinstance ( inp , float ) or ( isinstance ( inp , string_types ) and self . __floatRe . search ( inp )): return \"DT_FLOAT\" # null value handling - if inp == \".\" or inp == \"?\" : return \"DT_NULL_VALUE\" if inp == \"\" : return \"DT_NULL_VALUE\" # Contains white space or quotes ? if not self . __wsAndQuotesRe . search ( inp ): if inp . startswith ( \"_\" ): return \"DT_ITEM_NAME\" else : return \"DT_UNQUOTED_STRING\" else : if self . __nlRe . search ( inp ): return \"DT_MULTI_LINE_STRING\" else : if self . __avoidEmbeddedQuoting : if not self . __sqRe . search ( inp ) and not self . __dqWsRe . search ( inp ): return \"DT_DOUBLE_QUOTED_STRING\" elif not self . __dqRe . search ( inp ) and not self . __sqWsRe . search ( inp ): return \"DT_SINGLE_QUOTED_STRING\" else : return \"DT_MULTI_LINE_STRING\" else : if not self . __sqRe . search ( inp ): return \"DT_DOUBLE_QUOTED_STRING\" elif not self . __dqRe . search ( inp ): return \"DT_SINGLE_QUOTED_STRING\" else : return \"DT_MULTI_LINE_STRING\" def __singleQuotedList ( self , inp ): ll = [] ll . append ( \"'\" ) ll . append ( inp ) ll . append ( \"'\" ) return ll def __doubleQuotedList ( self , inp ): ll = [] ll . append ( '\"' ) ll . append ( inp ) ll . append ( '\"' ) return ll def __semiColonQuotedList ( self , inp ): ll = [] ll . append ( \" \\n \" ) if inp [ - 1 ] == \" \\n \" : ll . append ( \";\" ) ll . append ( inp ) ll . append ( \";\" ) ll . append ( \" \\n \" ) else : ll . append ( \";\" ) ll . append ( inp ) ll . append ( \" \\n \" ) ll . append ( \";\" ) ll . append ( \" \\n \" ) return ll def getValueFormatted ( self , attributeName = None , rowIndex = None ): if attributeName is None : attribute = self . _currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ): try : fList , _ = self . __formatPdbx ( self . data [ rowI ][ self . _attributeNameList . index ( attribute )]) return \"\" . join ( fList ) except IndexError : logger . exception ( \"attributeName %s rowI %r rowdata %r \" , attributeName , rowI , self . data [ rowI ]) raise IndexError except Exception as e : logger . exception ( \" Failing with %s - AttributeName %s rowI %r rowdata %r \" , str ( e ), attributeName , rowI , self . data [ rowI ]) else : logger . error ( \" Type error - AttributeName %r rowI %r rowdata %r \" , attributeName , rowI , self . data [ rowI ]) logger . error ( \" Type error - string types %r \" , self . _stringTypes ) raise TypeError ( attribute ) def getValueFormattedByIndex ( self , attributeIndex , rowIndex ): try : fList , _ = self . __formatPdbx ( self . data [ rowIndex ][ attributeIndex ]) return \"\" . join ( fList ) except IndexError : logger . exception ( \"attributeIndex %r rowIndex %r rowdata %r \" , attributeIndex , rowIndex , self . data [ rowIndex ][ attributeIndex ]) raise IndexError except Exception as e : logger . exception ( \"Failing with %s - attributeIndex %r rowIndex %r rowdata %r \" , str ( e ), attributeIndex , rowIndex , self . data [ rowIndex ][ attributeIndex ]) raise e def getAttributeValueMaxLengthList ( self , steps = 1 ): mList = [ 0 for i in range ( len ( self . _attributeNameList ))] for row in self . data [:: steps ]: for indx in range ( len ( self . _attributeNameList )): val = row [ indx ] if isinstance ( val , self . _stringTypes ): tLen = len ( val ) else : tLen = len ( str ( val )) mList [ indx ] = max ( mList [ indx ], tLen ) return mList def getFormatTypeList ( self , steps = 1 ): try : curFormatTypeList = [] curDataTypeList = [ \"DT_NULL_VALUE\" for i in range ( len ( self . _attributeNameList ))] for row in self . data [:: steps ]: for indx in range ( len ( self . _attributeNameList )): val = row [ indx ] # print \"index \",indx,\" val \",val dType = self . __dataTypePdbx ( val ) dIndx = self . __dataTypeList . index ( dType ) # print \"d type\", dType, \" d type index \",dIndx cType = curDataTypeList [ indx ] cIndx = self . __dataTypeList . index ( cType ) cIndx = max ( cIndx , dIndx ) curDataTypeList [ indx ] = self . __dataTypeList [ cIndx ] # Map the format types to the data types curFormatTypeList = [] for dt in curDataTypeList : ii = self . __dataTypeList . index ( dt ) curFormatTypeList . append ( self . __formatTypeList [ ii ]) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return curFormatTypeList , curDataTypeList __init__ ( self , dataCategoryObj , preferDoubleQuotes = True ) special Source code in mmcif/api/DataCategoryFormatted.py def __init__ ( self , dataCategoryObj , preferDoubleQuotes = True ): self . __dcObj = dataCategoryObj super ( DataCategoryFormatted , self ) . __init__ ( self . __dcObj . getName (), self . __dcObj . getAttributeList (), self . __dcObj . data ) # self . _currentRowIndex = 0 self . _currentAttribute = None # self . __avoidEmbeddedQuoting = False self . __preferDoubleQuotes = preferDoubleQuotes # # -------------------------------------------------------------------- # any whitespace self . __wsRe = re . compile ( r \"\\s\" ) # self.__wsAndQuotesRe=re.compile(r\"[\\s'\\\"]\") self . __wsAndQuotesRe = re . compile ( r \"[\\s' \\\" #]\" ) # any newline or carriage control self . __nlRe = re . compile ( r \"[\\n\\r]\" ) # # single quote self . __sqRe = re . compile ( r \"[']\" ) # self . __sqWsRe = re . compile ( r \"('\\s)|(\\s')\" ) # double quote self . __dqRe = re . compile ( r '[\"]' ) self . __dqWsRe = re . compile ( r '(\"\\s)|(\\s\")' ) # self . __intRe = re . compile ( r \"^[0-9]+$\" ) self . __floatRe = re . compile ( r \"^-?(([0-9]+)[.]?|([0-9]*[.][0-9]+))([(][0-9]+[)])?([eE][+-]?[0-9]+)?$\" ) # self . __dataTypeList = [ \"DT_NULL_VALUE\" , \"DT_INTEGER\" , \"DT_FLOAT\" , \"DT_UNQUOTED_STRING\" , \"DT_ITEM_NAME\" , \"DT_DOUBLE_QUOTED_STRING\" , \"DT_SINGLE_QUOTED_STRING\" , \"DT_MULTI_LINE_STRING\" , ] self . __formatTypeList = [ \"FT_NULL_VALUE\" , \"FT_NUMBER\" , \"FT_NUMBER\" , \"FT_UNQUOTED_STRING\" , \"FT_QUOTED_STRING\" , \"FT_QUOTED_STRING\" , \"FT_QUOTED_STRING\" , \"FT_MULTI_LINE_STRING\" , ] # # try: # basestring # except NameError: # basestring = str # # self.__string_types = basestring getAttributeValueMaxLengthList ( self , steps = 1 ) Source code in mmcif/api/DataCategoryFormatted.py def getAttributeValueMaxLengthList ( self , steps = 1 ): mList = [ 0 for i in range ( len ( self . _attributeNameList ))] for row in self . data [:: steps ]: for indx in range ( len ( self . _attributeNameList )): val = row [ indx ] if isinstance ( val , self . _stringTypes ): tLen = len ( val ) else : tLen = len ( str ( val )) mList [ indx ] = max ( mList [ indx ], tLen ) return mList getFormatTypeList ( self , steps = 1 ) Source code in mmcif/api/DataCategoryFormatted.py def getFormatTypeList ( self , steps = 1 ): try : curFormatTypeList = [] curDataTypeList = [ \"DT_NULL_VALUE\" for i in range ( len ( self . _attributeNameList ))] for row in self . data [:: steps ]: for indx in range ( len ( self . _attributeNameList )): val = row [ indx ] # print \"index \",indx,\" val \",val dType = self . __dataTypePdbx ( val ) dIndx = self . __dataTypeList . index ( dType ) # print \"d type\", dType, \" d type index \",dIndx cType = curDataTypeList [ indx ] cIndx = self . __dataTypeList . index ( cType ) cIndx = max ( cIndx , dIndx ) curDataTypeList [ indx ] = self . __dataTypeList [ cIndx ] # Map the format types to the data types curFormatTypeList = [] for dt in curDataTypeList : ii = self . __dataTypeList . index ( dt ) curFormatTypeList . append ( self . __formatTypeList [ ii ]) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return curFormatTypeList , curDataTypeList getValueFormatted ( self , attributeName = None , rowIndex = None ) Source code in mmcif/api/DataCategoryFormatted.py def getValueFormatted ( self , attributeName = None , rowIndex = None ): if attributeName is None : attribute = self . _currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ): try : fList , _ = self . __formatPdbx ( self . data [ rowI ][ self . _attributeNameList . index ( attribute )]) return \"\" . join ( fList ) except IndexError : logger . exception ( \"attributeName %s rowI %r rowdata %r \" , attributeName , rowI , self . data [ rowI ]) raise IndexError except Exception as e : logger . exception ( \" Failing with %s - AttributeName %s rowI %r rowdata %r \" , str ( e ), attributeName , rowI , self . data [ rowI ]) else : logger . error ( \" Type error - AttributeName %r rowI %r rowdata %r \" , attributeName , rowI , self . data [ rowI ]) logger . error ( \" Type error - string types %r \" , self . _stringTypes ) raise TypeError ( attribute ) getValueFormattedByIndex ( self , attributeIndex , rowIndex ) Source code in mmcif/api/DataCategoryFormatted.py def getValueFormattedByIndex ( self , attributeIndex , rowIndex ): try : fList , _ = self . __formatPdbx ( self . data [ rowIndex ][ attributeIndex ]) return \"\" . join ( fList ) except IndexError : logger . exception ( \"attributeIndex %r rowIndex %r rowdata %r \" , attributeIndex , rowIndex , self . data [ rowIndex ][ attributeIndex ]) raise IndexError except Exception as e : logger . exception ( \"Failing with %s - attributeIndex %r rowIndex %r rowdata %r \" , str ( e ), attributeIndex , rowIndex , self . data [ rowIndex ][ attributeIndex ]) raise e","title":"DataCategoryFormatted"},{"location":"api_reference/DataCategoryFormatted/#mmcif.api.DataCategoryFormatted.DataCategoryFormatted","text":"A subclass of DataCategory including additional formatting methods. Source code in mmcif/api/DataCategoryFormatted.py class DataCategoryFormatted ( DataCategory ): \"\"\"A subclass of DataCategory including additional formatting methods.\"\"\" def __init__ ( self , dataCategoryObj , preferDoubleQuotes = True ): self . __dcObj = dataCategoryObj super ( DataCategoryFormatted , self ) . __init__ ( self . __dcObj . getName (), self . __dcObj . getAttributeList (), self . __dcObj . data ) # self . _currentRowIndex = 0 self . _currentAttribute = None # self . __avoidEmbeddedQuoting = False self . __preferDoubleQuotes = preferDoubleQuotes # # -------------------------------------------------------------------- # any whitespace self . __wsRe = re . compile ( r \"\\s\" ) # self.__wsAndQuotesRe=re.compile(r\"[\\s'\\\"]\") self . __wsAndQuotesRe = re . compile ( r \"[\\s' \\\" #]\" ) # any newline or carriage control self . __nlRe = re . compile ( r \"[\\n\\r]\" ) # # single quote self . __sqRe = re . compile ( r \"[']\" ) # self . __sqWsRe = re . compile ( r \"('\\s)|(\\s')\" ) # double quote self . __dqRe = re . compile ( r '[\"]' ) self . __dqWsRe = re . compile ( r '(\"\\s)|(\\s\")' ) # self . __intRe = re . compile ( r \"^[0-9]+$\" ) self . __floatRe = re . compile ( r \"^-?(([0-9]+)[.]?|([0-9]*[.][0-9]+))([(][0-9]+[)])?([eE][+-]?[0-9]+)?$\" ) # self . __dataTypeList = [ \"DT_NULL_VALUE\" , \"DT_INTEGER\" , \"DT_FLOAT\" , \"DT_UNQUOTED_STRING\" , \"DT_ITEM_NAME\" , \"DT_DOUBLE_QUOTED_STRING\" , \"DT_SINGLE_QUOTED_STRING\" , \"DT_MULTI_LINE_STRING\" , ] self . __formatTypeList = [ \"FT_NULL_VALUE\" , \"FT_NUMBER\" , \"FT_NUMBER\" , \"FT_UNQUOTED_STRING\" , \"FT_QUOTED_STRING\" , \"FT_QUOTED_STRING\" , \"FT_QUOTED_STRING\" , \"FT_MULTI_LINE_STRING\" , ] # # try: # basestring # except NameError: # basestring = str # # self.__string_types = basestring def __formatPdbx ( self , inp ): \"\"\"Format input data following PDBx quoting rules -\"\"\" try : if inp is None : return ( \"?\" , \"DT_NULL_VALUE\" ) # pure numerical values are returned as unquoted strings # if (isinstance(inp, int) or self.__intRe.search(str(inp))): # try : if isinstance ( inp , int ) or self . __intRe . search ( inp ): return ([ str ( inp )], \"DT_INTEGER\" ) except Exception : pass # if (isinstance(inp, float) or self.__floatRe.search(str(inp))): try : if isinstance ( inp , float ) or self . __floatRe . search ( inp ): return ([ str ( inp )], \"DT_FLOAT\" ) except Exception : pass # null value handling - if inp == \".\" or inp == \"?\" : return ([ inp ], \"DT_NULL_VALUE\" ) if inp == \"\" : return ([ \".\" ], \"DT_NULL_VALUE\" ) # Contains white space or quotes ? if not self . __wsAndQuotesRe . search ( inp ): # if inp.startswith(\"_\"): if inp [ 0 ] in [ \"_\" ]: return ( self . __doubleQuotedList ( inp ), \"DT_ITEM_NAME\" ) elif inp [ 0 ] in [ \"[\" , \"]\" , \"$\" , \"#\" , \";\" ]: return ( self . __doubleQuotedList ( inp ), \"DT_DOUBLE_QUOTED_STRING\" ) elif inp [: 5 ] . lower () in [ \"data_\" , \"loop_\" , \"save_\" ]: return ( self . __doubleQuotedList ( inp ), \"DT_DOUBLE_QUOTED_STRING\" ) else : return ([ str ( inp )], \"DT_UNQUOTED_STRING\" ) else : if self . __nlRe . search ( inp ): return ( self . __semiColonQuotedList ( inp ), \"DT_MULTI_LINE_STRING\" ) else : if self . __preferDoubleQuotes : if self . __avoidEmbeddedQuoting : # change priority to choose double quoting where possible. if not self . __dqRe . search ( inp ) and not self . __sqWsRe . search ( inp ): return ( self . __doubleQuotedList ( inp ), \"DT_DOUBLE_QUOTED_STRING\" ) elif not self . __sqRe . search ( inp ) and not self . __dqWsRe . search ( inp ): return ( self . __singleQuotedList ( inp ), \"DT_SINGLE_QUOTED_STRING\" ) else : return ( self . __semiColonQuotedList ( inp ), \"DT_MULTI_LINE_STRING\" ) else : # change priority to choose double quoting where possible. if not self . __dqRe . search ( inp ): return ( self . __doubleQuotedList ( inp ), \"DT_DOUBLE_QUOTED_STRING\" ) elif not self . __sqRe . search ( inp ): return ( self . __singleQuotedList ( inp ), \"DT_SINGLE_QUOTED_STRING\" ) else : return ( self . __semiColonQuotedList ( inp ), \"DT_MULTI_LINE_STRING\" ) else : if self . __avoidEmbeddedQuoting : # change priority to choose double quoting where possible. if not self . __sqRe . search ( inp ) and not self . __dqWsRe . search ( inp ): return ( self . __singleQuotedList ( inp ), \"DT_SINGLE_QUOTED_STRING\" ) elif not self . __dqRe . search ( inp ) and not self . __sqWsRe . search ( inp ): return ( self . __doubleQuotedList ( inp ), \"DT_DOUBLE_QUOTED_STRING\" ) else : return ( self . __semiColonQuotedList ( inp ), \"DT_MULTI_LINE_STRING\" ) else : # change priority to choose double quoting where possible. if not self . __sqRe . search ( inp ): return ( self . __singleQuotedList ( inp ), \"DT_SINGLE_QUOTED_STRING\" ) elif not self . __dqRe . search ( inp ): return ( self . __doubleQuotedList ( inp ), \"DT_DOUBLE_QUOTED_STRING\" ) else : return ( self . __semiColonQuotedList ( inp ), \"DT_MULTI_LINE_STRING\" ) except Exception as e : logger . exception ( \"Failing with %s on input %r %r \" , str ( e ), inp , type ( inp )) return ( \"?\" , \"DT_NULL_VALUE\" ) def __dataTypePdbx ( self , inp ): \"\"\"Detect the PDBx data type -\"\"\" if inp is None : return \"DT_NULL_VALUE\" # pure numerical values are returned as unquoted strings # if isinstance(inp, int) or self.__intRe.search(str(inp)): if isinstance ( inp , int ) or ( isinstance ( inp , string_types ) and self . __intRe . search ( inp )): return \"DT_INTEGER\" # if isinstance(inp, float) or self.__floatRe.search(str(inp)): if isinstance ( inp , float ) or ( isinstance ( inp , string_types ) and self . __floatRe . search ( inp )): return \"DT_FLOAT\" # null value handling - if inp == \".\" or inp == \"?\" : return \"DT_NULL_VALUE\" if inp == \"\" : return \"DT_NULL_VALUE\" # Contains white space or quotes ? if not self . __wsAndQuotesRe . search ( inp ): if inp . startswith ( \"_\" ): return \"DT_ITEM_NAME\" else : return \"DT_UNQUOTED_STRING\" else : if self . __nlRe . search ( inp ): return \"DT_MULTI_LINE_STRING\" else : if self . __avoidEmbeddedQuoting : if not self . __sqRe . search ( inp ) and not self . __dqWsRe . search ( inp ): return \"DT_DOUBLE_QUOTED_STRING\" elif not self . __dqRe . search ( inp ) and not self . __sqWsRe . search ( inp ): return \"DT_SINGLE_QUOTED_STRING\" else : return \"DT_MULTI_LINE_STRING\" else : if not self . __sqRe . search ( inp ): return \"DT_DOUBLE_QUOTED_STRING\" elif not self . __dqRe . search ( inp ): return \"DT_SINGLE_QUOTED_STRING\" else : return \"DT_MULTI_LINE_STRING\" def __singleQuotedList ( self , inp ): ll = [] ll . append ( \"'\" ) ll . append ( inp ) ll . append ( \"'\" ) return ll def __doubleQuotedList ( self , inp ): ll = [] ll . append ( '\"' ) ll . append ( inp ) ll . append ( '\"' ) return ll def __semiColonQuotedList ( self , inp ): ll = [] ll . append ( \" \\n \" ) if inp [ - 1 ] == \" \\n \" : ll . append ( \";\" ) ll . append ( inp ) ll . append ( \";\" ) ll . append ( \" \\n \" ) else : ll . append ( \";\" ) ll . append ( inp ) ll . append ( \" \\n \" ) ll . append ( \";\" ) ll . append ( \" \\n \" ) return ll def getValueFormatted ( self , attributeName = None , rowIndex = None ): if attributeName is None : attribute = self . _currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ): try : fList , _ = self . __formatPdbx ( self . data [ rowI ][ self . _attributeNameList . index ( attribute )]) return \"\" . join ( fList ) except IndexError : logger . exception ( \"attributeName %s rowI %r rowdata %r \" , attributeName , rowI , self . data [ rowI ]) raise IndexError except Exception as e : logger . exception ( \" Failing with %s - AttributeName %s rowI %r rowdata %r \" , str ( e ), attributeName , rowI , self . data [ rowI ]) else : logger . error ( \" Type error - AttributeName %r rowI %r rowdata %r \" , attributeName , rowI , self . data [ rowI ]) logger . error ( \" Type error - string types %r \" , self . _stringTypes ) raise TypeError ( attribute ) def getValueFormattedByIndex ( self , attributeIndex , rowIndex ): try : fList , _ = self . __formatPdbx ( self . data [ rowIndex ][ attributeIndex ]) return \"\" . join ( fList ) except IndexError : logger . exception ( \"attributeIndex %r rowIndex %r rowdata %r \" , attributeIndex , rowIndex , self . data [ rowIndex ][ attributeIndex ]) raise IndexError except Exception as e : logger . exception ( \"Failing with %s - attributeIndex %r rowIndex %r rowdata %r \" , str ( e ), attributeIndex , rowIndex , self . data [ rowIndex ][ attributeIndex ]) raise e def getAttributeValueMaxLengthList ( self , steps = 1 ): mList = [ 0 for i in range ( len ( self . _attributeNameList ))] for row in self . data [:: steps ]: for indx in range ( len ( self . _attributeNameList )): val = row [ indx ] if isinstance ( val , self . _stringTypes ): tLen = len ( val ) else : tLen = len ( str ( val )) mList [ indx ] = max ( mList [ indx ], tLen ) return mList def getFormatTypeList ( self , steps = 1 ): try : curFormatTypeList = [] curDataTypeList = [ \"DT_NULL_VALUE\" for i in range ( len ( self . _attributeNameList ))] for row in self . data [:: steps ]: for indx in range ( len ( self . _attributeNameList )): val = row [ indx ] # print \"index \",indx,\" val \",val dType = self . __dataTypePdbx ( val ) dIndx = self . __dataTypeList . index ( dType ) # print \"d type\", dType, \" d type index \",dIndx cType = curDataTypeList [ indx ] cIndx = self . __dataTypeList . index ( cType ) cIndx = max ( cIndx , dIndx ) curDataTypeList [ indx ] = self . __dataTypeList [ cIndx ] # Map the format types to the data types curFormatTypeList = [] for dt in curDataTypeList : ii = self . __dataTypeList . index ( dt ) curFormatTypeList . append ( self . __formatTypeList [ ii ]) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return curFormatTypeList , curDataTypeList","title":"DataCategoryFormatted"},{"location":"api_reference/DataCategoryFormatted/#mmcif.api.DataCategoryFormatted.DataCategoryFormatted.__init__","text":"Source code in mmcif/api/DataCategoryFormatted.py def __init__ ( self , dataCategoryObj , preferDoubleQuotes = True ): self . __dcObj = dataCategoryObj super ( DataCategoryFormatted , self ) . __init__ ( self . __dcObj . getName (), self . __dcObj . getAttributeList (), self . __dcObj . data ) # self . _currentRowIndex = 0 self . _currentAttribute = None # self . __avoidEmbeddedQuoting = False self . __preferDoubleQuotes = preferDoubleQuotes # # -------------------------------------------------------------------- # any whitespace self . __wsRe = re . compile ( r \"\\s\" ) # self.__wsAndQuotesRe=re.compile(r\"[\\s'\\\"]\") self . __wsAndQuotesRe = re . compile ( r \"[\\s' \\\" #]\" ) # any newline or carriage control self . __nlRe = re . compile ( r \"[\\n\\r]\" ) # # single quote self . __sqRe = re . compile ( r \"[']\" ) # self . __sqWsRe = re . compile ( r \"('\\s)|(\\s')\" ) # double quote self . __dqRe = re . compile ( r '[\"]' ) self . __dqWsRe = re . compile ( r '(\"\\s)|(\\s\")' ) # self . __intRe = re . compile ( r \"^[0-9]+$\" ) self . __floatRe = re . compile ( r \"^-?(([0-9]+)[.]?|([0-9]*[.][0-9]+))([(][0-9]+[)])?([eE][+-]?[0-9]+)?$\" ) # self . __dataTypeList = [ \"DT_NULL_VALUE\" , \"DT_INTEGER\" , \"DT_FLOAT\" , \"DT_UNQUOTED_STRING\" , \"DT_ITEM_NAME\" , \"DT_DOUBLE_QUOTED_STRING\" , \"DT_SINGLE_QUOTED_STRING\" , \"DT_MULTI_LINE_STRING\" , ] self . __formatTypeList = [ \"FT_NULL_VALUE\" , \"FT_NUMBER\" , \"FT_NUMBER\" , \"FT_UNQUOTED_STRING\" , \"FT_QUOTED_STRING\" , \"FT_QUOTED_STRING\" , \"FT_QUOTED_STRING\" , \"FT_MULTI_LINE_STRING\" , ] # # try: # basestring # except NameError: # basestring = str # # self.__string_types = basestring","title":"__init__()"},{"location":"api_reference/DataCategoryFormatted/#mmcif.api.DataCategoryFormatted.DataCategoryFormatted.getAttributeValueMaxLengthList","text":"Source code in mmcif/api/DataCategoryFormatted.py def getAttributeValueMaxLengthList ( self , steps = 1 ): mList = [ 0 for i in range ( len ( self . _attributeNameList ))] for row in self . data [:: steps ]: for indx in range ( len ( self . _attributeNameList )): val = row [ indx ] if isinstance ( val , self . _stringTypes ): tLen = len ( val ) else : tLen = len ( str ( val )) mList [ indx ] = max ( mList [ indx ], tLen ) return mList","title":"getAttributeValueMaxLengthList()"},{"location":"api_reference/DataCategoryFormatted/#mmcif.api.DataCategoryFormatted.DataCategoryFormatted.getFormatTypeList","text":"Source code in mmcif/api/DataCategoryFormatted.py def getFormatTypeList ( self , steps = 1 ): try : curFormatTypeList = [] curDataTypeList = [ \"DT_NULL_VALUE\" for i in range ( len ( self . _attributeNameList ))] for row in self . data [:: steps ]: for indx in range ( len ( self . _attributeNameList )): val = row [ indx ] # print \"index \",indx,\" val \",val dType = self . __dataTypePdbx ( val ) dIndx = self . __dataTypeList . index ( dType ) # print \"d type\", dType, \" d type index \",dIndx cType = curDataTypeList [ indx ] cIndx = self . __dataTypeList . index ( cType ) cIndx = max ( cIndx , dIndx ) curDataTypeList [ indx ] = self . __dataTypeList [ cIndx ] # Map the format types to the data types curFormatTypeList = [] for dt in curDataTypeList : ii = self . __dataTypeList . index ( dt ) curFormatTypeList . append ( self . __formatTypeList [ ii ]) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return curFormatTypeList , curDataTypeList","title":"getFormatTypeList()"},{"location":"api_reference/DataCategoryFormatted/#mmcif.api.DataCategoryFormatted.DataCategoryFormatted.getValueFormatted","text":"Source code in mmcif/api/DataCategoryFormatted.py def getValueFormatted ( self , attributeName = None , rowIndex = None ): if attributeName is None : attribute = self . _currentAttribute else : attribute = attributeName if rowIndex is None : rowI = self . _currentRowIndex else : rowI = rowIndex if isinstance ( attribute , self . _stringTypes ) and isinstance ( rowI , int ): try : fList , _ = self . __formatPdbx ( self . data [ rowI ][ self . _attributeNameList . index ( attribute )]) return \"\" . join ( fList ) except IndexError : logger . exception ( \"attributeName %s rowI %r rowdata %r \" , attributeName , rowI , self . data [ rowI ]) raise IndexError except Exception as e : logger . exception ( \" Failing with %s - AttributeName %s rowI %r rowdata %r \" , str ( e ), attributeName , rowI , self . data [ rowI ]) else : logger . error ( \" Type error - AttributeName %r rowI %r rowdata %r \" , attributeName , rowI , self . data [ rowI ]) logger . error ( \" Type error - string types %r \" , self . _stringTypes ) raise TypeError ( attribute )","title":"getValueFormatted()"},{"location":"api_reference/DataCategoryFormatted/#mmcif.api.DataCategoryFormatted.DataCategoryFormatted.getValueFormattedByIndex","text":"Source code in mmcif/api/DataCategoryFormatted.py def getValueFormattedByIndex ( self , attributeIndex , rowIndex ): try : fList , _ = self . __formatPdbx ( self . data [ rowIndex ][ attributeIndex ]) return \"\" . join ( fList ) except IndexError : logger . exception ( \"attributeIndex %r rowIndex %r rowdata %r \" , attributeIndex , rowIndex , self . data [ rowIndex ][ attributeIndex ]) raise IndexError except Exception as e : logger . exception ( \"Failing with %s - attributeIndex %r rowIndex %r rowdata %r \" , str ( e ), attributeIndex , rowIndex , self . data [ rowIndex ][ attributeIndex ]) raise e","title":"getValueFormattedByIndex()"},{"location":"api_reference/DataCategoryTyped/","text":"mmcif.api.DataCategoryTyped.DataCategoryTyped ( DataCategory ) A subclass of DataCategory with methods to apply explicit data typing. Source code in mmcif/api/DataCategoryTyped.py class DataCategoryTyped ( DataCategory ): \"\"\"A subclass of DataCategory with methods to apply explicit data typing.\"\"\" def __init__ ( self , dataCategoryObj , dictionaryApi = None , raiseExceptions = True , copyInputData = True , ignoreCastErrors = False , useCifUnknowns = True , missingValueString = None , missingValueInteger = None , missingValueFloat = None , ): \"\"\"A subclass of DataCategory with methods to apply explicit data typing. Args: dataCategoryObj (object): DataCategory object instance dictionaryApi (object, optional): instance of DictionaryApi class. Defaults to None. raiseExceptions (bool, optional): raise exceptions. Defaults to True. copyInputData (bool, optional): make a new copy input data. Defaults to True. ignoreCastErrors (bool, optional): ignore data processing cast errors. Defaults to False. useCifUnknowns (bool, optional): use CIF style missing values ('.' and '?'). Defaults to True. missingValueString (str, optional): missing string value . Defaults to None. missingValueInteger (integer, optional): missing integer value. Defaults to None. missingValueFloat (float, optional): missing float value. Defaults to None. \"\"\" self . __dcObj = dataCategoryObj super ( DataCategoryTyped , self ) . __init__ ( self . __dcObj . getName (), self . __dcObj . getAttributeList (), self . __dcObj . data , raiseExceptions = raiseExceptions , copyInputData = copyInputData , ) # self . __dApi = dictionaryApi self . __attributeTypeD = {} self . __castD = { \"integer\" : int , \"float\" : float , \"string\" : str } self . __typesSet = self . applyTypes ( ignoreCastErrors = ignoreCastErrors , useCifUnknowns = useCifUnknowns , missingValueString = missingValueString , missingValueInteger = missingValueInteger , missingValueFloat = missingValueFloat , ) def applyTypes ( self , ignoreCastErrors = False , useCifUnknowns = True , missingValueString = None , missingValueInteger = None , missingValueFloat = None ): \"\"\"Cast data types (string, integer, float) in the current object based on dictionary type details. Missing values ('.' or '?') are set to None. Raises: e: any exception Returns: bool: True for success or False otherwise \"\"\" ok = False try : for ii , atName in enumerate ( self . getAttributeList ()): # colValL = self.getColumn(ii) dataType , isMandatory = self . __getAttributeInfo ( atName ) missingValue = missingValueInteger if dataType == \"integer\" else missingValueFloat if dataType in [ \"integer\" , \"float\" ] else missingValueString missingValue = missingValue if not useCifUnknowns else \".\" if isMandatory else \"?\" for row in self . data : try : row [ ii ] = self . __castD [ dataType ]( row [ ii ]) if row [ ii ] is not None and row [ ii ] not in [ \".\" , \"?\" ] else missingValue except Exception as e : if not ignoreCastErrors : logger . error ( \"Cast error %s %s ( %s ) %r %r \" , self . getName (), atName , dataType , row [ ii ], str ( e )) row [ ii ] = missingValue # logger . debug ( \" %s %s %r \" , self . getName (), atName , [ row [ ii ] for row in self . data ]) self . __attributeTypeD [ atName ] = dataType ok = True except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) if self . _raiseExceptions : raise e return ok def getAttributeInfo ( self , atName ): \"\"\"Get attribute data type (string, integer, or float) and optionality Args: atName (str): attribute name Returns: (string, bool): data type (string, integer or float) and mandatory code \"\"\" try : dataType , mandatoryCode = self . __getAttributeInfo ( atName ) return dataType , mandatoryCode except Exception : return None , None def applyStringTypes ( self ): \"\"\"Cast data types to strings in the current object. Missing values are set to '?' and '.' for optional and mandatory attributes, respectively. Raises: e: any exception Returns: bool: True for success or False otherwise \"\"\" ok = False try : for ii , atName in enumerate ( self . getAttributeList ()): _ , isMandatory = self . __getAttributeInfo ( atName ) dataType = \"string\" for row in self . data : if row [ ii ] is None or row [ ii ] in [ \".\" , \"?\" ]: row [ ii ] = \".\" if isMandatory else \"?\" else : row [ ii ] = self . __castD [ dataType ]( row [ ii ]) # self . __attributeTypeD [ atName ] = dataType ok = True except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) if self . _raiseExceptions : raise e return ok def cmpAttributeValues ( self , dcObj , ignoreOrder = True , ** kwargs ): \"\"\"Compare the values by attribute for current typed data category (dca) and input data category. The comparison is performed for values of the attributes common to both objects. Length differences are treated inequality out of hand. Args: dcObj (object): DataCategory object ignoreOrder (bool, optional): ignore attribute order. Defaults to True. floatRelTolerance (float, optional): relative tolerance for float comparisons. Defaults to 1e-05. floatAbsTolerance (float, optional): absolute tolerance for float comparisons. Defaults to 1e-04. Raises: e: any exception Returns: list: [(attributeName, values equal/close flag (bool)), (attributeName, values equal/close flag (bool), ...] \"\"\" rL = [] floatRelTolerance = kwargs . get ( \"floatRelTolerance\" , 1.0e-05 ) floatAbsTolerance = kwargs . get ( \"floatAbsTolerance\" , 1.0e-04 ) try : sa = set ( self . getAttributeList ()) sb = set ( dcObj . getAttributeList ()) atNameComList = list ( sa & sb ) # lenEq = self . getRowCount () == dcObj . getRowCount () if not lenEq : return [( atName , False ) for atName in atNameComList ] # for atName in atNameComList : dataType , _ = self . __getAttributeInfo ( atName ) if dataType in [ \"string\" , \"integer\" ]: if ignoreOrder : same = sorted ( self . getAttributeValueList ( atName )) == sorted ( dcObj . getAttributeValueList ( atName )) else : same = self . getAttributeValueList ( atName ) == dcObj . getAttributeValueList ( atName ) elif dataType in [ \"float\" ]: aVL = self . getAttributeValueList ( atName ) bVL = dcObj . getAttributeValueList ( atName ) if ignoreOrder : for aV , bV in zip ( sorted ( aVL ), sorted ( bVL )): same = self . __isClose ( aV , bV , relTol = floatRelTolerance , absTol = floatAbsTolerance ) if not same : break else : for aV , bV in zip ( aVL , bVL ): same = self . __isClose ( aV , bV , relTol = floatRelTolerance , absTol = floatAbsTolerance ) if not same : logger . info ( \" %s %s (rel= %r ) (abs= %r ) %r ( %r )\" , self . getName (), atName , aV * floatRelTolerance , floatAbsTolerance , aV , abs ( aV - bV )) break rL . append (( atName , same )) # return rL except Exception as e : if self . _raiseExceptions : raise e return rL def __getAttributeInfo ( self , atName ): \"\"\"Get attribute data type (string, integer, or float) and optionality Args: atName (str): attribute name Returns: (string, bool): data type (string, integer or float) and mandatory code \"\"\" cifDataType = self . __dApi . getTypeCode ( self . getName (), atName ) cifPrimitiveType = self . __dApi . getTypePrimitive ( self . getName (), atName ) isMandatory = self . __dApi . getMandatoryCode ( self . getName (), atName ) in [ \"yes\" , \"implicit\" , \"implicit-ordinal\" ] dataType = \"integer\" if \"int\" in cifDataType else \"float\" if cifPrimitiveType == \"numb\" else \"string\" return dataType , isMandatory def __isClose ( self , aV , bV , relTol = 1e-09 , absTol = 1e-06 ): if aV is None and bV is None : return True elif aV is not None and bV is not None and aV == bV : return True elif isinstance ( aV , ( float )) and isinstance ( bV , ( float )): return abs ( aV - bV ) <= max ( relTol * max ( abs ( aV ), abs ( bV )), absTol ) else : raise ValueError Methods __init__ ( self , dataCategoryObj , dictionaryApi = None , raiseExceptions = True , copyInputData = True , ignoreCastErrors = False , useCifUnknowns = True , missingValueString = None , missingValueInteger = None , missingValueFloat = None ) special A subclass of DataCategory with methods to apply explicit data typing. Parameters: Name Type Description Default dataCategoryObj object DataCategory object instance required dictionaryApi object instance of DictionaryApi class. Defaults to None. None raiseExceptions bool raise exceptions. Defaults to True. True copyInputData bool make a new copy input data. Defaults to True. True ignoreCastErrors bool ignore data processing cast errors. Defaults to False. False useCifUnknowns bool use CIF style missing values ('.' and '?'). Defaults to True. True missingValueString str missing string value . Defaults to None. None missingValueInteger integer missing integer value. Defaults to None. None missingValueFloat float missing float value. Defaults to None. None Source code in mmcif/api/DataCategoryTyped.py def __init__ ( self , dataCategoryObj , dictionaryApi = None , raiseExceptions = True , copyInputData = True , ignoreCastErrors = False , useCifUnknowns = True , missingValueString = None , missingValueInteger = None , missingValueFloat = None , ): \"\"\"A subclass of DataCategory with methods to apply explicit data typing. Args: dataCategoryObj (object): DataCategory object instance dictionaryApi (object, optional): instance of DictionaryApi class. Defaults to None. raiseExceptions (bool, optional): raise exceptions. Defaults to True. copyInputData (bool, optional): make a new copy input data. Defaults to True. ignoreCastErrors (bool, optional): ignore data processing cast errors. Defaults to False. useCifUnknowns (bool, optional): use CIF style missing values ('.' and '?'). Defaults to True. missingValueString (str, optional): missing string value . Defaults to None. missingValueInteger (integer, optional): missing integer value. Defaults to None. missingValueFloat (float, optional): missing float value. Defaults to None. \"\"\" self . __dcObj = dataCategoryObj super ( DataCategoryTyped , self ) . __init__ ( self . __dcObj . getName (), self . __dcObj . getAttributeList (), self . __dcObj . data , raiseExceptions = raiseExceptions , copyInputData = copyInputData , ) # self . __dApi = dictionaryApi self . __attributeTypeD = {} self . __castD = { \"integer\" : int , \"float\" : float , \"string\" : str } self . __typesSet = self . applyTypes ( ignoreCastErrors = ignoreCastErrors , useCifUnknowns = useCifUnknowns , missingValueString = missingValueString , missingValueInteger = missingValueInteger , missingValueFloat = missingValueFloat , ) applyStringTypes ( self ) Cast data types to strings in the current object. Missing values are set to '?' and '.' for optional and mandatory attributes, respectively. Exceptions: Type Description e any exception Returns: Type Description bool True for success or False otherwise Source code in mmcif/api/DataCategoryTyped.py def applyStringTypes ( self ): \"\"\"Cast data types to strings in the current object. Missing values are set to '?' and '.' for optional and mandatory attributes, respectively. Raises: e: any exception Returns: bool: True for success or False otherwise \"\"\" ok = False try : for ii , atName in enumerate ( self . getAttributeList ()): _ , isMandatory = self . __getAttributeInfo ( atName ) dataType = \"string\" for row in self . data : if row [ ii ] is None or row [ ii ] in [ \".\" , \"?\" ]: row [ ii ] = \".\" if isMandatory else \"?\" else : row [ ii ] = self . __castD [ dataType ]( row [ ii ]) # self . __attributeTypeD [ atName ] = dataType ok = True except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) if self . _raiseExceptions : raise e return ok applyTypes ( self , ignoreCastErrors = False , useCifUnknowns = True , missingValueString = None , missingValueInteger = None , missingValueFloat = None ) Cast data types (string, integer, float) in the current object based on dictionary type details. Missing values ('.' or '?') are set to None. Exceptions: Type Description e any exception Returns: Type Description bool True for success or False otherwise Source code in mmcif/api/DataCategoryTyped.py def applyTypes ( self , ignoreCastErrors = False , useCifUnknowns = True , missingValueString = None , missingValueInteger = None , missingValueFloat = None ): \"\"\"Cast data types (string, integer, float) in the current object based on dictionary type details. Missing values ('.' or '?') are set to None. Raises: e: any exception Returns: bool: True for success or False otherwise \"\"\" ok = False try : for ii , atName in enumerate ( self . getAttributeList ()): # colValL = self.getColumn(ii) dataType , isMandatory = self . __getAttributeInfo ( atName ) missingValue = missingValueInteger if dataType == \"integer\" else missingValueFloat if dataType in [ \"integer\" , \"float\" ] else missingValueString missingValue = missingValue if not useCifUnknowns else \".\" if isMandatory else \"?\" for row in self . data : try : row [ ii ] = self . __castD [ dataType ]( row [ ii ]) if row [ ii ] is not None and row [ ii ] not in [ \".\" , \"?\" ] else missingValue except Exception as e : if not ignoreCastErrors : logger . error ( \"Cast error %s %s ( %s ) %r %r \" , self . getName (), atName , dataType , row [ ii ], str ( e )) row [ ii ] = missingValue # logger . debug ( \" %s %s %r \" , self . getName (), atName , [ row [ ii ] for row in self . data ]) self . __attributeTypeD [ atName ] = dataType ok = True except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) if self . _raiseExceptions : raise e return ok cmpAttributeValues ( self , dcObj , ignoreOrder = True , ** kwargs ) Compare the values by attribute for current typed data category (dca) and input data category. The comparison is performed for values of the attributes common to both objects. Length differences are treated inequality out of hand. Parameters: Name Type Description Default dcObj object DataCategory object required ignoreOrder bool ignore attribute order. Defaults to True. True floatRelTolerance float relative tolerance for float comparisons. Defaults to 1e-05. required floatAbsTolerance float absolute tolerance for float comparisons. Defaults to 1e-04. required Exceptions: Type Description e any exception Returns: Type Description list [(attributeName, values equal/close flag (bool)), (attributeName, values equal/close flag (bool), ...] Source code in mmcif/api/DataCategoryTyped.py def cmpAttributeValues ( self , dcObj , ignoreOrder = True , ** kwargs ): \"\"\"Compare the values by attribute for current typed data category (dca) and input data category. The comparison is performed for values of the attributes common to both objects. Length differences are treated inequality out of hand. Args: dcObj (object): DataCategory object ignoreOrder (bool, optional): ignore attribute order. Defaults to True. floatRelTolerance (float, optional): relative tolerance for float comparisons. Defaults to 1e-05. floatAbsTolerance (float, optional): absolute tolerance for float comparisons. Defaults to 1e-04. Raises: e: any exception Returns: list: [(attributeName, values equal/close flag (bool)), (attributeName, values equal/close flag (bool), ...] \"\"\" rL = [] floatRelTolerance = kwargs . get ( \"floatRelTolerance\" , 1.0e-05 ) floatAbsTolerance = kwargs . get ( \"floatAbsTolerance\" , 1.0e-04 ) try : sa = set ( self . getAttributeList ()) sb = set ( dcObj . getAttributeList ()) atNameComList = list ( sa & sb ) # lenEq = self . getRowCount () == dcObj . getRowCount () if not lenEq : return [( atName , False ) for atName in atNameComList ] # for atName in atNameComList : dataType , _ = self . __getAttributeInfo ( atName ) if dataType in [ \"string\" , \"integer\" ]: if ignoreOrder : same = sorted ( self . getAttributeValueList ( atName )) == sorted ( dcObj . getAttributeValueList ( atName )) else : same = self . getAttributeValueList ( atName ) == dcObj . getAttributeValueList ( atName ) elif dataType in [ \"float\" ]: aVL = self . getAttributeValueList ( atName ) bVL = dcObj . getAttributeValueList ( atName ) if ignoreOrder : for aV , bV in zip ( sorted ( aVL ), sorted ( bVL )): same = self . __isClose ( aV , bV , relTol = floatRelTolerance , absTol = floatAbsTolerance ) if not same : break else : for aV , bV in zip ( aVL , bVL ): same = self . __isClose ( aV , bV , relTol = floatRelTolerance , absTol = floatAbsTolerance ) if not same : logger . info ( \" %s %s (rel= %r ) (abs= %r ) %r ( %r )\" , self . getName (), atName , aV * floatRelTolerance , floatAbsTolerance , aV , abs ( aV - bV )) break rL . append (( atName , same )) # return rL except Exception as e : if self . _raiseExceptions : raise e return rL getAttributeInfo ( self , atName ) Get attribute data type (string, integer, or float) and optionality Parameters: Name Type Description Default atName str attribute name required Returns: Type Description (string, bool) data type (string, integer or float) and mandatory code Source code in mmcif/api/DataCategoryTyped.py def getAttributeInfo ( self , atName ): \"\"\"Get attribute data type (string, integer, or float) and optionality Args: atName (str): attribute name Returns: (string, bool): data type (string, integer or float) and mandatory code \"\"\" try : dataType , mandatoryCode = self . __getAttributeInfo ( atName ) return dataType , mandatoryCode except Exception : return None , None","title":"DataCategoryTyped"},{"location":"api_reference/DataCategoryTyped/#mmcif.api.DataCategoryTyped.DataCategoryTyped","text":"A subclass of DataCategory with methods to apply explicit data typing. Source code in mmcif/api/DataCategoryTyped.py class DataCategoryTyped ( DataCategory ): \"\"\"A subclass of DataCategory with methods to apply explicit data typing.\"\"\" def __init__ ( self , dataCategoryObj , dictionaryApi = None , raiseExceptions = True , copyInputData = True , ignoreCastErrors = False , useCifUnknowns = True , missingValueString = None , missingValueInteger = None , missingValueFloat = None , ): \"\"\"A subclass of DataCategory with methods to apply explicit data typing. Args: dataCategoryObj (object): DataCategory object instance dictionaryApi (object, optional): instance of DictionaryApi class. Defaults to None. raiseExceptions (bool, optional): raise exceptions. Defaults to True. copyInputData (bool, optional): make a new copy input data. Defaults to True. ignoreCastErrors (bool, optional): ignore data processing cast errors. Defaults to False. useCifUnknowns (bool, optional): use CIF style missing values ('.' and '?'). Defaults to True. missingValueString (str, optional): missing string value . Defaults to None. missingValueInteger (integer, optional): missing integer value. Defaults to None. missingValueFloat (float, optional): missing float value. Defaults to None. \"\"\" self . __dcObj = dataCategoryObj super ( DataCategoryTyped , self ) . __init__ ( self . __dcObj . getName (), self . __dcObj . getAttributeList (), self . __dcObj . data , raiseExceptions = raiseExceptions , copyInputData = copyInputData , ) # self . __dApi = dictionaryApi self . __attributeTypeD = {} self . __castD = { \"integer\" : int , \"float\" : float , \"string\" : str } self . __typesSet = self . applyTypes ( ignoreCastErrors = ignoreCastErrors , useCifUnknowns = useCifUnknowns , missingValueString = missingValueString , missingValueInteger = missingValueInteger , missingValueFloat = missingValueFloat , ) def applyTypes ( self , ignoreCastErrors = False , useCifUnknowns = True , missingValueString = None , missingValueInteger = None , missingValueFloat = None ): \"\"\"Cast data types (string, integer, float) in the current object based on dictionary type details. Missing values ('.' or '?') are set to None. Raises: e: any exception Returns: bool: True for success or False otherwise \"\"\" ok = False try : for ii , atName in enumerate ( self . getAttributeList ()): # colValL = self.getColumn(ii) dataType , isMandatory = self . __getAttributeInfo ( atName ) missingValue = missingValueInteger if dataType == \"integer\" else missingValueFloat if dataType in [ \"integer\" , \"float\" ] else missingValueString missingValue = missingValue if not useCifUnknowns else \".\" if isMandatory else \"?\" for row in self . data : try : row [ ii ] = self . __castD [ dataType ]( row [ ii ]) if row [ ii ] is not None and row [ ii ] not in [ \".\" , \"?\" ] else missingValue except Exception as e : if not ignoreCastErrors : logger . error ( \"Cast error %s %s ( %s ) %r %r \" , self . getName (), atName , dataType , row [ ii ], str ( e )) row [ ii ] = missingValue # logger . debug ( \" %s %s %r \" , self . getName (), atName , [ row [ ii ] for row in self . data ]) self . __attributeTypeD [ atName ] = dataType ok = True except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) if self . _raiseExceptions : raise e return ok def getAttributeInfo ( self , atName ): \"\"\"Get attribute data type (string, integer, or float) and optionality Args: atName (str): attribute name Returns: (string, bool): data type (string, integer or float) and mandatory code \"\"\" try : dataType , mandatoryCode = self . __getAttributeInfo ( atName ) return dataType , mandatoryCode except Exception : return None , None def applyStringTypes ( self ): \"\"\"Cast data types to strings in the current object. Missing values are set to '?' and '.' for optional and mandatory attributes, respectively. Raises: e: any exception Returns: bool: True for success or False otherwise \"\"\" ok = False try : for ii , atName in enumerate ( self . getAttributeList ()): _ , isMandatory = self . __getAttributeInfo ( atName ) dataType = \"string\" for row in self . data : if row [ ii ] is None or row [ ii ] in [ \".\" , \"?\" ]: row [ ii ] = \".\" if isMandatory else \"?\" else : row [ ii ] = self . __castD [ dataType ]( row [ ii ]) # self . __attributeTypeD [ atName ] = dataType ok = True except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) if self . _raiseExceptions : raise e return ok def cmpAttributeValues ( self , dcObj , ignoreOrder = True , ** kwargs ): \"\"\"Compare the values by attribute for current typed data category (dca) and input data category. The comparison is performed for values of the attributes common to both objects. Length differences are treated inequality out of hand. Args: dcObj (object): DataCategory object ignoreOrder (bool, optional): ignore attribute order. Defaults to True. floatRelTolerance (float, optional): relative tolerance for float comparisons. Defaults to 1e-05. floatAbsTolerance (float, optional): absolute tolerance for float comparisons. Defaults to 1e-04. Raises: e: any exception Returns: list: [(attributeName, values equal/close flag (bool)), (attributeName, values equal/close flag (bool), ...] \"\"\" rL = [] floatRelTolerance = kwargs . get ( \"floatRelTolerance\" , 1.0e-05 ) floatAbsTolerance = kwargs . get ( \"floatAbsTolerance\" , 1.0e-04 ) try : sa = set ( self . getAttributeList ()) sb = set ( dcObj . getAttributeList ()) atNameComList = list ( sa & sb ) # lenEq = self . getRowCount () == dcObj . getRowCount () if not lenEq : return [( atName , False ) for atName in atNameComList ] # for atName in atNameComList : dataType , _ = self . __getAttributeInfo ( atName ) if dataType in [ \"string\" , \"integer\" ]: if ignoreOrder : same = sorted ( self . getAttributeValueList ( atName )) == sorted ( dcObj . getAttributeValueList ( atName )) else : same = self . getAttributeValueList ( atName ) == dcObj . getAttributeValueList ( atName ) elif dataType in [ \"float\" ]: aVL = self . getAttributeValueList ( atName ) bVL = dcObj . getAttributeValueList ( atName ) if ignoreOrder : for aV , bV in zip ( sorted ( aVL ), sorted ( bVL )): same = self . __isClose ( aV , bV , relTol = floatRelTolerance , absTol = floatAbsTolerance ) if not same : break else : for aV , bV in zip ( aVL , bVL ): same = self . __isClose ( aV , bV , relTol = floatRelTolerance , absTol = floatAbsTolerance ) if not same : logger . info ( \" %s %s (rel= %r ) (abs= %r ) %r ( %r )\" , self . getName (), atName , aV * floatRelTolerance , floatAbsTolerance , aV , abs ( aV - bV )) break rL . append (( atName , same )) # return rL except Exception as e : if self . _raiseExceptions : raise e return rL def __getAttributeInfo ( self , atName ): \"\"\"Get attribute data type (string, integer, or float) and optionality Args: atName (str): attribute name Returns: (string, bool): data type (string, integer or float) and mandatory code \"\"\" cifDataType = self . __dApi . getTypeCode ( self . getName (), atName ) cifPrimitiveType = self . __dApi . getTypePrimitive ( self . getName (), atName ) isMandatory = self . __dApi . getMandatoryCode ( self . getName (), atName ) in [ \"yes\" , \"implicit\" , \"implicit-ordinal\" ] dataType = \"integer\" if \"int\" in cifDataType else \"float\" if cifPrimitiveType == \"numb\" else \"string\" return dataType , isMandatory def __isClose ( self , aV , bV , relTol = 1e-09 , absTol = 1e-06 ): if aV is None and bV is None : return True elif aV is not None and bV is not None and aV == bV : return True elif isinstance ( aV , ( float )) and isinstance ( bV , ( float )): return abs ( aV - bV ) <= max ( relTol * max ( abs ( aV ), abs ( bV )), absTol ) else : raise ValueError","title":"DataCategoryTyped"},{"location":"api_reference/DataCategoryTyped/#mmcif.api.DataCategoryTyped.DataCategoryTyped-methods","text":"","title":"Methods"},{"location":"api_reference/DataCategoryTyped/#mmcif.api.DataCategoryTyped.DataCategoryTyped.__init__","text":"A subclass of DataCategory with methods to apply explicit data typing. Parameters: Name Type Description Default dataCategoryObj object DataCategory object instance required dictionaryApi object instance of DictionaryApi class. Defaults to None. None raiseExceptions bool raise exceptions. Defaults to True. True copyInputData bool make a new copy input data. Defaults to True. True ignoreCastErrors bool ignore data processing cast errors. Defaults to False. False useCifUnknowns bool use CIF style missing values ('.' and '?'). Defaults to True. True missingValueString str missing string value . Defaults to None. None missingValueInteger integer missing integer value. Defaults to None. None missingValueFloat float missing float value. Defaults to None. None Source code in mmcif/api/DataCategoryTyped.py def __init__ ( self , dataCategoryObj , dictionaryApi = None , raiseExceptions = True , copyInputData = True , ignoreCastErrors = False , useCifUnknowns = True , missingValueString = None , missingValueInteger = None , missingValueFloat = None , ): \"\"\"A subclass of DataCategory with methods to apply explicit data typing. Args: dataCategoryObj (object): DataCategory object instance dictionaryApi (object, optional): instance of DictionaryApi class. Defaults to None. raiseExceptions (bool, optional): raise exceptions. Defaults to True. copyInputData (bool, optional): make a new copy input data. Defaults to True. ignoreCastErrors (bool, optional): ignore data processing cast errors. Defaults to False. useCifUnknowns (bool, optional): use CIF style missing values ('.' and '?'). Defaults to True. missingValueString (str, optional): missing string value . Defaults to None. missingValueInteger (integer, optional): missing integer value. Defaults to None. missingValueFloat (float, optional): missing float value. Defaults to None. \"\"\" self . __dcObj = dataCategoryObj super ( DataCategoryTyped , self ) . __init__ ( self . __dcObj . getName (), self . __dcObj . getAttributeList (), self . __dcObj . data , raiseExceptions = raiseExceptions , copyInputData = copyInputData , ) # self . __dApi = dictionaryApi self . __attributeTypeD = {} self . __castD = { \"integer\" : int , \"float\" : float , \"string\" : str } self . __typesSet = self . applyTypes ( ignoreCastErrors = ignoreCastErrors , useCifUnknowns = useCifUnknowns , missingValueString = missingValueString , missingValueInteger = missingValueInteger , missingValueFloat = missingValueFloat , )","title":"__init__()"},{"location":"api_reference/DataCategoryTyped/#mmcif.api.DataCategoryTyped.DataCategoryTyped.applyStringTypes","text":"Cast data types to strings in the current object. Missing values are set to '?' and '.' for optional and mandatory attributes, respectively. Exceptions: Type Description e any exception Returns: Type Description bool True for success or False otherwise Source code in mmcif/api/DataCategoryTyped.py def applyStringTypes ( self ): \"\"\"Cast data types to strings in the current object. Missing values are set to '?' and '.' for optional and mandatory attributes, respectively. Raises: e: any exception Returns: bool: True for success or False otherwise \"\"\" ok = False try : for ii , atName in enumerate ( self . getAttributeList ()): _ , isMandatory = self . __getAttributeInfo ( atName ) dataType = \"string\" for row in self . data : if row [ ii ] is None or row [ ii ] in [ \".\" , \"?\" ]: row [ ii ] = \".\" if isMandatory else \"?\" else : row [ ii ] = self . __castD [ dataType ]( row [ ii ]) # self . __attributeTypeD [ atName ] = dataType ok = True except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) if self . _raiseExceptions : raise e return ok","title":"applyStringTypes()"},{"location":"api_reference/DataCategoryTyped/#mmcif.api.DataCategoryTyped.DataCategoryTyped.applyTypes","text":"Cast data types (string, integer, float) in the current object based on dictionary type details. Missing values ('.' or '?') are set to None. Exceptions: Type Description e any exception Returns: Type Description bool True for success or False otherwise Source code in mmcif/api/DataCategoryTyped.py def applyTypes ( self , ignoreCastErrors = False , useCifUnknowns = True , missingValueString = None , missingValueInteger = None , missingValueFloat = None ): \"\"\"Cast data types (string, integer, float) in the current object based on dictionary type details. Missing values ('.' or '?') are set to None. Raises: e: any exception Returns: bool: True for success or False otherwise \"\"\" ok = False try : for ii , atName in enumerate ( self . getAttributeList ()): # colValL = self.getColumn(ii) dataType , isMandatory = self . __getAttributeInfo ( atName ) missingValue = missingValueInteger if dataType == \"integer\" else missingValueFloat if dataType in [ \"integer\" , \"float\" ] else missingValueString missingValue = missingValue if not useCifUnknowns else \".\" if isMandatory else \"?\" for row in self . data : try : row [ ii ] = self . __castD [ dataType ]( row [ ii ]) if row [ ii ] is not None and row [ ii ] not in [ \".\" , \"?\" ] else missingValue except Exception as e : if not ignoreCastErrors : logger . error ( \"Cast error %s %s ( %s ) %r %r \" , self . getName (), atName , dataType , row [ ii ], str ( e )) row [ ii ] = missingValue # logger . debug ( \" %s %s %r \" , self . getName (), atName , [ row [ ii ] for row in self . data ]) self . __attributeTypeD [ atName ] = dataType ok = True except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) if self . _raiseExceptions : raise e return ok","title":"applyTypes()"},{"location":"api_reference/DataCategoryTyped/#mmcif.api.DataCategoryTyped.DataCategoryTyped.cmpAttributeValues","text":"Compare the values by attribute for current typed data category (dca) and input data category. The comparison is performed for values of the attributes common to both objects. Length differences are treated inequality out of hand. Parameters: Name Type Description Default dcObj object DataCategory object required ignoreOrder bool ignore attribute order. Defaults to True. True floatRelTolerance float relative tolerance for float comparisons. Defaults to 1e-05. required floatAbsTolerance float absolute tolerance for float comparisons. Defaults to 1e-04. required Exceptions: Type Description e any exception Returns: Type Description list [(attributeName, values equal/close flag (bool)), (attributeName, values equal/close flag (bool), ...] Source code in mmcif/api/DataCategoryTyped.py def cmpAttributeValues ( self , dcObj , ignoreOrder = True , ** kwargs ): \"\"\"Compare the values by attribute for current typed data category (dca) and input data category. The comparison is performed for values of the attributes common to both objects. Length differences are treated inequality out of hand. Args: dcObj (object): DataCategory object ignoreOrder (bool, optional): ignore attribute order. Defaults to True. floatRelTolerance (float, optional): relative tolerance for float comparisons. Defaults to 1e-05. floatAbsTolerance (float, optional): absolute tolerance for float comparisons. Defaults to 1e-04. Raises: e: any exception Returns: list: [(attributeName, values equal/close flag (bool)), (attributeName, values equal/close flag (bool), ...] \"\"\" rL = [] floatRelTolerance = kwargs . get ( \"floatRelTolerance\" , 1.0e-05 ) floatAbsTolerance = kwargs . get ( \"floatAbsTolerance\" , 1.0e-04 ) try : sa = set ( self . getAttributeList ()) sb = set ( dcObj . getAttributeList ()) atNameComList = list ( sa & sb ) # lenEq = self . getRowCount () == dcObj . getRowCount () if not lenEq : return [( atName , False ) for atName in atNameComList ] # for atName in atNameComList : dataType , _ = self . __getAttributeInfo ( atName ) if dataType in [ \"string\" , \"integer\" ]: if ignoreOrder : same = sorted ( self . getAttributeValueList ( atName )) == sorted ( dcObj . getAttributeValueList ( atName )) else : same = self . getAttributeValueList ( atName ) == dcObj . getAttributeValueList ( atName ) elif dataType in [ \"float\" ]: aVL = self . getAttributeValueList ( atName ) bVL = dcObj . getAttributeValueList ( atName ) if ignoreOrder : for aV , bV in zip ( sorted ( aVL ), sorted ( bVL )): same = self . __isClose ( aV , bV , relTol = floatRelTolerance , absTol = floatAbsTolerance ) if not same : break else : for aV , bV in zip ( aVL , bVL ): same = self . __isClose ( aV , bV , relTol = floatRelTolerance , absTol = floatAbsTolerance ) if not same : logger . info ( \" %s %s (rel= %r ) (abs= %r ) %r ( %r )\" , self . getName (), atName , aV * floatRelTolerance , floatAbsTolerance , aV , abs ( aV - bV )) break rL . append (( atName , same )) # return rL except Exception as e : if self . _raiseExceptions : raise e return rL","title":"cmpAttributeValues()"},{"location":"api_reference/DataCategoryTyped/#mmcif.api.DataCategoryTyped.DataCategoryTyped.getAttributeInfo","text":"Get attribute data type (string, integer, or float) and optionality Parameters: Name Type Description Default atName str attribute name required Returns: Type Description (string, bool) data type (string, integer or float) and mandatory code Source code in mmcif/api/DataCategoryTyped.py def getAttributeInfo ( self , atName ): \"\"\"Get attribute data type (string, integer, or float) and optionality Args: atName (str): attribute name Returns: (string, bool): data type (string, integer or float) and mandatory code \"\"\" try : dataType , mandatoryCode = self . __getAttributeInfo ( atName ) return dataType , mandatoryCode except Exception : return None , None","title":"getAttributeInfo()"},{"location":"api_reference/DictMethodRunner/","text":"mmcif.api.DictMethodRunner.DictMethodRunner Manage the invocation of dictionary methods implemented as class methods. Source code in mmcif/api/DictMethodRunner.py class DictMethodRunner ( object ): \"\"\"Manage the invocation of dictionary methods implemented as class methods.\"\"\" def __init__ ( self , dictionaryApi , modulePathMap = None , ** kwargs ): \"\"\"Manage invocation of dictionary methods referenced in external modules. Arguments: dictionaryApi {object} -- instance of DictionaryApi() for dictionary with target method definitions Keyword Arguments: modulePathMap {dict str} -- mapping between dictionary module path and execution path (default: {None}) cacheModuleFlag {bool} -- flag to cache module instances (defaullt: True) implentationSource {str} -- method implementation (default: 'reference') methodCodes (list str) -- filter methods by codes {default: ['calculation']} \"\"\" self . __dApi = dictionaryApi self . __modulePathMap = modulePathMap if modulePathMap else {} self . __cacheModuleFlag = kwargs . get ( \"cacheModuleFlag\" , True ) methodCodes = kwargs . get ( \"methodCodes\" , [ \"calculation\" ]) implementationSource = kwargs . get ( \"implementationCodes\" , \"reference\" ) # self . __kwargs = kwargs # # Preserve and reuse the module instances if caching is enabled self . __moduleCache = {} # self . __methodD = self . __getMethodInfo ( implementationSource = implementationSource , methodCodes = methodCodes ) logger . debug ( \"Method index %r \" , self . __methodD . items ()) def __getMethodInfo ( self , implementationSource = \"reference\" , methodCodes = None ): \"\"\"Get method implementation with the input implementation source.\"\"\" catName = atName = mId = mType = methDef = None methodCodes = methodCodes if methodCodes else [ \"calculation\" ] methodD = {} try : methodIndex = self . __dApi . getMethodIndex () for _ , mrL in methodIndex . items (): for mr in mrL : mId = mr . getId () catName = mr . getCategoryName () atName = mr . getAttributeName () mType = mr . getType () if ( catName , atName ) not in methodD : methodD [( catName , atName )] = [] methDef = self . __dApi . getMethod ( mId ) logger . debug ( \"Category %s attribute %s mId %r type %r methDef %r \" , catName , atName , mId , mType , methDef ) mSource = methDef . getImplementationSource () mCode = methDef . getCode () if mSource == implementationSource and mCode in methodCodes : mPriority = methDef . getPriority () mLang = methDef . getLanguage () mImplement = methDef . getImplementation () dD = { \"METHOD_LANGUAGE\" : mLang , \"METHOD_IMPLEMENT\" : mImplement , \"METHOD_TYPE\" : mType , \"METHOD_CODE\" : mCode , \"METHOD_PRIORITY\" : mPriority } methodD [( catName , atName )] . append ( dD ) # except Exception as e : logger . exception ( \"Failing for category %r attribute %r mId %r type %r methDef %r with %s \" , catName , atName , mId , mType , methDef , str ( e )) ## logger . debug ( \"Method dictionary %r \" , methodD ) return methodD def __invokeAttributeMethod ( self , methodPath , dataContainer , catName , atName , ** kwargs ): \"\"\"Invoke the input attribute method\"\"\" ok = False try : modulePath , methodName = self . __methodPathSplit ( methodPath ) mObj = self . __getModuleInstance ( modulePath , ** kwargs ) theMeth = getattr ( mObj , methodName , None ) ok = theMeth ( dataContainer , catName , atName , ** kwargs ) except Exception as e : logger . exception ( \"Failed invoking attribute %s %s method %r with %s \" , catName , atName , methodPath , str ( e )) return ok def __invokeCategoryMethod ( self , methodPath , dataContainer , catName , ** kwargs ): \"\"\"Invoke the input category method\"\"\" ok = False try : modulePath , methodName = self . __methodPathSplit ( methodPath ) mObj = self . __getModuleInstance ( modulePath , ** kwargs ) theMeth = getattr ( mObj , methodName , None ) ok = theMeth ( dataContainer , catName , ** kwargs ) except Exception as e : logger . exception ( \"Failed invoking category %s method %r with %s \" , catName , methodPath , str ( e )) return ok def __invokeDatablockMethod ( self , methodPath , dataContainer , blockName , ** kwargs ): \"\"\"Invoke the input data block method\"\"\" ok = False try : modulePath , methodName = self . __methodPathSplit ( methodPath ) mObj = self . __getModuleInstance ( modulePath , ** kwargs ) theMeth = getattr ( mObj , methodName , None ) ok = theMeth ( dataContainer , blockName , ** kwargs ) except Exception as e : logger . exception ( \"Failed invoking block %s method %r with %s \" , blockName , methodPath , str ( e )) return ok def apply ( self , dataContainer ): \"\"\"Apply category, attribute and block level dictionary methods on the input data container.\"\"\" kwargs = self . __kwargs mTupL = self . __getCategoryMethods () logger . debug ( \"Category methods %r \" , mTupL ) for catName , _ , methodPath , _ in mTupL : self . __invokeCategoryMethod ( methodPath , dataContainer , catName , ** kwargs ) mTupL = self . __getAttributeMethods () logger . debug ( \"Attribute methods %r \" , mTupL ) for catName , atName , methodPath , _ in mTupL : self . __invokeAttributeMethod ( methodPath , dataContainer , catName , atName , ** kwargs ) mTupL = self . __getDatablockMethods () logger . debug ( \"Datablock methods %r \" , mTupL ) for _ , _ , methodPath , _ in mTupL : self . __invokeDatablockMethod ( methodPath , dataContainer , dataContainer . getName (), ** kwargs ) return True def __getDatablockMethods ( self ): mL = [] try : for ( dictName , _ ), mDL in self . __methodD . items (): for mD in mDL : if mD [ \"METHOD_TYPE\" ] . lower () == \"datablock\" : methodPath = mD [ \"METHOD_IMPLEMENT\" ] mL . append (( dictName , None , methodPath , mD [ \"METHOD_PRIORITY\" ])) mL = sorted ( mL , key = itemgetter ( 3 )) return mL except Exception as e : logger . exception ( \"Failing dictName %s with %s \" , dictName , str ( e )) return mL def __getCategoryMethods ( self ): mL = [] try : for ( catName , _ ), mDL in self . __methodD . items (): for mD in mDL : if mD [ \"METHOD_TYPE\" ] . lower () == \"category\" : methodPath = mD [ \"METHOD_IMPLEMENT\" ] mL . append (( catName , None , methodPath , mD [ \"METHOD_PRIORITY\" ])) mL = sorted ( mL , key = itemgetter ( 3 )) return mL except Exception as e : logger . exception ( \"Failing catName %r with %s \" , catName , str ( e )) return mL def __getAttributeMethods ( self ): mL = [] try : for ( catName , atName ), mDL in self . __methodD . items (): for mD in mDL : if mD [ \"METHOD_TYPE\" ] . lower () == \"attribute\" : methodPath = mD [ \"METHOD_IMPLEMENT\" ] mL . append (( catName , atName , methodPath , mD [ \"METHOD_PRIORITY\" ])) mL = sorted ( mL , key = itemgetter ( 3 )) return mL except Exception as e : logger . exception ( \"Failing catName %s atName %s with %s \" , catName , atName , str ( e )) return mL def __methodPathSplit ( self , methodPath ): \"\"\"Extract module path and the method name from the input path. Optional remap the module path. Arguments: methodPath {str} -- implementation path from dictionary method definition Returns: {tuple str} -- module path, method name \"\"\" try : # Strip off any leading path of the module from the method path. mpL = str ( methodPath ) . split ( \".\" ) methodName = mpL [ - 1 ] tp = \".\" . join ( mpL [: - 1 ]) modulePath = self . __modulePathMap [ tp ] if tp in self . __modulePathMap else tp return modulePath , methodName except Exception as e : logger . error ( \"Failing for method path %r with %s \" , methodPath , str ( e )) return None , None def __getModuleInstance ( self , modulePath , ** kwargs ): # if self . __cacheModuleFlag and modulePath in self . __moduleCache : return self . __moduleCache [ modulePath ] # mObj = None try : aMod = __import__ ( modulePath , globals (), locals (), [ \"\" ]) sys . modules [ modulePath ] = aMod # # Strip off any leading path to the module before we instaniate the module object. mpL = str ( modulePath ) . split ( \".\" ) moduleName = mpL [ - 1 ] # # Add the internal dictionaryApi object instance as a kw option # kwargs [ \"dictionaryApi\" ] = self . __dApi mObj = getattr ( aMod , moduleName )( ** kwargs ) self . __moduleCache [ modulePath ] = mObj except Exception as e : logger . error ( \"Failing to instance helper %r with %s \" , modulePath , str ( e )) return mObj Methods __init__ ( self , dictionaryApi , modulePathMap = None , ** kwargs ) special Manage invocation of dictionary methods referenced in external modules. Keyword arguments: Name Type Description modulePathMap {dict str} -- mapping between dictionary module path and execution path (default {None}) cacheModuleFlag {bool} -- flag to cache module instances (defaullt True) implentationSource {str} -- method implementation (default 'reference') methodCodes list str) -- filter methods by codes {default ['calculation']} Source code in mmcif/api/DictMethodRunner.py def __init__ ( self , dictionaryApi , modulePathMap = None , ** kwargs ): \"\"\"Manage invocation of dictionary methods referenced in external modules. Arguments: dictionaryApi {object} -- instance of DictionaryApi() for dictionary with target method definitions Keyword Arguments: modulePathMap {dict str} -- mapping between dictionary module path and execution path (default: {None}) cacheModuleFlag {bool} -- flag to cache module instances (defaullt: True) implentationSource {str} -- method implementation (default: 'reference') methodCodes (list str) -- filter methods by codes {default: ['calculation']} \"\"\" self . __dApi = dictionaryApi self . __modulePathMap = modulePathMap if modulePathMap else {} self . __cacheModuleFlag = kwargs . get ( \"cacheModuleFlag\" , True ) methodCodes = kwargs . get ( \"methodCodes\" , [ \"calculation\" ]) implementationSource = kwargs . get ( \"implementationCodes\" , \"reference\" ) # self . __kwargs = kwargs # # Preserve and reuse the module instances if caching is enabled self . __moduleCache = {} # self . __methodD = self . __getMethodInfo ( implementationSource = implementationSource , methodCodes = methodCodes ) logger . debug ( \"Method index %r \" , self . __methodD . items ()) apply ( self , dataContainer ) Apply category, attribute and block level dictionary methods on the input data container. Source code in mmcif/api/DictMethodRunner.py def apply ( self , dataContainer ): \"\"\"Apply category, attribute and block level dictionary methods on the input data container.\"\"\" kwargs = self . __kwargs mTupL = self . __getCategoryMethods () logger . debug ( \"Category methods %r \" , mTupL ) for catName , _ , methodPath , _ in mTupL : self . __invokeCategoryMethod ( methodPath , dataContainer , catName , ** kwargs ) mTupL = self . __getAttributeMethods () logger . debug ( \"Attribute methods %r \" , mTupL ) for catName , atName , methodPath , _ in mTupL : self . __invokeAttributeMethod ( methodPath , dataContainer , catName , atName , ** kwargs ) mTupL = self . __getDatablockMethods () logger . debug ( \"Datablock methods %r \" , mTupL ) for _ , _ , methodPath , _ in mTupL : self . __invokeDatablockMethod ( methodPath , dataContainer , dataContainer . getName (), ** kwargs ) return True","title":"DictMethodRunner"},{"location":"api_reference/DictMethodRunner/#mmcif.api.DictMethodRunner.DictMethodRunner","text":"Manage the invocation of dictionary methods implemented as class methods. Source code in mmcif/api/DictMethodRunner.py class DictMethodRunner ( object ): \"\"\"Manage the invocation of dictionary methods implemented as class methods.\"\"\" def __init__ ( self , dictionaryApi , modulePathMap = None , ** kwargs ): \"\"\"Manage invocation of dictionary methods referenced in external modules. Arguments: dictionaryApi {object} -- instance of DictionaryApi() for dictionary with target method definitions Keyword Arguments: modulePathMap {dict str} -- mapping between dictionary module path and execution path (default: {None}) cacheModuleFlag {bool} -- flag to cache module instances (defaullt: True) implentationSource {str} -- method implementation (default: 'reference') methodCodes (list str) -- filter methods by codes {default: ['calculation']} \"\"\" self . __dApi = dictionaryApi self . __modulePathMap = modulePathMap if modulePathMap else {} self . __cacheModuleFlag = kwargs . get ( \"cacheModuleFlag\" , True ) methodCodes = kwargs . get ( \"methodCodes\" , [ \"calculation\" ]) implementationSource = kwargs . get ( \"implementationCodes\" , \"reference\" ) # self . __kwargs = kwargs # # Preserve and reuse the module instances if caching is enabled self . __moduleCache = {} # self . __methodD = self . __getMethodInfo ( implementationSource = implementationSource , methodCodes = methodCodes ) logger . debug ( \"Method index %r \" , self . __methodD . items ()) def __getMethodInfo ( self , implementationSource = \"reference\" , methodCodes = None ): \"\"\"Get method implementation with the input implementation source.\"\"\" catName = atName = mId = mType = methDef = None methodCodes = methodCodes if methodCodes else [ \"calculation\" ] methodD = {} try : methodIndex = self . __dApi . getMethodIndex () for _ , mrL in methodIndex . items (): for mr in mrL : mId = mr . getId () catName = mr . getCategoryName () atName = mr . getAttributeName () mType = mr . getType () if ( catName , atName ) not in methodD : methodD [( catName , atName )] = [] methDef = self . __dApi . getMethod ( mId ) logger . debug ( \"Category %s attribute %s mId %r type %r methDef %r \" , catName , atName , mId , mType , methDef ) mSource = methDef . getImplementationSource () mCode = methDef . getCode () if mSource == implementationSource and mCode in methodCodes : mPriority = methDef . getPriority () mLang = methDef . getLanguage () mImplement = methDef . getImplementation () dD = { \"METHOD_LANGUAGE\" : mLang , \"METHOD_IMPLEMENT\" : mImplement , \"METHOD_TYPE\" : mType , \"METHOD_CODE\" : mCode , \"METHOD_PRIORITY\" : mPriority } methodD [( catName , atName )] . append ( dD ) # except Exception as e : logger . exception ( \"Failing for category %r attribute %r mId %r type %r methDef %r with %s \" , catName , atName , mId , mType , methDef , str ( e )) ## logger . debug ( \"Method dictionary %r \" , methodD ) return methodD def __invokeAttributeMethod ( self , methodPath , dataContainer , catName , atName , ** kwargs ): \"\"\"Invoke the input attribute method\"\"\" ok = False try : modulePath , methodName = self . __methodPathSplit ( methodPath ) mObj = self . __getModuleInstance ( modulePath , ** kwargs ) theMeth = getattr ( mObj , methodName , None ) ok = theMeth ( dataContainer , catName , atName , ** kwargs ) except Exception as e : logger . exception ( \"Failed invoking attribute %s %s method %r with %s \" , catName , atName , methodPath , str ( e )) return ok def __invokeCategoryMethod ( self , methodPath , dataContainer , catName , ** kwargs ): \"\"\"Invoke the input category method\"\"\" ok = False try : modulePath , methodName = self . __methodPathSplit ( methodPath ) mObj = self . __getModuleInstance ( modulePath , ** kwargs ) theMeth = getattr ( mObj , methodName , None ) ok = theMeth ( dataContainer , catName , ** kwargs ) except Exception as e : logger . exception ( \"Failed invoking category %s method %r with %s \" , catName , methodPath , str ( e )) return ok def __invokeDatablockMethod ( self , methodPath , dataContainer , blockName , ** kwargs ): \"\"\"Invoke the input data block method\"\"\" ok = False try : modulePath , methodName = self . __methodPathSplit ( methodPath ) mObj = self . __getModuleInstance ( modulePath , ** kwargs ) theMeth = getattr ( mObj , methodName , None ) ok = theMeth ( dataContainer , blockName , ** kwargs ) except Exception as e : logger . exception ( \"Failed invoking block %s method %r with %s \" , blockName , methodPath , str ( e )) return ok def apply ( self , dataContainer ): \"\"\"Apply category, attribute and block level dictionary methods on the input data container.\"\"\" kwargs = self . __kwargs mTupL = self . __getCategoryMethods () logger . debug ( \"Category methods %r \" , mTupL ) for catName , _ , methodPath , _ in mTupL : self . __invokeCategoryMethod ( methodPath , dataContainer , catName , ** kwargs ) mTupL = self . __getAttributeMethods () logger . debug ( \"Attribute methods %r \" , mTupL ) for catName , atName , methodPath , _ in mTupL : self . __invokeAttributeMethod ( methodPath , dataContainer , catName , atName , ** kwargs ) mTupL = self . __getDatablockMethods () logger . debug ( \"Datablock methods %r \" , mTupL ) for _ , _ , methodPath , _ in mTupL : self . __invokeDatablockMethod ( methodPath , dataContainer , dataContainer . getName (), ** kwargs ) return True def __getDatablockMethods ( self ): mL = [] try : for ( dictName , _ ), mDL in self . __methodD . items (): for mD in mDL : if mD [ \"METHOD_TYPE\" ] . lower () == \"datablock\" : methodPath = mD [ \"METHOD_IMPLEMENT\" ] mL . append (( dictName , None , methodPath , mD [ \"METHOD_PRIORITY\" ])) mL = sorted ( mL , key = itemgetter ( 3 )) return mL except Exception as e : logger . exception ( \"Failing dictName %s with %s \" , dictName , str ( e )) return mL def __getCategoryMethods ( self ): mL = [] try : for ( catName , _ ), mDL in self . __methodD . items (): for mD in mDL : if mD [ \"METHOD_TYPE\" ] . lower () == \"category\" : methodPath = mD [ \"METHOD_IMPLEMENT\" ] mL . append (( catName , None , methodPath , mD [ \"METHOD_PRIORITY\" ])) mL = sorted ( mL , key = itemgetter ( 3 )) return mL except Exception as e : logger . exception ( \"Failing catName %r with %s \" , catName , str ( e )) return mL def __getAttributeMethods ( self ): mL = [] try : for ( catName , atName ), mDL in self . __methodD . items (): for mD in mDL : if mD [ \"METHOD_TYPE\" ] . lower () == \"attribute\" : methodPath = mD [ \"METHOD_IMPLEMENT\" ] mL . append (( catName , atName , methodPath , mD [ \"METHOD_PRIORITY\" ])) mL = sorted ( mL , key = itemgetter ( 3 )) return mL except Exception as e : logger . exception ( \"Failing catName %s atName %s with %s \" , catName , atName , str ( e )) return mL def __methodPathSplit ( self , methodPath ): \"\"\"Extract module path and the method name from the input path. Optional remap the module path. Arguments: methodPath {str} -- implementation path from dictionary method definition Returns: {tuple str} -- module path, method name \"\"\" try : # Strip off any leading path of the module from the method path. mpL = str ( methodPath ) . split ( \".\" ) methodName = mpL [ - 1 ] tp = \".\" . join ( mpL [: - 1 ]) modulePath = self . __modulePathMap [ tp ] if tp in self . __modulePathMap else tp return modulePath , methodName except Exception as e : logger . error ( \"Failing for method path %r with %s \" , methodPath , str ( e )) return None , None def __getModuleInstance ( self , modulePath , ** kwargs ): # if self . __cacheModuleFlag and modulePath in self . __moduleCache : return self . __moduleCache [ modulePath ] # mObj = None try : aMod = __import__ ( modulePath , globals (), locals (), [ \"\" ]) sys . modules [ modulePath ] = aMod # # Strip off any leading path to the module before we instaniate the module object. mpL = str ( modulePath ) . split ( \".\" ) moduleName = mpL [ - 1 ] # # Add the internal dictionaryApi object instance as a kw option # kwargs [ \"dictionaryApi\" ] = self . __dApi mObj = getattr ( aMod , moduleName )( ** kwargs ) self . __moduleCache [ modulePath ] = mObj except Exception as e : logger . error ( \"Failing to instance helper %r with %s \" , modulePath , str ( e )) return mObj","title":"DictMethodRunner"},{"location":"api_reference/DictMethodRunner/#mmcif.api.DictMethodRunner.DictMethodRunner-methods","text":"","title":"Methods"},{"location":"api_reference/DictMethodRunner/#mmcif.api.DictMethodRunner.DictMethodRunner.__init__","text":"Manage invocation of dictionary methods referenced in external modules. Keyword arguments: Name Type Description modulePathMap {dict str} -- mapping between dictionary module path and execution path (default {None}) cacheModuleFlag {bool} -- flag to cache module instances (defaullt True) implentationSource {str} -- method implementation (default 'reference') methodCodes list str) -- filter methods by codes {default ['calculation']} Source code in mmcif/api/DictMethodRunner.py def __init__ ( self , dictionaryApi , modulePathMap = None , ** kwargs ): \"\"\"Manage invocation of dictionary methods referenced in external modules. Arguments: dictionaryApi {object} -- instance of DictionaryApi() for dictionary with target method definitions Keyword Arguments: modulePathMap {dict str} -- mapping between dictionary module path and execution path (default: {None}) cacheModuleFlag {bool} -- flag to cache module instances (defaullt: True) implentationSource {str} -- method implementation (default: 'reference') methodCodes (list str) -- filter methods by codes {default: ['calculation']} \"\"\" self . __dApi = dictionaryApi self . __modulePathMap = modulePathMap if modulePathMap else {} self . __cacheModuleFlag = kwargs . get ( \"cacheModuleFlag\" , True ) methodCodes = kwargs . get ( \"methodCodes\" , [ \"calculation\" ]) implementationSource = kwargs . get ( \"implementationCodes\" , \"reference\" ) # self . __kwargs = kwargs # # Preserve and reuse the module instances if caching is enabled self . __moduleCache = {} # self . __methodD = self . __getMethodInfo ( implementationSource = implementationSource , methodCodes = methodCodes ) logger . debug ( \"Method index %r \" , self . __methodD . items ())","title":"__init__()"},{"location":"api_reference/DictMethodRunner/#mmcif.api.DictMethodRunner.DictMethodRunner.apply","text":"Apply category, attribute and block level dictionary methods on the input data container. Source code in mmcif/api/DictMethodRunner.py def apply ( self , dataContainer ): \"\"\"Apply category, attribute and block level dictionary methods on the input data container.\"\"\" kwargs = self . __kwargs mTupL = self . __getCategoryMethods () logger . debug ( \"Category methods %r \" , mTupL ) for catName , _ , methodPath , _ in mTupL : self . __invokeCategoryMethod ( methodPath , dataContainer , catName , ** kwargs ) mTupL = self . __getAttributeMethods () logger . debug ( \"Attribute methods %r \" , mTupL ) for catName , atName , methodPath , _ in mTupL : self . __invokeAttributeMethod ( methodPath , dataContainer , catName , atName , ** kwargs ) mTupL = self . __getDatablockMethods () logger . debug ( \"Datablock methods %r \" , mTupL ) for _ , _ , methodPath , _ in mTupL : self . __invokeDatablockMethod ( methodPath , dataContainer , dataContainer . getName (), ** kwargs ) return True","title":"apply()"},{"location":"api_reference/DictionaryApi/","text":"mmcif.api.DictionaryApi.DictionaryApi Source code in mmcif/api/DictionaryApi.py class DictionaryApi ( object ): def __init__ ( self , containerList , consolidate = True , expandItemLinked = False , replaceDefinition = False , ** kwargs ): \"\"\"Return an instance of the mmCIF dictionary API. Args: containerList (list): list of definition or data containers holding dictionary content consolidate (bool, optional): consolidate dictionary attributes within a single definition. Defaults to True. expandItemLinked (bool, optional): distribute item and item linked attributes defined for the parent to child definitions. Defaults to False. replaceDefinition (bool, optional): when consolidating definitions in the case of multiple occurences of the same definition, attributes from the latter occurences replace prior definitions content. Defaults to False. \"\"\" _ = kwargs # self . __containerList = containerList self . __replaceDefinition = replaceDefinition # if consolidate : self . __consolidateDefinitions () # if expandItemLinked : self . __expandLoopedDefinitions () self . __fullIndex = OrderedDict () # --- # # Map category name to the unique list of attributes self . __catNameIndex = OrderedDict () # Map category name to the unique list of item names self . __catNameItemIndex = OrderedDict () # Full unique list of item names - self . __itemNameList = [] # # Map dictionary objects names to definition containers - self . __definitionIndex = OrderedDict () # # data section/objects of the dictionary by category name - self . __dataIndex = OrderedDict () # # Map of types id->(regex,primitive_type) self . __typesDict = OrderedDict () # self . __enumD = { \"ENUMERATION_VALUE\" : ( \"item_enumeration\" , \"value\" ), \"ENUMERATION_DETAIL\" : ( \"item_enumeration\" , \"detail\" ), \"ENUMERATION_TYPE_UNITS\" : ( \"item_enumeration\" , \"rcsb_type_units_code\" ), \"ENUMERATION_DETAIL_BRIEF\" : ( \"item_enumeration\" , \"rcsb_detail_brief\" ), \"ENUMERATION_TUPLE\" : ( \"item_enumeration\" , None ), \"ITEM_LINKED_PARENT\" : ( \"item_linked\" , \"parent_name\" ), \"ITEM_LINKED_CHILD\" : ( \"item_linked\" , \"child_name\" ), \"DATA_TYPE_CODE\" : ( \"item_type\" , \"code\" ), \"DATA_TYPE_REGEX\" : ( \"item_type_list\" , \"construct\" ), \"DATA_TYPE_PRIMITIVE\" : ( \"item_type_list\" , \"primitive_code\" ), \"ITEM_NAME\" : ( \"item\" , \"name\" ), \"ITEM_CATEGORY_ID\" : ( \"item\" , \"category_id\" ), \"ITEM_MANDATORY_CODE\" : ( \"item\" , \"mandatory_code\" ), \"ITEM_DESCRIPTION\" : ( \"item_description\" , \"description\" ), \"ITEM_UNITS\" : ( \"item_units\" , \"code\" ), \"ITEM_DEFAULT_VALUE\" : ( \"item_default\" , \"value\" ), \"ITEM_EXAMPLE_CASE\" : ( \"item_examples\" , \"case\" ), \"ITEM_EXAMPLE_DETAIL\" : ( \"item_examples\" , \"detail\" ), \"ITEM_RANGE_MAXIMUM\" : ( \"item_range\" , \"maximum\" ), \"ITEM_RANGE_MINIMUM\" : ( \"item_range\" , \"minimum\" ), \"CATEGORY_KEY_ITEMS\" : ( \"category_key\" , \"name\" ), \"CATEGORY_EXAMPLE_CASE\" : ( \"category_examples\" , \"case\" ), \"CATEGORY_EXAMPLE_DETAIL\" : ( \"category_examples\" , \"detail\" ), \"CATEGORY_MANDATORY_CODE\" : ( \"category\" , \"mandatory_code\" ), \"CATEGORY_DESCRIPTION\" : ( \"category\" , \"description\" ), \"CATEGORY_NX_MAPPING_DETAILS\" : ( \"category\" , \"NX_mapping_details\" ), # \"DATA_TYPE_CODE_NDB\" : ( \"ndb_item_type\" , \"code\" ), \"ITEM_DESCRIPTION_NDB\" : ( \"ndb_item_description\" , \"description\" ), \"ENUMERATION_VALUE_NDB\" : ( \"ndb_item_enumeration\" , \"value\" ), \"ENUMERATION_DETAIL_NDB\" : ( \"ndb_item_enumeration\" , \"detail\" ), \"ITEM_MANDATORY_CODE_NDB\" : ( \"ndb_item\" , \"mandatory_code\" ), \"ITEM_EXAMPLE_CASE_NDB\" : ( \"ndb_item_examples\" , \"case\" ), \"ITEM_EXAMPLE_DETAIL_NDB\" : ( \"ndb_item_examples\" , \"detail\" ), \"ITEM_RANGE_MAXIMUM_NDB\" : ( \"ndb_item_range\" , \"maximum\" ), \"ITEM_RANGE_MINIMUM_NDB\" : ( \"ndb_item_range\" , \"minimum\" ), \"CATEGORY_EXAMPLE_CASE_NDB\" : ( \"ndb_category_examples\" , \"case\" ), \"CATEGORY_EXAMPLE_DETAIL_NDB\" : ( \"ndb_category_examples\" , \"detail\" ), \"CATEGORY_DESCRIPTION_NDB\" : ( \"ndb_category_description\" , \"description\" ), # \"DATA_TYPE_CODE_PDBX\" : ( \"pdbx_item_type\" , \"code\" ), \"ITEM_DESCRIPTION_PDBX\" : ( \"pdbx_item_description\" , \"description\" ), \"ENUMERATION_VALUE_PDBX\" : ( \"pdbx_item_enumeration\" , \"value\" ), \"ENUMERATION_DETAIL_PDBX\" : ( \"pdbx_item_enumeration\" , \"detail\" ), \"ENUMERATION_TYPE_UNITS_PDBX\" : ( \"pdbx_item_enumeration\" , \"type_units_code\" ), \"ENUMERATION_DETAIL_BRIEF_PDBX\" : ( \"pdbx_item_enumeration\" , \"detail_brief\" ), \"ITEM_MANDATORY_CODE_PDBX\" : ( \"pdbx_item\" , \"mandatory_code\" ), \"ITEM_EXAMPLE_CASE_PDBX\" : ( \"pdbx_item_examples\" , \"case\" ), \"ITEM_EXAMPLE_DETAIL_PDBX\" : ( \"pdbx_item_examples\" , \"detail\" ), \"ITEM_RANGE_MAXIMUM_PDBX\" : ( \"pdbx_item_range\" , \"maximum\" ), \"ITEM_RANGE_MINIMUM_PDBX\" : ( \"pdbx_item_range\" , \"minimum\" ), \"CATEGORY_EXAMPLE_CASE_PDBX\" : ( \"pdbx_category_examples\" , \"case\" ), \"CATEGORY_EXAMPLE_DETAIL_PDBX\" : ( \"pdbx_category_examples\" , \"detail\" ), \"CATEGORY_DESCRIPTION_PDBX\" : ( \"pdbx_category_description\" , \"description\" ), # \"CATEGORY_CONTEXT\" : ( \"pdbx_category_context\" , \"type\" ), \"CATEGORY_GROUP\" : ( \"category_group\" , \"id\" ), \"ITEM_CONTEXT\" : ( \"pdbx_item_context\" , \"type\" ), \"ENUMERATION_CLOSED_FLAG\" : ( \"pdbx_item_enumeration_details\" , \"closed_flag\" ), # \"ITEM_RELATED_FUNCTION_CODE\" : ( \"item_related\" , \"function_code\" ), \"ITEM_RELATED_RELATED_NAME\" : ( \"item_related\" , \"related_name\" ), \"ITEM_ALIAS_ALIAS_NAME\" : ( \"item_aliases\" , \"alias_name\" ), \"ITEM_ALIAS_DICTIONARY\" : ( \"item_aliases\" , \"dictionary\" ), \"ITEM_ALIAS_VERSION\" : ( \"item_aliases\" , \"version\" ), \"ITEM_DEPENDENT_DEPENDENT_NAME\" : ( \"item_dependent\" , \"dependent_name\" ), \"ITEM_SUB_CATEGORY_ID\" : ( \"item_sub_category\" , \"id\" ), \"ITEM_SUB_CATEGORY_LABEL\" : ( \"item_sub_category\" , \"pdbx_label\" ), \"ITEM_TYPE_CONDITIONS_CODE\" : ( \"item_type_conditions\" , \"code\" ), # \"ITEM_VALUE_CONDITION_DEPENDENT_NAME\" : ( \"pdbx_item_value_condition\" , \"dependent_item_name\" ), # \"ITEM_LINKED_PDBX_ID\" : ( \"pdbx_item_linked\" , \"id\" ), \"ITEM_LINKED_PDBX_CONDITION_ID\" : ( \"pdbx_item_linked\" , \"condition_id\" ), \"ITEM_LINKED_PDBX_PARENT_NAME\" : ( \"pdbx_item_linked\" , \"parent_name\" ), \"ITEM_LINKED_PDBX_CHILD_NAME\" : ( \"pdbx_item_linked\" , \"child_name\" ), # \"ITEM_LINKED_PDBX_CONDITION_CHILD_NAME\" : ( \"pdbx_item_linked\" , \"condition_child_name\" ), \"ITEM_LINKED_PDBX_CONDITION_CHILD_VALUE\" : ( \"pdbx_item_linked\" , \"condition_child_value\" ), \"ITEM_LINKED_PDBX_CONDITION_CHILD_TARGET_NAME\" : ( \"pdbx_item_linked\" , \"condition_child_target_name\" ), \"ITEM_LINKED_PDBX_CONDITION_CHILD_CMP_OP\" : ( \"pdbx_item_linked\" , \"condition_child_cmp_op\" ), \"ITEM_LINKED_PDBX_CONDITION_LOG_OP\" : ( \"pdbx_item_linked\" , \"condition_log_op\" ), } # self . __methodDict = OrderedDict () self . __methodIndex = OrderedDict () # self . __makeIndex () self . __getMethods () # self . __fullParentD , self . __fullChildD = self . __makeFullParentChildDictionaries () # # self . __dataBlockDictList = [] self . __dictionaryDictList = [] # self . __subCategoryDict = OrderedDict () self . __categoryGroupDict = OrderedDict () self . __groupIndex = False self . __groupChildIndex = OrderedDict () # # Data sections - # self . __dictionaryHistoryList = [] self . __itemUnitsDict = OrderedDict () self . __itemUnitsConversionList = [] self . __itemLinkedGroupDict = OrderedDict () self . __itemLinkedGroupItemDict = OrderedDict () # self . __dictionaryIncludeDict = OrderedDict () self . __categoryIncludeDict = OrderedDict () self . __itemIncludeDict = OrderedDict () # self . __dictionaryComponentList = [] self . __dictionaryComponentHistoryDict = OrderedDict () # self . __itemValueConditionDict = OrderedDict () self . __compOpDict = OrderedDict () # self . __getDataSections () # def testCache ( self ): return len ( self . __containerList ) > 0 # # Methods for data sections -- # def getItemValueConditionDict ( self ): try : return self . __itemValueConditionDict if self . __itemValueConditionDict else {} except Exception : return {} def getComparisonOperators ( self ): try : return list ( self . __compOpDict . keys ()) if self . __compOpDict else [] except Exception : return [] def getComparisonOperatorDict ( self ): try : return self . __compOpDict if self . __compOpDict else {} except Exception : return {} # def getDictionaryVersion ( self ): try : return \",\" . join ([ str ( tD [ \"version\" ]) for tD in self . __dictionaryDictList ]) except Exception : return None def getDictionaryTitle ( self ): try : return \",\" . join ([ str ( tD [ \"title\" ]) for tD in self . __dictionaryDictList ]) except Exception : return None def getDictionaryUpdate ( self , order = \"reverse\" ): \"\"\"Get details from the first/last history element.\"\"\" try : if order == \"reverse\" : tD = self . __dictionaryHistoryList [ - 1 ] else : tD = self . __dictionaryHistoryList [ 0 ] return tD [ \"update\" ] except Exception : return None def getDictionaryRevisionCount ( self ): \"\"\"Get the count of revision history records.\"\"\" try : return len ( self . __dictionaryHistoryList ) except Exception : return 0 def getDictionaryHistory ( self , order = \"reverse\" ): \"\"\"Returns the revision history as a list of tuples [(version,update,revisionText,dictionary),...]\"\"\" oL = [] try : if order == \"reverse\" : for tD in reversed ( self . __dictionaryHistoryList ): oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary\" ])) else : for tD in self . __dictionaryHistoryList : oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary\" ])) except Exception : pass return oL # def getDictionaryComponentDetails ( self ): \"\"\"Returns the component dictionary list as tuples [(version,title,dictionary_component_id),...]\"\"\" oL = [] try : for tD in self . __dictionaryComponentList : oL . append (( tD [ \"version\" ], tD [ \"title\" ], tD [ \"dictionary_component_id\" ])) except Exception : pass return oL def getDictionaryComponentCount ( self ): \"\"\"Get the count of dictionary components.\"\"\" try : return len ( self . __dictionaryComponentList ) except Exception : return 0 def getDictionaryComponents ( self ): \"\"\"Get the list of dictionary components.\"\"\" try : return list ( self . __dictionaryComponentHistoryDict . keys ()) except Exception : return [] def getDictionaryComponentHistory ( self , dictionaryComponentId , order = \"reverse\" ): \"\"\"Returns the revision history as a list of tuples [(version,update,revisionText,dictionary),...]\"\"\" oL = [] try : if order == \"reverse\" : for tD in reversed ( self . __dictionaryComponentHistoryDict [ dictionaryComponentId ]): oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary_component_id\" ])) else : for tD in self . __dictionaryComponentHistoryDict [ dictionaryComponentId ]: oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary_component_id\" ])) except Exception : pass return oL # def __makeCategoryGroupIndex ( self ): catNameList = self . getCategoryList () # add categories in group to self.__categoryGroupDict[<groupName>]['categories'] for catName in catNameList : groupNameList = self . getCategoryGroupList ( catName ) # logger.info(\"Category %s group list %r\\n\" % (catName,groupNameList)) for groupName in groupNameList : if groupName not in self . __categoryGroupDict : # handle undefined category group ? tD = OrderedDict () tD [ \"description\" ] = None tD [ \"parent_id\" ] = None tD [ \"categories\" ] = [] self . __categoryGroupDict [ groupName ] = tD self . __categoryGroupDict [ groupName ][ \"categories\" ] . append ( catName ) # for groupName in self . __categoryGroupDict : # logger.info(\"Group %s count %r\\n\" % (groupName, len(self.__categoryGroupDict[groupName]['categories']))) if \"categories\" in self . __categoryGroupDict [ groupName ]: self . __categoryGroupDict [ groupName ][ \"categories\" ] . sort () self . __groupChildIndex = OrderedDict () for groupName , gD in self . __categoryGroupDict . items (): if \"parent\" in gD : self . __groupChildIndex . setdefault ( gD [ \"parent\" ], []) . append ( groupName ) # self . __groupIndex = True # def getCategoryGroupDescription ( self , groupName ): try : return self . __categoryGroupDict [ groupName ][ \"description\" ] except Exception : return None def getCategoryGroupParent ( self , groupName ): try : return self . __categoryGroupDict [ groupName ][ \"parent_id\" ] except Exception : return None def getCategoryGroupChildGroups ( self , parentGroupName ): try : return self . __groupChildIndex [ parentGroupName ] except Exception : return [] def getCategoryGroupCategories ( self , groupName , followChildren = False ): try : if not self . __groupIndex : self . __makeCategoryGroupIndex () # if followChildren : cL = [] grpL = [ groupName ] grpL . extend ( self . getCategoryGroupChildGroups ( groupName )) for grp in grpL : cL . extend ( self . __categoryGroupDict [ grp ][ \"categories\" ] if grp in self . __categoryGroupDict else []) return sorted ( set ( cL )) else : return self . __categoryGroupDict [ groupName ][ \"categories\" ] if groupName in self . __categoryGroupDict else [] # except Exception : logger . exception ( \"DictionaryApi.getCategoryGroupCategories failed for group %s \" , groupName ) return [] def getCategoryGroups ( self ): try : kL = self . __categoryGroupDict . keys () return kL except Exception : return [] # def getParentCategories ( self , categoryName ): itemNameList = self . getItemNameList ( categoryName ) parentCategories = set () for itemName in itemNameList : categoryName = CifName . categoryPart ( itemName ) attributeName = CifName . attributePart ( itemName ) parentItemList = self . getFullParentList ( categoryName , attributeName ) for parentItem in parentItemList : parentCategoryName = CifName . categoryPart ( parentItem ) parentCategories . add ( parentCategoryName ) return list ( parentCategories ) def getChildCategories ( self , categoryName ): itemNameList = self . getItemNameList ( categoryName ) childCategories = set () for itemName in itemNameList : categoryName = CifName . categoryPart ( itemName ) attributeName = CifName . attributePart ( itemName ) childItemList = self . getFullChildList ( categoryName , attributeName ) for childItem in childItemList : childCategoryName = CifName . categoryPart ( childItem ) childCategories . add ( childCategoryName ) return list ( childCategories ) # def definitionExists ( self , definitionName ): if definitionName in self . __definitionIndex : return True return False def getTypeConditionsCode ( self , category , attribute ): return self . __get ( \"ITEM_TYPE_CONDITIONS_CODE\" , category , attribute ) def getItemDependentNameList ( self , category , attribute ): return self . __getList ( \"ITEM_DEPENDENT_DEPENDENT_NAME\" , category , attribute ) def getItemValueConditionDependentList ( self , category , attribute ): return self . __getList ( \"ITEM_VALUE_CONDITION_DEPENDENT_NAME\" , category , attribute ) def getItemSubCategoryIdList ( self , category , attribute ): return self . __getList ( \"ITEM_SUB_CATEGORY_ID\" , category , attribute ) def getItemSubCategoryLabelList ( self , category , attribute ): return self . __getList ( \"ITEM_SUB_CATEGORY_LABEL\" , category , attribute ) def getItemSubCategoryList ( self , category , attribute ): aL = [] itemName = CifName . itemName ( category , attribute ) obL = self . __definitionIndex [ itemName ] if itemName in self . __definitionIndex else None for ob in obL : tObj = ob . getObj ( self . __enumD [ \"ITEM_SUB_CATEGORY_ID\" ][ 0 ]) if tObj is not None : atId = self . __enumD [ \"ITEM_SUB_CATEGORY_ID\" ][ 1 ] atLabel = self . __enumD [ \"ITEM_SUB_CATEGORY_LABEL\" ][ 1 ] for row in tObj . getRowList (): # logger.info(\"subcategories for %s row is %r\" % (itemName, row)) idVal = row [ tObj . getIndex ( atId )] if tObj . hasAttribute ( atId ) else None labVal = row [ tObj . getIndex ( atLabel )] if tObj . hasAttribute ( atLabel ) else None aL . append (( idVal , labVal )) return aL def getItemAliasList ( self , category , attribute ): aNL = self . __getListAll ( \"ITEM_ALIAS_ALIAS_NAME\" , category , attribute ) aDL = self . __getListAll ( \"ITEM_ALIAS_DICTIONARY\" , category , attribute ) aVL = self . __getListAll ( \"ITEM_ALIAS_VERSION\" , category , attribute ) aL = [] for aN , aD , aV in zip ( aNL , aDL , aVL ): aL . append (( aN , aD , aV )) return aL def getEnumListWithDetail ( self , category , attribute ): eVL = self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL\" , category , attribute ) rL = [] dD = {} if len ( eVL ) == len ( eDL ): for eV , eD in zip ( eVL , eDL ): if not eD or eD in [ \".\" , \"?\" ]: dD [ eV ] = ( eV , None ) else : dD [ eV ] = ( eV , eD ) else : for eV in eVL : dD [ eV ] = ( eV , None ) # for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) return rL def getEnumListAltWithFullDetails ( self , category , attribute ): rL = [] dD = {} try : eVL = self . __getListAll ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL_PDBX\" , category , attribute ) eBL = self . __getListAll ( \"ENUMERATION_DETAIL_BRIEF_PDBX\" , category , attribute ) eUL = self . __getListAll ( \"ENUMERATION_TYPE_UNITS_PDBX\" , category , attribute ) rL = [] dD = {} for eV , eD , eB , eU in zip_longest ( eVL , eDL , eBL , eUL ): oL = [ v if v and v not in [ \".\" , \"?\" ] else None for v in [ eV , eD , eB , eU ]] dD [ eV ] = tuple ( oL ) for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) if rL : return rL # eVL = self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL\" , category , attribute ) eBL = self . __getListAll ( \"ENUMERATION_DETAIL_BRIEF\" , category , attribute ) eUL = self . __getListAll ( \"ENUMERATION_TYPE_UNITS\" , category , attribute ) rL = [] dD = {} for eV , eD , eB , eU in zip_longest ( eVL , eDL , eBL , eUL ): oL = [ v if v and v not in [ \".\" , \"?\" ] else None for v in [ eV , eD , eB , eU ]] dD [ eV ] = tuple ( oL ) for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) except Exception as e : logger . exception ( \"Failing dD %r rL %r with %s \" , dD , rL , str ( e )) return rL def getEnumListWithFullDetails ( self , category , attribute ): rL = [] dD = {} try : eVL = self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL\" , category , attribute ) eBL = self . __getListAll ( \"ENUMERATION_DETAIL_BRIEF\" , category , attribute ) eUL = self . __getListAll ( \"ENUMERATION_TYPE_UNITS\" , category , attribute ) # for eV , eD , eB , eU in zip_longest ( eVL , eDL , eBL , eUL ): oL = [ v if v and v not in [ \".\" , \"?\" ] else None for v in [ eV , eD , eB , eU ]] dD [ eV ] = tuple ( oL ) for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) except Exception as e : logger . info ( \"eVL %r \" , eVL ) logger . info ( \"eDL %r \" , eDL ) logger . info ( \"eBL %r \" , eBL ) logger . info ( \"eUL %r \" , eUL ) logger . exception ( \"Failing category %s attribute %s dD %r rL %r with %s \" , category , attribute , dD , rL , str ( e )) return rL def getEnumListAltWithDetail ( self , category , attribute ): eVL = self . __getListAll ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL_PDBX\" , category , attribute ) rL = [] dD = {} if len ( eVL ) == len ( eDL ): for eV , eD in zip ( eVL , eDL ): if not eD or eD in [ \".\" , \"?\" ]: dD [ eV ] = ( eV , None ) else : dD [ eV ] = ( eV , eD ) else : for eV in eVL : dD [ eV ] = ( eV , None ) # for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) # if not rL : return self . getEnumListWithDetail ( category , attribute ) else : return rL def getItemRelatedList ( self , category , attribute ): rNL = self . __getListAll ( \"ITEM_RELATED_RELATED_NAME\" , category , attribute ) rFL = self . __getListAll ( \"ITEM_RELATED_FUNCTION_CODE\" , category , attribute ) rL = [] for rN , rF in zip ( rNL , rFL ): rL . append (( rN , rF )) return rL def getTypeCode ( self , category , attribute ): return self . __get ( \"DATA_TYPE_CODE\" , category , attribute , followAncestors = True ) def getTypeCodeAlt ( self , category , attribute , fallBack = True ): v = self . getTypeCodePdbx ( category , attribute ) if v is None : v = self . getTypeCodeNdb ( category , attribute ) if fallBack and v is None : v = self . getTypeCode ( category , attribute ) return v def getTypeCodeNdb ( self , category , attribute ): return self . __get ( \"DATA_TYPE_CODE_NDB\" , category , attribute , followAncestors = False ) def getTypeCodePdbx ( self , category , attribute ): return self . __get ( \"DATA_TYPE_CODE_PDBX\" , category , attribute , followAncestors = False ) def getDefaultValue ( self , category , attribute ): return self . __get ( \"ITEM_DEFAULT_VALUE\" , category , attribute ) def getMandatoryCode ( self , category , attribute ): return self . __get ( \"ITEM_MANDATORY_CODE\" , category , attribute ) def getMandatoryCodeAlt ( self , category , attribute , fallBack = True ): v = self . getMandatoryCodePdbx ( category , attribute ) if v is None : v = self . getMandatoryCodeNdb ( category , attribute ) if fallBack and v is None : v = self . getMandatoryCode ( category , attribute ) return v def getMandatoryCodeNdb ( self , category , attribute ): return self . __get ( \"ITEM_MANDATORY_CODE_NDB\" , category , attribute ) def getMandatoryCodePdbx ( self , category , attribute ): return self . __get ( \"ITEM_MANDATORY_CODE_PDBX\" , category , attribute ) def getTypeRegex ( self , category , attribute ): code = self . getTypeCode ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 1 ] return None def getTypeRegexAlt ( self , category , attribute , fallBack = True ): v = self . getTypeRegexPdbx ( category , attribute ) if v is None : v = self . getTypeRegexNdb ( category , attribute ) if fallBack and v is None : v = self . getTypeRegex ( category , attribute ) return v def getTypeRegexNdb ( self , category , attribute ): code = self . getTypeCodeNdb ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 1 ] return None def getTypeRegexPdbx ( self , category , attribute ): code = self . getTypeCodePdbx ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 1 ] return None def getTypePrimitive ( self , category , attribute ): code = self . getTypeCode ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 0 ] return None def getTypeDetail ( self , category , attribute ): code = self . getTypeCode ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 2 ] return None def getContextList ( self , category , attribute ): return self . __getList ( \"ITEM_CONTEXT\" , category , attribute ) def getCategoryContextList ( self , category ): return self . __getList ( \"CATEGORY_CONTEXT\" , category , attribute = None ) def getEnumList ( self , category , attribute , sortFlag = True ): if sortFlag : return self . __getList ( \"ENUMERATION_VALUE\" , category , attribute ) else : return self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) def getEnumListAlt ( self , category , attribute , fallBack = True , sortFlag = True ): vL = self . getEnumListPdbx ( category , attribute , sortFlag = sortFlag ) if not vL : vL = self . getEnumListNdb ( category , attribute , sortFlag = sortFlag ) if fallBack and not vL : vL = self . getEnumList ( category , attribute , sortFlag = sortFlag ) return vL def getEnumListNdb ( self , category , attribute , sortFlag = True ): if sortFlag : return self . __getList ( \"ENUMERATION_VALUE_NDB\" , category , attribute ) else : return self . __getListAll ( \"ENUMERATION_VALUE_NDB\" , category , attribute ) def getEnumListPdbx ( self , category , attribute , sortFlag = True ): if sortFlag : return self . __getList ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) else : return self . __getListAll ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) def isEnumerated ( self , category , attribute ): return len ( self . __getList ( \"ENUMERATION_VALUE\" , category , attribute )) > 0 def isEnumeratedAlt ( self , category , attribute , fallBack = True ): eC = len ( self . __getList ( \"ENUMERATION_VALUE_PDBX\" , category , attribute )) if eC == 0 : eC = len ( self . __getList ( \"ENUMERATION_VALUE_NDB\" , category , attribute )) if fallBack and ( eC == 0 ): eC = len ( self . __getList ( \"ENUMERATION_VALUE\" , category , attribute )) return eC > 0 def getEnumerationClosedFlag ( self , category , attribute ): return self . __get ( \"ENUMERATION_CLOSED_FLAG\" , category , attribute ) def getUltimateParent ( self , category , attribute ): \"\"\"Return the first ultimate parent item for the input item.\"\"\" # pL=self.__getList('ITEM_LINKED_PARENT',category,attribute) pL = self . getFullParentList ( category , attribute ) itemName = CifName . itemName ( category , attribute ) while pL and ( pL [ 0 ] != itemName ): attN = CifName . attributePart ( pL [ 0 ]) catN = CifName . categoryPart ( pL [ 0 ]) itemName = pL [ 0 ] pL = self . getFullParentList ( catN , attN ) # pL=self.__getList('ITEM_LINKED_PARENT',catN,attN) return itemName def getParentList ( self , category , attribute , stripSelfParent = False ): if stripSelfParent : itemName = CifName . itemName ( category , attribute ) pL = self . __getList ( \"ITEM_LINKED_PARENT\" , category , attribute ) if pL : try : pL . remove ( itemName ) except Exception : pass return pL else : return self . __getList ( \"ITEM_LINKED_PARENT\" , category , attribute ) def getChildList ( self , category , attribute ): return self . __getList ( \"ITEM_LINKED_CHILD\" , category , attribute ) def getFullChildList ( self , category , attribute ): try : itemName = CifName . itemName ( category , attribute ) return self . __fullChildD [ itemName ] except Exception : return [] def getFullDescendentList ( self , category , attribute ): itemNameL = [] try : itemName = CifName . itemName ( category , attribute ) itemNameL = self . __fullChildD [ itemName ] if itemName in self . __fullChildD else [] itemNameL = list ( set ( itemNameL )) if itemNameL : begLen = 0 endLen = 1 # while endLen > begLen : begLen = len ( itemNameL ) for itemName in itemNameL : if itemName in self . __fullChildD : itemNameL . extend ( self . __fullChildD [ itemName ]) itemNameL = list ( set ( itemNameL )) endLen = len ( itemNameL ) except Exception as e : logger . exception ( \"Failing for %s %s with %s \" , category , attribute , str ( e )) return itemNameL def getFullParentList ( self , category , attribute , stripSelfParent = False ): try : itemName = CifName . itemName ( category , attribute ) pL = self . __fullParentD [ itemName ] if stripSelfParent : if pL : try : pL . remove ( itemName ) except Exception : pass return pL else : return pL except Exception : return [] def getUnits ( self , category , attribute ): return self . __get ( \"ITEM_UNITS\" , category , attribute ) def getImplicitList ( self ): iL = [] for name , dL in self . __definitionIndex . items (): for dD in dL : dType = dD . getType () if dType == \"definition\" and dD . isAttribute (): catN = CifName . categoryPart ( name ) attN = CifName . attributePart ( name ) if self . __get ( \"ITEM_MANDATORY_CODE\" , catN , attN ) == \"implicit\" : if name not in iL : iL . append ( name ) return iL def getDescription ( self , category , attribute ): return self . __get ( \"ITEM_DESCRIPTION\" , category , attribute ) def getDescriptionAlt ( self , category , attribute , fallBack = True ): v = self . getDescriptionPdbx ( category , attribute ) if v is None : v = self . getDescriptionNdb ( category , attribute ) if fallBack and v is None : v = self . getDescription ( category , attribute ) return v def getDescriptionNdb ( self , category , attribute ): return self . __get ( \"ITEM_DESCRIPTION_NDB\" , category , attribute ) def getDescriptionPdbx ( self , category , attribute ): return self . __get ( \"ITEM_DESCRIPTION_PDBX\" , category , attribute ) def getExampleList ( self , category , attribute ): exCL = self . __getListAll ( \"ITEM_EXAMPLE_CASE\" , category , attribute ) exDL = self . __getListAll ( \"ITEM_EXAMPLE_DETAIL\" , category , attribute ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL def getExampleListAlt ( self , category , attribute , fallBack = True ): vL = self . getExampleListPdbx ( category , attribute ) if not vL : vL = self . getExampleListNdb ( category , attribute ) if fallBack and not vL : vL = self . getExampleList ( category , attribute ) return vL def getExampleListNdb ( self , category , attribute ): exCL = self . __getListAll ( \"ITEM_EXAMPLE_CASE_NDB\" , category , attribute ) exDL = self . __getListAll ( \"ITEM_EXAMPLE_DETAIL_NDB\" , category , attribute ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL def getExampleListPdbx ( self , category , attribute ): exCL = self . __getListAll ( \"ITEM_EXAMPLE_CASE_PDBX\" , category , attribute ) exDL = self . __getListAll ( \"ITEM_EXAMPLE_DETAIL_PDBX\" , category , attribute ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL def getBoundaryList ( self , category , attribute ): minL = self . __getListAll ( \"ITEM_RANGE_MINIMUM\" , category , attribute ) maxL = self . __getListAll ( \"ITEM_RANGE_MAXIMUM\" , category , attribute ) bL = [] for vMin , vMax in zip ( minL , maxL ): bL . append (( vMin , vMax )) return bL def getBoundaryListAlt ( self , category , attribute , fallBack = True ): vL = self . getBoundaryListPdbx ( category , attribute ) if not vL : vL = self . getBoundaryListNdb ( category , attribute ) if fallBack and not vL : vL = self . getBoundaryList ( category , attribute ) return vL def getBoundaryListNdb ( self , category , attribute ): minL = self . __getListAll ( \"ITEM_RANGE_MINIMUM_NDB\" , category , attribute ) maxL = self . __getListAll ( \"ITEM_RANGE_MAXIMUM_NDB\" , category , attribute ) bL = [] for vMin , vMax in zip ( minL , maxL ): bL . append (( vMin , vMax )) # return bL def getBoundaryListPdbx ( self , category , attribute ): minL = self . __getListAll ( \"ITEM_RANGE_MINIMUM_PDBX\" , category , attribute ) maxL = self . __getListAll ( \"ITEM_RANGE_MAXIMUM_PDBX\" , category , attribute ) bL = [] for vMin , vMax in zip ( minL , maxL ): bL . append (( vMin , vMax )) # return bL def getCategoryKeyList ( self , category ): return self . __getList ( \"CATEGORY_KEY_ITEMS\" , category , attribute = None ) def getCategoryGroupList ( self , category ): return self . __getList ( \"CATEGORY_GROUP\" , category , attribute = None ) def getCategoryMandatoryCode ( self , category ): return self . __get ( \"CATEGORY_MANDATORY_CODE\" , category , attribute = None ) def getCategoryDescription ( self , category ): return self . __get ( \"CATEGORY_DESCRIPTION\" , category , attribute = None ) def getCategoryNxMappingDetails ( self , category ): return self . __get ( \"CATEGORY_NX_MAPPING_DETAILS\" , category , attribute = None ) def getCategoryDescriptionAlt ( self , category , fallBack = True ): v = self . getCategoryDescriptionPdbx ( category ) if v is None : v = self . getCategoryDescriptionNdb ( category ) if fallBack and v is None : v = self . getCategoryDescription ( category ) return v def getCategoryDescriptionNdb ( self , category ): val = self . __get ( \"CATEGORY_DESCRIPTION_NDB\" , category , attribute = None ) return val def getCategoryDescriptionPdbx ( self , category ): val = self . __get ( \"CATEGORY_DESCRIPTION_PDBX\" , category , attribute = None ) return val def getCategoryExampleList ( self , category ): exCL = self . __getListAll ( \"CATEGORY_EXAMPLE_CASE\" , category , attribute = None ) exDL = self . __getListAll ( \"CATEGORY_EXAMPLE_DETAIL\" , category , attribute = None ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL def getCategoryExampleListAlt ( self , category , fallBack = True ): vL = self . getCategoryExampleListPdbx ( category ) if not vL : vL = self . getCategoryExampleListNdb ( category ) if fallBack and not vL : vL = self . getCategoryExampleList ( category ) return vL def getCategoryExampleListNdb ( self , category ): exCL = self . __getListAll ( \"CATEGORY_EXAMPLE_CASE_NDB\" , category , attribute = None ) exDL = self . __getListAll ( \"CATEGORY_EXAMPLE_DETAIL_NDB\" , category , attribute = None ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL def getCategoryExampleListPdbx ( self , category ): exCL = self . __getListAll ( \"CATEGORY_EXAMPLE_CASE_PDBX\" , category , attribute = None ) exDL = self . __getListAll ( \"CATEGORY_EXAMPLE_DETAIL_PDBX\" , category , attribute = None ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL def getParentDictionary ( self ): \"\"\"Create a dictionary of parents relations accross all definnitions as {child : [parent, parent,...] Exclude self parents. \"\"\" parentD = {} pAtN = self . __enumD [ \"ITEM_LINKED_PARENT\" ][ 1 ] cAtN = self . __enumD [ \"ITEM_LINKED_CHILD\" ][ 1 ] for dObj in self . __containerList : dc = dObj . getObj ( self . __enumD [ \"ITEM_LINKED_PARENT\" ][ 0 ]) if dc is not None : idxP = dc . getIndex ( pAtN ) idxC = dc . getIndex ( cAtN ) for row in dc . getRowList (): pVal = row [ idxP ] cVal = row [ idxC ] if pVal == cVal : continue if cVal not in parentD : parentD [ cVal ] = [] parentD [ cVal ] . append ( pVal ) # return parentD def getItemLinkedConditions ( self ): \"\"\"Create a dictionary of conditional item link relationships. Returns: (dict): {{parent_name, child_name}: [{\"id\": , \"condition_id\": , \"condition_child_name\": , \"condition_child_value\": , \"condition_child_cmp_op\": , \"condition_log_op\": ,}, {},...]} Example: ```text loop_ _pdbx_item_linked.id _pdbx_item_linked.condition_id _pdbx_item_linked.parent_name _pdbx_item_linked.child_name # _pdbx_item_linked.condition_child_name _pdbx_item_linked.condition_child_value _pdbx_item_linked.condition_child_cmp_op _pdbx_item_linked.condition_child_target_name _pdbx_item_linked.condition_child_log_op 1 1 '_entity_poly_seq.num' '_atom_site.label_seq_id' '_atom_site.label_entity_id' . 'eq' '_entity.id' . 2 1 '_entity_poly_seq.num' '_atom_site.label_seq_id' '_entity.type' 'polymer' 'eq' . 'and' ``` \"\"\" rD = OrderedDict () try : for ob in self . __containerList : if ob . getType () == \"data\" : continue tl = ob . getObj ( self . __enumD [ \"ITEM_LINKED_PDBX_ID\" ][ 0 ]) if tl is not None : for row in tl . getRowList (): if ( tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_ID\" ][ 1 ]) and tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_ID\" ][ 1 ]) and tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CHILD_NAME\" ][ 1 ]) and tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_PARENT_NAME\" ][ 1 ]) ): tD = OrderedDict () tD [ \"id\" ] = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_ID\" ][ 1 ])] tD [ \"condition_id\" ] = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_ID\" ][ 1 ])] parentName = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_PARENT_NAME\" ][ 1 ])] childName = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CHILD_NAME\" ][ 1 ])] # tD [ \"condition_child_name\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_NAME\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_NAME\" ][ 1 ]) else None ) tD [ \"condition_child_value\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_VALUE\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_VALUE\" ][ 1 ]) else None ) tD [ \"condition_child_cmp_op\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_CMP_OP\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_CMP_OP\" ][ 1 ]) else None ) tD [ \"condition_child_target_name\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_TARGET_NAME\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_TARGET_NAME\" ][ 1 ]) else None ) tD [ \"condition_log_op\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_LOG_OP\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_LOG_OP\" ][ 1 ]) else None ) # rD . setdefault (( parentName , childName ), []) . append ( tD ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return rD def __makeFullParentChildDictionaries ( self ): \"\"\"Create a dictionaries of full parent/child relations accross all definnitions as fullParentD[child]=[parent,parent,...] and fullChildD[parent]=[child,child,...] Exclude self parents. \"\"\" fullParentD = {} fullChildD = {} pAtN = self . __enumD [ \"ITEM_LINKED_PARENT\" ][ 1 ] cAtN = self . __enumD [ \"ITEM_LINKED_CHILD\" ][ 1 ] for dObj in self . __containerList : # logger.info(\"\\n\\nSearching object %s\\n\" % dObj.getName()) dc = dObj . getObj ( self . __enumD [ \"ITEM_LINKED_PARENT\" ][ 0 ]) if dc is not None : idxP = dc . getIndex ( pAtN ) idxC = dc . getIndex ( cAtN ) for row in dc . getRowList (): pVal = row [ idxP ] cVal = row [ idxC ] # logger.info(\"%s found parent %s child %s \\n\" % (dObj.getName(),pVal,cVal)) if pVal == cVal : continue if cVal not in fullParentD : fullParentD [ cVal ] = [] fullParentD [ cVal ] . append ( pVal ) # if pVal not in fullChildD : fullChildD [ pVal ] = [] fullChildD [ pVal ] . append ( cVal ) # return fullParentD , fullChildD # def __get ( self , enumCode , category , attribute = None , followAncestors = False ): \"\"\"Return the last occurrence of the input dictionary metadata. If the value for the input category/attribute is null/missing then optionally check for an ancestor value. \"\"\" v0 = self . __getValue ( enumCode , category , attribute ) if not followAncestors : return v0 else : if ( v0 is None ) or ( not v0 ) or ( v0 in [ \".\" , \"?\" ]): pItem = self . getUltimateParent ( category , attribute ) if ( pItem is not None ) and pItem and ( pItem != CifName . itemName ( category , attribute )): logger . debug ( \"Reassigning enum code %s category %s attribute %s to parent %r \" , enumCode , category , attribute , pItem ) return self . __getValue ( enumCode , CifName . categoryPart ( pItem ), CifName . attributePart ( pItem )) return v0 # def __getValue ( self , enumCode , category , attribute = None ): \"\"\"Returns the last occurrence of the input dictionary metadata (enumCode) for the input category/attribute encountered in the list of objects stored at the indicated definition index. \"\"\" eS = None if enumCode not in self . __enumD : return eS if attribute is not None : nm = \"_\" + category + \".\" + attribute else : nm = category if nm in self . __definitionIndex : dObjL = self . __definitionIndex [ nm ] for dObj in dObjL : dc = dObj . getObj ( self . __enumD [ enumCode ][ 0 ]) if dc is not None : atN = self . __enumD [ enumCode ][ 1 ] rL = dc . getRowList () if rL : row = rL [ 0 ] if atN is not None : if dc . hasAttribute ( atN ): eS = row [ dc . getIndex ( atN )] else : eS = [ rv for rv in row ] return eS def __getList ( self , enumCode , category , attribute = None ): \"\"\"Return the list of unique values\"\"\" return list ( set ( self . __getListAll ( enumCode , category , attribute ))) def __getListAll ( self , enumCode , category , attribute = None ): \"\"\"Return a list of all values\"\"\" eL = [] if enumCode not in self . __enumD : return eL if attribute is not None : nm = \"_\" + category + \".\" + attribute else : nm = category if nm in self . __definitionIndex : dObjL = self . __definitionIndex [ nm ] for dObj in dObjL : dc = dObj . getObj ( self . __enumD [ enumCode ][ 0 ]) if dc is not None : atN = self . __enumD [ enumCode ][ 1 ] for row in dc . getRowList (): if atN is not None : if dc . hasAttribute ( atN ): eL . append ( row [ dc . getIndex ( atN )]) else : eL = [ rv for rv in row ] return eL def getMethodIndex ( self ): return self . __methodIndex def __makeIndex ( self ): \"\"\"Create indices of definitions, categories and items.\"\"\" iD = OrderedDict () for dD in self . __containerList : name = dD . getName () dType = dD . getType () # if name not in self . __fullIndex : self . __fullIndex [ name ] = [] self . __fullIndex [ name ] . append ( dD ) # if dType == \"definition\" and dD . isCategory (): if name not in self . __catNameIndex : self . __catNameIndex [ name ] = [] if name not in self . __catNameItemIndex : self . __catNameItemIndex [ name ] = [] if name not in self . __definitionIndex : self . __definitionIndex [ name ] = [] self . __definitionIndex [ name ] . append ( dD ) elif dType == \"definition\" and dD . isAttribute (): catN = CifName . categoryPart ( name ) attN = CifName . attributePart ( name ) if catN not in self . __catNameItemIndex : self . __catNameItemIndex [ catN ] = [] if name not in self . __catNameItemIndex : self . __catNameItemIndex [ catN ] . append ( name ) if catN not in self . __catNameIndex : self . __catNameIndex [ catN ] = [] if attN not in self . __catNameIndex [ catN ]: self . __catNameIndex [ catN ] . append ( attN ) if name not in self . __definitionIndex : self . __definitionIndex [ name ] = [] self . __definitionIndex [ name ] . append ( dD ) iD [ name ] = name elif dType == \"data\" : for nm in dD . getObjNameList (): if nm not in self . __dataIndex : self . __dataIndex [ nm ] = dD . getObj ( nm ) else : pass # self . __itemNameList = list ( iD . keys ()) def getDefinitionIndex ( self ): return self . __definitionIndex def getFullIndex ( self ): return self . __fullIndex def getMethod ( self , mId ): if mId in self . __methodDict : return self . __methodDict [ mId ] else : return None def getCategoryList ( self ): return list ( self . __catNameIndex . keys ()) def getCategoryIndex ( self ): return self . __catNameIndex def getAttributeNameList ( self , category ): try : return self . __catNameIndex [ category ] except Exception : pass return [] def getItemNameList ( self , category ): try : return self . __catNameItemIndex [ category ] except Exception : pass return [] def getSubCategoryDescription ( self , subCategoryName ): if subCategoryName in self . __subCategoryDict : return self . __subCategoryDict [ subCategoryName ] else : return \"\" def __getMethods ( self ): self . __methodDict = OrderedDict () self . __methodIndex = OrderedDict () for ob in self . __containerList : if ob . getType () == \"data\" : ml = ob . getObj ( \"method_list\" ) if ml is not None : # Use row order as priority for ii , row in enumerate ( ml . getRowList (), 1 ): if ml . hasAttribute ( \"id\" ) and ml . hasAttribute ( \"code\" ) and ml . hasAttribute ( \"language\" ) and ml . hasAttribute ( \"implementation_source\" ): tInline = row [ ml . getIndex ( \"inline\" )] if ml . hasAttribute ( \"inline\" ) else None tImpl = row [ ml . getIndex ( \"implementation\" )] if ml . hasAttribute ( \"implementation\" ) else None mth = MethodDefinition ( row [ ml . getIndex ( \"id\" )], row [ ml . getIndex ( \"code\" )], row [ ml . getIndex ( \"language\" )], tInline , ii , tImpl , row [ ml . getIndex ( \"implementation_source\" )] ) self . __methodDict [ row [ ml . getIndex ( \"id\" )]] = mth ml = ob . getObj ( \"datablock_methods\" ) if ml is not None : for row in ml . getRowList (): if ml . hasAttribute ( \"method_id\" ): # mth = MethodReference(row[ml.getIndex('method_id')], 'datablock', ob.getName(), None) mth = MethodReference ( row [ ml . getIndex ( \"method_id\" )], \"datablock\" , None , None ) if ob . getName () in self . __methodIndex : self . __methodIndex [ ob . getName ()] . append ( mth ) else : self . __methodIndex [ ob . getName ()] = [] self . __methodIndex [ ob . getName ()] . append ( mth ) elif ob . getType () == \"definition\" : mi = ob . getObj ( \"category_methods\" ) if mi is not None : for row in mi . getRowList (): if mi . hasAttribute ( \"method_id\" ): mth = MethodReference ( row [ mi . getIndex ( \"method_id\" )], \"category\" , ob . getName (), None ) if ob . getName () in self . __methodIndex : self . __methodIndex [ ob . getName ()] . append ( mth ) else : self . __methodIndex [ ob . getName ()] = [] self . __methodIndex [ ob . getName ()] . append ( mth ) mi = ob . getObj ( \"item_methods\" ) if mi is not None : for row in mi . getRowList (): if mi . hasAttribute ( \"method_id\" ): mth = MethodReference ( row [ mi . getIndex ( \"method_id\" )], \"attribute\" , CifName . categoryPart ( ob . getName ()), CifName . attributePart ( ob . getName ())) if ob . getName () in self . __methodIndex : self . __methodIndex [ ob . getName ()] . append ( mth ) else : self . __methodIndex [ ob . getName ()] = [] self . __methodIndex [ ob . getName ()] . append ( mth ) else : pass return self . __methodIndex def dumpCategoryIndex ( self , fh = sys . stdout ): for k , vL in self . __catNameIndex . items (): uvL = list ( set ( vL )) fh . write ( \"Category: %s has %d attributes \\n \" % ( k , len ( uvL ))) for v in sorted ( uvL ): fh . write ( \" Attribute: %s \\n \" % v ) def dumpMethods ( self , fh = sys . stdout ): for k , vL in self . __methodIndex . items (): fh . write ( \"Method index key: %s length %d \\n \" % ( k , len ( vL ))) for v in vL : v . printIt ( fh ) # fh . write ( \"Inline method details \\n \" ) for k , vL in self . __methodIndex . items (): fh . write ( \" \\n ------------------------------------ \\n \" ) fh . write ( \"Method index key: %s \\n \" % k ) for v in vL : fh . write ( \"Method ID: %r \\n \" % v . getId ()) if self . getMethod ( v . getId ()): fh . write ( \" %r \" % v ) # fh.write(\"Method text: %s\\n\" % self.getMethod(v.getId()).getInline()) else : fh . write ( \"Missing method for %r \" % v . getId ()) def dumpEnumFeatures ( self , fh = sys . stdout ): for k , vL in self . __catNameIndex . items (): uvL = list ( set ( vL )) for v in sorted ( uvL ): itL = self . getEnumList ( k , v ) if itL : fh . write ( \"----------------------------------------------- \\n \" ) fh . write ( \" Category : %s \\n \" % k ) fh . write ( \" Attribute: %s \\n \" % v ) fh . write ( \" Description: \\n %s \\n \" % self . getDescription ( k , v )) fh . write ( \" Type: %s \\n \" % self . getTypeCode ( k , v )) fh . write ( \" Primitive type: %s \\n \" % self . getTypePrimitive ( k , v )) fh . write ( \" Regex type: %s \\n \" % self . getTypeRegex ( k , v )) fh . write ( \" Enum list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Enum: %s \\n \" % it ) def dumpFeatures ( self , fh = sys . stdout ): for k , vL in self . __catNameIndex . items (): uvL = list ( set ( vL )) fh . write ( \"----------------------------------------------- \\n \" ) fh . write ( \"Category: %s has %d attributes \\n \" % ( k , len ( uvL ))) fh . write ( \" Category description: %s \\n \" % self . getCategoryDescription ( k )) fh . write ( \" Alt category description: %s \\n \" % self . getCategoryDescriptionAlt ( k )) fh . write ( \" Category context: %s \\n \" % self . getCategoryContextList ( k )) ctL = self . getCategoryExampleList ( k ) if ctL : fh . write ( \" Category example list length %d \\n \" % len ( ctL )) for ct1 , ct2 in ctL : fh . write ( \" Example case: %s \\n \" % ct1 ) fh . write ( \" Example detail: %s \\n \" % ct2 ) ctL = self . getCategoryExampleListAlt ( k ) if ctL : fh . write ( \" Alt category example list length %d \\n \" % len ( ctL )) for ct1 , ct2 in ctL : fh . write ( \" Alt example case: %s \\n \" % ct1 ) fh . write ( \" Alt example detail: %s \\n \" % ct2 ) for v in sorted ( uvL ): fh . write ( \" Attribute: %s \\n \" % v ) fh . write ( \" Description: %s \\n \" % self . getDescription ( k , v )) fh . write ( \" Alt description: %s \\n \" % self . getDescriptionAlt ( k , v )) fh . write ( \" Type: %s \\n \" % self . getTypeCode ( k , v )) fh . write ( \" Alt Type: %s \\n \" % self . getTypeCodeAlt ( k , v )) fh . write ( \" Primitive type: %s \\n \" % self . getTypePrimitive ( k , v )) fh . write ( \" Regex type: %s \\n \" % self . getTypeRegex ( k , v )) fh . write ( \" Context: %s \\n \" % self . getContextList ( k , v )) # fh . write ( \" Type conditions: %s \\n \" % self . getTypeConditionsCode ( k , v )) fh . write ( \" Subcategories: %s \\n \" % self . getItemSubCategoryIdList ( k , v )) # itL = self . getEnumList ( k , v ) if itL : fh . write ( \" Enum list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Enum: %s \\n \" % it ) itL = self . getParentList ( k , v ) if itL : fh . write ( \" Parent list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Parent: %s \\n \" % it ) itL = self . getChildList ( k , v ) if itL : fh . write ( \" Child list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Child: %s \\n \" % it ) itL = self . getExampleList ( k , v ) if itL : fh . write ( \" Example list length %d \\n \" % len ( itL )) for it1 , it2 in itL : fh . write ( \" Example case: %s \\n \" % it1 ) fh . write ( \" Example detail: %s \\n \" % it2 ) itL = self . getBoundaryList ( k , v ) if itL : fh . write ( \" Boundary list length %d \\n \" % len ( itL )) for ( it1 , it2 ) in itL : fh . write ( \" Boundary condition (min,max): ( %s , %s ) \\n \" % ( it1 , it2 )) itL = self . getEnumListAlt ( k , v ) if itL : fh . write ( \" Alt enum list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Alt enum: %s \\n \" % it ) itL = self . getExampleListAlt ( k , v ) if itL : fh . write ( \" Alt example list length %d \\n \" % len ( itL )) for it1 , it2 in itL : fh . write ( \" Alt example case: %s \\n \" % it1 ) fh . write ( \" Alt example detail: %s \\n \" % it2 ) itL = self . getBoundaryListAlt ( k , v ) if itL : fh . write ( \" Alt boundary list length %d \\n \" % len ( itL )) for ( it1 , it2 ) in itL : fh . write ( \" Alt boundary condition (min,max): ( %s , %s ) \\n \" % ( it1 , it2 )) itL = self . getItemRelatedList ( k , v ) if itL : fh . write ( \" Related name list length %d \\n \" % len ( itL )) for ( it1 , it2 ) in itL : fh . write ( \" Related item name %s function code %s \\n \" % ( it1 , it2 )) itL = self . getItemAliasList ( k , v ) if itL : fh . write ( \" Alias name list length %d \\n \" % len ( itL )) for ( it1 , it2 , it3 ) in itL : fh . write ( \" Alias name %s dictionary %s version %s \\n \" % ( it1 , it2 , it3 )) itL = self . getItemDependentNameList ( k , v ) if itL : fh . write ( \" Dependent name list length %d \\n \" % len ( itL )) for it1 in itL : fh . write ( \" Dependent item name %s \\n \" % it1 ) def dumpDataSections ( self , fh = sys . stdout ): fh . write ( \"Datablock: %r \\n \" % list ( self . __dataBlockDictList )) fh . write ( \"Dictionary: %r \\n \" % list ( self . __dictionaryDictList )) fh . write ( \"Dictionary History: %r \\n \" % self . __dictionaryHistoryList ) fh . write ( \"Subcategories: %r \\n \" % list ( self . __subCategoryDict . items ())) fh . write ( \"Category groups: %r \\n \" % list ( self . __categoryGroupDict . items ())) fh . write ( \"Item units: %r \\n \" % list ( self . __itemUnitsDict . items ())) fh . write ( \"Item units conversions: %r \\n \" % self . __itemUnitsConversionList ) fh . write ( \"Item linked groups: %r \\n \" % list ( self . __itemLinkedGroupDict . items ())) fh . write ( \"Item linked group item list: %r \\n \" % list ( self . __itemLinkedGroupItemDict . items ())) def dumpItemLinkedGroups ( self , fh = sys . stdout ): for categoryId , lgList in self . __itemLinkedGroupDict . items (): for lg in lgList : if ( categoryId , lg [ 1 ]) in self . __itemLinkedGroupItemDict : fh . write ( \" Category %s linked group %s : \\n \" % ( categoryId , lg [ 1 ])) lgIList = self . __itemLinkedGroupItemDict [( categoryId , lg [ 1 ])] for lgI in lgIList : fh . write ( \" group %s --- child item %s parent item %s \\n \" % ( lg [ 1 ], lgI [ 0 ], lgI [ 1 ])) def __addItemLinkToDef ( self , dObj , parentName , childName ): \"\"\"Add the input link relationship to the input definition object.\"\"\" if dObj . exists ( \"item_linked\" ): # update in place -- cObj = dObj . getObj ( \"item_linked\" ) iFound = False idxP = cObj . getIndex ( \"parent_name\" ) idxC = cObj . getIndex ( \"child_name\" ) for row in cObj . getRowList (): if parentName == row [ idxP ] and childName == row [ idxC ]: iFound = True break if not iFound : nRows = cObj . getRowCount () cObj . setValue ( childName , \"child_name\" , nRows ) cObj . setValue ( parentName , \"parent_name\" , nRows ) logger . debug ( \"Appending item link in category %s \" , dObj . getName ()) return True else : # create new category and append to input object cObj = DataCategory ( \"item_linked\" , attributeNameList = [ \"child_name\" , \"parent_name\" ]) cObj . append ([ childName , parentName ]) dObj . append ( cObj ) logger . debug ( \"Created new item link in category %s \" , dObj . getName ()) return True def __expandLoopedDefinitions ( self ): \"\"\"Handle definitions containing looped item and item_linked categories --\"\"\" fullIndex = OrderedDict () for dD in self . __containerList : name = dD . getName () if name not in fullIndex : fullIndex [ name ] = [] fullIndex [ name ] . append ( dD ) for name , dObjL in fullIndex . items (): if dObjL : ob = dObjL [ 0 ] if ( ob . getType () == \"definition\" ) and ob . exists ( \"item_linked\" ): cObj = ob . getObj ( \"item_linked\" ) if cObj . getRowCount () > 0 : idxP = cObj . getIndex ( \"parent_name\" ) idxC = cObj . getIndex ( \"child_name\" ) itemName = ob . getName () logger . debug ( \"Current target item %s \" , itemName ) cObjNext = DataCategory ( \"item_linked\" , attributeNameList = [ \"child_name\" , \"parent_name\" ]) # # Distribute the data for each row -- iChanges = 0 for row in cObj . getRowList (): # parentItemName = row [ idxP ] childItemName = row [ idxC ] if parentItemName == childItemName : continue if childItemName != itemName : iChanges += 1 if childItemName in fullIndex : # # Add this p/c link to the child definition - # self . __addItemLinkToDef ( fullIndex [ childItemName ][ 0 ], parentItemName , childItemName ) else : # error missing child definition object. logger . warning ( \"Missing child item %s \" , childItemName ) else : cObjNext . append ([ row [ idxC ], row [ idxP ]]) if cObjNext . getRowCount () > 0 : ob . replace ( cObjNext ) else : ob . remove ( \"item_linked\" ) def __consolidateDefinitions ( self ): \"\"\"Consolidate definition attributes into a single save frame section per definition.\"\"\" fullIndex = OrderedDict () for dD in self . __containerList : name = dD . getName () fullIndex . setdefault ( name , []) . append ( dD ) # preserve the original order of sections - # nList = [] for dObj in self . __containerList : nm = dObj . getName () if nm not in nList : nList . append ( nm ) # for name , dObjL in fullIndex . items (): if len ( dObjL ) > 1 : for dD in dObjL [ 1 :]: xList = dD . getObjNameList () for nm in xList : if nm not in dObjL [ 0 ] . getObjNameList (): logger . debug ( \"Adding %s to %s \" , nm , name ) catObj = dD . getObj ( nm ) dObjL [ 0 ] . append ( catObj ) elif self . __replaceDefinition : logger . debug ( \"Replacing dictionary %s in %s \" , nm , name ) catObj = dD . getObj ( nm ) dObjL [ 0 ] . replace ( catObj ) # create a new list of consolidated objects in original list order dList = [] for nm in nList : if nm in fullIndex : dl = fullIndex [ nm ] dList . append ( dl [ 0 ]) else : logger . info ( \"+DictionaryApi().__consolidate() missing object name %s \" , nm ) # update lists self . __containerList = dList def getDataTypeList ( self ): \"\"\"Return list of tuples containing ('code','primitive_code','construct','detail' )\"\"\" rowList = [] for code in sorted ( self . __typesDict . keys ()): tup = self . __typesDict [ code ] rowList . append (( code , tup [ 0 ], tup [ 1 ], tup [ 2 ])) return rowList def getSubCategoryList ( self ): \"\"\"Return list of tuples containing ('id', 'description')\"\"\" rowList = [] for tId in sorted ( self . __subCategoryDict . keys ()): description = self . __subCategoryDict [ tId ] rowList . append (( tId , description )) return rowList def getUnitsList ( self ): \"\"\"Return list of tuples containing ('id', 'description')\"\"\" rowList = [] for tId in sorted ( self . __itemUnitsDict . keys ()): description = self . __itemUnitsDict [ tId ] rowList . append (( tId , description )) return rowList def getUnitsConversionList ( self ): \"\"\"Return list of tuples containing ('from_code','to_code','operator','factor')\"\"\" return self . __itemUnitsConversionList def __getDataSections ( self ): \"\"\" \"\"\" for ob in self . __containerList : if ob . getType () == \"data\" : logger . debug ( \"Adding data sections from container name %s type %s \" , ob . getName (), ob . getType ()) # add detail to data type tuple tl = ob . getObj ( \"item_type_list\" ) if tl is not None : for row in tl . getRowList (): if tl . hasAttribute ( \"code\" ) and tl . hasAttribute ( \"primitive_code\" ) and tl . hasAttribute ( \"construct\" ) and tl . hasAttribute ( \"detail\" ): self . __typesDict [ row [ tl . getIndex ( \"code\" )]] = ( row [ tl . getIndex ( \"primitive_code\" )], row [ tl . getIndex ( \"construct\" )], row [ tl . getIndex ( \"detail\" )]) tl = ob . getObj ( \"datablock\" ) if tl is not None : rL = tl . getRowList () if rL : if tl . hasAttribute ( \"id\" ) and tl . hasAttribute ( \"description\" ): tD = OrderedDict () row = rL [ 0 ] tD [ \"id\" ] = row [ tl . getIndex ( \"id\" )] tD [ \"description\" ] = row [ tl . getIndex ( \"description\" )] self . __dataBlockDictList . append ( tD ) tl = ob . getObj ( \"dictionary\" ) if tl is not None : rL = tl . getRowList () if rL : tD = OrderedDict () row = rL [ 0 ] if tl . hasAttribute ( \"datablock_id\" ): tD [ \"datablock_id\" ] = row [ tl . getIndex ( \"datablock_id\" )] if tl . hasAttribute ( \"title\" ): tD [ \"title\" ] = row [ tl . getIndex ( \"title\" )] if tl . hasAttribute ( \"version\" ): tD [ \"version\" ] = row [ tl . getIndex ( \"version\" )] self . __dictionaryDictList . append ( tD ) tl = ob . getObj ( \"dictionary_history\" ) if tl is not None : # history as a list of dictionaries - dName = ob . getName () for row in tl . getRowList (): if tl . hasAttribute ( \"version\" ) and tl . hasAttribute ( \"revision\" ) and tl . hasAttribute ( \"update\" ): tD = OrderedDict () tD [ \"version\" ] = row [ tl . getIndex ( \"version\" )] tD [ \"revision\" ] = row [ tl . getIndex ( \"revision\" )] tD [ \"update\" ] = row [ tl . getIndex ( \"update\" )] tD [ \"dictionary\" ] = dName self . __dictionaryHistoryList . append ( tD ) # JDW tl = ob . getObj ( \"pdbx_include_dictionary\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () if tl . hasAttribute ( \"dictionary_id\" ): tD [ \"dictionary_id\" ] = row [ tl . getIndex ( \"dictionary_id\" )] if tl . hasAttribute ( \"dictionary_locator\" ): tD [ \"dictionary_locator\" ] = row [ tl . getIndex ( \"dictionary_locator\" )] if tl . hasAttribute ( \"include_mode\" ): tD [ \"include_mode\" ] = row [ tl . getIndex ( \"include_mode\" )] if tl . hasAttribute ( \"dictionary_namespace\" ): tD [ \"dictionary_namespace_prefix\" ] = row [ tl . getIndex ( \"dictionary_namespace_prefix\" )] if tl . hasAttribute ( \"dictionary_namespace_replace\" ): tD [ \"dictionary_namespace_prefix\" ] = row [ tl . getIndex ( \"dictionary_namespace_prefix_replace\" )] # self . __dictionaryIncludeDict [ tD [ \"dictionary_id\" ]] = tD # tl = ob . getObj ( \"pdbx_include_category\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () if tl . hasAttribute ( \"dictionary_id\" ): tD [ \"dictionary_id\" ] = row [ tl . getIndex ( \"dictionary_id\" )] if tl . hasAttribute ( \"category_id\" ): tD [ \"category_id\" ] = row [ tl . getIndex ( \"category_id\" )] if tl . hasAttribute ( \"include_as_category_id\" ): tD [ \"include_as_category_id\" ] = row [ tl . getIndex ( \"include_as_category_id\" )] if tl . hasAttribute ( \"include_mode\" ): tD [ \"include_mode\" ] = row [ tl . getIndex ( \"include_mode\" )] # self . __categoryIncludeDict . setdefault ( tD [ \"dictionary_id\" ], {}) . setdefault ( tD [ \"category_id\" ], tD ) tl = ob . getObj ( \"pdbx_include_item\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () if tl . hasAttribute ( \"dictionary_id\" ): tD [ \"dictionary_id\" ] = row [ tl . getIndex ( \"dictionary_id\" )] if tl . hasAttribute ( \"item_name\" ): tD [ \"item_name\" ] = row [ tl . getIndex ( \"item_name\" )] if tl . hasAttribute ( \"include_as_item_name\" ): tD [ \"include_as_item_name\" ] = row [ tl . getIndex ( \"include_as_item_name\" )] if tl . hasAttribute ( \"include_mode\" ): tD [ \"include_mode\" ] = row [ tl . getIndex ( \"include_mode\" )] # categoryId = CifName . categoryPart ( tD [ \"item_name\" ]) self . __itemIncludeDict . setdefault ( tD [ \"dictionary_id\" ], {}) . setdefault ( categoryId , {}) . setdefault ( tD [ \"item_name\" ], tD ) tl = ob . getObj ( \"dictionary_history\" ) if tl is not None : # history as a list of dictionaries - dName = ob . getName () for row in tl . getRowList (): if tl . hasAttribute ( \"version\" ) and tl . hasAttribute ( \"revision\" ) and tl . hasAttribute ( \"update\" ): tD = OrderedDict () tD [ \"version\" ] = row [ tl . getIndex ( \"version\" )] tD [ \"revision\" ] = row [ tl . getIndex ( \"revision\" )] tD [ \"update\" ] = row [ tl . getIndex ( \"update\" )] tD [ \"dictionary\" ] = dName self . __dictionaryHistoryList . append ( tD ) # tl = ob . getObj ( \"pdbx_dictionary_component\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () if tl . hasAttribute ( \"dictionary_component_id\" ): tD [ \"dictionary_component_id\" ] = row [ tl . getIndex ( \"dictionary_component_id\" )] if tl . hasAttribute ( \"title\" ): tD [ \"title\" ] = row [ tl . getIndex ( \"title\" )] if tl . hasAttribute ( \"version\" ): tD [ \"version\" ] = row [ tl . getIndex ( \"version\" )] self . __dictionaryComponentList . append ( tD ) tl = ob . getObj ( \"pdbx_dictionary_component_history\" ) if tl is not None : for row in tl . getRowList (): if tl . hasAttribute ( \"version\" ) and tl . hasAttribute ( \"revision\" ) and tl . hasAttribute ( \"update\" ): tD = OrderedDict () tD [ \"version\" ] = row [ tl . getIndex ( \"version\" )] tD [ \"revision\" ] = row [ tl . getIndex ( \"revision\" )] tD [ \"update\" ] = row [ tl . getIndex ( \"update\" )] tD [ \"dictionary_component_id\" ] = row [ tl . getIndex ( \"dictionary_component_id\" )] self . __dictionaryComponentHistoryDict . setdefault ( tD [ \"dictionary_component_id\" ], []) . append ( tD ) # JDW tl = ob . getObj ( \"sub_category\" ) if tl is not None : # subcategories as a dictionary by id self . __subCategoryDict = OrderedDict () for row in tl . getRowList (): if tl . hasAttribute ( \"id\" ) and tl . hasAttribute ( \"description\" ): self . __subCategoryDict [ row [ tl . getIndex ( \"id\" )]] = row [ tl . getIndex ( \"description\" )] tl = ob . getObj ( \"category_group_list\" ) if tl is not None : # category groups as a dictionary by id of tuples self . __categoryGroupDict = OrderedDict () for row in tl . getRowList (): if tl . hasAttribute ( \"id\" ) and tl . hasAttribute ( \"description\" ) and tl . hasAttribute ( \"parent_id\" ): tD = OrderedDict () tD [ \"description\" ] = row [ tl . getIndex ( \"description\" )] tD [ \"parent_id\" ] = row [ tl . getIndex ( \"parent_id\" )] tD [ \"categories\" ] = [] self . __categoryGroupDict [ row [ tl . getIndex ( \"id\" )]] = tD tl = ob . getObj ( \"item_units_list\" ) if tl is not None : # units as a dictionary by code self . __itemUnitsDict = OrderedDict () for row in tl . getRowList (): if tl . hasAttribute ( \"code\" ) and tl . hasAttribute ( \"detail\" ): self . __itemUnitsDict [ row [ tl . getIndex ( \"code\" )]] = row [ tl . getIndex ( \"detail\" )] tl = ob . getObj ( \"item_units_conversion\" ) if tl is not None : # units conversion as a simple list now self . __itemUnitsConversionList = [] for row in tl . getRowList (): if tl . hasAttribute ( \"from_code\" ) and tl . hasAttribute ( \"to_code\" ) and tl . hasAttribute ( \"operator\" ) and tl . hasAttribute ( \"factor\" ): self . __itemUnitsConversionList . append (( row [ tl . getIndex ( \"from_code\" )], row [ tl . getIndex ( \"to_code\" )], row [ tl . getIndex ( \"operator\" )], row [ tl . getIndex ( \"factor\" )])) tl = ob . getObj ( \"pdbx_item_linked_group\" ) if tl is not None : # parent-child collections [category_id] -> [(1,...),(3,...),(4,...) ] self . __itemLinkedGroupDict = OrderedDict () for row in tl . getRowList (): if ( tl . hasAttribute ( \"category_id\" ) and tl . hasAttribute ( \"link_group_id\" ) and tl . hasAttribute ( \"label\" ) and tl . hasAttribute ( \"context\" ) and tl . hasAttribute ( \"condition_id\" ) ): categoryId = row [ tl . getIndex ( \"category_id\" )] if categoryId not in self . __itemLinkedGroupDict : self . __itemLinkedGroupDict [ categoryId ] = [] self . __itemLinkedGroupDict [ categoryId ] . append ( ( row [ tl . getIndex ( \"category_id\" )], row [ tl . getIndex ( \"link_group_id\" )], row [ tl . getIndex ( \"context\" )], row [ tl . getIndex ( \"condition_id\" )]) ) tl = ob . getObj ( \"pdbx_item_linked_group_list\" ) if tl is not None : # parent-child collections [(category_id,link_group_id)] -> [(child_name,parent_name,parent_category),(,...),(,...) ] self . __itemLinkedGroupItemDict = OrderedDict () for row in tl . getRowList (): if ( tl . hasAttribute ( \"child_category_id\" ) and tl . hasAttribute ( \"link_group_id\" ) and tl . hasAttribute ( \"child_name\" ) and tl . hasAttribute ( \"parent_name\" ) and tl . hasAttribute ( \"parent_category_id\" ) ): childCategoryId = row [ tl . getIndex ( \"child_category_id\" )] linkGroupId = row [ tl . getIndex ( \"link_group_id\" )] if ( childCategoryId , linkGroupId ) not in self . __itemLinkedGroupItemDict : self . __itemLinkedGroupItemDict [( childCategoryId , linkGroupId )] = [] self . __itemLinkedGroupItemDict [( childCategoryId , linkGroupId )] . append ( ( row [ tl . getIndex ( \"child_name\" )], row [ tl . getIndex ( \"parent_name\" )], row [ tl . getIndex ( \"parent_category_id\" )]) ) # tl = ob . getObj ( \"pdbx_item_value_condition_list\" ) if tl is not None : for row in tl . getRowList (): if tl . hasAttribute ( \"dependent_item_name\" ) and tl . hasAttribute ( \"dependent_item_cmp_op\" ) and tl . hasAttribute ( \"target_item_name\" ) and tl . hasAttribute ( \"cond_id\" ): tD = OrderedDict () tD [ \"cond_id\" ] = row [ tl . getIndex ( \"cond_id\" )] tD [ \"target_item_name\" ] = row [ tl . getIndex ( \"target_item_name\" )] tD [ \"dependent_item_name\" ] = row [ tl . getIndex ( \"dependent_item_name\" )] tD [ \"dependent_item_cmp_op\" ] = row [ tl . getIndex ( \"dependent_item_cmp_op\" )] tD [ \"target_item_value\" ] = row [ tl . getIndex ( \"target_item_value\" )] if tl . hasAttribute ( \"target_item_value\" ) else None tD [ \"dependent_item_value\" ] = row [ tl . getIndex ( \"dependent_item_value\" )] if tl . hasAttribute ( \"dependent_item_value\" ) else None tD [ \"log_op\" ] = row [ tl . getIndex ( \"log_op\" )] if tl . hasAttribute ( \"log_op\" ) else \"and\" self . __itemValueConditionDict . setdefault ( tD [ \"target_item_name\" ], {}) . setdefault ( tD [ \"dependent_item_name\" ], []) . append ( tD ) # tl = ob . getObj ( \"pdbx_comparison_operator_list\" ) if tl is not None : for row in tl . getRowList (): if tl . hasAttribute ( \"code\" ) and tl . hasAttribute ( \"description\" ): tD = OrderedDict () tD [ \"code\" ] = row [ tl . getIndex ( \"code\" )] tD [ \"description\" ] = row [ tl . getIndex ( \"description\" )] self . __compOpDict [ tD [ \"code\" ]] = tD [ \"description\" ] Methods __init__ ( self , containerList , consolidate = True , expandItemLinked = False , replaceDefinition = False , ** kwargs ) special Return an instance of the mmCIF dictionary API. Parameters: Name Type Description Default containerList list list of definition or data containers holding dictionary content required consolidate bool consolidate dictionary attributes within a single definition. Defaults to True. True expandItemLinked bool distribute item and item linked attributes defined for the parent to child definitions. Defaults to False. False replaceDefinition bool when consolidating definitions in the case of multiple occurences of the same definition, attributes from the latter occurences replace prior definitions content. Defaults to False. False Source code in mmcif/api/DictionaryApi.py def __init__ ( self , containerList , consolidate = True , expandItemLinked = False , replaceDefinition = False , ** kwargs ): \"\"\"Return an instance of the mmCIF dictionary API. Args: containerList (list): list of definition or data containers holding dictionary content consolidate (bool, optional): consolidate dictionary attributes within a single definition. Defaults to True. expandItemLinked (bool, optional): distribute item and item linked attributes defined for the parent to child definitions. Defaults to False. replaceDefinition (bool, optional): when consolidating definitions in the case of multiple occurences of the same definition, attributes from the latter occurences replace prior definitions content. Defaults to False. \"\"\" _ = kwargs # self . __containerList = containerList self . __replaceDefinition = replaceDefinition # if consolidate : self . __consolidateDefinitions () # if expandItemLinked : self . __expandLoopedDefinitions () self . __fullIndex = OrderedDict () # --- # # Map category name to the unique list of attributes self . __catNameIndex = OrderedDict () # Map category name to the unique list of item names self . __catNameItemIndex = OrderedDict () # Full unique list of item names - self . __itemNameList = [] # # Map dictionary objects names to definition containers - self . __definitionIndex = OrderedDict () # # data section/objects of the dictionary by category name - self . __dataIndex = OrderedDict () # # Map of types id->(regex,primitive_type) self . __typesDict = OrderedDict () # self . __enumD = { \"ENUMERATION_VALUE\" : ( \"item_enumeration\" , \"value\" ), \"ENUMERATION_DETAIL\" : ( \"item_enumeration\" , \"detail\" ), \"ENUMERATION_TYPE_UNITS\" : ( \"item_enumeration\" , \"rcsb_type_units_code\" ), \"ENUMERATION_DETAIL_BRIEF\" : ( \"item_enumeration\" , \"rcsb_detail_brief\" ), \"ENUMERATION_TUPLE\" : ( \"item_enumeration\" , None ), \"ITEM_LINKED_PARENT\" : ( \"item_linked\" , \"parent_name\" ), \"ITEM_LINKED_CHILD\" : ( \"item_linked\" , \"child_name\" ), \"DATA_TYPE_CODE\" : ( \"item_type\" , \"code\" ), \"DATA_TYPE_REGEX\" : ( \"item_type_list\" , \"construct\" ), \"DATA_TYPE_PRIMITIVE\" : ( \"item_type_list\" , \"primitive_code\" ), \"ITEM_NAME\" : ( \"item\" , \"name\" ), \"ITEM_CATEGORY_ID\" : ( \"item\" , \"category_id\" ), \"ITEM_MANDATORY_CODE\" : ( \"item\" , \"mandatory_code\" ), \"ITEM_DESCRIPTION\" : ( \"item_description\" , \"description\" ), \"ITEM_UNITS\" : ( \"item_units\" , \"code\" ), \"ITEM_DEFAULT_VALUE\" : ( \"item_default\" , \"value\" ), \"ITEM_EXAMPLE_CASE\" : ( \"item_examples\" , \"case\" ), \"ITEM_EXAMPLE_DETAIL\" : ( \"item_examples\" , \"detail\" ), \"ITEM_RANGE_MAXIMUM\" : ( \"item_range\" , \"maximum\" ), \"ITEM_RANGE_MINIMUM\" : ( \"item_range\" , \"minimum\" ), \"CATEGORY_KEY_ITEMS\" : ( \"category_key\" , \"name\" ), \"CATEGORY_EXAMPLE_CASE\" : ( \"category_examples\" , \"case\" ), \"CATEGORY_EXAMPLE_DETAIL\" : ( \"category_examples\" , \"detail\" ), \"CATEGORY_MANDATORY_CODE\" : ( \"category\" , \"mandatory_code\" ), \"CATEGORY_DESCRIPTION\" : ( \"category\" , \"description\" ), \"CATEGORY_NX_MAPPING_DETAILS\" : ( \"category\" , \"NX_mapping_details\" ), # \"DATA_TYPE_CODE_NDB\" : ( \"ndb_item_type\" , \"code\" ), \"ITEM_DESCRIPTION_NDB\" : ( \"ndb_item_description\" , \"description\" ), \"ENUMERATION_VALUE_NDB\" : ( \"ndb_item_enumeration\" , \"value\" ), \"ENUMERATION_DETAIL_NDB\" : ( \"ndb_item_enumeration\" , \"detail\" ), \"ITEM_MANDATORY_CODE_NDB\" : ( \"ndb_item\" , \"mandatory_code\" ), \"ITEM_EXAMPLE_CASE_NDB\" : ( \"ndb_item_examples\" , \"case\" ), \"ITEM_EXAMPLE_DETAIL_NDB\" : ( \"ndb_item_examples\" , \"detail\" ), \"ITEM_RANGE_MAXIMUM_NDB\" : ( \"ndb_item_range\" , \"maximum\" ), \"ITEM_RANGE_MINIMUM_NDB\" : ( \"ndb_item_range\" , \"minimum\" ), \"CATEGORY_EXAMPLE_CASE_NDB\" : ( \"ndb_category_examples\" , \"case\" ), \"CATEGORY_EXAMPLE_DETAIL_NDB\" : ( \"ndb_category_examples\" , \"detail\" ), \"CATEGORY_DESCRIPTION_NDB\" : ( \"ndb_category_description\" , \"description\" ), # \"DATA_TYPE_CODE_PDBX\" : ( \"pdbx_item_type\" , \"code\" ), \"ITEM_DESCRIPTION_PDBX\" : ( \"pdbx_item_description\" , \"description\" ), \"ENUMERATION_VALUE_PDBX\" : ( \"pdbx_item_enumeration\" , \"value\" ), \"ENUMERATION_DETAIL_PDBX\" : ( \"pdbx_item_enumeration\" , \"detail\" ), \"ENUMERATION_TYPE_UNITS_PDBX\" : ( \"pdbx_item_enumeration\" , \"type_units_code\" ), \"ENUMERATION_DETAIL_BRIEF_PDBX\" : ( \"pdbx_item_enumeration\" , \"detail_brief\" ), \"ITEM_MANDATORY_CODE_PDBX\" : ( \"pdbx_item\" , \"mandatory_code\" ), \"ITEM_EXAMPLE_CASE_PDBX\" : ( \"pdbx_item_examples\" , \"case\" ), \"ITEM_EXAMPLE_DETAIL_PDBX\" : ( \"pdbx_item_examples\" , \"detail\" ), \"ITEM_RANGE_MAXIMUM_PDBX\" : ( \"pdbx_item_range\" , \"maximum\" ), \"ITEM_RANGE_MINIMUM_PDBX\" : ( \"pdbx_item_range\" , \"minimum\" ), \"CATEGORY_EXAMPLE_CASE_PDBX\" : ( \"pdbx_category_examples\" , \"case\" ), \"CATEGORY_EXAMPLE_DETAIL_PDBX\" : ( \"pdbx_category_examples\" , \"detail\" ), \"CATEGORY_DESCRIPTION_PDBX\" : ( \"pdbx_category_description\" , \"description\" ), # \"CATEGORY_CONTEXT\" : ( \"pdbx_category_context\" , \"type\" ), \"CATEGORY_GROUP\" : ( \"category_group\" , \"id\" ), \"ITEM_CONTEXT\" : ( \"pdbx_item_context\" , \"type\" ), \"ENUMERATION_CLOSED_FLAG\" : ( \"pdbx_item_enumeration_details\" , \"closed_flag\" ), # \"ITEM_RELATED_FUNCTION_CODE\" : ( \"item_related\" , \"function_code\" ), \"ITEM_RELATED_RELATED_NAME\" : ( \"item_related\" , \"related_name\" ), \"ITEM_ALIAS_ALIAS_NAME\" : ( \"item_aliases\" , \"alias_name\" ), \"ITEM_ALIAS_DICTIONARY\" : ( \"item_aliases\" , \"dictionary\" ), \"ITEM_ALIAS_VERSION\" : ( \"item_aliases\" , \"version\" ), \"ITEM_DEPENDENT_DEPENDENT_NAME\" : ( \"item_dependent\" , \"dependent_name\" ), \"ITEM_SUB_CATEGORY_ID\" : ( \"item_sub_category\" , \"id\" ), \"ITEM_SUB_CATEGORY_LABEL\" : ( \"item_sub_category\" , \"pdbx_label\" ), \"ITEM_TYPE_CONDITIONS_CODE\" : ( \"item_type_conditions\" , \"code\" ), # \"ITEM_VALUE_CONDITION_DEPENDENT_NAME\" : ( \"pdbx_item_value_condition\" , \"dependent_item_name\" ), # \"ITEM_LINKED_PDBX_ID\" : ( \"pdbx_item_linked\" , \"id\" ), \"ITEM_LINKED_PDBX_CONDITION_ID\" : ( \"pdbx_item_linked\" , \"condition_id\" ), \"ITEM_LINKED_PDBX_PARENT_NAME\" : ( \"pdbx_item_linked\" , \"parent_name\" ), \"ITEM_LINKED_PDBX_CHILD_NAME\" : ( \"pdbx_item_linked\" , \"child_name\" ), # \"ITEM_LINKED_PDBX_CONDITION_CHILD_NAME\" : ( \"pdbx_item_linked\" , \"condition_child_name\" ), \"ITEM_LINKED_PDBX_CONDITION_CHILD_VALUE\" : ( \"pdbx_item_linked\" , \"condition_child_value\" ), \"ITEM_LINKED_PDBX_CONDITION_CHILD_TARGET_NAME\" : ( \"pdbx_item_linked\" , \"condition_child_target_name\" ), \"ITEM_LINKED_PDBX_CONDITION_CHILD_CMP_OP\" : ( \"pdbx_item_linked\" , \"condition_child_cmp_op\" ), \"ITEM_LINKED_PDBX_CONDITION_LOG_OP\" : ( \"pdbx_item_linked\" , \"condition_log_op\" ), } # self . __methodDict = OrderedDict () self . __methodIndex = OrderedDict () # self . __makeIndex () self . __getMethods () # self . __fullParentD , self . __fullChildD = self . __makeFullParentChildDictionaries () # # self . __dataBlockDictList = [] self . __dictionaryDictList = [] # self . __subCategoryDict = OrderedDict () self . __categoryGroupDict = OrderedDict () self . __groupIndex = False self . __groupChildIndex = OrderedDict () # # Data sections - # self . __dictionaryHistoryList = [] self . __itemUnitsDict = OrderedDict () self . __itemUnitsConversionList = [] self . __itemLinkedGroupDict = OrderedDict () self . __itemLinkedGroupItemDict = OrderedDict () # self . __dictionaryIncludeDict = OrderedDict () self . __categoryIncludeDict = OrderedDict () self . __itemIncludeDict = OrderedDict () # self . __dictionaryComponentList = [] self . __dictionaryComponentHistoryDict = OrderedDict () # self . __itemValueConditionDict = OrderedDict () self . __compOpDict = OrderedDict () # self . __getDataSections () # definitionExists ( self , definitionName ) Source code in mmcif/api/DictionaryApi.py def definitionExists ( self , definitionName ): if definitionName in self . __definitionIndex : return True return False dumpCategoryIndex ( self , fh =< _io . StringIO object at 0x106b4dc10 > ) Source code in mmcif/api/DictionaryApi.py def dumpCategoryIndex ( self , fh = sys . stdout ): for k , vL in self . __catNameIndex . items (): uvL = list ( set ( vL )) fh . write ( \"Category: %s has %d attributes \\n \" % ( k , len ( uvL ))) for v in sorted ( uvL ): fh . write ( \" Attribute: %s \\n \" % v ) dumpDataSections ( self , fh =< _io . StringIO object at 0x106b4dc10 > ) Source code in mmcif/api/DictionaryApi.py def dumpDataSections ( self , fh = sys . stdout ): fh . write ( \"Datablock: %r \\n \" % list ( self . __dataBlockDictList )) fh . write ( \"Dictionary: %r \\n \" % list ( self . __dictionaryDictList )) fh . write ( \"Dictionary History: %r \\n \" % self . __dictionaryHistoryList ) fh . write ( \"Subcategories: %r \\n \" % list ( self . __subCategoryDict . items ())) fh . write ( \"Category groups: %r \\n \" % list ( self . __categoryGroupDict . items ())) fh . write ( \"Item units: %r \\n \" % list ( self . __itemUnitsDict . items ())) fh . write ( \"Item units conversions: %r \\n \" % self . __itemUnitsConversionList ) fh . write ( \"Item linked groups: %r \\n \" % list ( self . __itemLinkedGroupDict . items ())) fh . write ( \"Item linked group item list: %r \\n \" % list ( self . __itemLinkedGroupItemDict . items ())) dumpEnumFeatures ( self , fh =< _io . StringIO object at 0x106b4dc10 > ) Source code in mmcif/api/DictionaryApi.py def dumpEnumFeatures ( self , fh = sys . stdout ): for k , vL in self . __catNameIndex . items (): uvL = list ( set ( vL )) for v in sorted ( uvL ): itL = self . getEnumList ( k , v ) if itL : fh . write ( \"----------------------------------------------- \\n \" ) fh . write ( \" Category : %s \\n \" % k ) fh . write ( \" Attribute: %s \\n \" % v ) fh . write ( \" Description: \\n %s \\n \" % self . getDescription ( k , v )) fh . write ( \" Type: %s \\n \" % self . getTypeCode ( k , v )) fh . write ( \" Primitive type: %s \\n \" % self . getTypePrimitive ( k , v )) fh . write ( \" Regex type: %s \\n \" % self . getTypeRegex ( k , v )) fh . write ( \" Enum list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Enum: %s \\n \" % it ) dumpFeatures ( self , fh =< _io . StringIO object at 0x106b4dc10 > ) Source code in mmcif/api/DictionaryApi.py def dumpFeatures ( self , fh = sys . stdout ): for k , vL in self . __catNameIndex . items (): uvL = list ( set ( vL )) fh . write ( \"----------------------------------------------- \\n \" ) fh . write ( \"Category: %s has %d attributes \\n \" % ( k , len ( uvL ))) fh . write ( \" Category description: %s \\n \" % self . getCategoryDescription ( k )) fh . write ( \" Alt category description: %s \\n \" % self . getCategoryDescriptionAlt ( k )) fh . write ( \" Category context: %s \\n \" % self . getCategoryContextList ( k )) ctL = self . getCategoryExampleList ( k ) if ctL : fh . write ( \" Category example list length %d \\n \" % len ( ctL )) for ct1 , ct2 in ctL : fh . write ( \" Example case: %s \\n \" % ct1 ) fh . write ( \" Example detail: %s \\n \" % ct2 ) ctL = self . getCategoryExampleListAlt ( k ) if ctL : fh . write ( \" Alt category example list length %d \\n \" % len ( ctL )) for ct1 , ct2 in ctL : fh . write ( \" Alt example case: %s \\n \" % ct1 ) fh . write ( \" Alt example detail: %s \\n \" % ct2 ) for v in sorted ( uvL ): fh . write ( \" Attribute: %s \\n \" % v ) fh . write ( \" Description: %s \\n \" % self . getDescription ( k , v )) fh . write ( \" Alt description: %s \\n \" % self . getDescriptionAlt ( k , v )) fh . write ( \" Type: %s \\n \" % self . getTypeCode ( k , v )) fh . write ( \" Alt Type: %s \\n \" % self . getTypeCodeAlt ( k , v )) fh . write ( \" Primitive type: %s \\n \" % self . getTypePrimitive ( k , v )) fh . write ( \" Regex type: %s \\n \" % self . getTypeRegex ( k , v )) fh . write ( \" Context: %s \\n \" % self . getContextList ( k , v )) # fh . write ( \" Type conditions: %s \\n \" % self . getTypeConditionsCode ( k , v )) fh . write ( \" Subcategories: %s \\n \" % self . getItemSubCategoryIdList ( k , v )) # itL = self . getEnumList ( k , v ) if itL : fh . write ( \" Enum list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Enum: %s \\n \" % it ) itL = self . getParentList ( k , v ) if itL : fh . write ( \" Parent list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Parent: %s \\n \" % it ) itL = self . getChildList ( k , v ) if itL : fh . write ( \" Child list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Child: %s \\n \" % it ) itL = self . getExampleList ( k , v ) if itL : fh . write ( \" Example list length %d \\n \" % len ( itL )) for it1 , it2 in itL : fh . write ( \" Example case: %s \\n \" % it1 ) fh . write ( \" Example detail: %s \\n \" % it2 ) itL = self . getBoundaryList ( k , v ) if itL : fh . write ( \" Boundary list length %d \\n \" % len ( itL )) for ( it1 , it2 ) in itL : fh . write ( \" Boundary condition (min,max): ( %s , %s ) \\n \" % ( it1 , it2 )) itL = self . getEnumListAlt ( k , v ) if itL : fh . write ( \" Alt enum list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Alt enum: %s \\n \" % it ) itL = self . getExampleListAlt ( k , v ) if itL : fh . write ( \" Alt example list length %d \\n \" % len ( itL )) for it1 , it2 in itL : fh . write ( \" Alt example case: %s \\n \" % it1 ) fh . write ( \" Alt example detail: %s \\n \" % it2 ) itL = self . getBoundaryListAlt ( k , v ) if itL : fh . write ( \" Alt boundary list length %d \\n \" % len ( itL )) for ( it1 , it2 ) in itL : fh . write ( \" Alt boundary condition (min,max): ( %s , %s ) \\n \" % ( it1 , it2 )) itL = self . getItemRelatedList ( k , v ) if itL : fh . write ( \" Related name list length %d \\n \" % len ( itL )) for ( it1 , it2 ) in itL : fh . write ( \" Related item name %s function code %s \\n \" % ( it1 , it2 )) itL = self . getItemAliasList ( k , v ) if itL : fh . write ( \" Alias name list length %d \\n \" % len ( itL )) for ( it1 , it2 , it3 ) in itL : fh . write ( \" Alias name %s dictionary %s version %s \\n \" % ( it1 , it2 , it3 )) itL = self . getItemDependentNameList ( k , v ) if itL : fh . write ( \" Dependent name list length %d \\n \" % len ( itL )) for it1 in itL : fh . write ( \" Dependent item name %s \\n \" % it1 ) dumpItemLinkedGroups ( self , fh =< _io . StringIO object at 0x106b4dc10 > ) Source code in mmcif/api/DictionaryApi.py def dumpItemLinkedGroups ( self , fh = sys . stdout ): for categoryId , lgList in self . __itemLinkedGroupDict . items (): for lg in lgList : if ( categoryId , lg [ 1 ]) in self . __itemLinkedGroupItemDict : fh . write ( \" Category %s linked group %s : \\n \" % ( categoryId , lg [ 1 ])) lgIList = self . __itemLinkedGroupItemDict [( categoryId , lg [ 1 ])] for lgI in lgIList : fh . write ( \" group %s --- child item %s parent item %s \\n \" % ( lg [ 1 ], lgI [ 0 ], lgI [ 1 ])) dumpMethods ( self , fh =< _io . StringIO object at 0x106b4dc10 > ) Source code in mmcif/api/DictionaryApi.py def dumpMethods ( self , fh = sys . stdout ): for k , vL in self . __methodIndex . items (): fh . write ( \"Method index key: %s length %d \\n \" % ( k , len ( vL ))) for v in vL : v . printIt ( fh ) # fh . write ( \"Inline method details \\n \" ) for k , vL in self . __methodIndex . items (): fh . write ( \" \\n ------------------------------------ \\n \" ) fh . write ( \"Method index key: %s \\n \" % k ) for v in vL : fh . write ( \"Method ID: %r \\n \" % v . getId ()) if self . getMethod ( v . getId ()): fh . write ( \" %r \" % v ) # fh.write(\"Method text: %s\\n\" % self.getMethod(v.getId()).getInline()) else : fh . write ( \"Missing method for %r \" % v . getId ()) getAttributeNameList ( self , category ) Source code in mmcif/api/DictionaryApi.py def getAttributeNameList ( self , category ): try : return self . __catNameIndex [ category ] except Exception : pass return [] getBoundaryList ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getBoundaryList ( self , category , attribute ): minL = self . __getListAll ( \"ITEM_RANGE_MINIMUM\" , category , attribute ) maxL = self . __getListAll ( \"ITEM_RANGE_MAXIMUM\" , category , attribute ) bL = [] for vMin , vMax in zip ( minL , maxL ): bL . append (( vMin , vMax )) return bL getBoundaryListAlt ( self , category , attribute , fallBack = True ) Source code in mmcif/api/DictionaryApi.py def getBoundaryListAlt ( self , category , attribute , fallBack = True ): vL = self . getBoundaryListPdbx ( category , attribute ) if not vL : vL = self . getBoundaryListNdb ( category , attribute ) if fallBack and not vL : vL = self . getBoundaryList ( category , attribute ) return vL getBoundaryListNdb ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getBoundaryListNdb ( self , category , attribute ): minL = self . __getListAll ( \"ITEM_RANGE_MINIMUM_NDB\" , category , attribute ) maxL = self . __getListAll ( \"ITEM_RANGE_MAXIMUM_NDB\" , category , attribute ) bL = [] for vMin , vMax in zip ( minL , maxL ): bL . append (( vMin , vMax )) # return bL getBoundaryListPdbx ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getBoundaryListPdbx ( self , category , attribute ): minL = self . __getListAll ( \"ITEM_RANGE_MINIMUM_PDBX\" , category , attribute ) maxL = self . __getListAll ( \"ITEM_RANGE_MAXIMUM_PDBX\" , category , attribute ) bL = [] for vMin , vMax in zip ( minL , maxL ): bL . append (( vMin , vMax )) # return bL getCategoryContextList ( self , category ) Source code in mmcif/api/DictionaryApi.py def getCategoryContextList ( self , category ): return self . __getList ( \"CATEGORY_CONTEXT\" , category , attribute = None ) getCategoryDescription ( self , category ) Source code in mmcif/api/DictionaryApi.py def getCategoryDescription ( self , category ): return self . __get ( \"CATEGORY_DESCRIPTION\" , category , attribute = None ) getCategoryDescriptionAlt ( self , category , fallBack = True ) Source code in mmcif/api/DictionaryApi.py def getCategoryDescriptionAlt ( self , category , fallBack = True ): v = self . getCategoryDescriptionPdbx ( category ) if v is None : v = self . getCategoryDescriptionNdb ( category ) if fallBack and v is None : v = self . getCategoryDescription ( category ) return v getCategoryDescriptionNdb ( self , category ) Source code in mmcif/api/DictionaryApi.py def getCategoryDescriptionNdb ( self , category ): val = self . __get ( \"CATEGORY_DESCRIPTION_NDB\" , category , attribute = None ) return val getCategoryDescriptionPdbx ( self , category ) Source code in mmcif/api/DictionaryApi.py def getCategoryDescriptionPdbx ( self , category ): val = self . __get ( \"CATEGORY_DESCRIPTION_PDBX\" , category , attribute = None ) return val getCategoryExampleList ( self , category ) Source code in mmcif/api/DictionaryApi.py def getCategoryExampleList ( self , category ): exCL = self . __getListAll ( \"CATEGORY_EXAMPLE_CASE\" , category , attribute = None ) exDL = self . __getListAll ( \"CATEGORY_EXAMPLE_DETAIL\" , category , attribute = None ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL getCategoryExampleListAlt ( self , category , fallBack = True ) Source code in mmcif/api/DictionaryApi.py def getCategoryExampleListAlt ( self , category , fallBack = True ): vL = self . getCategoryExampleListPdbx ( category ) if not vL : vL = self . getCategoryExampleListNdb ( category ) if fallBack and not vL : vL = self . getCategoryExampleList ( category ) return vL getCategoryExampleListNdb ( self , category ) Source code in mmcif/api/DictionaryApi.py def getCategoryExampleListNdb ( self , category ): exCL = self . __getListAll ( \"CATEGORY_EXAMPLE_CASE_NDB\" , category , attribute = None ) exDL = self . __getListAll ( \"CATEGORY_EXAMPLE_DETAIL_NDB\" , category , attribute = None ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL getCategoryExampleListPdbx ( self , category ) Source code in mmcif/api/DictionaryApi.py def getCategoryExampleListPdbx ( self , category ): exCL = self . __getListAll ( \"CATEGORY_EXAMPLE_CASE_PDBX\" , category , attribute = None ) exDL = self . __getListAll ( \"CATEGORY_EXAMPLE_DETAIL_PDBX\" , category , attribute = None ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL getCategoryGroupCategories ( self , groupName , followChildren = False ) Source code in mmcif/api/DictionaryApi.py def getCategoryGroupCategories ( self , groupName , followChildren = False ): try : if not self . __groupIndex : self . __makeCategoryGroupIndex () # if followChildren : cL = [] grpL = [ groupName ] grpL . extend ( self . getCategoryGroupChildGroups ( groupName )) for grp in grpL : cL . extend ( self . __categoryGroupDict [ grp ][ \"categories\" ] if grp in self . __categoryGroupDict else []) return sorted ( set ( cL )) else : return self . __categoryGroupDict [ groupName ][ \"categories\" ] if groupName in self . __categoryGroupDict else [] # except Exception : logger . exception ( \"DictionaryApi.getCategoryGroupCategories failed for group %s \" , groupName ) return [] getCategoryGroupChildGroups ( self , parentGroupName ) Source code in mmcif/api/DictionaryApi.py def getCategoryGroupChildGroups ( self , parentGroupName ): try : return self . __groupChildIndex [ parentGroupName ] except Exception : return [] getCategoryGroupDescription ( self , groupName ) Source code in mmcif/api/DictionaryApi.py def getCategoryGroupDescription ( self , groupName ): try : return self . __categoryGroupDict [ groupName ][ \"description\" ] except Exception : return None getCategoryGroupList ( self , category ) Source code in mmcif/api/DictionaryApi.py def getCategoryGroupList ( self , category ): return self . __getList ( \"CATEGORY_GROUP\" , category , attribute = None ) getCategoryGroupParent ( self , groupName ) Source code in mmcif/api/DictionaryApi.py def getCategoryGroupParent ( self , groupName ): try : return self . __categoryGroupDict [ groupName ][ \"parent_id\" ] except Exception : return None getCategoryGroups ( self ) Source code in mmcif/api/DictionaryApi.py def getCategoryGroups ( self ): try : kL = self . __categoryGroupDict . keys () return kL except Exception : return [] getCategoryIndex ( self ) Source code in mmcif/api/DictionaryApi.py def getCategoryIndex ( self ): return self . __catNameIndex getCategoryKeyList ( self , category ) Source code in mmcif/api/DictionaryApi.py def getCategoryKeyList ( self , category ): return self . __getList ( \"CATEGORY_KEY_ITEMS\" , category , attribute = None ) getCategoryList ( self ) Source code in mmcif/api/DictionaryApi.py def getCategoryList ( self ): return list ( self . __catNameIndex . keys ()) getCategoryMandatoryCode ( self , category ) Source code in mmcif/api/DictionaryApi.py def getCategoryMandatoryCode ( self , category ): return self . __get ( \"CATEGORY_MANDATORY_CODE\" , category , attribute = None ) getCategoryNxMappingDetails ( self , category ) Source code in mmcif/api/DictionaryApi.py def getCategoryNxMappingDetails ( self , category ): return self . __get ( \"CATEGORY_NX_MAPPING_DETAILS\" , category , attribute = None ) getChildCategories ( self , categoryName ) Source code in mmcif/api/DictionaryApi.py def getChildCategories ( self , categoryName ): itemNameList = self . getItemNameList ( categoryName ) childCategories = set () for itemName in itemNameList : categoryName = CifName . categoryPart ( itemName ) attributeName = CifName . attributePart ( itemName ) childItemList = self . getFullChildList ( categoryName , attributeName ) for childItem in childItemList : childCategoryName = CifName . categoryPart ( childItem ) childCategories . add ( childCategoryName ) return list ( childCategories ) getChildList ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getChildList ( self , category , attribute ): return self . __getList ( \"ITEM_LINKED_CHILD\" , category , attribute ) getComparisonOperatorDict ( self ) Source code in mmcif/api/DictionaryApi.py def getComparisonOperatorDict ( self ): try : return self . __compOpDict if self . __compOpDict else {} except Exception : return {} getComparisonOperators ( self ) Source code in mmcif/api/DictionaryApi.py def getComparisonOperators ( self ): try : return list ( self . __compOpDict . keys ()) if self . __compOpDict else [] except Exception : return [] getContextList ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getContextList ( self , category , attribute ): return self . __getList ( \"ITEM_CONTEXT\" , category , attribute ) getDataTypeList ( self ) Return list of tuples containing ('code','primitive_code','construct','detail' ) Source code in mmcif/api/DictionaryApi.py def getDataTypeList ( self ): \"\"\"Return list of tuples containing ('code','primitive_code','construct','detail' )\"\"\" rowList = [] for code in sorted ( self . __typesDict . keys ()): tup = self . __typesDict [ code ] rowList . append (( code , tup [ 0 ], tup [ 1 ], tup [ 2 ])) return rowList getDefaultValue ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getDefaultValue ( self , category , attribute ): return self . __get ( \"ITEM_DEFAULT_VALUE\" , category , attribute ) getDefinitionIndex ( self ) Source code in mmcif/api/DictionaryApi.py def getDefinitionIndex ( self ): return self . __definitionIndex getDescription ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getDescription ( self , category , attribute ): return self . __get ( \"ITEM_DESCRIPTION\" , category , attribute ) getDescriptionAlt ( self , category , attribute , fallBack = True ) Source code in mmcif/api/DictionaryApi.py def getDescriptionAlt ( self , category , attribute , fallBack = True ): v = self . getDescriptionPdbx ( category , attribute ) if v is None : v = self . getDescriptionNdb ( category , attribute ) if fallBack and v is None : v = self . getDescription ( category , attribute ) return v getDescriptionNdb ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getDescriptionNdb ( self , category , attribute ): return self . __get ( \"ITEM_DESCRIPTION_NDB\" , category , attribute ) getDescriptionPdbx ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getDescriptionPdbx ( self , category , attribute ): return self . __get ( \"ITEM_DESCRIPTION_PDBX\" , category , attribute ) getDictionaryComponentCount ( self ) Get the count of dictionary components. Source code in mmcif/api/DictionaryApi.py def getDictionaryComponentCount ( self ): \"\"\"Get the count of dictionary components.\"\"\" try : return len ( self . __dictionaryComponentList ) except Exception : return 0 getDictionaryComponentDetails ( self ) Returns the component dictionary list as tuples [(version,title,dictionary_component_id),...] Source code in mmcif/api/DictionaryApi.py def getDictionaryComponentDetails ( self ): \"\"\"Returns the component dictionary list as tuples [(version,title,dictionary_component_id),...]\"\"\" oL = [] try : for tD in self . __dictionaryComponentList : oL . append (( tD [ \"version\" ], tD [ \"title\" ], tD [ \"dictionary_component_id\" ])) except Exception : pass return oL getDictionaryComponentHistory ( self , dictionaryComponentId , order = 'reverse' ) Returns the revision history as a list of tuples [(version,update,revisionText,dictionary),...] Source code in mmcif/api/DictionaryApi.py def getDictionaryComponentHistory ( self , dictionaryComponentId , order = \"reverse\" ): \"\"\"Returns the revision history as a list of tuples [(version,update,revisionText,dictionary),...]\"\"\" oL = [] try : if order == \"reverse\" : for tD in reversed ( self . __dictionaryComponentHistoryDict [ dictionaryComponentId ]): oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary_component_id\" ])) else : for tD in self . __dictionaryComponentHistoryDict [ dictionaryComponentId ]: oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary_component_id\" ])) except Exception : pass return oL getDictionaryComponents ( self ) Get the list of dictionary components. Source code in mmcif/api/DictionaryApi.py def getDictionaryComponents ( self ): \"\"\"Get the list of dictionary components.\"\"\" try : return list ( self . __dictionaryComponentHistoryDict . keys ()) except Exception : return [] getDictionaryHistory ( self , order = 'reverse' ) Returns the revision history as a list of tuples [(version,update,revisionText,dictionary),...] Source code in mmcif/api/DictionaryApi.py def getDictionaryHistory ( self , order = \"reverse\" ): \"\"\"Returns the revision history as a list of tuples [(version,update,revisionText,dictionary),...]\"\"\" oL = [] try : if order == \"reverse\" : for tD in reversed ( self . __dictionaryHistoryList ): oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary\" ])) else : for tD in self . __dictionaryHistoryList : oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary\" ])) except Exception : pass return oL getDictionaryRevisionCount ( self ) Get the count of revision history records. Source code in mmcif/api/DictionaryApi.py def getDictionaryRevisionCount ( self ): \"\"\"Get the count of revision history records.\"\"\" try : return len ( self . __dictionaryHistoryList ) except Exception : return 0 getDictionaryTitle ( self ) Source code in mmcif/api/DictionaryApi.py def getDictionaryTitle ( self ): try : return \",\" . join ([ str ( tD [ \"title\" ]) for tD in self . __dictionaryDictList ]) except Exception : return None getDictionaryUpdate ( self , order = 'reverse' ) Get details from the first/last history element. Source code in mmcif/api/DictionaryApi.py def getDictionaryUpdate ( self , order = \"reverse\" ): \"\"\"Get details from the first/last history element.\"\"\" try : if order == \"reverse\" : tD = self . __dictionaryHistoryList [ - 1 ] else : tD = self . __dictionaryHistoryList [ 0 ] return tD [ \"update\" ] except Exception : return None getDictionaryVersion ( self ) Source code in mmcif/api/DictionaryApi.py def getDictionaryVersion ( self ): try : return \",\" . join ([ str ( tD [ \"version\" ]) for tD in self . __dictionaryDictList ]) except Exception : return None getEnumList ( self , category , attribute , sortFlag = True ) Source code in mmcif/api/DictionaryApi.py def getEnumList ( self , category , attribute , sortFlag = True ): if sortFlag : return self . __getList ( \"ENUMERATION_VALUE\" , category , attribute ) else : return self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) getEnumListAlt ( self , category , attribute , fallBack = True , sortFlag = True ) Source code in mmcif/api/DictionaryApi.py def getEnumListAlt ( self , category , attribute , fallBack = True , sortFlag = True ): vL = self . getEnumListPdbx ( category , attribute , sortFlag = sortFlag ) if not vL : vL = self . getEnumListNdb ( category , attribute , sortFlag = sortFlag ) if fallBack and not vL : vL = self . getEnumList ( category , attribute , sortFlag = sortFlag ) return vL getEnumListAltWithDetail ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getEnumListAltWithDetail ( self , category , attribute ): eVL = self . __getListAll ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL_PDBX\" , category , attribute ) rL = [] dD = {} if len ( eVL ) == len ( eDL ): for eV , eD in zip ( eVL , eDL ): if not eD or eD in [ \".\" , \"?\" ]: dD [ eV ] = ( eV , None ) else : dD [ eV ] = ( eV , eD ) else : for eV in eVL : dD [ eV ] = ( eV , None ) # for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) # if not rL : return self . getEnumListWithDetail ( category , attribute ) else : return rL getEnumListAltWithFullDetails ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getEnumListAltWithFullDetails ( self , category , attribute ): rL = [] dD = {} try : eVL = self . __getListAll ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL_PDBX\" , category , attribute ) eBL = self . __getListAll ( \"ENUMERATION_DETAIL_BRIEF_PDBX\" , category , attribute ) eUL = self . __getListAll ( \"ENUMERATION_TYPE_UNITS_PDBX\" , category , attribute ) rL = [] dD = {} for eV , eD , eB , eU in zip_longest ( eVL , eDL , eBL , eUL ): oL = [ v if v and v not in [ \".\" , \"?\" ] else None for v in [ eV , eD , eB , eU ]] dD [ eV ] = tuple ( oL ) for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) if rL : return rL # eVL = self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL\" , category , attribute ) eBL = self . __getListAll ( \"ENUMERATION_DETAIL_BRIEF\" , category , attribute ) eUL = self . __getListAll ( \"ENUMERATION_TYPE_UNITS\" , category , attribute ) rL = [] dD = {} for eV , eD , eB , eU in zip_longest ( eVL , eDL , eBL , eUL ): oL = [ v if v and v not in [ \".\" , \"?\" ] else None for v in [ eV , eD , eB , eU ]] dD [ eV ] = tuple ( oL ) for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) except Exception as e : logger . exception ( \"Failing dD %r rL %r with %s \" , dD , rL , str ( e )) return rL getEnumListNdb ( self , category , attribute , sortFlag = True ) Source code in mmcif/api/DictionaryApi.py def getEnumListNdb ( self , category , attribute , sortFlag = True ): if sortFlag : return self . __getList ( \"ENUMERATION_VALUE_NDB\" , category , attribute ) else : return self . __getListAll ( \"ENUMERATION_VALUE_NDB\" , category , attribute ) getEnumListPdbx ( self , category , attribute , sortFlag = True ) Source code in mmcif/api/DictionaryApi.py def getEnumListPdbx ( self , category , attribute , sortFlag = True ): if sortFlag : return self . __getList ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) else : return self . __getListAll ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) getEnumListWithDetail ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getEnumListWithDetail ( self , category , attribute ): eVL = self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL\" , category , attribute ) rL = [] dD = {} if len ( eVL ) == len ( eDL ): for eV , eD in zip ( eVL , eDL ): if not eD or eD in [ \".\" , \"?\" ]: dD [ eV ] = ( eV , None ) else : dD [ eV ] = ( eV , eD ) else : for eV in eVL : dD [ eV ] = ( eV , None ) # for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) return rL getEnumListWithFullDetails ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getEnumListWithFullDetails ( self , category , attribute ): rL = [] dD = {} try : eVL = self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL\" , category , attribute ) eBL = self . __getListAll ( \"ENUMERATION_DETAIL_BRIEF\" , category , attribute ) eUL = self . __getListAll ( \"ENUMERATION_TYPE_UNITS\" , category , attribute ) # for eV , eD , eB , eU in zip_longest ( eVL , eDL , eBL , eUL ): oL = [ v if v and v not in [ \".\" , \"?\" ] else None for v in [ eV , eD , eB , eU ]] dD [ eV ] = tuple ( oL ) for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) except Exception as e : logger . info ( \"eVL %r \" , eVL ) logger . info ( \"eDL %r \" , eDL ) logger . info ( \"eBL %r \" , eBL ) logger . info ( \"eUL %r \" , eUL ) logger . exception ( \"Failing category %s attribute %s dD %r rL %r with %s \" , category , attribute , dD , rL , str ( e )) return rL getEnumerationClosedFlag ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getEnumerationClosedFlag ( self , category , attribute ): return self . __get ( \"ENUMERATION_CLOSED_FLAG\" , category , attribute ) getExampleList ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getExampleList ( self , category , attribute ): exCL = self . __getListAll ( \"ITEM_EXAMPLE_CASE\" , category , attribute ) exDL = self . __getListAll ( \"ITEM_EXAMPLE_DETAIL\" , category , attribute ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL getExampleListAlt ( self , category , attribute , fallBack = True ) Source code in mmcif/api/DictionaryApi.py def getExampleListAlt ( self , category , attribute , fallBack = True ): vL = self . getExampleListPdbx ( category , attribute ) if not vL : vL = self . getExampleListNdb ( category , attribute ) if fallBack and not vL : vL = self . getExampleList ( category , attribute ) return vL getExampleListNdb ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getExampleListNdb ( self , category , attribute ): exCL = self . __getListAll ( \"ITEM_EXAMPLE_CASE_NDB\" , category , attribute ) exDL = self . __getListAll ( \"ITEM_EXAMPLE_DETAIL_NDB\" , category , attribute ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL getExampleListPdbx ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getExampleListPdbx ( self , category , attribute ): exCL = self . __getListAll ( \"ITEM_EXAMPLE_CASE_PDBX\" , category , attribute ) exDL = self . __getListAll ( \"ITEM_EXAMPLE_DETAIL_PDBX\" , category , attribute ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL getFullChildList ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getFullChildList ( self , category , attribute ): try : itemName = CifName . itemName ( category , attribute ) return self . __fullChildD [ itemName ] except Exception : return [] getFullDescendentList ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getFullDescendentList ( self , category , attribute ): itemNameL = [] try : itemName = CifName . itemName ( category , attribute ) itemNameL = self . __fullChildD [ itemName ] if itemName in self . __fullChildD else [] itemNameL = list ( set ( itemNameL )) if itemNameL : begLen = 0 endLen = 1 # while endLen > begLen : begLen = len ( itemNameL ) for itemName in itemNameL : if itemName in self . __fullChildD : itemNameL . extend ( self . __fullChildD [ itemName ]) itemNameL = list ( set ( itemNameL )) endLen = len ( itemNameL ) except Exception as e : logger . exception ( \"Failing for %s %s with %s \" , category , attribute , str ( e )) return itemNameL getFullIndex ( self ) Source code in mmcif/api/DictionaryApi.py def getFullIndex ( self ): return self . __fullIndex getFullParentList ( self , category , attribute , stripSelfParent = False ) Source code in mmcif/api/DictionaryApi.py def getFullParentList ( self , category , attribute , stripSelfParent = False ): try : itemName = CifName . itemName ( category , attribute ) pL = self . __fullParentD [ itemName ] if stripSelfParent : if pL : try : pL . remove ( itemName ) except Exception : pass return pL else : return pL except Exception : return [] getImplicitList ( self ) Source code in mmcif/api/DictionaryApi.py def getImplicitList ( self ): iL = [] for name , dL in self . __definitionIndex . items (): for dD in dL : dType = dD . getType () if dType == \"definition\" and dD . isAttribute (): catN = CifName . categoryPart ( name ) attN = CifName . attributePart ( name ) if self . __get ( \"ITEM_MANDATORY_CODE\" , catN , attN ) == \"implicit\" : if name not in iL : iL . append ( name ) return iL getItemAliasList ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getItemAliasList ( self , category , attribute ): aNL = self . __getListAll ( \"ITEM_ALIAS_ALIAS_NAME\" , category , attribute ) aDL = self . __getListAll ( \"ITEM_ALIAS_DICTIONARY\" , category , attribute ) aVL = self . __getListAll ( \"ITEM_ALIAS_VERSION\" , category , attribute ) aL = [] for aN , aD , aV in zip ( aNL , aDL , aVL ): aL . append (( aN , aD , aV )) return aL getItemDependentNameList ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getItemDependentNameList ( self , category , attribute ): return self . __getList ( \"ITEM_DEPENDENT_DEPENDENT_NAME\" , category , attribute ) getItemLinkedConditions ( self ) Create a dictionary of conditional item link relationships. Returns: Type Description (dict) {{parent_name, child_name}: [{\"id\": , \"condition_id\": , \"condition_child_name\": , \"condition_child_value\": , \"condition_child_cmp_op\": , \"condition_log_op\": ,}, {},...]} Examples: loop_ _pdbx_item_linked.id _pdbx_item_linked.condition_id _pdbx_item_linked.parent_name _pdbx_item_linked.child_name # _pdbx_item_linked.condition_child_name _pdbx_item_linked.condition_child_value _pdbx_item_linked.condition_child_cmp_op _pdbx_item_linked.condition_child_target_name _pdbx_item_linked.condition_child_log_op 1 1 '_entity_poly_seq.num' '_atom_site.label_seq_id' '_atom_site.label_entity_id' . 'eq' '_entity.id' . 2 1 '_entity_poly_seq.num' '_atom_site.label_seq_id' '_entity.type' 'polymer' 'eq' . 'and' Source code in mmcif/api/DictionaryApi.py def getItemLinkedConditions ( self ): \"\"\"Create a dictionary of conditional item link relationships. Returns: (dict): {{parent_name, child_name}: [{\"id\": , \"condition_id\": , \"condition_child_name\": , \"condition_child_value\": , \"condition_child_cmp_op\": , \"condition_log_op\": ,}, {},...]} Example: ```text loop_ _pdbx_item_linked.id _pdbx_item_linked.condition_id _pdbx_item_linked.parent_name _pdbx_item_linked.child_name # _pdbx_item_linked.condition_child_name _pdbx_item_linked.condition_child_value _pdbx_item_linked.condition_child_cmp_op _pdbx_item_linked.condition_child_target_name _pdbx_item_linked.condition_child_log_op 1 1 '_entity_poly_seq.num' '_atom_site.label_seq_id' '_atom_site.label_entity_id' . 'eq' '_entity.id' . 2 1 '_entity_poly_seq.num' '_atom_site.label_seq_id' '_entity.type' 'polymer' 'eq' . 'and' ``` \"\"\" rD = OrderedDict () try : for ob in self . __containerList : if ob . getType () == \"data\" : continue tl = ob . getObj ( self . __enumD [ \"ITEM_LINKED_PDBX_ID\" ][ 0 ]) if tl is not None : for row in tl . getRowList (): if ( tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_ID\" ][ 1 ]) and tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_ID\" ][ 1 ]) and tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CHILD_NAME\" ][ 1 ]) and tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_PARENT_NAME\" ][ 1 ]) ): tD = OrderedDict () tD [ \"id\" ] = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_ID\" ][ 1 ])] tD [ \"condition_id\" ] = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_ID\" ][ 1 ])] parentName = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_PARENT_NAME\" ][ 1 ])] childName = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CHILD_NAME\" ][ 1 ])] # tD [ \"condition_child_name\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_NAME\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_NAME\" ][ 1 ]) else None ) tD [ \"condition_child_value\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_VALUE\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_VALUE\" ][ 1 ]) else None ) tD [ \"condition_child_cmp_op\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_CMP_OP\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_CMP_OP\" ][ 1 ]) else None ) tD [ \"condition_child_target_name\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_TARGET_NAME\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_TARGET_NAME\" ][ 1 ]) else None ) tD [ \"condition_log_op\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_LOG_OP\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_LOG_OP\" ][ 1 ]) else None ) # rD . setdefault (( parentName , childName ), []) . append ( tD ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return rD getItemNameList ( self , category ) Source code in mmcif/api/DictionaryApi.py def getItemNameList ( self , category ): try : return self . __catNameItemIndex [ category ] except Exception : pass return [] getItemRelatedList ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getItemRelatedList ( self , category , attribute ): rNL = self . __getListAll ( \"ITEM_RELATED_RELATED_NAME\" , category , attribute ) rFL = self . __getListAll ( \"ITEM_RELATED_FUNCTION_CODE\" , category , attribute ) rL = [] for rN , rF in zip ( rNL , rFL ): rL . append (( rN , rF )) return rL getItemSubCategoryIdList ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getItemSubCategoryIdList ( self , category , attribute ): return self . __getList ( \"ITEM_SUB_CATEGORY_ID\" , category , attribute ) getItemSubCategoryLabelList ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getItemSubCategoryLabelList ( self , category , attribute ): return self . __getList ( \"ITEM_SUB_CATEGORY_LABEL\" , category , attribute ) getItemSubCategoryList ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getItemSubCategoryList ( self , category , attribute ): aL = [] itemName = CifName . itemName ( category , attribute ) obL = self . __definitionIndex [ itemName ] if itemName in self . __definitionIndex else None for ob in obL : tObj = ob . getObj ( self . __enumD [ \"ITEM_SUB_CATEGORY_ID\" ][ 0 ]) if tObj is not None : atId = self . __enumD [ \"ITEM_SUB_CATEGORY_ID\" ][ 1 ] atLabel = self . __enumD [ \"ITEM_SUB_CATEGORY_LABEL\" ][ 1 ] for row in tObj . getRowList (): # logger.info(\"subcategories for %s row is %r\" % (itemName, row)) idVal = row [ tObj . getIndex ( atId )] if tObj . hasAttribute ( atId ) else None labVal = row [ tObj . getIndex ( atLabel )] if tObj . hasAttribute ( atLabel ) else None aL . append (( idVal , labVal )) return aL getItemValueConditionDependentList ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getItemValueConditionDependentList ( self , category , attribute ): return self . __getList ( \"ITEM_VALUE_CONDITION_DEPENDENT_NAME\" , category , attribute ) getItemValueConditionDict ( self ) Source code in mmcif/api/DictionaryApi.py def getItemValueConditionDict ( self ): try : return self . __itemValueConditionDict if self . __itemValueConditionDict else {} except Exception : return {} getMandatoryCode ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getMandatoryCode ( self , category , attribute ): return self . __get ( \"ITEM_MANDATORY_CODE\" , category , attribute ) getMandatoryCodeAlt ( self , category , attribute , fallBack = True ) Source code in mmcif/api/DictionaryApi.py def getMandatoryCodeAlt ( self , category , attribute , fallBack = True ): v = self . getMandatoryCodePdbx ( category , attribute ) if v is None : v = self . getMandatoryCodeNdb ( category , attribute ) if fallBack and v is None : v = self . getMandatoryCode ( category , attribute ) return v getMandatoryCodeNdb ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getMandatoryCodeNdb ( self , category , attribute ): return self . __get ( \"ITEM_MANDATORY_CODE_NDB\" , category , attribute ) getMandatoryCodePdbx ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getMandatoryCodePdbx ( self , category , attribute ): return self . __get ( \"ITEM_MANDATORY_CODE_PDBX\" , category , attribute ) getMethod ( self , mId ) Source code in mmcif/api/DictionaryApi.py def getMethod ( self , mId ): if mId in self . __methodDict : return self . __methodDict [ mId ] else : return None getMethodIndex ( self ) Source code in mmcif/api/DictionaryApi.py def getMethodIndex ( self ): return self . __methodIndex getParentCategories ( self , categoryName ) Source code in mmcif/api/DictionaryApi.py def getParentCategories ( self , categoryName ): itemNameList = self . getItemNameList ( categoryName ) parentCategories = set () for itemName in itemNameList : categoryName = CifName . categoryPart ( itemName ) attributeName = CifName . attributePart ( itemName ) parentItemList = self . getFullParentList ( categoryName , attributeName ) for parentItem in parentItemList : parentCategoryName = CifName . categoryPart ( parentItem ) parentCategories . add ( parentCategoryName ) return list ( parentCategories ) getParentDictionary ( self ) Create a dictionary of parents relations accross all definnitions as {child : [parent, parent,...] Exclude self parents. Source code in mmcif/api/DictionaryApi.py def getParentDictionary ( self ): \"\"\"Create a dictionary of parents relations accross all definnitions as {child : [parent, parent,...] Exclude self parents. \"\"\" parentD = {} pAtN = self . __enumD [ \"ITEM_LINKED_PARENT\" ][ 1 ] cAtN = self . __enumD [ \"ITEM_LINKED_CHILD\" ][ 1 ] for dObj in self . __containerList : dc = dObj . getObj ( self . __enumD [ \"ITEM_LINKED_PARENT\" ][ 0 ]) if dc is not None : idxP = dc . getIndex ( pAtN ) idxC = dc . getIndex ( cAtN ) for row in dc . getRowList (): pVal = row [ idxP ] cVal = row [ idxC ] if pVal == cVal : continue if cVal not in parentD : parentD [ cVal ] = [] parentD [ cVal ] . append ( pVal ) # return parentD getParentList ( self , category , attribute , stripSelfParent = False ) Source code in mmcif/api/DictionaryApi.py def getParentList ( self , category , attribute , stripSelfParent = False ): if stripSelfParent : itemName = CifName . itemName ( category , attribute ) pL = self . __getList ( \"ITEM_LINKED_PARENT\" , category , attribute ) if pL : try : pL . remove ( itemName ) except Exception : pass return pL else : return self . __getList ( \"ITEM_LINKED_PARENT\" , category , attribute ) getSubCategoryDescription ( self , subCategoryName ) Source code in mmcif/api/DictionaryApi.py def getSubCategoryDescription ( self , subCategoryName ): if subCategoryName in self . __subCategoryDict : return self . __subCategoryDict [ subCategoryName ] else : return \"\" getSubCategoryList ( self ) Return list of tuples containing ('id', 'description') Source code in mmcif/api/DictionaryApi.py def getSubCategoryList ( self ): \"\"\"Return list of tuples containing ('id', 'description')\"\"\" rowList = [] for tId in sorted ( self . __subCategoryDict . keys ()): description = self . __subCategoryDict [ tId ] rowList . append (( tId , description )) return rowList getTypeCode ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getTypeCode ( self , category , attribute ): return self . __get ( \"DATA_TYPE_CODE\" , category , attribute , followAncestors = True ) getTypeCodeAlt ( self , category , attribute , fallBack = True ) Source code in mmcif/api/DictionaryApi.py def getTypeCodeAlt ( self , category , attribute , fallBack = True ): v = self . getTypeCodePdbx ( category , attribute ) if v is None : v = self . getTypeCodeNdb ( category , attribute ) if fallBack and v is None : v = self . getTypeCode ( category , attribute ) return v getTypeCodeNdb ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getTypeCodeNdb ( self , category , attribute ): return self . __get ( \"DATA_TYPE_CODE_NDB\" , category , attribute , followAncestors = False ) getTypeCodePdbx ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getTypeCodePdbx ( self , category , attribute ): return self . __get ( \"DATA_TYPE_CODE_PDBX\" , category , attribute , followAncestors = False ) getTypeConditionsCode ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getTypeConditionsCode ( self , category , attribute ): return self . __get ( \"ITEM_TYPE_CONDITIONS_CODE\" , category , attribute ) getTypeDetail ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getTypeDetail ( self , category , attribute ): code = self . getTypeCode ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 2 ] return None getTypePrimitive ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getTypePrimitive ( self , category , attribute ): code = self . getTypeCode ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 0 ] return None getTypeRegex ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getTypeRegex ( self , category , attribute ): code = self . getTypeCode ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 1 ] return None getTypeRegexAlt ( self , category , attribute , fallBack = True ) Source code in mmcif/api/DictionaryApi.py def getTypeRegexAlt ( self , category , attribute , fallBack = True ): v = self . getTypeRegexPdbx ( category , attribute ) if v is None : v = self . getTypeRegexNdb ( category , attribute ) if fallBack and v is None : v = self . getTypeRegex ( category , attribute ) return v getTypeRegexNdb ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getTypeRegexNdb ( self , category , attribute ): code = self . getTypeCodeNdb ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 1 ] return None getTypeRegexPdbx ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getTypeRegexPdbx ( self , category , attribute ): code = self . getTypeCodePdbx ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 1 ] return None getUltimateParent ( self , category , attribute ) Return the first ultimate parent item for the input item. Source code in mmcif/api/DictionaryApi.py def getUltimateParent ( self , category , attribute ): \"\"\"Return the first ultimate parent item for the input item.\"\"\" # pL=self.__getList('ITEM_LINKED_PARENT',category,attribute) pL = self . getFullParentList ( category , attribute ) itemName = CifName . itemName ( category , attribute ) while pL and ( pL [ 0 ] != itemName ): attN = CifName . attributePart ( pL [ 0 ]) catN = CifName . categoryPart ( pL [ 0 ]) itemName = pL [ 0 ] pL = self . getFullParentList ( catN , attN ) # pL=self.__getList('ITEM_LINKED_PARENT',catN,attN) return itemName getUnits ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def getUnits ( self , category , attribute ): return self . __get ( \"ITEM_UNITS\" , category , attribute ) getUnitsConversionList ( self ) Return list of tuples containing ('from_code','to_code','operator','factor') Source code in mmcif/api/DictionaryApi.py def getUnitsConversionList ( self ): \"\"\"Return list of tuples containing ('from_code','to_code','operator','factor')\"\"\" return self . __itemUnitsConversionList getUnitsList ( self ) Return list of tuples containing ('id', 'description') Source code in mmcif/api/DictionaryApi.py def getUnitsList ( self ): \"\"\"Return list of tuples containing ('id', 'description')\"\"\" rowList = [] for tId in sorted ( self . __itemUnitsDict . keys ()): description = self . __itemUnitsDict [ tId ] rowList . append (( tId , description )) return rowList isEnumerated ( self , category , attribute ) Source code in mmcif/api/DictionaryApi.py def isEnumerated ( self , category , attribute ): return len ( self . __getList ( \"ENUMERATION_VALUE\" , category , attribute )) > 0 isEnumeratedAlt ( self , category , attribute , fallBack = True ) Source code in mmcif/api/DictionaryApi.py def isEnumeratedAlt ( self , category , attribute , fallBack = True ): eC = len ( self . __getList ( \"ENUMERATION_VALUE_PDBX\" , category , attribute )) if eC == 0 : eC = len ( self . __getList ( \"ENUMERATION_VALUE_NDB\" , category , attribute )) if fallBack and ( eC == 0 ): eC = len ( self . __getList ( \"ENUMERATION_VALUE\" , category , attribute )) return eC > 0 testCache ( self ) Source code in mmcif/api/DictionaryApi.py def testCache ( self ): return len ( self . __containerList ) > 0","title":"DictionaryApi"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi","text":"Source code in mmcif/api/DictionaryApi.py class DictionaryApi ( object ): def __init__ ( self , containerList , consolidate = True , expandItemLinked = False , replaceDefinition = False , ** kwargs ): \"\"\"Return an instance of the mmCIF dictionary API. Args: containerList (list): list of definition or data containers holding dictionary content consolidate (bool, optional): consolidate dictionary attributes within a single definition. Defaults to True. expandItemLinked (bool, optional): distribute item and item linked attributes defined for the parent to child definitions. Defaults to False. replaceDefinition (bool, optional): when consolidating definitions in the case of multiple occurences of the same definition, attributes from the latter occurences replace prior definitions content. Defaults to False. \"\"\" _ = kwargs # self . __containerList = containerList self . __replaceDefinition = replaceDefinition # if consolidate : self . __consolidateDefinitions () # if expandItemLinked : self . __expandLoopedDefinitions () self . __fullIndex = OrderedDict () # --- # # Map category name to the unique list of attributes self . __catNameIndex = OrderedDict () # Map category name to the unique list of item names self . __catNameItemIndex = OrderedDict () # Full unique list of item names - self . __itemNameList = [] # # Map dictionary objects names to definition containers - self . __definitionIndex = OrderedDict () # # data section/objects of the dictionary by category name - self . __dataIndex = OrderedDict () # # Map of types id->(regex,primitive_type) self . __typesDict = OrderedDict () # self . __enumD = { \"ENUMERATION_VALUE\" : ( \"item_enumeration\" , \"value\" ), \"ENUMERATION_DETAIL\" : ( \"item_enumeration\" , \"detail\" ), \"ENUMERATION_TYPE_UNITS\" : ( \"item_enumeration\" , \"rcsb_type_units_code\" ), \"ENUMERATION_DETAIL_BRIEF\" : ( \"item_enumeration\" , \"rcsb_detail_brief\" ), \"ENUMERATION_TUPLE\" : ( \"item_enumeration\" , None ), \"ITEM_LINKED_PARENT\" : ( \"item_linked\" , \"parent_name\" ), \"ITEM_LINKED_CHILD\" : ( \"item_linked\" , \"child_name\" ), \"DATA_TYPE_CODE\" : ( \"item_type\" , \"code\" ), \"DATA_TYPE_REGEX\" : ( \"item_type_list\" , \"construct\" ), \"DATA_TYPE_PRIMITIVE\" : ( \"item_type_list\" , \"primitive_code\" ), \"ITEM_NAME\" : ( \"item\" , \"name\" ), \"ITEM_CATEGORY_ID\" : ( \"item\" , \"category_id\" ), \"ITEM_MANDATORY_CODE\" : ( \"item\" , \"mandatory_code\" ), \"ITEM_DESCRIPTION\" : ( \"item_description\" , \"description\" ), \"ITEM_UNITS\" : ( \"item_units\" , \"code\" ), \"ITEM_DEFAULT_VALUE\" : ( \"item_default\" , \"value\" ), \"ITEM_EXAMPLE_CASE\" : ( \"item_examples\" , \"case\" ), \"ITEM_EXAMPLE_DETAIL\" : ( \"item_examples\" , \"detail\" ), \"ITEM_RANGE_MAXIMUM\" : ( \"item_range\" , \"maximum\" ), \"ITEM_RANGE_MINIMUM\" : ( \"item_range\" , \"minimum\" ), \"CATEGORY_KEY_ITEMS\" : ( \"category_key\" , \"name\" ), \"CATEGORY_EXAMPLE_CASE\" : ( \"category_examples\" , \"case\" ), \"CATEGORY_EXAMPLE_DETAIL\" : ( \"category_examples\" , \"detail\" ), \"CATEGORY_MANDATORY_CODE\" : ( \"category\" , \"mandatory_code\" ), \"CATEGORY_DESCRIPTION\" : ( \"category\" , \"description\" ), \"CATEGORY_NX_MAPPING_DETAILS\" : ( \"category\" , \"NX_mapping_details\" ), # \"DATA_TYPE_CODE_NDB\" : ( \"ndb_item_type\" , \"code\" ), \"ITEM_DESCRIPTION_NDB\" : ( \"ndb_item_description\" , \"description\" ), \"ENUMERATION_VALUE_NDB\" : ( \"ndb_item_enumeration\" , \"value\" ), \"ENUMERATION_DETAIL_NDB\" : ( \"ndb_item_enumeration\" , \"detail\" ), \"ITEM_MANDATORY_CODE_NDB\" : ( \"ndb_item\" , \"mandatory_code\" ), \"ITEM_EXAMPLE_CASE_NDB\" : ( \"ndb_item_examples\" , \"case\" ), \"ITEM_EXAMPLE_DETAIL_NDB\" : ( \"ndb_item_examples\" , \"detail\" ), \"ITEM_RANGE_MAXIMUM_NDB\" : ( \"ndb_item_range\" , \"maximum\" ), \"ITEM_RANGE_MINIMUM_NDB\" : ( \"ndb_item_range\" , \"minimum\" ), \"CATEGORY_EXAMPLE_CASE_NDB\" : ( \"ndb_category_examples\" , \"case\" ), \"CATEGORY_EXAMPLE_DETAIL_NDB\" : ( \"ndb_category_examples\" , \"detail\" ), \"CATEGORY_DESCRIPTION_NDB\" : ( \"ndb_category_description\" , \"description\" ), # \"DATA_TYPE_CODE_PDBX\" : ( \"pdbx_item_type\" , \"code\" ), \"ITEM_DESCRIPTION_PDBX\" : ( \"pdbx_item_description\" , \"description\" ), \"ENUMERATION_VALUE_PDBX\" : ( \"pdbx_item_enumeration\" , \"value\" ), \"ENUMERATION_DETAIL_PDBX\" : ( \"pdbx_item_enumeration\" , \"detail\" ), \"ENUMERATION_TYPE_UNITS_PDBX\" : ( \"pdbx_item_enumeration\" , \"type_units_code\" ), \"ENUMERATION_DETAIL_BRIEF_PDBX\" : ( \"pdbx_item_enumeration\" , \"detail_brief\" ), \"ITEM_MANDATORY_CODE_PDBX\" : ( \"pdbx_item\" , \"mandatory_code\" ), \"ITEM_EXAMPLE_CASE_PDBX\" : ( \"pdbx_item_examples\" , \"case\" ), \"ITEM_EXAMPLE_DETAIL_PDBX\" : ( \"pdbx_item_examples\" , \"detail\" ), \"ITEM_RANGE_MAXIMUM_PDBX\" : ( \"pdbx_item_range\" , \"maximum\" ), \"ITEM_RANGE_MINIMUM_PDBX\" : ( \"pdbx_item_range\" , \"minimum\" ), \"CATEGORY_EXAMPLE_CASE_PDBX\" : ( \"pdbx_category_examples\" , \"case\" ), \"CATEGORY_EXAMPLE_DETAIL_PDBX\" : ( \"pdbx_category_examples\" , \"detail\" ), \"CATEGORY_DESCRIPTION_PDBX\" : ( \"pdbx_category_description\" , \"description\" ), # \"CATEGORY_CONTEXT\" : ( \"pdbx_category_context\" , \"type\" ), \"CATEGORY_GROUP\" : ( \"category_group\" , \"id\" ), \"ITEM_CONTEXT\" : ( \"pdbx_item_context\" , \"type\" ), \"ENUMERATION_CLOSED_FLAG\" : ( \"pdbx_item_enumeration_details\" , \"closed_flag\" ), # \"ITEM_RELATED_FUNCTION_CODE\" : ( \"item_related\" , \"function_code\" ), \"ITEM_RELATED_RELATED_NAME\" : ( \"item_related\" , \"related_name\" ), \"ITEM_ALIAS_ALIAS_NAME\" : ( \"item_aliases\" , \"alias_name\" ), \"ITEM_ALIAS_DICTIONARY\" : ( \"item_aliases\" , \"dictionary\" ), \"ITEM_ALIAS_VERSION\" : ( \"item_aliases\" , \"version\" ), \"ITEM_DEPENDENT_DEPENDENT_NAME\" : ( \"item_dependent\" , \"dependent_name\" ), \"ITEM_SUB_CATEGORY_ID\" : ( \"item_sub_category\" , \"id\" ), \"ITEM_SUB_CATEGORY_LABEL\" : ( \"item_sub_category\" , \"pdbx_label\" ), \"ITEM_TYPE_CONDITIONS_CODE\" : ( \"item_type_conditions\" , \"code\" ), # \"ITEM_VALUE_CONDITION_DEPENDENT_NAME\" : ( \"pdbx_item_value_condition\" , \"dependent_item_name\" ), # \"ITEM_LINKED_PDBX_ID\" : ( \"pdbx_item_linked\" , \"id\" ), \"ITEM_LINKED_PDBX_CONDITION_ID\" : ( \"pdbx_item_linked\" , \"condition_id\" ), \"ITEM_LINKED_PDBX_PARENT_NAME\" : ( \"pdbx_item_linked\" , \"parent_name\" ), \"ITEM_LINKED_PDBX_CHILD_NAME\" : ( \"pdbx_item_linked\" , \"child_name\" ), # \"ITEM_LINKED_PDBX_CONDITION_CHILD_NAME\" : ( \"pdbx_item_linked\" , \"condition_child_name\" ), \"ITEM_LINKED_PDBX_CONDITION_CHILD_VALUE\" : ( \"pdbx_item_linked\" , \"condition_child_value\" ), \"ITEM_LINKED_PDBX_CONDITION_CHILD_TARGET_NAME\" : ( \"pdbx_item_linked\" , \"condition_child_target_name\" ), \"ITEM_LINKED_PDBX_CONDITION_CHILD_CMP_OP\" : ( \"pdbx_item_linked\" , \"condition_child_cmp_op\" ), \"ITEM_LINKED_PDBX_CONDITION_LOG_OP\" : ( \"pdbx_item_linked\" , \"condition_log_op\" ), } # self . __methodDict = OrderedDict () self . __methodIndex = OrderedDict () # self . __makeIndex () self . __getMethods () # self . __fullParentD , self . __fullChildD = self . __makeFullParentChildDictionaries () # # self . __dataBlockDictList = [] self . __dictionaryDictList = [] # self . __subCategoryDict = OrderedDict () self . __categoryGroupDict = OrderedDict () self . __groupIndex = False self . __groupChildIndex = OrderedDict () # # Data sections - # self . __dictionaryHistoryList = [] self . __itemUnitsDict = OrderedDict () self . __itemUnitsConversionList = [] self . __itemLinkedGroupDict = OrderedDict () self . __itemLinkedGroupItemDict = OrderedDict () # self . __dictionaryIncludeDict = OrderedDict () self . __categoryIncludeDict = OrderedDict () self . __itemIncludeDict = OrderedDict () # self . __dictionaryComponentList = [] self . __dictionaryComponentHistoryDict = OrderedDict () # self . __itemValueConditionDict = OrderedDict () self . __compOpDict = OrderedDict () # self . __getDataSections () # def testCache ( self ): return len ( self . __containerList ) > 0 # # Methods for data sections -- # def getItemValueConditionDict ( self ): try : return self . __itemValueConditionDict if self . __itemValueConditionDict else {} except Exception : return {} def getComparisonOperators ( self ): try : return list ( self . __compOpDict . keys ()) if self . __compOpDict else [] except Exception : return [] def getComparisonOperatorDict ( self ): try : return self . __compOpDict if self . __compOpDict else {} except Exception : return {} # def getDictionaryVersion ( self ): try : return \",\" . join ([ str ( tD [ \"version\" ]) for tD in self . __dictionaryDictList ]) except Exception : return None def getDictionaryTitle ( self ): try : return \",\" . join ([ str ( tD [ \"title\" ]) for tD in self . __dictionaryDictList ]) except Exception : return None def getDictionaryUpdate ( self , order = \"reverse\" ): \"\"\"Get details from the first/last history element.\"\"\" try : if order == \"reverse\" : tD = self . __dictionaryHistoryList [ - 1 ] else : tD = self . __dictionaryHistoryList [ 0 ] return tD [ \"update\" ] except Exception : return None def getDictionaryRevisionCount ( self ): \"\"\"Get the count of revision history records.\"\"\" try : return len ( self . __dictionaryHistoryList ) except Exception : return 0 def getDictionaryHistory ( self , order = \"reverse\" ): \"\"\"Returns the revision history as a list of tuples [(version,update,revisionText,dictionary),...]\"\"\" oL = [] try : if order == \"reverse\" : for tD in reversed ( self . __dictionaryHistoryList ): oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary\" ])) else : for tD in self . __dictionaryHistoryList : oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary\" ])) except Exception : pass return oL # def getDictionaryComponentDetails ( self ): \"\"\"Returns the component dictionary list as tuples [(version,title,dictionary_component_id),...]\"\"\" oL = [] try : for tD in self . __dictionaryComponentList : oL . append (( tD [ \"version\" ], tD [ \"title\" ], tD [ \"dictionary_component_id\" ])) except Exception : pass return oL def getDictionaryComponentCount ( self ): \"\"\"Get the count of dictionary components.\"\"\" try : return len ( self . __dictionaryComponentList ) except Exception : return 0 def getDictionaryComponents ( self ): \"\"\"Get the list of dictionary components.\"\"\" try : return list ( self . __dictionaryComponentHistoryDict . keys ()) except Exception : return [] def getDictionaryComponentHistory ( self , dictionaryComponentId , order = \"reverse\" ): \"\"\"Returns the revision history as a list of tuples [(version,update,revisionText,dictionary),...]\"\"\" oL = [] try : if order == \"reverse\" : for tD in reversed ( self . __dictionaryComponentHistoryDict [ dictionaryComponentId ]): oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary_component_id\" ])) else : for tD in self . __dictionaryComponentHistoryDict [ dictionaryComponentId ]: oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary_component_id\" ])) except Exception : pass return oL # def __makeCategoryGroupIndex ( self ): catNameList = self . getCategoryList () # add categories in group to self.__categoryGroupDict[<groupName>]['categories'] for catName in catNameList : groupNameList = self . getCategoryGroupList ( catName ) # logger.info(\"Category %s group list %r\\n\" % (catName,groupNameList)) for groupName in groupNameList : if groupName not in self . __categoryGroupDict : # handle undefined category group ? tD = OrderedDict () tD [ \"description\" ] = None tD [ \"parent_id\" ] = None tD [ \"categories\" ] = [] self . __categoryGroupDict [ groupName ] = tD self . __categoryGroupDict [ groupName ][ \"categories\" ] . append ( catName ) # for groupName in self . __categoryGroupDict : # logger.info(\"Group %s count %r\\n\" % (groupName, len(self.__categoryGroupDict[groupName]['categories']))) if \"categories\" in self . __categoryGroupDict [ groupName ]: self . __categoryGroupDict [ groupName ][ \"categories\" ] . sort () self . __groupChildIndex = OrderedDict () for groupName , gD in self . __categoryGroupDict . items (): if \"parent\" in gD : self . __groupChildIndex . setdefault ( gD [ \"parent\" ], []) . append ( groupName ) # self . __groupIndex = True # def getCategoryGroupDescription ( self , groupName ): try : return self . __categoryGroupDict [ groupName ][ \"description\" ] except Exception : return None def getCategoryGroupParent ( self , groupName ): try : return self . __categoryGroupDict [ groupName ][ \"parent_id\" ] except Exception : return None def getCategoryGroupChildGroups ( self , parentGroupName ): try : return self . __groupChildIndex [ parentGroupName ] except Exception : return [] def getCategoryGroupCategories ( self , groupName , followChildren = False ): try : if not self . __groupIndex : self . __makeCategoryGroupIndex () # if followChildren : cL = [] grpL = [ groupName ] grpL . extend ( self . getCategoryGroupChildGroups ( groupName )) for grp in grpL : cL . extend ( self . __categoryGroupDict [ grp ][ \"categories\" ] if grp in self . __categoryGroupDict else []) return sorted ( set ( cL )) else : return self . __categoryGroupDict [ groupName ][ \"categories\" ] if groupName in self . __categoryGroupDict else [] # except Exception : logger . exception ( \"DictionaryApi.getCategoryGroupCategories failed for group %s \" , groupName ) return [] def getCategoryGroups ( self ): try : kL = self . __categoryGroupDict . keys () return kL except Exception : return [] # def getParentCategories ( self , categoryName ): itemNameList = self . getItemNameList ( categoryName ) parentCategories = set () for itemName in itemNameList : categoryName = CifName . categoryPart ( itemName ) attributeName = CifName . attributePart ( itemName ) parentItemList = self . getFullParentList ( categoryName , attributeName ) for parentItem in parentItemList : parentCategoryName = CifName . categoryPart ( parentItem ) parentCategories . add ( parentCategoryName ) return list ( parentCategories ) def getChildCategories ( self , categoryName ): itemNameList = self . getItemNameList ( categoryName ) childCategories = set () for itemName in itemNameList : categoryName = CifName . categoryPart ( itemName ) attributeName = CifName . attributePart ( itemName ) childItemList = self . getFullChildList ( categoryName , attributeName ) for childItem in childItemList : childCategoryName = CifName . categoryPart ( childItem ) childCategories . add ( childCategoryName ) return list ( childCategories ) # def definitionExists ( self , definitionName ): if definitionName in self . __definitionIndex : return True return False def getTypeConditionsCode ( self , category , attribute ): return self . __get ( \"ITEM_TYPE_CONDITIONS_CODE\" , category , attribute ) def getItemDependentNameList ( self , category , attribute ): return self . __getList ( \"ITEM_DEPENDENT_DEPENDENT_NAME\" , category , attribute ) def getItemValueConditionDependentList ( self , category , attribute ): return self . __getList ( \"ITEM_VALUE_CONDITION_DEPENDENT_NAME\" , category , attribute ) def getItemSubCategoryIdList ( self , category , attribute ): return self . __getList ( \"ITEM_SUB_CATEGORY_ID\" , category , attribute ) def getItemSubCategoryLabelList ( self , category , attribute ): return self . __getList ( \"ITEM_SUB_CATEGORY_LABEL\" , category , attribute ) def getItemSubCategoryList ( self , category , attribute ): aL = [] itemName = CifName . itemName ( category , attribute ) obL = self . __definitionIndex [ itemName ] if itemName in self . __definitionIndex else None for ob in obL : tObj = ob . getObj ( self . __enumD [ \"ITEM_SUB_CATEGORY_ID\" ][ 0 ]) if tObj is not None : atId = self . __enumD [ \"ITEM_SUB_CATEGORY_ID\" ][ 1 ] atLabel = self . __enumD [ \"ITEM_SUB_CATEGORY_LABEL\" ][ 1 ] for row in tObj . getRowList (): # logger.info(\"subcategories for %s row is %r\" % (itemName, row)) idVal = row [ tObj . getIndex ( atId )] if tObj . hasAttribute ( atId ) else None labVal = row [ tObj . getIndex ( atLabel )] if tObj . hasAttribute ( atLabel ) else None aL . append (( idVal , labVal )) return aL def getItemAliasList ( self , category , attribute ): aNL = self . __getListAll ( \"ITEM_ALIAS_ALIAS_NAME\" , category , attribute ) aDL = self . __getListAll ( \"ITEM_ALIAS_DICTIONARY\" , category , attribute ) aVL = self . __getListAll ( \"ITEM_ALIAS_VERSION\" , category , attribute ) aL = [] for aN , aD , aV in zip ( aNL , aDL , aVL ): aL . append (( aN , aD , aV )) return aL def getEnumListWithDetail ( self , category , attribute ): eVL = self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL\" , category , attribute ) rL = [] dD = {} if len ( eVL ) == len ( eDL ): for eV , eD in zip ( eVL , eDL ): if not eD or eD in [ \".\" , \"?\" ]: dD [ eV ] = ( eV , None ) else : dD [ eV ] = ( eV , eD ) else : for eV in eVL : dD [ eV ] = ( eV , None ) # for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) return rL def getEnumListAltWithFullDetails ( self , category , attribute ): rL = [] dD = {} try : eVL = self . __getListAll ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL_PDBX\" , category , attribute ) eBL = self . __getListAll ( \"ENUMERATION_DETAIL_BRIEF_PDBX\" , category , attribute ) eUL = self . __getListAll ( \"ENUMERATION_TYPE_UNITS_PDBX\" , category , attribute ) rL = [] dD = {} for eV , eD , eB , eU in zip_longest ( eVL , eDL , eBL , eUL ): oL = [ v if v and v not in [ \".\" , \"?\" ] else None for v in [ eV , eD , eB , eU ]] dD [ eV ] = tuple ( oL ) for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) if rL : return rL # eVL = self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL\" , category , attribute ) eBL = self . __getListAll ( \"ENUMERATION_DETAIL_BRIEF\" , category , attribute ) eUL = self . __getListAll ( \"ENUMERATION_TYPE_UNITS\" , category , attribute ) rL = [] dD = {} for eV , eD , eB , eU in zip_longest ( eVL , eDL , eBL , eUL ): oL = [ v if v and v not in [ \".\" , \"?\" ] else None for v in [ eV , eD , eB , eU ]] dD [ eV ] = tuple ( oL ) for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) except Exception as e : logger . exception ( \"Failing dD %r rL %r with %s \" , dD , rL , str ( e )) return rL def getEnumListWithFullDetails ( self , category , attribute ): rL = [] dD = {} try : eVL = self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL\" , category , attribute ) eBL = self . __getListAll ( \"ENUMERATION_DETAIL_BRIEF\" , category , attribute ) eUL = self . __getListAll ( \"ENUMERATION_TYPE_UNITS\" , category , attribute ) # for eV , eD , eB , eU in zip_longest ( eVL , eDL , eBL , eUL ): oL = [ v if v and v not in [ \".\" , \"?\" ] else None for v in [ eV , eD , eB , eU ]] dD [ eV ] = tuple ( oL ) for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) except Exception as e : logger . info ( \"eVL %r \" , eVL ) logger . info ( \"eDL %r \" , eDL ) logger . info ( \"eBL %r \" , eBL ) logger . info ( \"eUL %r \" , eUL ) logger . exception ( \"Failing category %s attribute %s dD %r rL %r with %s \" , category , attribute , dD , rL , str ( e )) return rL def getEnumListAltWithDetail ( self , category , attribute ): eVL = self . __getListAll ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL_PDBX\" , category , attribute ) rL = [] dD = {} if len ( eVL ) == len ( eDL ): for eV , eD in zip ( eVL , eDL ): if not eD or eD in [ \".\" , \"?\" ]: dD [ eV ] = ( eV , None ) else : dD [ eV ] = ( eV , eD ) else : for eV in eVL : dD [ eV ] = ( eV , None ) # for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) # if not rL : return self . getEnumListWithDetail ( category , attribute ) else : return rL def getItemRelatedList ( self , category , attribute ): rNL = self . __getListAll ( \"ITEM_RELATED_RELATED_NAME\" , category , attribute ) rFL = self . __getListAll ( \"ITEM_RELATED_FUNCTION_CODE\" , category , attribute ) rL = [] for rN , rF in zip ( rNL , rFL ): rL . append (( rN , rF )) return rL def getTypeCode ( self , category , attribute ): return self . __get ( \"DATA_TYPE_CODE\" , category , attribute , followAncestors = True ) def getTypeCodeAlt ( self , category , attribute , fallBack = True ): v = self . getTypeCodePdbx ( category , attribute ) if v is None : v = self . getTypeCodeNdb ( category , attribute ) if fallBack and v is None : v = self . getTypeCode ( category , attribute ) return v def getTypeCodeNdb ( self , category , attribute ): return self . __get ( \"DATA_TYPE_CODE_NDB\" , category , attribute , followAncestors = False ) def getTypeCodePdbx ( self , category , attribute ): return self . __get ( \"DATA_TYPE_CODE_PDBX\" , category , attribute , followAncestors = False ) def getDefaultValue ( self , category , attribute ): return self . __get ( \"ITEM_DEFAULT_VALUE\" , category , attribute ) def getMandatoryCode ( self , category , attribute ): return self . __get ( \"ITEM_MANDATORY_CODE\" , category , attribute ) def getMandatoryCodeAlt ( self , category , attribute , fallBack = True ): v = self . getMandatoryCodePdbx ( category , attribute ) if v is None : v = self . getMandatoryCodeNdb ( category , attribute ) if fallBack and v is None : v = self . getMandatoryCode ( category , attribute ) return v def getMandatoryCodeNdb ( self , category , attribute ): return self . __get ( \"ITEM_MANDATORY_CODE_NDB\" , category , attribute ) def getMandatoryCodePdbx ( self , category , attribute ): return self . __get ( \"ITEM_MANDATORY_CODE_PDBX\" , category , attribute ) def getTypeRegex ( self , category , attribute ): code = self . getTypeCode ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 1 ] return None def getTypeRegexAlt ( self , category , attribute , fallBack = True ): v = self . getTypeRegexPdbx ( category , attribute ) if v is None : v = self . getTypeRegexNdb ( category , attribute ) if fallBack and v is None : v = self . getTypeRegex ( category , attribute ) return v def getTypeRegexNdb ( self , category , attribute ): code = self . getTypeCodeNdb ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 1 ] return None def getTypeRegexPdbx ( self , category , attribute ): code = self . getTypeCodePdbx ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 1 ] return None def getTypePrimitive ( self , category , attribute ): code = self . getTypeCode ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 0 ] return None def getTypeDetail ( self , category , attribute ): code = self . getTypeCode ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 2 ] return None def getContextList ( self , category , attribute ): return self . __getList ( \"ITEM_CONTEXT\" , category , attribute ) def getCategoryContextList ( self , category ): return self . __getList ( \"CATEGORY_CONTEXT\" , category , attribute = None ) def getEnumList ( self , category , attribute , sortFlag = True ): if sortFlag : return self . __getList ( \"ENUMERATION_VALUE\" , category , attribute ) else : return self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) def getEnumListAlt ( self , category , attribute , fallBack = True , sortFlag = True ): vL = self . getEnumListPdbx ( category , attribute , sortFlag = sortFlag ) if not vL : vL = self . getEnumListNdb ( category , attribute , sortFlag = sortFlag ) if fallBack and not vL : vL = self . getEnumList ( category , attribute , sortFlag = sortFlag ) return vL def getEnumListNdb ( self , category , attribute , sortFlag = True ): if sortFlag : return self . __getList ( \"ENUMERATION_VALUE_NDB\" , category , attribute ) else : return self . __getListAll ( \"ENUMERATION_VALUE_NDB\" , category , attribute ) def getEnumListPdbx ( self , category , attribute , sortFlag = True ): if sortFlag : return self . __getList ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) else : return self . __getListAll ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) def isEnumerated ( self , category , attribute ): return len ( self . __getList ( \"ENUMERATION_VALUE\" , category , attribute )) > 0 def isEnumeratedAlt ( self , category , attribute , fallBack = True ): eC = len ( self . __getList ( \"ENUMERATION_VALUE_PDBX\" , category , attribute )) if eC == 0 : eC = len ( self . __getList ( \"ENUMERATION_VALUE_NDB\" , category , attribute )) if fallBack and ( eC == 0 ): eC = len ( self . __getList ( \"ENUMERATION_VALUE\" , category , attribute )) return eC > 0 def getEnumerationClosedFlag ( self , category , attribute ): return self . __get ( \"ENUMERATION_CLOSED_FLAG\" , category , attribute ) def getUltimateParent ( self , category , attribute ): \"\"\"Return the first ultimate parent item for the input item.\"\"\" # pL=self.__getList('ITEM_LINKED_PARENT',category,attribute) pL = self . getFullParentList ( category , attribute ) itemName = CifName . itemName ( category , attribute ) while pL and ( pL [ 0 ] != itemName ): attN = CifName . attributePart ( pL [ 0 ]) catN = CifName . categoryPart ( pL [ 0 ]) itemName = pL [ 0 ] pL = self . getFullParentList ( catN , attN ) # pL=self.__getList('ITEM_LINKED_PARENT',catN,attN) return itemName def getParentList ( self , category , attribute , stripSelfParent = False ): if stripSelfParent : itemName = CifName . itemName ( category , attribute ) pL = self . __getList ( \"ITEM_LINKED_PARENT\" , category , attribute ) if pL : try : pL . remove ( itemName ) except Exception : pass return pL else : return self . __getList ( \"ITEM_LINKED_PARENT\" , category , attribute ) def getChildList ( self , category , attribute ): return self . __getList ( \"ITEM_LINKED_CHILD\" , category , attribute ) def getFullChildList ( self , category , attribute ): try : itemName = CifName . itemName ( category , attribute ) return self . __fullChildD [ itemName ] except Exception : return [] def getFullDescendentList ( self , category , attribute ): itemNameL = [] try : itemName = CifName . itemName ( category , attribute ) itemNameL = self . __fullChildD [ itemName ] if itemName in self . __fullChildD else [] itemNameL = list ( set ( itemNameL )) if itemNameL : begLen = 0 endLen = 1 # while endLen > begLen : begLen = len ( itemNameL ) for itemName in itemNameL : if itemName in self . __fullChildD : itemNameL . extend ( self . __fullChildD [ itemName ]) itemNameL = list ( set ( itemNameL )) endLen = len ( itemNameL ) except Exception as e : logger . exception ( \"Failing for %s %s with %s \" , category , attribute , str ( e )) return itemNameL def getFullParentList ( self , category , attribute , stripSelfParent = False ): try : itemName = CifName . itemName ( category , attribute ) pL = self . __fullParentD [ itemName ] if stripSelfParent : if pL : try : pL . remove ( itemName ) except Exception : pass return pL else : return pL except Exception : return [] def getUnits ( self , category , attribute ): return self . __get ( \"ITEM_UNITS\" , category , attribute ) def getImplicitList ( self ): iL = [] for name , dL in self . __definitionIndex . items (): for dD in dL : dType = dD . getType () if dType == \"definition\" and dD . isAttribute (): catN = CifName . categoryPart ( name ) attN = CifName . attributePart ( name ) if self . __get ( \"ITEM_MANDATORY_CODE\" , catN , attN ) == \"implicit\" : if name not in iL : iL . append ( name ) return iL def getDescription ( self , category , attribute ): return self . __get ( \"ITEM_DESCRIPTION\" , category , attribute ) def getDescriptionAlt ( self , category , attribute , fallBack = True ): v = self . getDescriptionPdbx ( category , attribute ) if v is None : v = self . getDescriptionNdb ( category , attribute ) if fallBack and v is None : v = self . getDescription ( category , attribute ) return v def getDescriptionNdb ( self , category , attribute ): return self . __get ( \"ITEM_DESCRIPTION_NDB\" , category , attribute ) def getDescriptionPdbx ( self , category , attribute ): return self . __get ( \"ITEM_DESCRIPTION_PDBX\" , category , attribute ) def getExampleList ( self , category , attribute ): exCL = self . __getListAll ( \"ITEM_EXAMPLE_CASE\" , category , attribute ) exDL = self . __getListAll ( \"ITEM_EXAMPLE_DETAIL\" , category , attribute ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL def getExampleListAlt ( self , category , attribute , fallBack = True ): vL = self . getExampleListPdbx ( category , attribute ) if not vL : vL = self . getExampleListNdb ( category , attribute ) if fallBack and not vL : vL = self . getExampleList ( category , attribute ) return vL def getExampleListNdb ( self , category , attribute ): exCL = self . __getListAll ( \"ITEM_EXAMPLE_CASE_NDB\" , category , attribute ) exDL = self . __getListAll ( \"ITEM_EXAMPLE_DETAIL_NDB\" , category , attribute ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL def getExampleListPdbx ( self , category , attribute ): exCL = self . __getListAll ( \"ITEM_EXAMPLE_CASE_PDBX\" , category , attribute ) exDL = self . __getListAll ( \"ITEM_EXAMPLE_DETAIL_PDBX\" , category , attribute ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL def getBoundaryList ( self , category , attribute ): minL = self . __getListAll ( \"ITEM_RANGE_MINIMUM\" , category , attribute ) maxL = self . __getListAll ( \"ITEM_RANGE_MAXIMUM\" , category , attribute ) bL = [] for vMin , vMax in zip ( minL , maxL ): bL . append (( vMin , vMax )) return bL def getBoundaryListAlt ( self , category , attribute , fallBack = True ): vL = self . getBoundaryListPdbx ( category , attribute ) if not vL : vL = self . getBoundaryListNdb ( category , attribute ) if fallBack and not vL : vL = self . getBoundaryList ( category , attribute ) return vL def getBoundaryListNdb ( self , category , attribute ): minL = self . __getListAll ( \"ITEM_RANGE_MINIMUM_NDB\" , category , attribute ) maxL = self . __getListAll ( \"ITEM_RANGE_MAXIMUM_NDB\" , category , attribute ) bL = [] for vMin , vMax in zip ( minL , maxL ): bL . append (( vMin , vMax )) # return bL def getBoundaryListPdbx ( self , category , attribute ): minL = self . __getListAll ( \"ITEM_RANGE_MINIMUM_PDBX\" , category , attribute ) maxL = self . __getListAll ( \"ITEM_RANGE_MAXIMUM_PDBX\" , category , attribute ) bL = [] for vMin , vMax in zip ( minL , maxL ): bL . append (( vMin , vMax )) # return bL def getCategoryKeyList ( self , category ): return self . __getList ( \"CATEGORY_KEY_ITEMS\" , category , attribute = None ) def getCategoryGroupList ( self , category ): return self . __getList ( \"CATEGORY_GROUP\" , category , attribute = None ) def getCategoryMandatoryCode ( self , category ): return self . __get ( \"CATEGORY_MANDATORY_CODE\" , category , attribute = None ) def getCategoryDescription ( self , category ): return self . __get ( \"CATEGORY_DESCRIPTION\" , category , attribute = None ) def getCategoryNxMappingDetails ( self , category ): return self . __get ( \"CATEGORY_NX_MAPPING_DETAILS\" , category , attribute = None ) def getCategoryDescriptionAlt ( self , category , fallBack = True ): v = self . getCategoryDescriptionPdbx ( category ) if v is None : v = self . getCategoryDescriptionNdb ( category ) if fallBack and v is None : v = self . getCategoryDescription ( category ) return v def getCategoryDescriptionNdb ( self , category ): val = self . __get ( \"CATEGORY_DESCRIPTION_NDB\" , category , attribute = None ) return val def getCategoryDescriptionPdbx ( self , category ): val = self . __get ( \"CATEGORY_DESCRIPTION_PDBX\" , category , attribute = None ) return val def getCategoryExampleList ( self , category ): exCL = self . __getListAll ( \"CATEGORY_EXAMPLE_CASE\" , category , attribute = None ) exDL = self . __getListAll ( \"CATEGORY_EXAMPLE_DETAIL\" , category , attribute = None ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL def getCategoryExampleListAlt ( self , category , fallBack = True ): vL = self . getCategoryExampleListPdbx ( category ) if not vL : vL = self . getCategoryExampleListNdb ( category ) if fallBack and not vL : vL = self . getCategoryExampleList ( category ) return vL def getCategoryExampleListNdb ( self , category ): exCL = self . __getListAll ( \"CATEGORY_EXAMPLE_CASE_NDB\" , category , attribute = None ) exDL = self . __getListAll ( \"CATEGORY_EXAMPLE_DETAIL_NDB\" , category , attribute = None ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL def getCategoryExampleListPdbx ( self , category ): exCL = self . __getListAll ( \"CATEGORY_EXAMPLE_CASE_PDBX\" , category , attribute = None ) exDL = self . __getListAll ( \"CATEGORY_EXAMPLE_DETAIL_PDBX\" , category , attribute = None ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL def getParentDictionary ( self ): \"\"\"Create a dictionary of parents relations accross all definnitions as {child : [parent, parent,...] Exclude self parents. \"\"\" parentD = {} pAtN = self . __enumD [ \"ITEM_LINKED_PARENT\" ][ 1 ] cAtN = self . __enumD [ \"ITEM_LINKED_CHILD\" ][ 1 ] for dObj in self . __containerList : dc = dObj . getObj ( self . __enumD [ \"ITEM_LINKED_PARENT\" ][ 0 ]) if dc is not None : idxP = dc . getIndex ( pAtN ) idxC = dc . getIndex ( cAtN ) for row in dc . getRowList (): pVal = row [ idxP ] cVal = row [ idxC ] if pVal == cVal : continue if cVal not in parentD : parentD [ cVal ] = [] parentD [ cVal ] . append ( pVal ) # return parentD def getItemLinkedConditions ( self ): \"\"\"Create a dictionary of conditional item link relationships. Returns: (dict): {{parent_name, child_name}: [{\"id\": , \"condition_id\": , \"condition_child_name\": , \"condition_child_value\": , \"condition_child_cmp_op\": , \"condition_log_op\": ,}, {},...]} Example: ```text loop_ _pdbx_item_linked.id _pdbx_item_linked.condition_id _pdbx_item_linked.parent_name _pdbx_item_linked.child_name # _pdbx_item_linked.condition_child_name _pdbx_item_linked.condition_child_value _pdbx_item_linked.condition_child_cmp_op _pdbx_item_linked.condition_child_target_name _pdbx_item_linked.condition_child_log_op 1 1 '_entity_poly_seq.num' '_atom_site.label_seq_id' '_atom_site.label_entity_id' . 'eq' '_entity.id' . 2 1 '_entity_poly_seq.num' '_atom_site.label_seq_id' '_entity.type' 'polymer' 'eq' . 'and' ``` \"\"\" rD = OrderedDict () try : for ob in self . __containerList : if ob . getType () == \"data\" : continue tl = ob . getObj ( self . __enumD [ \"ITEM_LINKED_PDBX_ID\" ][ 0 ]) if tl is not None : for row in tl . getRowList (): if ( tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_ID\" ][ 1 ]) and tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_ID\" ][ 1 ]) and tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CHILD_NAME\" ][ 1 ]) and tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_PARENT_NAME\" ][ 1 ]) ): tD = OrderedDict () tD [ \"id\" ] = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_ID\" ][ 1 ])] tD [ \"condition_id\" ] = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_ID\" ][ 1 ])] parentName = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_PARENT_NAME\" ][ 1 ])] childName = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CHILD_NAME\" ][ 1 ])] # tD [ \"condition_child_name\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_NAME\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_NAME\" ][ 1 ]) else None ) tD [ \"condition_child_value\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_VALUE\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_VALUE\" ][ 1 ]) else None ) tD [ \"condition_child_cmp_op\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_CMP_OP\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_CMP_OP\" ][ 1 ]) else None ) tD [ \"condition_child_target_name\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_TARGET_NAME\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_TARGET_NAME\" ][ 1 ]) else None ) tD [ \"condition_log_op\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_LOG_OP\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_LOG_OP\" ][ 1 ]) else None ) # rD . setdefault (( parentName , childName ), []) . append ( tD ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return rD def __makeFullParentChildDictionaries ( self ): \"\"\"Create a dictionaries of full parent/child relations accross all definnitions as fullParentD[child]=[parent,parent,...] and fullChildD[parent]=[child,child,...] Exclude self parents. \"\"\" fullParentD = {} fullChildD = {} pAtN = self . __enumD [ \"ITEM_LINKED_PARENT\" ][ 1 ] cAtN = self . __enumD [ \"ITEM_LINKED_CHILD\" ][ 1 ] for dObj in self . __containerList : # logger.info(\"\\n\\nSearching object %s\\n\" % dObj.getName()) dc = dObj . getObj ( self . __enumD [ \"ITEM_LINKED_PARENT\" ][ 0 ]) if dc is not None : idxP = dc . getIndex ( pAtN ) idxC = dc . getIndex ( cAtN ) for row in dc . getRowList (): pVal = row [ idxP ] cVal = row [ idxC ] # logger.info(\"%s found parent %s child %s \\n\" % (dObj.getName(),pVal,cVal)) if pVal == cVal : continue if cVal not in fullParentD : fullParentD [ cVal ] = [] fullParentD [ cVal ] . append ( pVal ) # if pVal not in fullChildD : fullChildD [ pVal ] = [] fullChildD [ pVal ] . append ( cVal ) # return fullParentD , fullChildD # def __get ( self , enumCode , category , attribute = None , followAncestors = False ): \"\"\"Return the last occurrence of the input dictionary metadata. If the value for the input category/attribute is null/missing then optionally check for an ancestor value. \"\"\" v0 = self . __getValue ( enumCode , category , attribute ) if not followAncestors : return v0 else : if ( v0 is None ) or ( not v0 ) or ( v0 in [ \".\" , \"?\" ]): pItem = self . getUltimateParent ( category , attribute ) if ( pItem is not None ) and pItem and ( pItem != CifName . itemName ( category , attribute )): logger . debug ( \"Reassigning enum code %s category %s attribute %s to parent %r \" , enumCode , category , attribute , pItem ) return self . __getValue ( enumCode , CifName . categoryPart ( pItem ), CifName . attributePart ( pItem )) return v0 # def __getValue ( self , enumCode , category , attribute = None ): \"\"\"Returns the last occurrence of the input dictionary metadata (enumCode) for the input category/attribute encountered in the list of objects stored at the indicated definition index. \"\"\" eS = None if enumCode not in self . __enumD : return eS if attribute is not None : nm = \"_\" + category + \".\" + attribute else : nm = category if nm in self . __definitionIndex : dObjL = self . __definitionIndex [ nm ] for dObj in dObjL : dc = dObj . getObj ( self . __enumD [ enumCode ][ 0 ]) if dc is not None : atN = self . __enumD [ enumCode ][ 1 ] rL = dc . getRowList () if rL : row = rL [ 0 ] if atN is not None : if dc . hasAttribute ( atN ): eS = row [ dc . getIndex ( atN )] else : eS = [ rv for rv in row ] return eS def __getList ( self , enumCode , category , attribute = None ): \"\"\"Return the list of unique values\"\"\" return list ( set ( self . __getListAll ( enumCode , category , attribute ))) def __getListAll ( self , enumCode , category , attribute = None ): \"\"\"Return a list of all values\"\"\" eL = [] if enumCode not in self . __enumD : return eL if attribute is not None : nm = \"_\" + category + \".\" + attribute else : nm = category if nm in self . __definitionIndex : dObjL = self . __definitionIndex [ nm ] for dObj in dObjL : dc = dObj . getObj ( self . __enumD [ enumCode ][ 0 ]) if dc is not None : atN = self . __enumD [ enumCode ][ 1 ] for row in dc . getRowList (): if atN is not None : if dc . hasAttribute ( atN ): eL . append ( row [ dc . getIndex ( atN )]) else : eL = [ rv for rv in row ] return eL def getMethodIndex ( self ): return self . __methodIndex def __makeIndex ( self ): \"\"\"Create indices of definitions, categories and items.\"\"\" iD = OrderedDict () for dD in self . __containerList : name = dD . getName () dType = dD . getType () # if name not in self . __fullIndex : self . __fullIndex [ name ] = [] self . __fullIndex [ name ] . append ( dD ) # if dType == \"definition\" and dD . isCategory (): if name not in self . __catNameIndex : self . __catNameIndex [ name ] = [] if name not in self . __catNameItemIndex : self . __catNameItemIndex [ name ] = [] if name not in self . __definitionIndex : self . __definitionIndex [ name ] = [] self . __definitionIndex [ name ] . append ( dD ) elif dType == \"definition\" and dD . isAttribute (): catN = CifName . categoryPart ( name ) attN = CifName . attributePart ( name ) if catN not in self . __catNameItemIndex : self . __catNameItemIndex [ catN ] = [] if name not in self . __catNameItemIndex : self . __catNameItemIndex [ catN ] . append ( name ) if catN not in self . __catNameIndex : self . __catNameIndex [ catN ] = [] if attN not in self . __catNameIndex [ catN ]: self . __catNameIndex [ catN ] . append ( attN ) if name not in self . __definitionIndex : self . __definitionIndex [ name ] = [] self . __definitionIndex [ name ] . append ( dD ) iD [ name ] = name elif dType == \"data\" : for nm in dD . getObjNameList (): if nm not in self . __dataIndex : self . __dataIndex [ nm ] = dD . getObj ( nm ) else : pass # self . __itemNameList = list ( iD . keys ()) def getDefinitionIndex ( self ): return self . __definitionIndex def getFullIndex ( self ): return self . __fullIndex def getMethod ( self , mId ): if mId in self . __methodDict : return self . __methodDict [ mId ] else : return None def getCategoryList ( self ): return list ( self . __catNameIndex . keys ()) def getCategoryIndex ( self ): return self . __catNameIndex def getAttributeNameList ( self , category ): try : return self . __catNameIndex [ category ] except Exception : pass return [] def getItemNameList ( self , category ): try : return self . __catNameItemIndex [ category ] except Exception : pass return [] def getSubCategoryDescription ( self , subCategoryName ): if subCategoryName in self . __subCategoryDict : return self . __subCategoryDict [ subCategoryName ] else : return \"\" def __getMethods ( self ): self . __methodDict = OrderedDict () self . __methodIndex = OrderedDict () for ob in self . __containerList : if ob . getType () == \"data\" : ml = ob . getObj ( \"method_list\" ) if ml is not None : # Use row order as priority for ii , row in enumerate ( ml . getRowList (), 1 ): if ml . hasAttribute ( \"id\" ) and ml . hasAttribute ( \"code\" ) and ml . hasAttribute ( \"language\" ) and ml . hasAttribute ( \"implementation_source\" ): tInline = row [ ml . getIndex ( \"inline\" )] if ml . hasAttribute ( \"inline\" ) else None tImpl = row [ ml . getIndex ( \"implementation\" )] if ml . hasAttribute ( \"implementation\" ) else None mth = MethodDefinition ( row [ ml . getIndex ( \"id\" )], row [ ml . getIndex ( \"code\" )], row [ ml . getIndex ( \"language\" )], tInline , ii , tImpl , row [ ml . getIndex ( \"implementation_source\" )] ) self . __methodDict [ row [ ml . getIndex ( \"id\" )]] = mth ml = ob . getObj ( \"datablock_methods\" ) if ml is not None : for row in ml . getRowList (): if ml . hasAttribute ( \"method_id\" ): # mth = MethodReference(row[ml.getIndex('method_id')], 'datablock', ob.getName(), None) mth = MethodReference ( row [ ml . getIndex ( \"method_id\" )], \"datablock\" , None , None ) if ob . getName () in self . __methodIndex : self . __methodIndex [ ob . getName ()] . append ( mth ) else : self . __methodIndex [ ob . getName ()] = [] self . __methodIndex [ ob . getName ()] . append ( mth ) elif ob . getType () == \"definition\" : mi = ob . getObj ( \"category_methods\" ) if mi is not None : for row in mi . getRowList (): if mi . hasAttribute ( \"method_id\" ): mth = MethodReference ( row [ mi . getIndex ( \"method_id\" )], \"category\" , ob . getName (), None ) if ob . getName () in self . __methodIndex : self . __methodIndex [ ob . getName ()] . append ( mth ) else : self . __methodIndex [ ob . getName ()] = [] self . __methodIndex [ ob . getName ()] . append ( mth ) mi = ob . getObj ( \"item_methods\" ) if mi is not None : for row in mi . getRowList (): if mi . hasAttribute ( \"method_id\" ): mth = MethodReference ( row [ mi . getIndex ( \"method_id\" )], \"attribute\" , CifName . categoryPart ( ob . getName ()), CifName . attributePart ( ob . getName ())) if ob . getName () in self . __methodIndex : self . __methodIndex [ ob . getName ()] . append ( mth ) else : self . __methodIndex [ ob . getName ()] = [] self . __methodIndex [ ob . getName ()] . append ( mth ) else : pass return self . __methodIndex def dumpCategoryIndex ( self , fh = sys . stdout ): for k , vL in self . __catNameIndex . items (): uvL = list ( set ( vL )) fh . write ( \"Category: %s has %d attributes \\n \" % ( k , len ( uvL ))) for v in sorted ( uvL ): fh . write ( \" Attribute: %s \\n \" % v ) def dumpMethods ( self , fh = sys . stdout ): for k , vL in self . __methodIndex . items (): fh . write ( \"Method index key: %s length %d \\n \" % ( k , len ( vL ))) for v in vL : v . printIt ( fh ) # fh . write ( \"Inline method details \\n \" ) for k , vL in self . __methodIndex . items (): fh . write ( \" \\n ------------------------------------ \\n \" ) fh . write ( \"Method index key: %s \\n \" % k ) for v in vL : fh . write ( \"Method ID: %r \\n \" % v . getId ()) if self . getMethod ( v . getId ()): fh . write ( \" %r \" % v ) # fh.write(\"Method text: %s\\n\" % self.getMethod(v.getId()).getInline()) else : fh . write ( \"Missing method for %r \" % v . getId ()) def dumpEnumFeatures ( self , fh = sys . stdout ): for k , vL in self . __catNameIndex . items (): uvL = list ( set ( vL )) for v in sorted ( uvL ): itL = self . getEnumList ( k , v ) if itL : fh . write ( \"----------------------------------------------- \\n \" ) fh . write ( \" Category : %s \\n \" % k ) fh . write ( \" Attribute: %s \\n \" % v ) fh . write ( \" Description: \\n %s \\n \" % self . getDescription ( k , v )) fh . write ( \" Type: %s \\n \" % self . getTypeCode ( k , v )) fh . write ( \" Primitive type: %s \\n \" % self . getTypePrimitive ( k , v )) fh . write ( \" Regex type: %s \\n \" % self . getTypeRegex ( k , v )) fh . write ( \" Enum list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Enum: %s \\n \" % it ) def dumpFeatures ( self , fh = sys . stdout ): for k , vL in self . __catNameIndex . items (): uvL = list ( set ( vL )) fh . write ( \"----------------------------------------------- \\n \" ) fh . write ( \"Category: %s has %d attributes \\n \" % ( k , len ( uvL ))) fh . write ( \" Category description: %s \\n \" % self . getCategoryDescription ( k )) fh . write ( \" Alt category description: %s \\n \" % self . getCategoryDescriptionAlt ( k )) fh . write ( \" Category context: %s \\n \" % self . getCategoryContextList ( k )) ctL = self . getCategoryExampleList ( k ) if ctL : fh . write ( \" Category example list length %d \\n \" % len ( ctL )) for ct1 , ct2 in ctL : fh . write ( \" Example case: %s \\n \" % ct1 ) fh . write ( \" Example detail: %s \\n \" % ct2 ) ctL = self . getCategoryExampleListAlt ( k ) if ctL : fh . write ( \" Alt category example list length %d \\n \" % len ( ctL )) for ct1 , ct2 in ctL : fh . write ( \" Alt example case: %s \\n \" % ct1 ) fh . write ( \" Alt example detail: %s \\n \" % ct2 ) for v in sorted ( uvL ): fh . write ( \" Attribute: %s \\n \" % v ) fh . write ( \" Description: %s \\n \" % self . getDescription ( k , v )) fh . write ( \" Alt description: %s \\n \" % self . getDescriptionAlt ( k , v )) fh . write ( \" Type: %s \\n \" % self . getTypeCode ( k , v )) fh . write ( \" Alt Type: %s \\n \" % self . getTypeCodeAlt ( k , v )) fh . write ( \" Primitive type: %s \\n \" % self . getTypePrimitive ( k , v )) fh . write ( \" Regex type: %s \\n \" % self . getTypeRegex ( k , v )) fh . write ( \" Context: %s \\n \" % self . getContextList ( k , v )) # fh . write ( \" Type conditions: %s \\n \" % self . getTypeConditionsCode ( k , v )) fh . write ( \" Subcategories: %s \\n \" % self . getItemSubCategoryIdList ( k , v )) # itL = self . getEnumList ( k , v ) if itL : fh . write ( \" Enum list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Enum: %s \\n \" % it ) itL = self . getParentList ( k , v ) if itL : fh . write ( \" Parent list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Parent: %s \\n \" % it ) itL = self . getChildList ( k , v ) if itL : fh . write ( \" Child list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Child: %s \\n \" % it ) itL = self . getExampleList ( k , v ) if itL : fh . write ( \" Example list length %d \\n \" % len ( itL )) for it1 , it2 in itL : fh . write ( \" Example case: %s \\n \" % it1 ) fh . write ( \" Example detail: %s \\n \" % it2 ) itL = self . getBoundaryList ( k , v ) if itL : fh . write ( \" Boundary list length %d \\n \" % len ( itL )) for ( it1 , it2 ) in itL : fh . write ( \" Boundary condition (min,max): ( %s , %s ) \\n \" % ( it1 , it2 )) itL = self . getEnumListAlt ( k , v ) if itL : fh . write ( \" Alt enum list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Alt enum: %s \\n \" % it ) itL = self . getExampleListAlt ( k , v ) if itL : fh . write ( \" Alt example list length %d \\n \" % len ( itL )) for it1 , it2 in itL : fh . write ( \" Alt example case: %s \\n \" % it1 ) fh . write ( \" Alt example detail: %s \\n \" % it2 ) itL = self . getBoundaryListAlt ( k , v ) if itL : fh . write ( \" Alt boundary list length %d \\n \" % len ( itL )) for ( it1 , it2 ) in itL : fh . write ( \" Alt boundary condition (min,max): ( %s , %s ) \\n \" % ( it1 , it2 )) itL = self . getItemRelatedList ( k , v ) if itL : fh . write ( \" Related name list length %d \\n \" % len ( itL )) for ( it1 , it2 ) in itL : fh . write ( \" Related item name %s function code %s \\n \" % ( it1 , it2 )) itL = self . getItemAliasList ( k , v ) if itL : fh . write ( \" Alias name list length %d \\n \" % len ( itL )) for ( it1 , it2 , it3 ) in itL : fh . write ( \" Alias name %s dictionary %s version %s \\n \" % ( it1 , it2 , it3 )) itL = self . getItemDependentNameList ( k , v ) if itL : fh . write ( \" Dependent name list length %d \\n \" % len ( itL )) for it1 in itL : fh . write ( \" Dependent item name %s \\n \" % it1 ) def dumpDataSections ( self , fh = sys . stdout ): fh . write ( \"Datablock: %r \\n \" % list ( self . __dataBlockDictList )) fh . write ( \"Dictionary: %r \\n \" % list ( self . __dictionaryDictList )) fh . write ( \"Dictionary History: %r \\n \" % self . __dictionaryHistoryList ) fh . write ( \"Subcategories: %r \\n \" % list ( self . __subCategoryDict . items ())) fh . write ( \"Category groups: %r \\n \" % list ( self . __categoryGroupDict . items ())) fh . write ( \"Item units: %r \\n \" % list ( self . __itemUnitsDict . items ())) fh . write ( \"Item units conversions: %r \\n \" % self . __itemUnitsConversionList ) fh . write ( \"Item linked groups: %r \\n \" % list ( self . __itemLinkedGroupDict . items ())) fh . write ( \"Item linked group item list: %r \\n \" % list ( self . __itemLinkedGroupItemDict . items ())) def dumpItemLinkedGroups ( self , fh = sys . stdout ): for categoryId , lgList in self . __itemLinkedGroupDict . items (): for lg in lgList : if ( categoryId , lg [ 1 ]) in self . __itemLinkedGroupItemDict : fh . write ( \" Category %s linked group %s : \\n \" % ( categoryId , lg [ 1 ])) lgIList = self . __itemLinkedGroupItemDict [( categoryId , lg [ 1 ])] for lgI in lgIList : fh . write ( \" group %s --- child item %s parent item %s \\n \" % ( lg [ 1 ], lgI [ 0 ], lgI [ 1 ])) def __addItemLinkToDef ( self , dObj , parentName , childName ): \"\"\"Add the input link relationship to the input definition object.\"\"\" if dObj . exists ( \"item_linked\" ): # update in place -- cObj = dObj . getObj ( \"item_linked\" ) iFound = False idxP = cObj . getIndex ( \"parent_name\" ) idxC = cObj . getIndex ( \"child_name\" ) for row in cObj . getRowList (): if parentName == row [ idxP ] and childName == row [ idxC ]: iFound = True break if not iFound : nRows = cObj . getRowCount () cObj . setValue ( childName , \"child_name\" , nRows ) cObj . setValue ( parentName , \"parent_name\" , nRows ) logger . debug ( \"Appending item link in category %s \" , dObj . getName ()) return True else : # create new category and append to input object cObj = DataCategory ( \"item_linked\" , attributeNameList = [ \"child_name\" , \"parent_name\" ]) cObj . append ([ childName , parentName ]) dObj . append ( cObj ) logger . debug ( \"Created new item link in category %s \" , dObj . getName ()) return True def __expandLoopedDefinitions ( self ): \"\"\"Handle definitions containing looped item and item_linked categories --\"\"\" fullIndex = OrderedDict () for dD in self . __containerList : name = dD . getName () if name not in fullIndex : fullIndex [ name ] = [] fullIndex [ name ] . append ( dD ) for name , dObjL in fullIndex . items (): if dObjL : ob = dObjL [ 0 ] if ( ob . getType () == \"definition\" ) and ob . exists ( \"item_linked\" ): cObj = ob . getObj ( \"item_linked\" ) if cObj . getRowCount () > 0 : idxP = cObj . getIndex ( \"parent_name\" ) idxC = cObj . getIndex ( \"child_name\" ) itemName = ob . getName () logger . debug ( \"Current target item %s \" , itemName ) cObjNext = DataCategory ( \"item_linked\" , attributeNameList = [ \"child_name\" , \"parent_name\" ]) # # Distribute the data for each row -- iChanges = 0 for row in cObj . getRowList (): # parentItemName = row [ idxP ] childItemName = row [ idxC ] if parentItemName == childItemName : continue if childItemName != itemName : iChanges += 1 if childItemName in fullIndex : # # Add this p/c link to the child definition - # self . __addItemLinkToDef ( fullIndex [ childItemName ][ 0 ], parentItemName , childItemName ) else : # error missing child definition object. logger . warning ( \"Missing child item %s \" , childItemName ) else : cObjNext . append ([ row [ idxC ], row [ idxP ]]) if cObjNext . getRowCount () > 0 : ob . replace ( cObjNext ) else : ob . remove ( \"item_linked\" ) def __consolidateDefinitions ( self ): \"\"\"Consolidate definition attributes into a single save frame section per definition.\"\"\" fullIndex = OrderedDict () for dD in self . __containerList : name = dD . getName () fullIndex . setdefault ( name , []) . append ( dD ) # preserve the original order of sections - # nList = [] for dObj in self . __containerList : nm = dObj . getName () if nm not in nList : nList . append ( nm ) # for name , dObjL in fullIndex . items (): if len ( dObjL ) > 1 : for dD in dObjL [ 1 :]: xList = dD . getObjNameList () for nm in xList : if nm not in dObjL [ 0 ] . getObjNameList (): logger . debug ( \"Adding %s to %s \" , nm , name ) catObj = dD . getObj ( nm ) dObjL [ 0 ] . append ( catObj ) elif self . __replaceDefinition : logger . debug ( \"Replacing dictionary %s in %s \" , nm , name ) catObj = dD . getObj ( nm ) dObjL [ 0 ] . replace ( catObj ) # create a new list of consolidated objects in original list order dList = [] for nm in nList : if nm in fullIndex : dl = fullIndex [ nm ] dList . append ( dl [ 0 ]) else : logger . info ( \"+DictionaryApi().__consolidate() missing object name %s \" , nm ) # update lists self . __containerList = dList def getDataTypeList ( self ): \"\"\"Return list of tuples containing ('code','primitive_code','construct','detail' )\"\"\" rowList = [] for code in sorted ( self . __typesDict . keys ()): tup = self . __typesDict [ code ] rowList . append (( code , tup [ 0 ], tup [ 1 ], tup [ 2 ])) return rowList def getSubCategoryList ( self ): \"\"\"Return list of tuples containing ('id', 'description')\"\"\" rowList = [] for tId in sorted ( self . __subCategoryDict . keys ()): description = self . __subCategoryDict [ tId ] rowList . append (( tId , description )) return rowList def getUnitsList ( self ): \"\"\"Return list of tuples containing ('id', 'description')\"\"\" rowList = [] for tId in sorted ( self . __itemUnitsDict . keys ()): description = self . __itemUnitsDict [ tId ] rowList . append (( tId , description )) return rowList def getUnitsConversionList ( self ): \"\"\"Return list of tuples containing ('from_code','to_code','operator','factor')\"\"\" return self . __itemUnitsConversionList def __getDataSections ( self ): \"\"\" \"\"\" for ob in self . __containerList : if ob . getType () == \"data\" : logger . debug ( \"Adding data sections from container name %s type %s \" , ob . getName (), ob . getType ()) # add detail to data type tuple tl = ob . getObj ( \"item_type_list\" ) if tl is not None : for row in tl . getRowList (): if tl . hasAttribute ( \"code\" ) and tl . hasAttribute ( \"primitive_code\" ) and tl . hasAttribute ( \"construct\" ) and tl . hasAttribute ( \"detail\" ): self . __typesDict [ row [ tl . getIndex ( \"code\" )]] = ( row [ tl . getIndex ( \"primitive_code\" )], row [ tl . getIndex ( \"construct\" )], row [ tl . getIndex ( \"detail\" )]) tl = ob . getObj ( \"datablock\" ) if tl is not None : rL = tl . getRowList () if rL : if tl . hasAttribute ( \"id\" ) and tl . hasAttribute ( \"description\" ): tD = OrderedDict () row = rL [ 0 ] tD [ \"id\" ] = row [ tl . getIndex ( \"id\" )] tD [ \"description\" ] = row [ tl . getIndex ( \"description\" )] self . __dataBlockDictList . append ( tD ) tl = ob . getObj ( \"dictionary\" ) if tl is not None : rL = tl . getRowList () if rL : tD = OrderedDict () row = rL [ 0 ] if tl . hasAttribute ( \"datablock_id\" ): tD [ \"datablock_id\" ] = row [ tl . getIndex ( \"datablock_id\" )] if tl . hasAttribute ( \"title\" ): tD [ \"title\" ] = row [ tl . getIndex ( \"title\" )] if tl . hasAttribute ( \"version\" ): tD [ \"version\" ] = row [ tl . getIndex ( \"version\" )] self . __dictionaryDictList . append ( tD ) tl = ob . getObj ( \"dictionary_history\" ) if tl is not None : # history as a list of dictionaries - dName = ob . getName () for row in tl . getRowList (): if tl . hasAttribute ( \"version\" ) and tl . hasAttribute ( \"revision\" ) and tl . hasAttribute ( \"update\" ): tD = OrderedDict () tD [ \"version\" ] = row [ tl . getIndex ( \"version\" )] tD [ \"revision\" ] = row [ tl . getIndex ( \"revision\" )] tD [ \"update\" ] = row [ tl . getIndex ( \"update\" )] tD [ \"dictionary\" ] = dName self . __dictionaryHistoryList . append ( tD ) # JDW tl = ob . getObj ( \"pdbx_include_dictionary\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () if tl . hasAttribute ( \"dictionary_id\" ): tD [ \"dictionary_id\" ] = row [ tl . getIndex ( \"dictionary_id\" )] if tl . hasAttribute ( \"dictionary_locator\" ): tD [ \"dictionary_locator\" ] = row [ tl . getIndex ( \"dictionary_locator\" )] if tl . hasAttribute ( \"include_mode\" ): tD [ \"include_mode\" ] = row [ tl . getIndex ( \"include_mode\" )] if tl . hasAttribute ( \"dictionary_namespace\" ): tD [ \"dictionary_namespace_prefix\" ] = row [ tl . getIndex ( \"dictionary_namespace_prefix\" )] if tl . hasAttribute ( \"dictionary_namespace_replace\" ): tD [ \"dictionary_namespace_prefix\" ] = row [ tl . getIndex ( \"dictionary_namespace_prefix_replace\" )] # self . __dictionaryIncludeDict [ tD [ \"dictionary_id\" ]] = tD # tl = ob . getObj ( \"pdbx_include_category\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () if tl . hasAttribute ( \"dictionary_id\" ): tD [ \"dictionary_id\" ] = row [ tl . getIndex ( \"dictionary_id\" )] if tl . hasAttribute ( \"category_id\" ): tD [ \"category_id\" ] = row [ tl . getIndex ( \"category_id\" )] if tl . hasAttribute ( \"include_as_category_id\" ): tD [ \"include_as_category_id\" ] = row [ tl . getIndex ( \"include_as_category_id\" )] if tl . hasAttribute ( \"include_mode\" ): tD [ \"include_mode\" ] = row [ tl . getIndex ( \"include_mode\" )] # self . __categoryIncludeDict . setdefault ( tD [ \"dictionary_id\" ], {}) . setdefault ( tD [ \"category_id\" ], tD ) tl = ob . getObj ( \"pdbx_include_item\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () if tl . hasAttribute ( \"dictionary_id\" ): tD [ \"dictionary_id\" ] = row [ tl . getIndex ( \"dictionary_id\" )] if tl . hasAttribute ( \"item_name\" ): tD [ \"item_name\" ] = row [ tl . getIndex ( \"item_name\" )] if tl . hasAttribute ( \"include_as_item_name\" ): tD [ \"include_as_item_name\" ] = row [ tl . getIndex ( \"include_as_item_name\" )] if tl . hasAttribute ( \"include_mode\" ): tD [ \"include_mode\" ] = row [ tl . getIndex ( \"include_mode\" )] # categoryId = CifName . categoryPart ( tD [ \"item_name\" ]) self . __itemIncludeDict . setdefault ( tD [ \"dictionary_id\" ], {}) . setdefault ( categoryId , {}) . setdefault ( tD [ \"item_name\" ], tD ) tl = ob . getObj ( \"dictionary_history\" ) if tl is not None : # history as a list of dictionaries - dName = ob . getName () for row in tl . getRowList (): if tl . hasAttribute ( \"version\" ) and tl . hasAttribute ( \"revision\" ) and tl . hasAttribute ( \"update\" ): tD = OrderedDict () tD [ \"version\" ] = row [ tl . getIndex ( \"version\" )] tD [ \"revision\" ] = row [ tl . getIndex ( \"revision\" )] tD [ \"update\" ] = row [ tl . getIndex ( \"update\" )] tD [ \"dictionary\" ] = dName self . __dictionaryHistoryList . append ( tD ) # tl = ob . getObj ( \"pdbx_dictionary_component\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () if tl . hasAttribute ( \"dictionary_component_id\" ): tD [ \"dictionary_component_id\" ] = row [ tl . getIndex ( \"dictionary_component_id\" )] if tl . hasAttribute ( \"title\" ): tD [ \"title\" ] = row [ tl . getIndex ( \"title\" )] if tl . hasAttribute ( \"version\" ): tD [ \"version\" ] = row [ tl . getIndex ( \"version\" )] self . __dictionaryComponentList . append ( tD ) tl = ob . getObj ( \"pdbx_dictionary_component_history\" ) if tl is not None : for row in tl . getRowList (): if tl . hasAttribute ( \"version\" ) and tl . hasAttribute ( \"revision\" ) and tl . hasAttribute ( \"update\" ): tD = OrderedDict () tD [ \"version\" ] = row [ tl . getIndex ( \"version\" )] tD [ \"revision\" ] = row [ tl . getIndex ( \"revision\" )] tD [ \"update\" ] = row [ tl . getIndex ( \"update\" )] tD [ \"dictionary_component_id\" ] = row [ tl . getIndex ( \"dictionary_component_id\" )] self . __dictionaryComponentHistoryDict . setdefault ( tD [ \"dictionary_component_id\" ], []) . append ( tD ) # JDW tl = ob . getObj ( \"sub_category\" ) if tl is not None : # subcategories as a dictionary by id self . __subCategoryDict = OrderedDict () for row in tl . getRowList (): if tl . hasAttribute ( \"id\" ) and tl . hasAttribute ( \"description\" ): self . __subCategoryDict [ row [ tl . getIndex ( \"id\" )]] = row [ tl . getIndex ( \"description\" )] tl = ob . getObj ( \"category_group_list\" ) if tl is not None : # category groups as a dictionary by id of tuples self . __categoryGroupDict = OrderedDict () for row in tl . getRowList (): if tl . hasAttribute ( \"id\" ) and tl . hasAttribute ( \"description\" ) and tl . hasAttribute ( \"parent_id\" ): tD = OrderedDict () tD [ \"description\" ] = row [ tl . getIndex ( \"description\" )] tD [ \"parent_id\" ] = row [ tl . getIndex ( \"parent_id\" )] tD [ \"categories\" ] = [] self . __categoryGroupDict [ row [ tl . getIndex ( \"id\" )]] = tD tl = ob . getObj ( \"item_units_list\" ) if tl is not None : # units as a dictionary by code self . __itemUnitsDict = OrderedDict () for row in tl . getRowList (): if tl . hasAttribute ( \"code\" ) and tl . hasAttribute ( \"detail\" ): self . __itemUnitsDict [ row [ tl . getIndex ( \"code\" )]] = row [ tl . getIndex ( \"detail\" )] tl = ob . getObj ( \"item_units_conversion\" ) if tl is not None : # units conversion as a simple list now self . __itemUnitsConversionList = [] for row in tl . getRowList (): if tl . hasAttribute ( \"from_code\" ) and tl . hasAttribute ( \"to_code\" ) and tl . hasAttribute ( \"operator\" ) and tl . hasAttribute ( \"factor\" ): self . __itemUnitsConversionList . append (( row [ tl . getIndex ( \"from_code\" )], row [ tl . getIndex ( \"to_code\" )], row [ tl . getIndex ( \"operator\" )], row [ tl . getIndex ( \"factor\" )])) tl = ob . getObj ( \"pdbx_item_linked_group\" ) if tl is not None : # parent-child collections [category_id] -> [(1,...),(3,...),(4,...) ] self . __itemLinkedGroupDict = OrderedDict () for row in tl . getRowList (): if ( tl . hasAttribute ( \"category_id\" ) and tl . hasAttribute ( \"link_group_id\" ) and tl . hasAttribute ( \"label\" ) and tl . hasAttribute ( \"context\" ) and tl . hasAttribute ( \"condition_id\" ) ): categoryId = row [ tl . getIndex ( \"category_id\" )] if categoryId not in self . __itemLinkedGroupDict : self . __itemLinkedGroupDict [ categoryId ] = [] self . __itemLinkedGroupDict [ categoryId ] . append ( ( row [ tl . getIndex ( \"category_id\" )], row [ tl . getIndex ( \"link_group_id\" )], row [ tl . getIndex ( \"context\" )], row [ tl . getIndex ( \"condition_id\" )]) ) tl = ob . getObj ( \"pdbx_item_linked_group_list\" ) if tl is not None : # parent-child collections [(category_id,link_group_id)] -> [(child_name,parent_name,parent_category),(,...),(,...) ] self . __itemLinkedGroupItemDict = OrderedDict () for row in tl . getRowList (): if ( tl . hasAttribute ( \"child_category_id\" ) and tl . hasAttribute ( \"link_group_id\" ) and tl . hasAttribute ( \"child_name\" ) and tl . hasAttribute ( \"parent_name\" ) and tl . hasAttribute ( \"parent_category_id\" ) ): childCategoryId = row [ tl . getIndex ( \"child_category_id\" )] linkGroupId = row [ tl . getIndex ( \"link_group_id\" )] if ( childCategoryId , linkGroupId ) not in self . __itemLinkedGroupItemDict : self . __itemLinkedGroupItemDict [( childCategoryId , linkGroupId )] = [] self . __itemLinkedGroupItemDict [( childCategoryId , linkGroupId )] . append ( ( row [ tl . getIndex ( \"child_name\" )], row [ tl . getIndex ( \"parent_name\" )], row [ tl . getIndex ( \"parent_category_id\" )]) ) # tl = ob . getObj ( \"pdbx_item_value_condition_list\" ) if tl is not None : for row in tl . getRowList (): if tl . hasAttribute ( \"dependent_item_name\" ) and tl . hasAttribute ( \"dependent_item_cmp_op\" ) and tl . hasAttribute ( \"target_item_name\" ) and tl . hasAttribute ( \"cond_id\" ): tD = OrderedDict () tD [ \"cond_id\" ] = row [ tl . getIndex ( \"cond_id\" )] tD [ \"target_item_name\" ] = row [ tl . getIndex ( \"target_item_name\" )] tD [ \"dependent_item_name\" ] = row [ tl . getIndex ( \"dependent_item_name\" )] tD [ \"dependent_item_cmp_op\" ] = row [ tl . getIndex ( \"dependent_item_cmp_op\" )] tD [ \"target_item_value\" ] = row [ tl . getIndex ( \"target_item_value\" )] if tl . hasAttribute ( \"target_item_value\" ) else None tD [ \"dependent_item_value\" ] = row [ tl . getIndex ( \"dependent_item_value\" )] if tl . hasAttribute ( \"dependent_item_value\" ) else None tD [ \"log_op\" ] = row [ tl . getIndex ( \"log_op\" )] if tl . hasAttribute ( \"log_op\" ) else \"and\" self . __itemValueConditionDict . setdefault ( tD [ \"target_item_name\" ], {}) . setdefault ( tD [ \"dependent_item_name\" ], []) . append ( tD ) # tl = ob . getObj ( \"pdbx_comparison_operator_list\" ) if tl is not None : for row in tl . getRowList (): if tl . hasAttribute ( \"code\" ) and tl . hasAttribute ( \"description\" ): tD = OrderedDict () tD [ \"code\" ] = row [ tl . getIndex ( \"code\" )] tD [ \"description\" ] = row [ tl . getIndex ( \"description\" )] self . __compOpDict [ tD [ \"code\" ]] = tD [ \"description\" ]","title":"DictionaryApi"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi-methods","text":"","title":"Methods"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.__init__","text":"Return an instance of the mmCIF dictionary API. Parameters: Name Type Description Default containerList list list of definition or data containers holding dictionary content required consolidate bool consolidate dictionary attributes within a single definition. Defaults to True. True expandItemLinked bool distribute item and item linked attributes defined for the parent to child definitions. Defaults to False. False replaceDefinition bool when consolidating definitions in the case of multiple occurences of the same definition, attributes from the latter occurences replace prior definitions content. Defaults to False. False Source code in mmcif/api/DictionaryApi.py def __init__ ( self , containerList , consolidate = True , expandItemLinked = False , replaceDefinition = False , ** kwargs ): \"\"\"Return an instance of the mmCIF dictionary API. Args: containerList (list): list of definition or data containers holding dictionary content consolidate (bool, optional): consolidate dictionary attributes within a single definition. Defaults to True. expandItemLinked (bool, optional): distribute item and item linked attributes defined for the parent to child definitions. Defaults to False. replaceDefinition (bool, optional): when consolidating definitions in the case of multiple occurences of the same definition, attributes from the latter occurences replace prior definitions content. Defaults to False. \"\"\" _ = kwargs # self . __containerList = containerList self . __replaceDefinition = replaceDefinition # if consolidate : self . __consolidateDefinitions () # if expandItemLinked : self . __expandLoopedDefinitions () self . __fullIndex = OrderedDict () # --- # # Map category name to the unique list of attributes self . __catNameIndex = OrderedDict () # Map category name to the unique list of item names self . __catNameItemIndex = OrderedDict () # Full unique list of item names - self . __itemNameList = [] # # Map dictionary objects names to definition containers - self . __definitionIndex = OrderedDict () # # data section/objects of the dictionary by category name - self . __dataIndex = OrderedDict () # # Map of types id->(regex,primitive_type) self . __typesDict = OrderedDict () # self . __enumD = { \"ENUMERATION_VALUE\" : ( \"item_enumeration\" , \"value\" ), \"ENUMERATION_DETAIL\" : ( \"item_enumeration\" , \"detail\" ), \"ENUMERATION_TYPE_UNITS\" : ( \"item_enumeration\" , \"rcsb_type_units_code\" ), \"ENUMERATION_DETAIL_BRIEF\" : ( \"item_enumeration\" , \"rcsb_detail_brief\" ), \"ENUMERATION_TUPLE\" : ( \"item_enumeration\" , None ), \"ITEM_LINKED_PARENT\" : ( \"item_linked\" , \"parent_name\" ), \"ITEM_LINKED_CHILD\" : ( \"item_linked\" , \"child_name\" ), \"DATA_TYPE_CODE\" : ( \"item_type\" , \"code\" ), \"DATA_TYPE_REGEX\" : ( \"item_type_list\" , \"construct\" ), \"DATA_TYPE_PRIMITIVE\" : ( \"item_type_list\" , \"primitive_code\" ), \"ITEM_NAME\" : ( \"item\" , \"name\" ), \"ITEM_CATEGORY_ID\" : ( \"item\" , \"category_id\" ), \"ITEM_MANDATORY_CODE\" : ( \"item\" , \"mandatory_code\" ), \"ITEM_DESCRIPTION\" : ( \"item_description\" , \"description\" ), \"ITEM_UNITS\" : ( \"item_units\" , \"code\" ), \"ITEM_DEFAULT_VALUE\" : ( \"item_default\" , \"value\" ), \"ITEM_EXAMPLE_CASE\" : ( \"item_examples\" , \"case\" ), \"ITEM_EXAMPLE_DETAIL\" : ( \"item_examples\" , \"detail\" ), \"ITEM_RANGE_MAXIMUM\" : ( \"item_range\" , \"maximum\" ), \"ITEM_RANGE_MINIMUM\" : ( \"item_range\" , \"minimum\" ), \"CATEGORY_KEY_ITEMS\" : ( \"category_key\" , \"name\" ), \"CATEGORY_EXAMPLE_CASE\" : ( \"category_examples\" , \"case\" ), \"CATEGORY_EXAMPLE_DETAIL\" : ( \"category_examples\" , \"detail\" ), \"CATEGORY_MANDATORY_CODE\" : ( \"category\" , \"mandatory_code\" ), \"CATEGORY_DESCRIPTION\" : ( \"category\" , \"description\" ), \"CATEGORY_NX_MAPPING_DETAILS\" : ( \"category\" , \"NX_mapping_details\" ), # \"DATA_TYPE_CODE_NDB\" : ( \"ndb_item_type\" , \"code\" ), \"ITEM_DESCRIPTION_NDB\" : ( \"ndb_item_description\" , \"description\" ), \"ENUMERATION_VALUE_NDB\" : ( \"ndb_item_enumeration\" , \"value\" ), \"ENUMERATION_DETAIL_NDB\" : ( \"ndb_item_enumeration\" , \"detail\" ), \"ITEM_MANDATORY_CODE_NDB\" : ( \"ndb_item\" , \"mandatory_code\" ), \"ITEM_EXAMPLE_CASE_NDB\" : ( \"ndb_item_examples\" , \"case\" ), \"ITEM_EXAMPLE_DETAIL_NDB\" : ( \"ndb_item_examples\" , \"detail\" ), \"ITEM_RANGE_MAXIMUM_NDB\" : ( \"ndb_item_range\" , \"maximum\" ), \"ITEM_RANGE_MINIMUM_NDB\" : ( \"ndb_item_range\" , \"minimum\" ), \"CATEGORY_EXAMPLE_CASE_NDB\" : ( \"ndb_category_examples\" , \"case\" ), \"CATEGORY_EXAMPLE_DETAIL_NDB\" : ( \"ndb_category_examples\" , \"detail\" ), \"CATEGORY_DESCRIPTION_NDB\" : ( \"ndb_category_description\" , \"description\" ), # \"DATA_TYPE_CODE_PDBX\" : ( \"pdbx_item_type\" , \"code\" ), \"ITEM_DESCRIPTION_PDBX\" : ( \"pdbx_item_description\" , \"description\" ), \"ENUMERATION_VALUE_PDBX\" : ( \"pdbx_item_enumeration\" , \"value\" ), \"ENUMERATION_DETAIL_PDBX\" : ( \"pdbx_item_enumeration\" , \"detail\" ), \"ENUMERATION_TYPE_UNITS_PDBX\" : ( \"pdbx_item_enumeration\" , \"type_units_code\" ), \"ENUMERATION_DETAIL_BRIEF_PDBX\" : ( \"pdbx_item_enumeration\" , \"detail_brief\" ), \"ITEM_MANDATORY_CODE_PDBX\" : ( \"pdbx_item\" , \"mandatory_code\" ), \"ITEM_EXAMPLE_CASE_PDBX\" : ( \"pdbx_item_examples\" , \"case\" ), \"ITEM_EXAMPLE_DETAIL_PDBX\" : ( \"pdbx_item_examples\" , \"detail\" ), \"ITEM_RANGE_MAXIMUM_PDBX\" : ( \"pdbx_item_range\" , \"maximum\" ), \"ITEM_RANGE_MINIMUM_PDBX\" : ( \"pdbx_item_range\" , \"minimum\" ), \"CATEGORY_EXAMPLE_CASE_PDBX\" : ( \"pdbx_category_examples\" , \"case\" ), \"CATEGORY_EXAMPLE_DETAIL_PDBX\" : ( \"pdbx_category_examples\" , \"detail\" ), \"CATEGORY_DESCRIPTION_PDBX\" : ( \"pdbx_category_description\" , \"description\" ), # \"CATEGORY_CONTEXT\" : ( \"pdbx_category_context\" , \"type\" ), \"CATEGORY_GROUP\" : ( \"category_group\" , \"id\" ), \"ITEM_CONTEXT\" : ( \"pdbx_item_context\" , \"type\" ), \"ENUMERATION_CLOSED_FLAG\" : ( \"pdbx_item_enumeration_details\" , \"closed_flag\" ), # \"ITEM_RELATED_FUNCTION_CODE\" : ( \"item_related\" , \"function_code\" ), \"ITEM_RELATED_RELATED_NAME\" : ( \"item_related\" , \"related_name\" ), \"ITEM_ALIAS_ALIAS_NAME\" : ( \"item_aliases\" , \"alias_name\" ), \"ITEM_ALIAS_DICTIONARY\" : ( \"item_aliases\" , \"dictionary\" ), \"ITEM_ALIAS_VERSION\" : ( \"item_aliases\" , \"version\" ), \"ITEM_DEPENDENT_DEPENDENT_NAME\" : ( \"item_dependent\" , \"dependent_name\" ), \"ITEM_SUB_CATEGORY_ID\" : ( \"item_sub_category\" , \"id\" ), \"ITEM_SUB_CATEGORY_LABEL\" : ( \"item_sub_category\" , \"pdbx_label\" ), \"ITEM_TYPE_CONDITIONS_CODE\" : ( \"item_type_conditions\" , \"code\" ), # \"ITEM_VALUE_CONDITION_DEPENDENT_NAME\" : ( \"pdbx_item_value_condition\" , \"dependent_item_name\" ), # \"ITEM_LINKED_PDBX_ID\" : ( \"pdbx_item_linked\" , \"id\" ), \"ITEM_LINKED_PDBX_CONDITION_ID\" : ( \"pdbx_item_linked\" , \"condition_id\" ), \"ITEM_LINKED_PDBX_PARENT_NAME\" : ( \"pdbx_item_linked\" , \"parent_name\" ), \"ITEM_LINKED_PDBX_CHILD_NAME\" : ( \"pdbx_item_linked\" , \"child_name\" ), # \"ITEM_LINKED_PDBX_CONDITION_CHILD_NAME\" : ( \"pdbx_item_linked\" , \"condition_child_name\" ), \"ITEM_LINKED_PDBX_CONDITION_CHILD_VALUE\" : ( \"pdbx_item_linked\" , \"condition_child_value\" ), \"ITEM_LINKED_PDBX_CONDITION_CHILD_TARGET_NAME\" : ( \"pdbx_item_linked\" , \"condition_child_target_name\" ), \"ITEM_LINKED_PDBX_CONDITION_CHILD_CMP_OP\" : ( \"pdbx_item_linked\" , \"condition_child_cmp_op\" ), \"ITEM_LINKED_PDBX_CONDITION_LOG_OP\" : ( \"pdbx_item_linked\" , \"condition_log_op\" ), } # self . __methodDict = OrderedDict () self . __methodIndex = OrderedDict () # self . __makeIndex () self . __getMethods () # self . __fullParentD , self . __fullChildD = self . __makeFullParentChildDictionaries () # # self . __dataBlockDictList = [] self . __dictionaryDictList = [] # self . __subCategoryDict = OrderedDict () self . __categoryGroupDict = OrderedDict () self . __groupIndex = False self . __groupChildIndex = OrderedDict () # # Data sections - # self . __dictionaryHistoryList = [] self . __itemUnitsDict = OrderedDict () self . __itemUnitsConversionList = [] self . __itemLinkedGroupDict = OrderedDict () self . __itemLinkedGroupItemDict = OrderedDict () # self . __dictionaryIncludeDict = OrderedDict () self . __categoryIncludeDict = OrderedDict () self . __itemIncludeDict = OrderedDict () # self . __dictionaryComponentList = [] self . __dictionaryComponentHistoryDict = OrderedDict () # self . __itemValueConditionDict = OrderedDict () self . __compOpDict = OrderedDict () # self . __getDataSections () #","title":"__init__()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.definitionExists","text":"Source code in mmcif/api/DictionaryApi.py def definitionExists ( self , definitionName ): if definitionName in self . __definitionIndex : return True return False","title":"definitionExists()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.dumpCategoryIndex","text":"Source code in mmcif/api/DictionaryApi.py def dumpCategoryIndex ( self , fh = sys . stdout ): for k , vL in self . __catNameIndex . items (): uvL = list ( set ( vL )) fh . write ( \"Category: %s has %d attributes \\n \" % ( k , len ( uvL ))) for v in sorted ( uvL ): fh . write ( \" Attribute: %s \\n \" % v )","title":"dumpCategoryIndex()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.dumpDataSections","text":"Source code in mmcif/api/DictionaryApi.py def dumpDataSections ( self , fh = sys . stdout ): fh . write ( \"Datablock: %r \\n \" % list ( self . __dataBlockDictList )) fh . write ( \"Dictionary: %r \\n \" % list ( self . __dictionaryDictList )) fh . write ( \"Dictionary History: %r \\n \" % self . __dictionaryHistoryList ) fh . write ( \"Subcategories: %r \\n \" % list ( self . __subCategoryDict . items ())) fh . write ( \"Category groups: %r \\n \" % list ( self . __categoryGroupDict . items ())) fh . write ( \"Item units: %r \\n \" % list ( self . __itemUnitsDict . items ())) fh . write ( \"Item units conversions: %r \\n \" % self . __itemUnitsConversionList ) fh . write ( \"Item linked groups: %r \\n \" % list ( self . __itemLinkedGroupDict . items ())) fh . write ( \"Item linked group item list: %r \\n \" % list ( self . __itemLinkedGroupItemDict . items ()))","title":"dumpDataSections()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.dumpEnumFeatures","text":"Source code in mmcif/api/DictionaryApi.py def dumpEnumFeatures ( self , fh = sys . stdout ): for k , vL in self . __catNameIndex . items (): uvL = list ( set ( vL )) for v in sorted ( uvL ): itL = self . getEnumList ( k , v ) if itL : fh . write ( \"----------------------------------------------- \\n \" ) fh . write ( \" Category : %s \\n \" % k ) fh . write ( \" Attribute: %s \\n \" % v ) fh . write ( \" Description: \\n %s \\n \" % self . getDescription ( k , v )) fh . write ( \" Type: %s \\n \" % self . getTypeCode ( k , v )) fh . write ( \" Primitive type: %s \\n \" % self . getTypePrimitive ( k , v )) fh . write ( \" Regex type: %s \\n \" % self . getTypeRegex ( k , v )) fh . write ( \" Enum list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Enum: %s \\n \" % it )","title":"dumpEnumFeatures()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.dumpFeatures","text":"Source code in mmcif/api/DictionaryApi.py def dumpFeatures ( self , fh = sys . stdout ): for k , vL in self . __catNameIndex . items (): uvL = list ( set ( vL )) fh . write ( \"----------------------------------------------- \\n \" ) fh . write ( \"Category: %s has %d attributes \\n \" % ( k , len ( uvL ))) fh . write ( \" Category description: %s \\n \" % self . getCategoryDescription ( k )) fh . write ( \" Alt category description: %s \\n \" % self . getCategoryDescriptionAlt ( k )) fh . write ( \" Category context: %s \\n \" % self . getCategoryContextList ( k )) ctL = self . getCategoryExampleList ( k ) if ctL : fh . write ( \" Category example list length %d \\n \" % len ( ctL )) for ct1 , ct2 in ctL : fh . write ( \" Example case: %s \\n \" % ct1 ) fh . write ( \" Example detail: %s \\n \" % ct2 ) ctL = self . getCategoryExampleListAlt ( k ) if ctL : fh . write ( \" Alt category example list length %d \\n \" % len ( ctL )) for ct1 , ct2 in ctL : fh . write ( \" Alt example case: %s \\n \" % ct1 ) fh . write ( \" Alt example detail: %s \\n \" % ct2 ) for v in sorted ( uvL ): fh . write ( \" Attribute: %s \\n \" % v ) fh . write ( \" Description: %s \\n \" % self . getDescription ( k , v )) fh . write ( \" Alt description: %s \\n \" % self . getDescriptionAlt ( k , v )) fh . write ( \" Type: %s \\n \" % self . getTypeCode ( k , v )) fh . write ( \" Alt Type: %s \\n \" % self . getTypeCodeAlt ( k , v )) fh . write ( \" Primitive type: %s \\n \" % self . getTypePrimitive ( k , v )) fh . write ( \" Regex type: %s \\n \" % self . getTypeRegex ( k , v )) fh . write ( \" Context: %s \\n \" % self . getContextList ( k , v )) # fh . write ( \" Type conditions: %s \\n \" % self . getTypeConditionsCode ( k , v )) fh . write ( \" Subcategories: %s \\n \" % self . getItemSubCategoryIdList ( k , v )) # itL = self . getEnumList ( k , v ) if itL : fh . write ( \" Enum list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Enum: %s \\n \" % it ) itL = self . getParentList ( k , v ) if itL : fh . write ( \" Parent list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Parent: %s \\n \" % it ) itL = self . getChildList ( k , v ) if itL : fh . write ( \" Child list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Child: %s \\n \" % it ) itL = self . getExampleList ( k , v ) if itL : fh . write ( \" Example list length %d \\n \" % len ( itL )) for it1 , it2 in itL : fh . write ( \" Example case: %s \\n \" % it1 ) fh . write ( \" Example detail: %s \\n \" % it2 ) itL = self . getBoundaryList ( k , v ) if itL : fh . write ( \" Boundary list length %d \\n \" % len ( itL )) for ( it1 , it2 ) in itL : fh . write ( \" Boundary condition (min,max): ( %s , %s ) \\n \" % ( it1 , it2 )) itL = self . getEnumListAlt ( k , v ) if itL : fh . write ( \" Alt enum list length %d \\n \" % len ( itL )) for it in itL : fh . write ( \" Alt enum: %s \\n \" % it ) itL = self . getExampleListAlt ( k , v ) if itL : fh . write ( \" Alt example list length %d \\n \" % len ( itL )) for it1 , it2 in itL : fh . write ( \" Alt example case: %s \\n \" % it1 ) fh . write ( \" Alt example detail: %s \\n \" % it2 ) itL = self . getBoundaryListAlt ( k , v ) if itL : fh . write ( \" Alt boundary list length %d \\n \" % len ( itL )) for ( it1 , it2 ) in itL : fh . write ( \" Alt boundary condition (min,max): ( %s , %s ) \\n \" % ( it1 , it2 )) itL = self . getItemRelatedList ( k , v ) if itL : fh . write ( \" Related name list length %d \\n \" % len ( itL )) for ( it1 , it2 ) in itL : fh . write ( \" Related item name %s function code %s \\n \" % ( it1 , it2 )) itL = self . getItemAliasList ( k , v ) if itL : fh . write ( \" Alias name list length %d \\n \" % len ( itL )) for ( it1 , it2 , it3 ) in itL : fh . write ( \" Alias name %s dictionary %s version %s \\n \" % ( it1 , it2 , it3 )) itL = self . getItemDependentNameList ( k , v ) if itL : fh . write ( \" Dependent name list length %d \\n \" % len ( itL )) for it1 in itL : fh . write ( \" Dependent item name %s \\n \" % it1 )","title":"dumpFeatures()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.dumpItemLinkedGroups","text":"Source code in mmcif/api/DictionaryApi.py def dumpItemLinkedGroups ( self , fh = sys . stdout ): for categoryId , lgList in self . __itemLinkedGroupDict . items (): for lg in lgList : if ( categoryId , lg [ 1 ]) in self . __itemLinkedGroupItemDict : fh . write ( \" Category %s linked group %s : \\n \" % ( categoryId , lg [ 1 ])) lgIList = self . __itemLinkedGroupItemDict [( categoryId , lg [ 1 ])] for lgI in lgIList : fh . write ( \" group %s --- child item %s parent item %s \\n \" % ( lg [ 1 ], lgI [ 0 ], lgI [ 1 ]))","title":"dumpItemLinkedGroups()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.dumpMethods","text":"Source code in mmcif/api/DictionaryApi.py def dumpMethods ( self , fh = sys . stdout ): for k , vL in self . __methodIndex . items (): fh . write ( \"Method index key: %s length %d \\n \" % ( k , len ( vL ))) for v in vL : v . printIt ( fh ) # fh . write ( \"Inline method details \\n \" ) for k , vL in self . __methodIndex . items (): fh . write ( \" \\n ------------------------------------ \\n \" ) fh . write ( \"Method index key: %s \\n \" % k ) for v in vL : fh . write ( \"Method ID: %r \\n \" % v . getId ()) if self . getMethod ( v . getId ()): fh . write ( \" %r \" % v ) # fh.write(\"Method text: %s\\n\" % self.getMethod(v.getId()).getInline()) else : fh . write ( \"Missing method for %r \" % v . getId ())","title":"dumpMethods()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getAttributeNameList","text":"Source code in mmcif/api/DictionaryApi.py def getAttributeNameList ( self , category ): try : return self . __catNameIndex [ category ] except Exception : pass return []","title":"getAttributeNameList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getBoundaryList","text":"Source code in mmcif/api/DictionaryApi.py def getBoundaryList ( self , category , attribute ): minL = self . __getListAll ( \"ITEM_RANGE_MINIMUM\" , category , attribute ) maxL = self . __getListAll ( \"ITEM_RANGE_MAXIMUM\" , category , attribute ) bL = [] for vMin , vMax in zip ( minL , maxL ): bL . append (( vMin , vMax )) return bL","title":"getBoundaryList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getBoundaryListAlt","text":"Source code in mmcif/api/DictionaryApi.py def getBoundaryListAlt ( self , category , attribute , fallBack = True ): vL = self . getBoundaryListPdbx ( category , attribute ) if not vL : vL = self . getBoundaryListNdb ( category , attribute ) if fallBack and not vL : vL = self . getBoundaryList ( category , attribute ) return vL","title":"getBoundaryListAlt()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getBoundaryListNdb","text":"Source code in mmcif/api/DictionaryApi.py def getBoundaryListNdb ( self , category , attribute ): minL = self . __getListAll ( \"ITEM_RANGE_MINIMUM_NDB\" , category , attribute ) maxL = self . __getListAll ( \"ITEM_RANGE_MAXIMUM_NDB\" , category , attribute ) bL = [] for vMin , vMax in zip ( minL , maxL ): bL . append (( vMin , vMax )) # return bL","title":"getBoundaryListNdb()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getBoundaryListPdbx","text":"Source code in mmcif/api/DictionaryApi.py def getBoundaryListPdbx ( self , category , attribute ): minL = self . __getListAll ( \"ITEM_RANGE_MINIMUM_PDBX\" , category , attribute ) maxL = self . __getListAll ( \"ITEM_RANGE_MAXIMUM_PDBX\" , category , attribute ) bL = [] for vMin , vMax in zip ( minL , maxL ): bL . append (( vMin , vMax )) # return bL","title":"getBoundaryListPdbx()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryContextList","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryContextList ( self , category ): return self . __getList ( \"CATEGORY_CONTEXT\" , category , attribute = None )","title":"getCategoryContextList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryDescription","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryDescription ( self , category ): return self . __get ( \"CATEGORY_DESCRIPTION\" , category , attribute = None )","title":"getCategoryDescription()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryDescriptionAlt","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryDescriptionAlt ( self , category , fallBack = True ): v = self . getCategoryDescriptionPdbx ( category ) if v is None : v = self . getCategoryDescriptionNdb ( category ) if fallBack and v is None : v = self . getCategoryDescription ( category ) return v","title":"getCategoryDescriptionAlt()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryDescriptionNdb","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryDescriptionNdb ( self , category ): val = self . __get ( \"CATEGORY_DESCRIPTION_NDB\" , category , attribute = None ) return val","title":"getCategoryDescriptionNdb()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryDescriptionPdbx","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryDescriptionPdbx ( self , category ): val = self . __get ( \"CATEGORY_DESCRIPTION_PDBX\" , category , attribute = None ) return val","title":"getCategoryDescriptionPdbx()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryExampleList","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryExampleList ( self , category ): exCL = self . __getListAll ( \"CATEGORY_EXAMPLE_CASE\" , category , attribute = None ) exDL = self . __getListAll ( \"CATEGORY_EXAMPLE_DETAIL\" , category , attribute = None ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL","title":"getCategoryExampleList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryExampleListAlt","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryExampleListAlt ( self , category , fallBack = True ): vL = self . getCategoryExampleListPdbx ( category ) if not vL : vL = self . getCategoryExampleListNdb ( category ) if fallBack and not vL : vL = self . getCategoryExampleList ( category ) return vL","title":"getCategoryExampleListAlt()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryExampleListNdb","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryExampleListNdb ( self , category ): exCL = self . __getListAll ( \"CATEGORY_EXAMPLE_CASE_NDB\" , category , attribute = None ) exDL = self . __getListAll ( \"CATEGORY_EXAMPLE_DETAIL_NDB\" , category , attribute = None ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL","title":"getCategoryExampleListNdb()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryExampleListPdbx","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryExampleListPdbx ( self , category ): exCL = self . __getListAll ( \"CATEGORY_EXAMPLE_CASE_PDBX\" , category , attribute = None ) exDL = self . __getListAll ( \"CATEGORY_EXAMPLE_DETAIL_PDBX\" , category , attribute = None ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL","title":"getCategoryExampleListPdbx()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryGroupCategories","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryGroupCategories ( self , groupName , followChildren = False ): try : if not self . __groupIndex : self . __makeCategoryGroupIndex () # if followChildren : cL = [] grpL = [ groupName ] grpL . extend ( self . getCategoryGroupChildGroups ( groupName )) for grp in grpL : cL . extend ( self . __categoryGroupDict [ grp ][ \"categories\" ] if grp in self . __categoryGroupDict else []) return sorted ( set ( cL )) else : return self . __categoryGroupDict [ groupName ][ \"categories\" ] if groupName in self . __categoryGroupDict else [] # except Exception : logger . exception ( \"DictionaryApi.getCategoryGroupCategories failed for group %s \" , groupName ) return []","title":"getCategoryGroupCategories()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryGroupChildGroups","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryGroupChildGroups ( self , parentGroupName ): try : return self . __groupChildIndex [ parentGroupName ] except Exception : return []","title":"getCategoryGroupChildGroups()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryGroupDescription","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryGroupDescription ( self , groupName ): try : return self . __categoryGroupDict [ groupName ][ \"description\" ] except Exception : return None","title":"getCategoryGroupDescription()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryGroupList","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryGroupList ( self , category ): return self . __getList ( \"CATEGORY_GROUP\" , category , attribute = None )","title":"getCategoryGroupList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryGroupParent","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryGroupParent ( self , groupName ): try : return self . __categoryGroupDict [ groupName ][ \"parent_id\" ] except Exception : return None","title":"getCategoryGroupParent()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryGroups","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryGroups ( self ): try : kL = self . __categoryGroupDict . keys () return kL except Exception : return []","title":"getCategoryGroups()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryIndex","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryIndex ( self ): return self . __catNameIndex","title":"getCategoryIndex()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryKeyList","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryKeyList ( self , category ): return self . __getList ( \"CATEGORY_KEY_ITEMS\" , category , attribute = None )","title":"getCategoryKeyList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryList","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryList ( self ): return list ( self . __catNameIndex . keys ())","title":"getCategoryList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryMandatoryCode","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryMandatoryCode ( self , category ): return self . __get ( \"CATEGORY_MANDATORY_CODE\" , category , attribute = None )","title":"getCategoryMandatoryCode()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getCategoryNxMappingDetails","text":"Source code in mmcif/api/DictionaryApi.py def getCategoryNxMappingDetails ( self , category ): return self . __get ( \"CATEGORY_NX_MAPPING_DETAILS\" , category , attribute = None )","title":"getCategoryNxMappingDetails()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getChildCategories","text":"Source code in mmcif/api/DictionaryApi.py def getChildCategories ( self , categoryName ): itemNameList = self . getItemNameList ( categoryName ) childCategories = set () for itemName in itemNameList : categoryName = CifName . categoryPart ( itemName ) attributeName = CifName . attributePart ( itemName ) childItemList = self . getFullChildList ( categoryName , attributeName ) for childItem in childItemList : childCategoryName = CifName . categoryPart ( childItem ) childCategories . add ( childCategoryName ) return list ( childCategories )","title":"getChildCategories()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getChildList","text":"Source code in mmcif/api/DictionaryApi.py def getChildList ( self , category , attribute ): return self . __getList ( \"ITEM_LINKED_CHILD\" , category , attribute )","title":"getChildList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getComparisonOperatorDict","text":"Source code in mmcif/api/DictionaryApi.py def getComparisonOperatorDict ( self ): try : return self . __compOpDict if self . __compOpDict else {} except Exception : return {}","title":"getComparisonOperatorDict()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getComparisonOperators","text":"Source code in mmcif/api/DictionaryApi.py def getComparisonOperators ( self ): try : return list ( self . __compOpDict . keys ()) if self . __compOpDict else [] except Exception : return []","title":"getComparisonOperators()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getContextList","text":"Source code in mmcif/api/DictionaryApi.py def getContextList ( self , category , attribute ): return self . __getList ( \"ITEM_CONTEXT\" , category , attribute )","title":"getContextList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDataTypeList","text":"Return list of tuples containing ('code','primitive_code','construct','detail' ) Source code in mmcif/api/DictionaryApi.py def getDataTypeList ( self ): \"\"\"Return list of tuples containing ('code','primitive_code','construct','detail' )\"\"\" rowList = [] for code in sorted ( self . __typesDict . keys ()): tup = self . __typesDict [ code ] rowList . append (( code , tup [ 0 ], tup [ 1 ], tup [ 2 ])) return rowList","title":"getDataTypeList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDefaultValue","text":"Source code in mmcif/api/DictionaryApi.py def getDefaultValue ( self , category , attribute ): return self . __get ( \"ITEM_DEFAULT_VALUE\" , category , attribute )","title":"getDefaultValue()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDefinitionIndex","text":"Source code in mmcif/api/DictionaryApi.py def getDefinitionIndex ( self ): return self . __definitionIndex","title":"getDefinitionIndex()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDescription","text":"Source code in mmcif/api/DictionaryApi.py def getDescription ( self , category , attribute ): return self . __get ( \"ITEM_DESCRIPTION\" , category , attribute )","title":"getDescription()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDescriptionAlt","text":"Source code in mmcif/api/DictionaryApi.py def getDescriptionAlt ( self , category , attribute , fallBack = True ): v = self . getDescriptionPdbx ( category , attribute ) if v is None : v = self . getDescriptionNdb ( category , attribute ) if fallBack and v is None : v = self . getDescription ( category , attribute ) return v","title":"getDescriptionAlt()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDescriptionNdb","text":"Source code in mmcif/api/DictionaryApi.py def getDescriptionNdb ( self , category , attribute ): return self . __get ( \"ITEM_DESCRIPTION_NDB\" , category , attribute )","title":"getDescriptionNdb()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDescriptionPdbx","text":"Source code in mmcif/api/DictionaryApi.py def getDescriptionPdbx ( self , category , attribute ): return self . __get ( \"ITEM_DESCRIPTION_PDBX\" , category , attribute )","title":"getDescriptionPdbx()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDictionaryComponentCount","text":"Get the count of dictionary components. Source code in mmcif/api/DictionaryApi.py def getDictionaryComponentCount ( self ): \"\"\"Get the count of dictionary components.\"\"\" try : return len ( self . __dictionaryComponentList ) except Exception : return 0","title":"getDictionaryComponentCount()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDictionaryComponentDetails","text":"Returns the component dictionary list as tuples [(version,title,dictionary_component_id),...] Source code in mmcif/api/DictionaryApi.py def getDictionaryComponentDetails ( self ): \"\"\"Returns the component dictionary list as tuples [(version,title,dictionary_component_id),...]\"\"\" oL = [] try : for tD in self . __dictionaryComponentList : oL . append (( tD [ \"version\" ], tD [ \"title\" ], tD [ \"dictionary_component_id\" ])) except Exception : pass return oL","title":"getDictionaryComponentDetails()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDictionaryComponentHistory","text":"Returns the revision history as a list of tuples [(version,update,revisionText,dictionary),...] Source code in mmcif/api/DictionaryApi.py def getDictionaryComponentHistory ( self , dictionaryComponentId , order = \"reverse\" ): \"\"\"Returns the revision history as a list of tuples [(version,update,revisionText,dictionary),...]\"\"\" oL = [] try : if order == \"reverse\" : for tD in reversed ( self . __dictionaryComponentHistoryDict [ dictionaryComponentId ]): oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary_component_id\" ])) else : for tD in self . __dictionaryComponentHistoryDict [ dictionaryComponentId ]: oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary_component_id\" ])) except Exception : pass return oL","title":"getDictionaryComponentHistory()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDictionaryComponents","text":"Get the list of dictionary components. Source code in mmcif/api/DictionaryApi.py def getDictionaryComponents ( self ): \"\"\"Get the list of dictionary components.\"\"\" try : return list ( self . __dictionaryComponentHistoryDict . keys ()) except Exception : return []","title":"getDictionaryComponents()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDictionaryHistory","text":"Returns the revision history as a list of tuples [(version,update,revisionText,dictionary),...] Source code in mmcif/api/DictionaryApi.py def getDictionaryHistory ( self , order = \"reverse\" ): \"\"\"Returns the revision history as a list of tuples [(version,update,revisionText,dictionary),...]\"\"\" oL = [] try : if order == \"reverse\" : for tD in reversed ( self . __dictionaryHistoryList ): oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary\" ])) else : for tD in self . __dictionaryHistoryList : oL . append (( tD [ \"version\" ], tD [ \"update\" ], tD [ \"revision\" ], tD [ \"dictionary\" ])) except Exception : pass return oL","title":"getDictionaryHistory()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDictionaryRevisionCount","text":"Get the count of revision history records. Source code in mmcif/api/DictionaryApi.py def getDictionaryRevisionCount ( self ): \"\"\"Get the count of revision history records.\"\"\" try : return len ( self . __dictionaryHistoryList ) except Exception : return 0","title":"getDictionaryRevisionCount()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDictionaryTitle","text":"Source code in mmcif/api/DictionaryApi.py def getDictionaryTitle ( self ): try : return \",\" . join ([ str ( tD [ \"title\" ]) for tD in self . __dictionaryDictList ]) except Exception : return None","title":"getDictionaryTitle()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDictionaryUpdate","text":"Get details from the first/last history element. Source code in mmcif/api/DictionaryApi.py def getDictionaryUpdate ( self , order = \"reverse\" ): \"\"\"Get details from the first/last history element.\"\"\" try : if order == \"reverse\" : tD = self . __dictionaryHistoryList [ - 1 ] else : tD = self . __dictionaryHistoryList [ 0 ] return tD [ \"update\" ] except Exception : return None","title":"getDictionaryUpdate()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getDictionaryVersion","text":"Source code in mmcif/api/DictionaryApi.py def getDictionaryVersion ( self ): try : return \",\" . join ([ str ( tD [ \"version\" ]) for tD in self . __dictionaryDictList ]) except Exception : return None","title":"getDictionaryVersion()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getEnumList","text":"Source code in mmcif/api/DictionaryApi.py def getEnumList ( self , category , attribute , sortFlag = True ): if sortFlag : return self . __getList ( \"ENUMERATION_VALUE\" , category , attribute ) else : return self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute )","title":"getEnumList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getEnumListAlt","text":"Source code in mmcif/api/DictionaryApi.py def getEnumListAlt ( self , category , attribute , fallBack = True , sortFlag = True ): vL = self . getEnumListPdbx ( category , attribute , sortFlag = sortFlag ) if not vL : vL = self . getEnumListNdb ( category , attribute , sortFlag = sortFlag ) if fallBack and not vL : vL = self . getEnumList ( category , attribute , sortFlag = sortFlag ) return vL","title":"getEnumListAlt()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getEnumListAltWithDetail","text":"Source code in mmcif/api/DictionaryApi.py def getEnumListAltWithDetail ( self , category , attribute ): eVL = self . __getListAll ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL_PDBX\" , category , attribute ) rL = [] dD = {} if len ( eVL ) == len ( eDL ): for eV , eD in zip ( eVL , eDL ): if not eD or eD in [ \".\" , \"?\" ]: dD [ eV ] = ( eV , None ) else : dD [ eV ] = ( eV , eD ) else : for eV in eVL : dD [ eV ] = ( eV , None ) # for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) # if not rL : return self . getEnumListWithDetail ( category , attribute ) else : return rL","title":"getEnumListAltWithDetail()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getEnumListAltWithFullDetails","text":"Source code in mmcif/api/DictionaryApi.py def getEnumListAltWithFullDetails ( self , category , attribute ): rL = [] dD = {} try : eVL = self . __getListAll ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL_PDBX\" , category , attribute ) eBL = self . __getListAll ( \"ENUMERATION_DETAIL_BRIEF_PDBX\" , category , attribute ) eUL = self . __getListAll ( \"ENUMERATION_TYPE_UNITS_PDBX\" , category , attribute ) rL = [] dD = {} for eV , eD , eB , eU in zip_longest ( eVL , eDL , eBL , eUL ): oL = [ v if v and v not in [ \".\" , \"?\" ] else None for v in [ eV , eD , eB , eU ]] dD [ eV ] = tuple ( oL ) for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) if rL : return rL # eVL = self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL\" , category , attribute ) eBL = self . __getListAll ( \"ENUMERATION_DETAIL_BRIEF\" , category , attribute ) eUL = self . __getListAll ( \"ENUMERATION_TYPE_UNITS\" , category , attribute ) rL = [] dD = {} for eV , eD , eB , eU in zip_longest ( eVL , eDL , eBL , eUL ): oL = [ v if v and v not in [ \".\" , \"?\" ] else None for v in [ eV , eD , eB , eU ]] dD [ eV ] = tuple ( oL ) for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) except Exception as e : logger . exception ( \"Failing dD %r rL %r with %s \" , dD , rL , str ( e )) return rL","title":"getEnumListAltWithFullDetails()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getEnumListNdb","text":"Source code in mmcif/api/DictionaryApi.py def getEnumListNdb ( self , category , attribute , sortFlag = True ): if sortFlag : return self . __getList ( \"ENUMERATION_VALUE_NDB\" , category , attribute ) else : return self . __getListAll ( \"ENUMERATION_VALUE_NDB\" , category , attribute )","title":"getEnumListNdb()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getEnumListPdbx","text":"Source code in mmcif/api/DictionaryApi.py def getEnumListPdbx ( self , category , attribute , sortFlag = True ): if sortFlag : return self . __getList ( \"ENUMERATION_VALUE_PDBX\" , category , attribute ) else : return self . __getListAll ( \"ENUMERATION_VALUE_PDBX\" , category , attribute )","title":"getEnumListPdbx()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getEnumListWithDetail","text":"Source code in mmcif/api/DictionaryApi.py def getEnumListWithDetail ( self , category , attribute ): eVL = self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL\" , category , attribute ) rL = [] dD = {} if len ( eVL ) == len ( eDL ): for eV , eD in zip ( eVL , eDL ): if not eD or eD in [ \".\" , \"?\" ]: dD [ eV ] = ( eV , None ) else : dD [ eV ] = ( eV , eD ) else : for eV in eVL : dD [ eV ] = ( eV , None ) # for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) return rL","title":"getEnumListWithDetail()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getEnumListWithFullDetails","text":"Source code in mmcif/api/DictionaryApi.py def getEnumListWithFullDetails ( self , category , attribute ): rL = [] dD = {} try : eVL = self . __getListAll ( \"ENUMERATION_VALUE\" , category , attribute ) eDL = self . __getListAll ( \"ENUMERATION_DETAIL\" , category , attribute ) eBL = self . __getListAll ( \"ENUMERATION_DETAIL_BRIEF\" , category , attribute ) eUL = self . __getListAll ( \"ENUMERATION_TYPE_UNITS\" , category , attribute ) # for eV , eD , eB , eU in zip_longest ( eVL , eDL , eBL , eUL ): oL = [ v if v and v not in [ \".\" , \"?\" ] else None for v in [ eV , eD , eB , eU ]] dD [ eV ] = tuple ( oL ) for ky in sorted ( dD . keys ()): rL . append ( dD [ ky ]) except Exception as e : logger . info ( \"eVL %r \" , eVL ) logger . info ( \"eDL %r \" , eDL ) logger . info ( \"eBL %r \" , eBL ) logger . info ( \"eUL %r \" , eUL ) logger . exception ( \"Failing category %s attribute %s dD %r rL %r with %s \" , category , attribute , dD , rL , str ( e )) return rL","title":"getEnumListWithFullDetails()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getEnumerationClosedFlag","text":"Source code in mmcif/api/DictionaryApi.py def getEnumerationClosedFlag ( self , category , attribute ): return self . __get ( \"ENUMERATION_CLOSED_FLAG\" , category , attribute )","title":"getEnumerationClosedFlag()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getExampleList","text":"Source code in mmcif/api/DictionaryApi.py def getExampleList ( self , category , attribute ): exCL = self . __getListAll ( \"ITEM_EXAMPLE_CASE\" , category , attribute ) exDL = self . __getListAll ( \"ITEM_EXAMPLE_DETAIL\" , category , attribute ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL","title":"getExampleList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getExampleListAlt","text":"Source code in mmcif/api/DictionaryApi.py def getExampleListAlt ( self , category , attribute , fallBack = True ): vL = self . getExampleListPdbx ( category , attribute ) if not vL : vL = self . getExampleListNdb ( category , attribute ) if fallBack and not vL : vL = self . getExampleList ( category , attribute ) return vL","title":"getExampleListAlt()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getExampleListNdb","text":"Source code in mmcif/api/DictionaryApi.py def getExampleListNdb ( self , category , attribute ): exCL = self . __getListAll ( \"ITEM_EXAMPLE_CASE_NDB\" , category , attribute ) exDL = self . __getListAll ( \"ITEM_EXAMPLE_DETAIL_NDB\" , category , attribute ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL","title":"getExampleListNdb()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getExampleListPdbx","text":"Source code in mmcif/api/DictionaryApi.py def getExampleListPdbx ( self , category , attribute ): exCL = self . __getListAll ( \"ITEM_EXAMPLE_CASE_PDBX\" , category , attribute ) exDL = self . __getListAll ( \"ITEM_EXAMPLE_DETAIL_PDBX\" , category , attribute ) exL = [] if len ( exCL ) == len ( exDL ): for exC , exD in zip ( exCL , exDL ): exL . append (( exC , exD )) else : for exC in exCL : exL . append (( exC , None )) return exL","title":"getExampleListPdbx()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getFullChildList","text":"Source code in mmcif/api/DictionaryApi.py def getFullChildList ( self , category , attribute ): try : itemName = CifName . itemName ( category , attribute ) return self . __fullChildD [ itemName ] except Exception : return []","title":"getFullChildList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getFullDescendentList","text":"Source code in mmcif/api/DictionaryApi.py def getFullDescendentList ( self , category , attribute ): itemNameL = [] try : itemName = CifName . itemName ( category , attribute ) itemNameL = self . __fullChildD [ itemName ] if itemName in self . __fullChildD else [] itemNameL = list ( set ( itemNameL )) if itemNameL : begLen = 0 endLen = 1 # while endLen > begLen : begLen = len ( itemNameL ) for itemName in itemNameL : if itemName in self . __fullChildD : itemNameL . extend ( self . __fullChildD [ itemName ]) itemNameL = list ( set ( itemNameL )) endLen = len ( itemNameL ) except Exception as e : logger . exception ( \"Failing for %s %s with %s \" , category , attribute , str ( e )) return itemNameL","title":"getFullDescendentList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getFullIndex","text":"Source code in mmcif/api/DictionaryApi.py def getFullIndex ( self ): return self . __fullIndex","title":"getFullIndex()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getFullParentList","text":"Source code in mmcif/api/DictionaryApi.py def getFullParentList ( self , category , attribute , stripSelfParent = False ): try : itemName = CifName . itemName ( category , attribute ) pL = self . __fullParentD [ itemName ] if stripSelfParent : if pL : try : pL . remove ( itemName ) except Exception : pass return pL else : return pL except Exception : return []","title":"getFullParentList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getImplicitList","text":"Source code in mmcif/api/DictionaryApi.py def getImplicitList ( self ): iL = [] for name , dL in self . __definitionIndex . items (): for dD in dL : dType = dD . getType () if dType == \"definition\" and dD . isAttribute (): catN = CifName . categoryPart ( name ) attN = CifName . attributePart ( name ) if self . __get ( \"ITEM_MANDATORY_CODE\" , catN , attN ) == \"implicit\" : if name not in iL : iL . append ( name ) return iL","title":"getImplicitList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getItemAliasList","text":"Source code in mmcif/api/DictionaryApi.py def getItemAliasList ( self , category , attribute ): aNL = self . __getListAll ( \"ITEM_ALIAS_ALIAS_NAME\" , category , attribute ) aDL = self . __getListAll ( \"ITEM_ALIAS_DICTIONARY\" , category , attribute ) aVL = self . __getListAll ( \"ITEM_ALIAS_VERSION\" , category , attribute ) aL = [] for aN , aD , aV in zip ( aNL , aDL , aVL ): aL . append (( aN , aD , aV )) return aL","title":"getItemAliasList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getItemDependentNameList","text":"Source code in mmcif/api/DictionaryApi.py def getItemDependentNameList ( self , category , attribute ): return self . __getList ( \"ITEM_DEPENDENT_DEPENDENT_NAME\" , category , attribute )","title":"getItemDependentNameList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getItemLinkedConditions","text":"Create a dictionary of conditional item link relationships. Returns: Type Description (dict) {{parent_name, child_name}: [{\"id\": , \"condition_id\": , \"condition_child_name\": , \"condition_child_value\": , \"condition_child_cmp_op\": , \"condition_log_op\": ,}, {},...]} Examples: loop_ _pdbx_item_linked.id _pdbx_item_linked.condition_id _pdbx_item_linked.parent_name _pdbx_item_linked.child_name # _pdbx_item_linked.condition_child_name _pdbx_item_linked.condition_child_value _pdbx_item_linked.condition_child_cmp_op _pdbx_item_linked.condition_child_target_name _pdbx_item_linked.condition_child_log_op 1 1 '_entity_poly_seq.num' '_atom_site.label_seq_id' '_atom_site.label_entity_id' . 'eq' '_entity.id' . 2 1 '_entity_poly_seq.num' '_atom_site.label_seq_id' '_entity.type' 'polymer' 'eq' . 'and' Source code in mmcif/api/DictionaryApi.py def getItemLinkedConditions ( self ): \"\"\"Create a dictionary of conditional item link relationships. Returns: (dict): {{parent_name, child_name}: [{\"id\": , \"condition_id\": , \"condition_child_name\": , \"condition_child_value\": , \"condition_child_cmp_op\": , \"condition_log_op\": ,}, {},...]} Example: ```text loop_ _pdbx_item_linked.id _pdbx_item_linked.condition_id _pdbx_item_linked.parent_name _pdbx_item_linked.child_name # _pdbx_item_linked.condition_child_name _pdbx_item_linked.condition_child_value _pdbx_item_linked.condition_child_cmp_op _pdbx_item_linked.condition_child_target_name _pdbx_item_linked.condition_child_log_op 1 1 '_entity_poly_seq.num' '_atom_site.label_seq_id' '_atom_site.label_entity_id' . 'eq' '_entity.id' . 2 1 '_entity_poly_seq.num' '_atom_site.label_seq_id' '_entity.type' 'polymer' 'eq' . 'and' ``` \"\"\" rD = OrderedDict () try : for ob in self . __containerList : if ob . getType () == \"data\" : continue tl = ob . getObj ( self . __enumD [ \"ITEM_LINKED_PDBX_ID\" ][ 0 ]) if tl is not None : for row in tl . getRowList (): if ( tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_ID\" ][ 1 ]) and tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_ID\" ][ 1 ]) and tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CHILD_NAME\" ][ 1 ]) and tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_PARENT_NAME\" ][ 1 ]) ): tD = OrderedDict () tD [ \"id\" ] = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_ID\" ][ 1 ])] tD [ \"condition_id\" ] = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_ID\" ][ 1 ])] parentName = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_PARENT_NAME\" ][ 1 ])] childName = row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CHILD_NAME\" ][ 1 ])] # tD [ \"condition_child_name\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_NAME\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_NAME\" ][ 1 ]) else None ) tD [ \"condition_child_value\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_VALUE\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_VALUE\" ][ 1 ]) else None ) tD [ \"condition_child_cmp_op\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_CMP_OP\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_CMP_OP\" ][ 1 ]) else None ) tD [ \"condition_child_target_name\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_TARGET_NAME\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_CHILD_TARGET_NAME\" ][ 1 ]) else None ) tD [ \"condition_log_op\" ] = ( row [ tl . getIndex ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_LOG_OP\" ][ 1 ])] if tl . hasAttribute ( self . __enumD [ \"ITEM_LINKED_PDBX_CONDITION_LOG_OP\" ][ 1 ]) else None ) # rD . setdefault (( parentName , childName ), []) . append ( tD ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return rD","title":"getItemLinkedConditions()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getItemNameList","text":"Source code in mmcif/api/DictionaryApi.py def getItemNameList ( self , category ): try : return self . __catNameItemIndex [ category ] except Exception : pass return []","title":"getItemNameList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getItemRelatedList","text":"Source code in mmcif/api/DictionaryApi.py def getItemRelatedList ( self , category , attribute ): rNL = self . __getListAll ( \"ITEM_RELATED_RELATED_NAME\" , category , attribute ) rFL = self . __getListAll ( \"ITEM_RELATED_FUNCTION_CODE\" , category , attribute ) rL = [] for rN , rF in zip ( rNL , rFL ): rL . append (( rN , rF )) return rL","title":"getItemRelatedList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getItemSubCategoryIdList","text":"Source code in mmcif/api/DictionaryApi.py def getItemSubCategoryIdList ( self , category , attribute ): return self . __getList ( \"ITEM_SUB_CATEGORY_ID\" , category , attribute )","title":"getItemSubCategoryIdList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getItemSubCategoryLabelList","text":"Source code in mmcif/api/DictionaryApi.py def getItemSubCategoryLabelList ( self , category , attribute ): return self . __getList ( \"ITEM_SUB_CATEGORY_LABEL\" , category , attribute )","title":"getItemSubCategoryLabelList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getItemSubCategoryList","text":"Source code in mmcif/api/DictionaryApi.py def getItemSubCategoryList ( self , category , attribute ): aL = [] itemName = CifName . itemName ( category , attribute ) obL = self . __definitionIndex [ itemName ] if itemName in self . __definitionIndex else None for ob in obL : tObj = ob . getObj ( self . __enumD [ \"ITEM_SUB_CATEGORY_ID\" ][ 0 ]) if tObj is not None : atId = self . __enumD [ \"ITEM_SUB_CATEGORY_ID\" ][ 1 ] atLabel = self . __enumD [ \"ITEM_SUB_CATEGORY_LABEL\" ][ 1 ] for row in tObj . getRowList (): # logger.info(\"subcategories for %s row is %r\" % (itemName, row)) idVal = row [ tObj . getIndex ( atId )] if tObj . hasAttribute ( atId ) else None labVal = row [ tObj . getIndex ( atLabel )] if tObj . hasAttribute ( atLabel ) else None aL . append (( idVal , labVal )) return aL","title":"getItemSubCategoryList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getItemValueConditionDependentList","text":"Source code in mmcif/api/DictionaryApi.py def getItemValueConditionDependentList ( self , category , attribute ): return self . __getList ( \"ITEM_VALUE_CONDITION_DEPENDENT_NAME\" , category , attribute )","title":"getItemValueConditionDependentList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getItemValueConditionDict","text":"Source code in mmcif/api/DictionaryApi.py def getItemValueConditionDict ( self ): try : return self . __itemValueConditionDict if self . __itemValueConditionDict else {} except Exception : return {}","title":"getItemValueConditionDict()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getMandatoryCode","text":"Source code in mmcif/api/DictionaryApi.py def getMandatoryCode ( self , category , attribute ): return self . __get ( \"ITEM_MANDATORY_CODE\" , category , attribute )","title":"getMandatoryCode()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getMandatoryCodeAlt","text":"Source code in mmcif/api/DictionaryApi.py def getMandatoryCodeAlt ( self , category , attribute , fallBack = True ): v = self . getMandatoryCodePdbx ( category , attribute ) if v is None : v = self . getMandatoryCodeNdb ( category , attribute ) if fallBack and v is None : v = self . getMandatoryCode ( category , attribute ) return v","title":"getMandatoryCodeAlt()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getMandatoryCodeNdb","text":"Source code in mmcif/api/DictionaryApi.py def getMandatoryCodeNdb ( self , category , attribute ): return self . __get ( \"ITEM_MANDATORY_CODE_NDB\" , category , attribute )","title":"getMandatoryCodeNdb()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getMandatoryCodePdbx","text":"Source code in mmcif/api/DictionaryApi.py def getMandatoryCodePdbx ( self , category , attribute ): return self . __get ( \"ITEM_MANDATORY_CODE_PDBX\" , category , attribute )","title":"getMandatoryCodePdbx()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getMethod","text":"Source code in mmcif/api/DictionaryApi.py def getMethod ( self , mId ): if mId in self . __methodDict : return self . __methodDict [ mId ] else : return None","title":"getMethod()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getMethodIndex","text":"Source code in mmcif/api/DictionaryApi.py def getMethodIndex ( self ): return self . __methodIndex","title":"getMethodIndex()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getParentCategories","text":"Source code in mmcif/api/DictionaryApi.py def getParentCategories ( self , categoryName ): itemNameList = self . getItemNameList ( categoryName ) parentCategories = set () for itemName in itemNameList : categoryName = CifName . categoryPart ( itemName ) attributeName = CifName . attributePart ( itemName ) parentItemList = self . getFullParentList ( categoryName , attributeName ) for parentItem in parentItemList : parentCategoryName = CifName . categoryPart ( parentItem ) parentCategories . add ( parentCategoryName ) return list ( parentCategories )","title":"getParentCategories()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getParentDictionary","text":"Create a dictionary of parents relations accross all definnitions as {child : [parent, parent,...] Exclude self parents. Source code in mmcif/api/DictionaryApi.py def getParentDictionary ( self ): \"\"\"Create a dictionary of parents relations accross all definnitions as {child : [parent, parent,...] Exclude self parents. \"\"\" parentD = {} pAtN = self . __enumD [ \"ITEM_LINKED_PARENT\" ][ 1 ] cAtN = self . __enumD [ \"ITEM_LINKED_CHILD\" ][ 1 ] for dObj in self . __containerList : dc = dObj . getObj ( self . __enumD [ \"ITEM_LINKED_PARENT\" ][ 0 ]) if dc is not None : idxP = dc . getIndex ( pAtN ) idxC = dc . getIndex ( cAtN ) for row in dc . getRowList (): pVal = row [ idxP ] cVal = row [ idxC ] if pVal == cVal : continue if cVal not in parentD : parentD [ cVal ] = [] parentD [ cVal ] . append ( pVal ) # return parentD","title":"getParentDictionary()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getParentList","text":"Source code in mmcif/api/DictionaryApi.py def getParentList ( self , category , attribute , stripSelfParent = False ): if stripSelfParent : itemName = CifName . itemName ( category , attribute ) pL = self . __getList ( \"ITEM_LINKED_PARENT\" , category , attribute ) if pL : try : pL . remove ( itemName ) except Exception : pass return pL else : return self . __getList ( \"ITEM_LINKED_PARENT\" , category , attribute )","title":"getParentList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getSubCategoryDescription","text":"Source code in mmcif/api/DictionaryApi.py def getSubCategoryDescription ( self , subCategoryName ): if subCategoryName in self . __subCategoryDict : return self . __subCategoryDict [ subCategoryName ] else : return \"\"","title":"getSubCategoryDescription()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getSubCategoryList","text":"Return list of tuples containing ('id', 'description') Source code in mmcif/api/DictionaryApi.py def getSubCategoryList ( self ): \"\"\"Return list of tuples containing ('id', 'description')\"\"\" rowList = [] for tId in sorted ( self . __subCategoryDict . keys ()): description = self . __subCategoryDict [ tId ] rowList . append (( tId , description )) return rowList","title":"getSubCategoryList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getTypeCode","text":"Source code in mmcif/api/DictionaryApi.py def getTypeCode ( self , category , attribute ): return self . __get ( \"DATA_TYPE_CODE\" , category , attribute , followAncestors = True )","title":"getTypeCode()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getTypeCodeAlt","text":"Source code in mmcif/api/DictionaryApi.py def getTypeCodeAlt ( self , category , attribute , fallBack = True ): v = self . getTypeCodePdbx ( category , attribute ) if v is None : v = self . getTypeCodeNdb ( category , attribute ) if fallBack and v is None : v = self . getTypeCode ( category , attribute ) return v","title":"getTypeCodeAlt()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getTypeCodeNdb","text":"Source code in mmcif/api/DictionaryApi.py def getTypeCodeNdb ( self , category , attribute ): return self . __get ( \"DATA_TYPE_CODE_NDB\" , category , attribute , followAncestors = False )","title":"getTypeCodeNdb()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getTypeCodePdbx","text":"Source code in mmcif/api/DictionaryApi.py def getTypeCodePdbx ( self , category , attribute ): return self . __get ( \"DATA_TYPE_CODE_PDBX\" , category , attribute , followAncestors = False )","title":"getTypeCodePdbx()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getTypeConditionsCode","text":"Source code in mmcif/api/DictionaryApi.py def getTypeConditionsCode ( self , category , attribute ): return self . __get ( \"ITEM_TYPE_CONDITIONS_CODE\" , category , attribute )","title":"getTypeConditionsCode()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getTypeDetail","text":"Source code in mmcif/api/DictionaryApi.py def getTypeDetail ( self , category , attribute ): code = self . getTypeCode ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 2 ] return None","title":"getTypeDetail()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getTypePrimitive","text":"Source code in mmcif/api/DictionaryApi.py def getTypePrimitive ( self , category , attribute ): code = self . getTypeCode ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 0 ] return None","title":"getTypePrimitive()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getTypeRegex","text":"Source code in mmcif/api/DictionaryApi.py def getTypeRegex ( self , category , attribute ): code = self . getTypeCode ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 1 ] return None","title":"getTypeRegex()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getTypeRegexAlt","text":"Source code in mmcif/api/DictionaryApi.py def getTypeRegexAlt ( self , category , attribute , fallBack = True ): v = self . getTypeRegexPdbx ( category , attribute ) if v is None : v = self . getTypeRegexNdb ( category , attribute ) if fallBack and v is None : v = self . getTypeRegex ( category , attribute ) return v","title":"getTypeRegexAlt()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getTypeRegexNdb","text":"Source code in mmcif/api/DictionaryApi.py def getTypeRegexNdb ( self , category , attribute ): code = self . getTypeCodeNdb ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 1 ] return None","title":"getTypeRegexNdb()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getTypeRegexPdbx","text":"Source code in mmcif/api/DictionaryApi.py def getTypeRegexPdbx ( self , category , attribute ): code = self . getTypeCodePdbx ( category , attribute ) if code in self . __typesDict : return self . __typesDict [ code ][ 1 ] return None","title":"getTypeRegexPdbx()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getUltimateParent","text":"Return the first ultimate parent item for the input item. Source code in mmcif/api/DictionaryApi.py def getUltimateParent ( self , category , attribute ): \"\"\"Return the first ultimate parent item for the input item.\"\"\" # pL=self.__getList('ITEM_LINKED_PARENT',category,attribute) pL = self . getFullParentList ( category , attribute ) itemName = CifName . itemName ( category , attribute ) while pL and ( pL [ 0 ] != itemName ): attN = CifName . attributePart ( pL [ 0 ]) catN = CifName . categoryPart ( pL [ 0 ]) itemName = pL [ 0 ] pL = self . getFullParentList ( catN , attN ) # pL=self.__getList('ITEM_LINKED_PARENT',catN,attN) return itemName","title":"getUltimateParent()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getUnits","text":"Source code in mmcif/api/DictionaryApi.py def getUnits ( self , category , attribute ): return self . __get ( \"ITEM_UNITS\" , category , attribute )","title":"getUnits()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getUnitsConversionList","text":"Return list of tuples containing ('from_code','to_code','operator','factor') Source code in mmcif/api/DictionaryApi.py def getUnitsConversionList ( self ): \"\"\"Return list of tuples containing ('from_code','to_code','operator','factor')\"\"\" return self . __itemUnitsConversionList","title":"getUnitsConversionList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.getUnitsList","text":"Return list of tuples containing ('id', 'description') Source code in mmcif/api/DictionaryApi.py def getUnitsList ( self ): \"\"\"Return list of tuples containing ('id', 'description')\"\"\" rowList = [] for tId in sorted ( self . __itemUnitsDict . keys ()): description = self . __itemUnitsDict [ tId ] rowList . append (( tId , description )) return rowList","title":"getUnitsList()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.isEnumerated","text":"Source code in mmcif/api/DictionaryApi.py def isEnumerated ( self , category , attribute ): return len ( self . __getList ( \"ENUMERATION_VALUE\" , category , attribute )) > 0","title":"isEnumerated()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.isEnumeratedAlt","text":"Source code in mmcif/api/DictionaryApi.py def isEnumeratedAlt ( self , category , attribute , fallBack = True ): eC = len ( self . __getList ( \"ENUMERATION_VALUE_PDBX\" , category , attribute )) if eC == 0 : eC = len ( self . __getList ( \"ENUMERATION_VALUE_NDB\" , category , attribute )) if fallBack and ( eC == 0 ): eC = len ( self . __getList ( \"ENUMERATION_VALUE\" , category , attribute )) return eC > 0","title":"isEnumeratedAlt()"},{"location":"api_reference/DictionaryApi/#mmcif.api.DictionaryApi.DictionaryApi.testCache","text":"Source code in mmcif/api/DictionaryApi.py def testCache ( self ): return len ( self . __containerList ) > 0","title":"testCache()"},{"location":"api_reference/DictionaryInclude/","text":"mmcif.api.DictionaryInclude.DictionaryInclude Source code in mmcif/api/DictionaryInclude.py class DictionaryInclude ( object ): def __init__ ( self , ** kwargs ): # self . __itemNameRelatives = [ \"_item.name\" , \"_item_examples.name\" , \"_ndb_item_description.name\" , \"_item_related.name\" , \"_category_key.name\" , \"_item_structure.name\" , \"_item_methods.name\" , \"_item_aliases.name\" , \"_item_dependent.dependent_name\" , \"_item_default.name\" , \"_pdbx_item_examples.name\" , \"_item_units.name\" , \"_item_related.related_name\" , \"_item_description.name\" , \"_item_dependent.name\" , \"_item_range.name\" , \"_item_sub_category.name\" , \"_pdbx_item_range.name\" , \"_pdbx_item_linked.condition_child_name\" , \"_ndb_item_examples.name\" , \"_pdbx_item_value_condition.item_name\" , \"_ndb_item_range.name\" , \"_item_linked.child_name\" , \"_pdbx_item_description.name\" , \"_pdbx_item_context.item_name\" , \"_pdbx_item_enumeration_details.name\" , \"_pdbx_item_linked_group_list.child_name\" , \"_pdbx_item_linked_group_list.parent_name\" , \"_pdbx_item_value_condition_list.target_item_name\" , \"_ndb_item_enumeration.name\" , \"_pdbx_item_linked.child_name\" , \"_pdbx_item_value_condition.dependent_item_name\" , \"_pdbx_item_enumeration.name\" , \"_item_linked.parent_name\" , \"_pdbx_item_value_condition_list.dependent_item_name\" , \"_item_type.name\" , \"_item_type_conditions.name\" , \"_pdbx_item_linked.parent_name\" , \"_item_enumeration.name\" , ] self . __categoryIdRelatives = [ \"_category.id\" , \"_category_key.id\" , \"_pdbx_item_linked_group.category_id\" , \"_pdbx_category_examples.id\" , \"_item.category_id\" , \"_pdbx_category_context.category_id\" , \"_pdbx_item_linked_group_list.parent_category_id\" , \"_category_group.category_id\" , \"_pdbx_category_description.id\" , \"_ndb_category_examples.id\" , \"_category_examples.id\" , \"_category_methods.category_id\" , \"_ndb_category_description.id\" , \"_pdbx_item_linked_group_list.child_category_id\" , ] # self . __cwd = os . getcwd () self . __dirPath = kwargs . get ( \"dirPath\" , os . getcwd ()) logger . info ( \"Local dictionary include path relative to %s \" , self . __dirPath ) self . __dirStack = [] self . __locatorIndexD = {} def processIncludedContent ( self , containerList , cleanup = False ): \"\"\"Process any dictionary, category or item include instructions in any data containers in the input list of dictionary data and definition containers. Args: containerList (list): list of input PdbxContainer data or definition container objects cleanup (bool, optional): flag to remove generator category objects after parsing (default: False) Returns: (list): list of data and definition containers incorporating included content Examples: ```python pathDdlIncludeDictionary = \"mmcif_ddl-generator.dic\" myIo = IoAdapter(raiseExceptions=True) containerList = myIo.readFile(inputFilePath=pathDdlIncludeDictionary) logger.info(\"Starting container list length (%d)\", len(containerList)) dIncl = DictionaryInclude() inclL = dIncl.processIncludedContent(containerList) logger.info(\"Processed included container length (%d)\", len(inclL)) ``` \"\"\" includeD = self . __getIncludeInstructions ( containerList , cleanup = cleanup ) includeContentD = self . __fetchIncludedContent ( includeD , cleanup = cleanup ) return self . __addIncludedContent ( containerList , includeContentD ) def __addIncludedContent ( self , containerList , includeContentD ): \"\"\"Incorporate included content described in the input dictionary of include instructions produced by internal method __getIncludeInstructions(). Args: containerList (list): list of input PdbxContainer data or definition container objects includeContentD (dict): {\"dictionaryIncludeDict\": {dictionary_id: {...include details...}}, \"categoryIncludeDict\": {dictionary_id: {category_id: {...include details... }}}, \"itemIncludeDict\": {dictionary_id: {category_id: {itemName: {...include details...}}}} } Returns: (list): list of data and definition containers incorporating included content \"\"\" # Index the current container list... cD = OrderedDict () datablockName = \"unnamed_1\" for container in containerList : if container . getType () == \"data\" : datablockName = container . getName () # Handle potentially unconsolidated definitions -- cD . setdefault ( datablockName , OrderedDict ()) . setdefault ( container . getName (), []) . append ( container ) # # for datablockName in cD : if datablockName in includeContentD : if \"replace\" in includeContentD [ datablockName ]: # Organize the replacements by name replaceDefinitionD = OrderedDict () replaceDataD = OrderedDict () for container in includeContentD [ datablockName ][ \"replace\" ]: if container . getType () == \"definition\" : replaceDefinitionD . setdefault ( container . getName (), []) . append ( container ) else : replaceDataD . setdefault ( datablockName , []) . append ( container ) # for rN , rL in replaceDefinitionD . items (): if rN in cD [ datablockName ]: cD [ datablockName ][ rN ] = rL # replace data sections in the base container baseContainer = cD [ datablockName ][ datablockName ][ 0 ] for rN , containerL in replaceDataD . items (): for container in containerL : for nm in container . getObjNameList (): obj = container . getObj ( nm ) baseContainer . replace ( obj ) # if \"extend\" in includeContentD [ datablockName ]: extendDataD = OrderedDict () for container in includeContentD [ datablockName ][ \"extend\" ]: if container . getType () == \"definition\" : cD . setdefault ( datablockName , OrderedDict ()) . setdefault ( container . getName (), []) . append ( container ) else : extendDataD . setdefault ( datablockName , []) . append ( container ) # extend data sections in the base container baseContainer = cD [ datablockName ][ datablockName ][ 0 ] for rN , containerL in extendDataD . items (): for container in containerL : for nm in container . getObjNameList (): obj = container . getObj ( nm ) if baseContainer . exists ( nm ): baseObj = baseContainer . getObj ( nm ) for ii in range ( obj . getRowCount ()): rowD = obj . getRowAttributeDict ( ii ) baseObj . append ( rowD ) else : baseContainer . append ( obj ) # # Unwind the container index # fullL = [] for datablockName in cD : for cL in cD [ datablockName ] . values (): fullL . extend ( cL ) # return fullL def __getIncludeInstructions ( self , containerList , cleanup = False ): \"\"\"Extract include instructions from categories pdbx_include_dictionary, pdbx_include_category, and pdbx_include_item. Args: containerList (list): list of input PdbxContainer data or definition container objects cleanup (optional, bool): flag to remove generator category objects after parsing (default: False) Returns: A dictionary containing the dictionary, category and and item level include details. For example, ```python { \"dictionaryIncludeDict\": {dictionary_id: {...include details...}}, \"categoryIncludeDict\": {dictionary_id: {category_id: {...include details... }}}, \"itemIncludeDict\": {dictionary_id: {category_id: {itemName: {...include details...}}}}, } ``` \"\"\" includeD = OrderedDict () try : unNamed = 1 for container in containerList : if container . getType () == \"data\" : dictionaryIncludeDict = OrderedDict () categoryIncludeDict = OrderedDict () itemIncludeDict = OrderedDict () if container . getName (): datablockName = container . getName () else : datablockName = str ( unNamed ) unNamed += 1 logger . debug ( \"Adding data sections from container name %s type %s \" , datablockName , container . getType ()) tl = container . getObj ( \"pdbx_include_dictionary\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () for atName in [ \"dictionary_id\" , \"dictionary_locator\" , \"include_mode\" , \"dictionary_namespace_prefix\" , \"dictionary_namespace_prefix_replace\" ]: tD [ atName ] = row [ tl . getIndex ( atName )] if tl . hasAttribute ( atName ) else None dictionaryIncludeDict [ tD [ \"dictionary_id\" ]] = tD # tl = container . getObj ( \"pdbx_include_category\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () for atName in [ \"dictionary_id\" , \"category_id\" , \"include_as_category_id\" , \"include_mode\" ]: tD [ atName ] = row [ tl . getIndex ( atName )] if tl . hasAttribute ( atName ) else None categoryIncludeDict . setdefault ( tD [ \"dictionary_id\" ], {}) . setdefault ( tD [ \"category_id\" ], tD ) # tl = container . getObj ( \"pdbx_include_item\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () for atName in [ \"dictionary_id\" , \"item_name\" , \"include_as_item_name\" , \"include_mode\" ]: tD [ atName ] = row [ tl . getIndex ( atName )] if tl . hasAttribute ( atName ) else None categoryId = CifName . categoryPart ( tD [ \"item_name\" ]) itemIncludeDict . setdefault ( tD [ \"dictionary_id\" ], {}) . setdefault ( categoryId , {}) . setdefault ( tD [ \"item_name\" ], tD ) if cleanup : for catName in [ \"pdbx_include_dictionary\" , \"pdbx_include_category\" , \"pdbx_include_item\" ]: if container . exists ( catName ): container . remove ( catName ) # includeD [ datablockName ] = { \"dictionaryIncludeDict\" : dictionaryIncludeDict , \"categoryIncludeDict\" : categoryIncludeDict , \"itemIncludeDict\" : itemIncludeDict , } except Exception as e : logger . exception ( \"Include processing failing with %s \" , str ( e )) return includeD def __fetchIncludedContent ( self , includeD , cleanup = False ): \"\"\"Fetch included content following the instructions encoded in the input data structure. Args: includeD (dict): {\"dictionaryIncludeDict\": {dictionary_id: {...include details...}}, \"categoryIncludeDict\": {dictionary_id: {category_id: {...include details... }}}, \"itemIncludeDict\": {dictionary_id: {category_id: {itemName: {...include details...}}}}, } cleanup (optional, bool): flag to remove generator category objects after parsing (default: false) Returns: (dict): {datablockName: {\"extend\": [container,...], \"replace\": [container, ...]}, ... } \"\"\" includeDataD = {} try : for datablockName , inclD in includeD . items (): cL = [] for dictName , iD in inclD [ \"dictionaryIncludeDict\" ] . items (): locator = iD [ \"dictionary_locator\" ] if locator in self . __locatorIndexD : logger . info ( \"Skipping redundant include for %r at %r \" , dictName , locator ) continue self . __locatorIndexD [ locator ] = dictName # # --- Fetch the dictionary component - # updateStack = self . __isLocal ( locator ) if updateStack : if not self . __dirStack : # top-level include case self . __dirStack . append ( os . path . abspath ( self . __dirPath )) # embedded include case (push directory containing the locator) if not os . path . isabs ( locator ): # handle the relative path case - locator = os . path . abspath ( os . path . join ( self . __dirStack [ - 1 ], locator )) logger . debug ( \"modified local relative locator is %r \" , locator ) self . __dirStack . append ( os . path . dirname ( locator )) logger . debug ( \"dirStack ( %d ) top %r \" , len ( self . __dirStack ), self . __dirStack [ - 1 ]) containerList = self . processIncludedContent ( self . __fetchLocator ( locator ), cleanup = cleanup ) if updateStack : # restore stack context self . __dirStack . pop () # nsPrefix = iD [ \"dictionary_namespace_prefix\" ] nsPrefixReplace = iD [ \"dictionary_namespace_prefix_replace\" ] dictInclMode = iD [ \"include_mode\" ] dataIncludeMode = iD [ \"data_include_mode\" ] if \"data_include_mode\" in iD else \"extend\" catInclD = inclD [ \"categoryIncludeDict\" ][ dictName ] if dictName in inclD [ \"categoryIncludeDict\" ] else None itemInclD = inclD [ \"itemIncludeDict\" ][ dictName ] if dictName in inclD [ \"itemIncludeDict\" ] else None # # Do data sections first. for container in containerList : if container . getType () == \"data\" : logger . debug ( \"Including data container %r with %r \" , container . getName (), container . getObjNameList ()) cL . append (( container , dataIncludeMode )) # if catInclD or itemInclD : # Process only explicitly included categories/items in the dictionary component if catInclD : for container in containerList : if container . getType () == \"data\" : continue cName = container . getName () catName = cName if container . isCategory () else CifName . categoryPart ( cName ) # if catName in catInclD : if container . isAttribute () and itemInclD and catName in itemInclD and cName in itemInclD [ catName ]: inclMode = itemInclD [ catName ][ cName ][ \"include_mode\" ] if itemInclD [ catName ][ cName ][ \"include_mode\" ] else dictInclMode cL . append (( self . __renameItem ( container , itemInclD [ catName ][ cName ][ \"include_as_item_name\" ]), inclMode )) else : inclMode = catInclD [ catName ][ \"include_mode\" ] if catInclD [ catName ][ \"include_mode\" ] else dictInclMode cL . append (( self . __renameCategory ( container , catInclD [ catName ][ \"include_as_category_id\" ]), inclMode )) elif itemInclD : # Process only explicitly included items exclusive of explicitly included categories in the dictionary component for container in containerList : if container . getType () == \"data\" : continue cName = container . getName () catName = cName if container . isCategory () else CifName . categoryPart ( cName ) # if container . isAttribute () and catName in itemInclD and cName in itemInclD [ catName ]: inclMode = itemInclD [ catName ][ cName ][ \"include_mode\" ] if itemInclD [ catName ][ cName ][ \"include_mode\" ] else dictInclMode cL . append (( self . __renameItem ( container , itemInclD [ catName ][ cName ][ \"include_as_item_name\" ]), inclMode )) else : # Process the full content of the dictionary component for container in containerList : if container . getType () == \"data\" : continue cName = container . getName () catName = cName if container . isCategory () else CifName . categoryPart ( cName ) # if container . isAttribute (): newName = self . __substituteItemPrefix ( cName , nsPrefix , nsPrefixReplace ) cL . append (( self . __renameItem ( container , newName ), dictInclMode )) else : newName = self . __substituteCategoryPrefix ( catName , nsPrefix , nsPrefixReplace ) cL . append (( self . __renameCategory ( container , newName ), dictInclMode )) # for container , inclMode in cL : if inclMode == \"replace\" : includeDataD . setdefault ( datablockName , {}) . setdefault ( \"replace\" , []) . append ( container ) elif inclMode == \"extend\" : logger . debug ( \" %r extending with %r \" , datablockName , container . getName ()) includeDataD . setdefault ( datablockName , {}) . setdefault ( \"extend\" , []) . append ( container ) # for nm in includeDataD : numReplace = len ( includeDataD [ nm ][ \"replace\" ]) if \"replace\" in includeDataD [ nm ] else 0 numExtend = len ( includeDataD [ nm ][ \"extend\" ]) if \"extend\" in includeDataD [ nm ] else 0 logger . debug ( \"includeDataD %s replace ( %d ) extend ( %d )\" , nm , numReplace , numExtend ) # except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return includeDataD def __isLocal ( self , locator ): try : locSp = urlsplit ( locator ) return locSp . scheme in [ \"\" , \"file\" ] except Exception as e : logger . error ( \"Bad include file path ( %r ) : %s \" , locator , str ( e )) return False def __fetchLocator ( self , locator , ** kwargs ): \"\"\"\"\"\" try : # Locate non-absolute paths relative to the dictionary incude file if self . __isLocal ( locator ) and not os . path . isabs ( locator ): logger . info ( \"locator is %r \" , locator ) logger . info ( \"dirStack ( %d ) top %r \" , len ( self . __dirStack ), self . __dirStack [ - 1 ]) locator = os . path . abspath ( os . path . relpath ( locator , start = self . __dirStack [ - 1 ])) # containerList = [] workPath = kwargs . get ( \"workPath\" , None ) enforceAscii = kwargs . get ( \"enforceAscii\" , False ) raiseExceptions = kwargs . get ( \"raiseExceptions\" , True ) useCharRefs = kwargs . get ( \"useCharRefs\" , True ) # myIo = IoAdapterPy ( raiseExceptions = raiseExceptions , useCharRefs = useCharRefs ) containerList = myIo . readFile ( locator , enforceAscii = enforceAscii , outDirPath = workPath ) logger . info ( \"Fetched %r dictionary container length ( %d )\" , locator , len ( containerList ) if containerList else 0 ) logger . debug ( \" %r \" , [ container . getName () for container in containerList ]) except Exception as e : logger . exception ( \"Failing for %s with %s \" , locator , str ( e )) return containerList def __substituteCategoryPrefix ( self , catName , curPrefix , newPrefix ): return catName . replace ( curPrefix , newPrefix , 1 ) if catName and catName . startswith ( curPrefix ) else catName def __substituteItemPrefix ( self , itemName , curPrefix , newPrefix ): atName = CifName . attributePart ( itemName ) atName = atName . replace ( curPrefix , newPrefix , 1 ) if atName and atName . startswith ( curPrefix ) else atName catName = CifName . categoryPart ( itemName ) catName = catName . replace ( curPrefix , newPrefix , 1 ) if atName and catName . startswith ( curPrefix ) else catName return CifName . itemName ( catName , atName ) def __renameItem ( self , container , newItemName ): if not container and not container . isAttribute () or not newItemName : return container # itemNameCur = container . getName () if itemNameCur == newItemName : return container # try : for item in self . __itemNameRelatives : catName = CifName . categoryPart ( item ) if container . exists ( catName ): cObj = container . getObj ( catName ) atName = CifName . attributePart ( item ) if cObj . hasAttribute ( atName ): for iRow in range ( cObj . getRowCount ()): curVal = cObj . getValue ( atName , iRow ) if curVal == itemNameCur : cObj . setValue ( newItemName , atName , iRow ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return container def __renameCategory ( self , container , newCategoryName ): if not container and not container . isCategory () or not newCategoryName : return container # catNameCur = container . getName () if catNameCur == newCategoryName : return container try : for item in self . __categoryIdRelatives : catName = CifName . categoryPart ( item ) if container . exists ( catName ): cObj = container . getObj ( catName ) atName = CifName . attributePart ( item ) if cObj . hasAttribute ( atName ): for iRow in range ( cObj . getRowCount ()): testVal = cObj . getValue ( atName , iRow ) if testVal == catNameCur : cObj . setValue ( newCategoryName , atName , iRow ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return container Methods __init__ ( self , ** kwargs ) special Source code in mmcif/api/DictionaryInclude.py def __init__ ( self , ** kwargs ): # self . __itemNameRelatives = [ \"_item.name\" , \"_item_examples.name\" , \"_ndb_item_description.name\" , \"_item_related.name\" , \"_category_key.name\" , \"_item_structure.name\" , \"_item_methods.name\" , \"_item_aliases.name\" , \"_item_dependent.dependent_name\" , \"_item_default.name\" , \"_pdbx_item_examples.name\" , \"_item_units.name\" , \"_item_related.related_name\" , \"_item_description.name\" , \"_item_dependent.name\" , \"_item_range.name\" , \"_item_sub_category.name\" , \"_pdbx_item_range.name\" , \"_pdbx_item_linked.condition_child_name\" , \"_ndb_item_examples.name\" , \"_pdbx_item_value_condition.item_name\" , \"_ndb_item_range.name\" , \"_item_linked.child_name\" , \"_pdbx_item_description.name\" , \"_pdbx_item_context.item_name\" , \"_pdbx_item_enumeration_details.name\" , \"_pdbx_item_linked_group_list.child_name\" , \"_pdbx_item_linked_group_list.parent_name\" , \"_pdbx_item_value_condition_list.target_item_name\" , \"_ndb_item_enumeration.name\" , \"_pdbx_item_linked.child_name\" , \"_pdbx_item_value_condition.dependent_item_name\" , \"_pdbx_item_enumeration.name\" , \"_item_linked.parent_name\" , \"_pdbx_item_value_condition_list.dependent_item_name\" , \"_item_type.name\" , \"_item_type_conditions.name\" , \"_pdbx_item_linked.parent_name\" , \"_item_enumeration.name\" , ] self . __categoryIdRelatives = [ \"_category.id\" , \"_category_key.id\" , \"_pdbx_item_linked_group.category_id\" , \"_pdbx_category_examples.id\" , \"_item.category_id\" , \"_pdbx_category_context.category_id\" , \"_pdbx_item_linked_group_list.parent_category_id\" , \"_category_group.category_id\" , \"_pdbx_category_description.id\" , \"_ndb_category_examples.id\" , \"_category_examples.id\" , \"_category_methods.category_id\" , \"_ndb_category_description.id\" , \"_pdbx_item_linked_group_list.child_category_id\" , ] # self . __cwd = os . getcwd () self . __dirPath = kwargs . get ( \"dirPath\" , os . getcwd ()) logger . info ( \"Local dictionary include path relative to %s \" , self . __dirPath ) self . __dirStack = [] self . __locatorIndexD = {} processIncludedContent ( self , containerList , cleanup = False ) Process any dictionary, category or item include instructions in any data containers in the input list of dictionary data and definition containers. Parameters: Name Type Description Default containerList list list of input PdbxContainer data or definition container objects required cleanup bool flag to remove generator category objects after parsing (default: False) False Returns: Type Description (list) list of data and definition containers incorporating included content Examples: pathDdlIncludeDictionary = \"mmcif_ddl-generator.dic\" myIo = IoAdapter ( raiseExceptions = True ) containerList = myIo . readFile ( inputFilePath = pathDdlIncludeDictionary ) logger . info ( \"Starting container list length ( %d )\" , len ( containerList )) dIncl = DictionaryInclude () inclL = dIncl . processIncludedContent ( containerList ) logger . info ( \"Processed included container length ( %d )\" , len ( inclL )) Source code in mmcif/api/DictionaryInclude.py def processIncludedContent ( self , containerList , cleanup = False ): \"\"\"Process any dictionary, category or item include instructions in any data containers in the input list of dictionary data and definition containers. Args: containerList (list): list of input PdbxContainer data or definition container objects cleanup (bool, optional): flag to remove generator category objects after parsing (default: False) Returns: (list): list of data and definition containers incorporating included content Examples: ```python pathDdlIncludeDictionary = \"mmcif_ddl-generator.dic\" myIo = IoAdapter(raiseExceptions=True) containerList = myIo.readFile(inputFilePath=pathDdlIncludeDictionary) logger.info(\"Starting container list length (%d)\", len(containerList)) dIncl = DictionaryInclude() inclL = dIncl.processIncludedContent(containerList) logger.info(\"Processed included container length (%d)\", len(inclL)) ``` \"\"\" includeD = self . __getIncludeInstructions ( containerList , cleanup = cleanup ) includeContentD = self . __fetchIncludedContent ( includeD , cleanup = cleanup ) return self . __addIncludedContent ( containerList , includeContentD )","title":"DictionaryInclude"},{"location":"api_reference/DictionaryInclude/#mmcif.api.DictionaryInclude.DictionaryInclude","text":"Source code in mmcif/api/DictionaryInclude.py class DictionaryInclude ( object ): def __init__ ( self , ** kwargs ): # self . __itemNameRelatives = [ \"_item.name\" , \"_item_examples.name\" , \"_ndb_item_description.name\" , \"_item_related.name\" , \"_category_key.name\" , \"_item_structure.name\" , \"_item_methods.name\" , \"_item_aliases.name\" , \"_item_dependent.dependent_name\" , \"_item_default.name\" , \"_pdbx_item_examples.name\" , \"_item_units.name\" , \"_item_related.related_name\" , \"_item_description.name\" , \"_item_dependent.name\" , \"_item_range.name\" , \"_item_sub_category.name\" , \"_pdbx_item_range.name\" , \"_pdbx_item_linked.condition_child_name\" , \"_ndb_item_examples.name\" , \"_pdbx_item_value_condition.item_name\" , \"_ndb_item_range.name\" , \"_item_linked.child_name\" , \"_pdbx_item_description.name\" , \"_pdbx_item_context.item_name\" , \"_pdbx_item_enumeration_details.name\" , \"_pdbx_item_linked_group_list.child_name\" , \"_pdbx_item_linked_group_list.parent_name\" , \"_pdbx_item_value_condition_list.target_item_name\" , \"_ndb_item_enumeration.name\" , \"_pdbx_item_linked.child_name\" , \"_pdbx_item_value_condition.dependent_item_name\" , \"_pdbx_item_enumeration.name\" , \"_item_linked.parent_name\" , \"_pdbx_item_value_condition_list.dependent_item_name\" , \"_item_type.name\" , \"_item_type_conditions.name\" , \"_pdbx_item_linked.parent_name\" , \"_item_enumeration.name\" , ] self . __categoryIdRelatives = [ \"_category.id\" , \"_category_key.id\" , \"_pdbx_item_linked_group.category_id\" , \"_pdbx_category_examples.id\" , \"_item.category_id\" , \"_pdbx_category_context.category_id\" , \"_pdbx_item_linked_group_list.parent_category_id\" , \"_category_group.category_id\" , \"_pdbx_category_description.id\" , \"_ndb_category_examples.id\" , \"_category_examples.id\" , \"_category_methods.category_id\" , \"_ndb_category_description.id\" , \"_pdbx_item_linked_group_list.child_category_id\" , ] # self . __cwd = os . getcwd () self . __dirPath = kwargs . get ( \"dirPath\" , os . getcwd ()) logger . info ( \"Local dictionary include path relative to %s \" , self . __dirPath ) self . __dirStack = [] self . __locatorIndexD = {} def processIncludedContent ( self , containerList , cleanup = False ): \"\"\"Process any dictionary, category or item include instructions in any data containers in the input list of dictionary data and definition containers. Args: containerList (list): list of input PdbxContainer data or definition container objects cleanup (bool, optional): flag to remove generator category objects after parsing (default: False) Returns: (list): list of data and definition containers incorporating included content Examples: ```python pathDdlIncludeDictionary = \"mmcif_ddl-generator.dic\" myIo = IoAdapter(raiseExceptions=True) containerList = myIo.readFile(inputFilePath=pathDdlIncludeDictionary) logger.info(\"Starting container list length (%d)\", len(containerList)) dIncl = DictionaryInclude() inclL = dIncl.processIncludedContent(containerList) logger.info(\"Processed included container length (%d)\", len(inclL)) ``` \"\"\" includeD = self . __getIncludeInstructions ( containerList , cleanup = cleanup ) includeContentD = self . __fetchIncludedContent ( includeD , cleanup = cleanup ) return self . __addIncludedContent ( containerList , includeContentD ) def __addIncludedContent ( self , containerList , includeContentD ): \"\"\"Incorporate included content described in the input dictionary of include instructions produced by internal method __getIncludeInstructions(). Args: containerList (list): list of input PdbxContainer data or definition container objects includeContentD (dict): {\"dictionaryIncludeDict\": {dictionary_id: {...include details...}}, \"categoryIncludeDict\": {dictionary_id: {category_id: {...include details... }}}, \"itemIncludeDict\": {dictionary_id: {category_id: {itemName: {...include details...}}}} } Returns: (list): list of data and definition containers incorporating included content \"\"\" # Index the current container list... cD = OrderedDict () datablockName = \"unnamed_1\" for container in containerList : if container . getType () == \"data\" : datablockName = container . getName () # Handle potentially unconsolidated definitions -- cD . setdefault ( datablockName , OrderedDict ()) . setdefault ( container . getName (), []) . append ( container ) # # for datablockName in cD : if datablockName in includeContentD : if \"replace\" in includeContentD [ datablockName ]: # Organize the replacements by name replaceDefinitionD = OrderedDict () replaceDataD = OrderedDict () for container in includeContentD [ datablockName ][ \"replace\" ]: if container . getType () == \"definition\" : replaceDefinitionD . setdefault ( container . getName (), []) . append ( container ) else : replaceDataD . setdefault ( datablockName , []) . append ( container ) # for rN , rL in replaceDefinitionD . items (): if rN in cD [ datablockName ]: cD [ datablockName ][ rN ] = rL # replace data sections in the base container baseContainer = cD [ datablockName ][ datablockName ][ 0 ] for rN , containerL in replaceDataD . items (): for container in containerL : for nm in container . getObjNameList (): obj = container . getObj ( nm ) baseContainer . replace ( obj ) # if \"extend\" in includeContentD [ datablockName ]: extendDataD = OrderedDict () for container in includeContentD [ datablockName ][ \"extend\" ]: if container . getType () == \"definition\" : cD . setdefault ( datablockName , OrderedDict ()) . setdefault ( container . getName (), []) . append ( container ) else : extendDataD . setdefault ( datablockName , []) . append ( container ) # extend data sections in the base container baseContainer = cD [ datablockName ][ datablockName ][ 0 ] for rN , containerL in extendDataD . items (): for container in containerL : for nm in container . getObjNameList (): obj = container . getObj ( nm ) if baseContainer . exists ( nm ): baseObj = baseContainer . getObj ( nm ) for ii in range ( obj . getRowCount ()): rowD = obj . getRowAttributeDict ( ii ) baseObj . append ( rowD ) else : baseContainer . append ( obj ) # # Unwind the container index # fullL = [] for datablockName in cD : for cL in cD [ datablockName ] . values (): fullL . extend ( cL ) # return fullL def __getIncludeInstructions ( self , containerList , cleanup = False ): \"\"\"Extract include instructions from categories pdbx_include_dictionary, pdbx_include_category, and pdbx_include_item. Args: containerList (list): list of input PdbxContainer data or definition container objects cleanup (optional, bool): flag to remove generator category objects after parsing (default: False) Returns: A dictionary containing the dictionary, category and and item level include details. For example, ```python { \"dictionaryIncludeDict\": {dictionary_id: {...include details...}}, \"categoryIncludeDict\": {dictionary_id: {category_id: {...include details... }}}, \"itemIncludeDict\": {dictionary_id: {category_id: {itemName: {...include details...}}}}, } ``` \"\"\" includeD = OrderedDict () try : unNamed = 1 for container in containerList : if container . getType () == \"data\" : dictionaryIncludeDict = OrderedDict () categoryIncludeDict = OrderedDict () itemIncludeDict = OrderedDict () if container . getName (): datablockName = container . getName () else : datablockName = str ( unNamed ) unNamed += 1 logger . debug ( \"Adding data sections from container name %s type %s \" , datablockName , container . getType ()) tl = container . getObj ( \"pdbx_include_dictionary\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () for atName in [ \"dictionary_id\" , \"dictionary_locator\" , \"include_mode\" , \"dictionary_namespace_prefix\" , \"dictionary_namespace_prefix_replace\" ]: tD [ atName ] = row [ tl . getIndex ( atName )] if tl . hasAttribute ( atName ) else None dictionaryIncludeDict [ tD [ \"dictionary_id\" ]] = tD # tl = container . getObj ( \"pdbx_include_category\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () for atName in [ \"dictionary_id\" , \"category_id\" , \"include_as_category_id\" , \"include_mode\" ]: tD [ atName ] = row [ tl . getIndex ( atName )] if tl . hasAttribute ( atName ) else None categoryIncludeDict . setdefault ( tD [ \"dictionary_id\" ], {}) . setdefault ( tD [ \"category_id\" ], tD ) # tl = container . getObj ( \"pdbx_include_item\" ) if tl is not None : for row in tl . getRowList (): tD = OrderedDict () for atName in [ \"dictionary_id\" , \"item_name\" , \"include_as_item_name\" , \"include_mode\" ]: tD [ atName ] = row [ tl . getIndex ( atName )] if tl . hasAttribute ( atName ) else None categoryId = CifName . categoryPart ( tD [ \"item_name\" ]) itemIncludeDict . setdefault ( tD [ \"dictionary_id\" ], {}) . setdefault ( categoryId , {}) . setdefault ( tD [ \"item_name\" ], tD ) if cleanup : for catName in [ \"pdbx_include_dictionary\" , \"pdbx_include_category\" , \"pdbx_include_item\" ]: if container . exists ( catName ): container . remove ( catName ) # includeD [ datablockName ] = { \"dictionaryIncludeDict\" : dictionaryIncludeDict , \"categoryIncludeDict\" : categoryIncludeDict , \"itemIncludeDict\" : itemIncludeDict , } except Exception as e : logger . exception ( \"Include processing failing with %s \" , str ( e )) return includeD def __fetchIncludedContent ( self , includeD , cleanup = False ): \"\"\"Fetch included content following the instructions encoded in the input data structure. Args: includeD (dict): {\"dictionaryIncludeDict\": {dictionary_id: {...include details...}}, \"categoryIncludeDict\": {dictionary_id: {category_id: {...include details... }}}, \"itemIncludeDict\": {dictionary_id: {category_id: {itemName: {...include details...}}}}, } cleanup (optional, bool): flag to remove generator category objects after parsing (default: false) Returns: (dict): {datablockName: {\"extend\": [container,...], \"replace\": [container, ...]}, ... } \"\"\" includeDataD = {} try : for datablockName , inclD in includeD . items (): cL = [] for dictName , iD in inclD [ \"dictionaryIncludeDict\" ] . items (): locator = iD [ \"dictionary_locator\" ] if locator in self . __locatorIndexD : logger . info ( \"Skipping redundant include for %r at %r \" , dictName , locator ) continue self . __locatorIndexD [ locator ] = dictName # # --- Fetch the dictionary component - # updateStack = self . __isLocal ( locator ) if updateStack : if not self . __dirStack : # top-level include case self . __dirStack . append ( os . path . abspath ( self . __dirPath )) # embedded include case (push directory containing the locator) if not os . path . isabs ( locator ): # handle the relative path case - locator = os . path . abspath ( os . path . join ( self . __dirStack [ - 1 ], locator )) logger . debug ( \"modified local relative locator is %r \" , locator ) self . __dirStack . append ( os . path . dirname ( locator )) logger . debug ( \"dirStack ( %d ) top %r \" , len ( self . __dirStack ), self . __dirStack [ - 1 ]) containerList = self . processIncludedContent ( self . __fetchLocator ( locator ), cleanup = cleanup ) if updateStack : # restore stack context self . __dirStack . pop () # nsPrefix = iD [ \"dictionary_namespace_prefix\" ] nsPrefixReplace = iD [ \"dictionary_namespace_prefix_replace\" ] dictInclMode = iD [ \"include_mode\" ] dataIncludeMode = iD [ \"data_include_mode\" ] if \"data_include_mode\" in iD else \"extend\" catInclD = inclD [ \"categoryIncludeDict\" ][ dictName ] if dictName in inclD [ \"categoryIncludeDict\" ] else None itemInclD = inclD [ \"itemIncludeDict\" ][ dictName ] if dictName in inclD [ \"itemIncludeDict\" ] else None # # Do data sections first. for container in containerList : if container . getType () == \"data\" : logger . debug ( \"Including data container %r with %r \" , container . getName (), container . getObjNameList ()) cL . append (( container , dataIncludeMode )) # if catInclD or itemInclD : # Process only explicitly included categories/items in the dictionary component if catInclD : for container in containerList : if container . getType () == \"data\" : continue cName = container . getName () catName = cName if container . isCategory () else CifName . categoryPart ( cName ) # if catName in catInclD : if container . isAttribute () and itemInclD and catName in itemInclD and cName in itemInclD [ catName ]: inclMode = itemInclD [ catName ][ cName ][ \"include_mode\" ] if itemInclD [ catName ][ cName ][ \"include_mode\" ] else dictInclMode cL . append (( self . __renameItem ( container , itemInclD [ catName ][ cName ][ \"include_as_item_name\" ]), inclMode )) else : inclMode = catInclD [ catName ][ \"include_mode\" ] if catInclD [ catName ][ \"include_mode\" ] else dictInclMode cL . append (( self . __renameCategory ( container , catInclD [ catName ][ \"include_as_category_id\" ]), inclMode )) elif itemInclD : # Process only explicitly included items exclusive of explicitly included categories in the dictionary component for container in containerList : if container . getType () == \"data\" : continue cName = container . getName () catName = cName if container . isCategory () else CifName . categoryPart ( cName ) # if container . isAttribute () and catName in itemInclD and cName in itemInclD [ catName ]: inclMode = itemInclD [ catName ][ cName ][ \"include_mode\" ] if itemInclD [ catName ][ cName ][ \"include_mode\" ] else dictInclMode cL . append (( self . __renameItem ( container , itemInclD [ catName ][ cName ][ \"include_as_item_name\" ]), inclMode )) else : # Process the full content of the dictionary component for container in containerList : if container . getType () == \"data\" : continue cName = container . getName () catName = cName if container . isCategory () else CifName . categoryPart ( cName ) # if container . isAttribute (): newName = self . __substituteItemPrefix ( cName , nsPrefix , nsPrefixReplace ) cL . append (( self . __renameItem ( container , newName ), dictInclMode )) else : newName = self . __substituteCategoryPrefix ( catName , nsPrefix , nsPrefixReplace ) cL . append (( self . __renameCategory ( container , newName ), dictInclMode )) # for container , inclMode in cL : if inclMode == \"replace\" : includeDataD . setdefault ( datablockName , {}) . setdefault ( \"replace\" , []) . append ( container ) elif inclMode == \"extend\" : logger . debug ( \" %r extending with %r \" , datablockName , container . getName ()) includeDataD . setdefault ( datablockName , {}) . setdefault ( \"extend\" , []) . append ( container ) # for nm in includeDataD : numReplace = len ( includeDataD [ nm ][ \"replace\" ]) if \"replace\" in includeDataD [ nm ] else 0 numExtend = len ( includeDataD [ nm ][ \"extend\" ]) if \"extend\" in includeDataD [ nm ] else 0 logger . debug ( \"includeDataD %s replace ( %d ) extend ( %d )\" , nm , numReplace , numExtend ) # except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return includeDataD def __isLocal ( self , locator ): try : locSp = urlsplit ( locator ) return locSp . scheme in [ \"\" , \"file\" ] except Exception as e : logger . error ( \"Bad include file path ( %r ) : %s \" , locator , str ( e )) return False def __fetchLocator ( self , locator , ** kwargs ): \"\"\"\"\"\" try : # Locate non-absolute paths relative to the dictionary incude file if self . __isLocal ( locator ) and not os . path . isabs ( locator ): logger . info ( \"locator is %r \" , locator ) logger . info ( \"dirStack ( %d ) top %r \" , len ( self . __dirStack ), self . __dirStack [ - 1 ]) locator = os . path . abspath ( os . path . relpath ( locator , start = self . __dirStack [ - 1 ])) # containerList = [] workPath = kwargs . get ( \"workPath\" , None ) enforceAscii = kwargs . get ( \"enforceAscii\" , False ) raiseExceptions = kwargs . get ( \"raiseExceptions\" , True ) useCharRefs = kwargs . get ( \"useCharRefs\" , True ) # myIo = IoAdapterPy ( raiseExceptions = raiseExceptions , useCharRefs = useCharRefs ) containerList = myIo . readFile ( locator , enforceAscii = enforceAscii , outDirPath = workPath ) logger . info ( \"Fetched %r dictionary container length ( %d )\" , locator , len ( containerList ) if containerList else 0 ) logger . debug ( \" %r \" , [ container . getName () for container in containerList ]) except Exception as e : logger . exception ( \"Failing for %s with %s \" , locator , str ( e )) return containerList def __substituteCategoryPrefix ( self , catName , curPrefix , newPrefix ): return catName . replace ( curPrefix , newPrefix , 1 ) if catName and catName . startswith ( curPrefix ) else catName def __substituteItemPrefix ( self , itemName , curPrefix , newPrefix ): atName = CifName . attributePart ( itemName ) atName = atName . replace ( curPrefix , newPrefix , 1 ) if atName and atName . startswith ( curPrefix ) else atName catName = CifName . categoryPart ( itemName ) catName = catName . replace ( curPrefix , newPrefix , 1 ) if atName and catName . startswith ( curPrefix ) else catName return CifName . itemName ( catName , atName ) def __renameItem ( self , container , newItemName ): if not container and not container . isAttribute () or not newItemName : return container # itemNameCur = container . getName () if itemNameCur == newItemName : return container # try : for item in self . __itemNameRelatives : catName = CifName . categoryPart ( item ) if container . exists ( catName ): cObj = container . getObj ( catName ) atName = CifName . attributePart ( item ) if cObj . hasAttribute ( atName ): for iRow in range ( cObj . getRowCount ()): curVal = cObj . getValue ( atName , iRow ) if curVal == itemNameCur : cObj . setValue ( newItemName , atName , iRow ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return container def __renameCategory ( self , container , newCategoryName ): if not container and not container . isCategory () or not newCategoryName : return container # catNameCur = container . getName () if catNameCur == newCategoryName : return container try : for item in self . __categoryIdRelatives : catName = CifName . categoryPart ( item ) if container . exists ( catName ): cObj = container . getObj ( catName ) atName = CifName . attributePart ( item ) if cObj . hasAttribute ( atName ): for iRow in range ( cObj . getRowCount ()): testVal = cObj . getValue ( atName , iRow ) if testVal == catNameCur : cObj . setValue ( newCategoryName , atName , iRow ) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return container","title":"DictionaryInclude"},{"location":"api_reference/DictionaryInclude/#mmcif.api.DictionaryInclude.DictionaryInclude-methods","text":"","title":"Methods"},{"location":"api_reference/DictionaryInclude/#mmcif.api.DictionaryInclude.DictionaryInclude.__init__","text":"Source code in mmcif/api/DictionaryInclude.py def __init__ ( self , ** kwargs ): # self . __itemNameRelatives = [ \"_item.name\" , \"_item_examples.name\" , \"_ndb_item_description.name\" , \"_item_related.name\" , \"_category_key.name\" , \"_item_structure.name\" , \"_item_methods.name\" , \"_item_aliases.name\" , \"_item_dependent.dependent_name\" , \"_item_default.name\" , \"_pdbx_item_examples.name\" , \"_item_units.name\" , \"_item_related.related_name\" , \"_item_description.name\" , \"_item_dependent.name\" , \"_item_range.name\" , \"_item_sub_category.name\" , \"_pdbx_item_range.name\" , \"_pdbx_item_linked.condition_child_name\" , \"_ndb_item_examples.name\" , \"_pdbx_item_value_condition.item_name\" , \"_ndb_item_range.name\" , \"_item_linked.child_name\" , \"_pdbx_item_description.name\" , \"_pdbx_item_context.item_name\" , \"_pdbx_item_enumeration_details.name\" , \"_pdbx_item_linked_group_list.child_name\" , \"_pdbx_item_linked_group_list.parent_name\" , \"_pdbx_item_value_condition_list.target_item_name\" , \"_ndb_item_enumeration.name\" , \"_pdbx_item_linked.child_name\" , \"_pdbx_item_value_condition.dependent_item_name\" , \"_pdbx_item_enumeration.name\" , \"_item_linked.parent_name\" , \"_pdbx_item_value_condition_list.dependent_item_name\" , \"_item_type.name\" , \"_item_type_conditions.name\" , \"_pdbx_item_linked.parent_name\" , \"_item_enumeration.name\" , ] self . __categoryIdRelatives = [ \"_category.id\" , \"_category_key.id\" , \"_pdbx_item_linked_group.category_id\" , \"_pdbx_category_examples.id\" , \"_item.category_id\" , \"_pdbx_category_context.category_id\" , \"_pdbx_item_linked_group_list.parent_category_id\" , \"_category_group.category_id\" , \"_pdbx_category_description.id\" , \"_ndb_category_examples.id\" , \"_category_examples.id\" , \"_category_methods.category_id\" , \"_ndb_category_description.id\" , \"_pdbx_item_linked_group_list.child_category_id\" , ] # self . __cwd = os . getcwd () self . __dirPath = kwargs . get ( \"dirPath\" , os . getcwd ()) logger . info ( \"Local dictionary include path relative to %s \" , self . __dirPath ) self . __dirStack = [] self . __locatorIndexD = {}","title":"__init__()"},{"location":"api_reference/DictionaryInclude/#mmcif.api.DictionaryInclude.DictionaryInclude.processIncludedContent","text":"Process any dictionary, category or item include instructions in any data containers in the input list of dictionary data and definition containers. Parameters: Name Type Description Default containerList list list of input PdbxContainer data or definition container objects required cleanup bool flag to remove generator category objects after parsing (default: False) False Returns: Type Description (list) list of data and definition containers incorporating included content Examples: pathDdlIncludeDictionary = \"mmcif_ddl-generator.dic\" myIo = IoAdapter ( raiseExceptions = True ) containerList = myIo . readFile ( inputFilePath = pathDdlIncludeDictionary ) logger . info ( \"Starting container list length ( %d )\" , len ( containerList )) dIncl = DictionaryInclude () inclL = dIncl . processIncludedContent ( containerList ) logger . info ( \"Processed included container length ( %d )\" , len ( inclL )) Source code in mmcif/api/DictionaryInclude.py def processIncludedContent ( self , containerList , cleanup = False ): \"\"\"Process any dictionary, category or item include instructions in any data containers in the input list of dictionary data and definition containers. Args: containerList (list): list of input PdbxContainer data or definition container objects cleanup (bool, optional): flag to remove generator category objects after parsing (default: False) Returns: (list): list of data and definition containers incorporating included content Examples: ```python pathDdlIncludeDictionary = \"mmcif_ddl-generator.dic\" myIo = IoAdapter(raiseExceptions=True) containerList = myIo.readFile(inputFilePath=pathDdlIncludeDictionary) logger.info(\"Starting container list length (%d)\", len(containerList)) dIncl = DictionaryInclude() inclL = dIncl.processIncludedContent(containerList) logger.info(\"Processed included container length (%d)\", len(inclL)) ``` \"\"\" includeD = self . __getIncludeInstructions ( containerList , cleanup = cleanup ) includeContentD = self . __fetchIncludedContent ( includeD , cleanup = cleanup ) return self . __addIncludedContent ( containerList , includeContentD )","title":"processIncludedContent()"},{"location":"api_reference/IoAdapterBase/","text":"mmcif.io.IoAdapterBase.IoAdapterBase Base class presenting essential mmCIF I/O methods. Source code in mmcif/io/IoAdapterBase.py class IoAdapterBase ( object ): \"\"\"Base class presenting essential mmCIF I/O methods.\"\"\" def __init__ ( self , * args , ** kwargs ): \"\"\"General options controlling I/O method operations: Args: raiseExceptions (bool, optional): Flag to indicate that API errors should generate exceptions (True) or catch and log errors (default=False) maxInputLineLength (int, optional): Default maximum input line length (default=4096) useCharRefs (bool, optional): Replace non-ascii characters with XML Character References (default=True) readEncodingErrors (str, optional): treatment of encoding errors at read time (default='ignore') timing (bool, optional): log timing details for parsing and processing steps (default=False) verbose (bool,optional): log verbose output from wrapped libraries \"\"\" _ = args self . _raiseExceptions = kwargs . get ( \"raiseExceptions\" , False ) self . _maxInputLineLength = kwargs . get ( \"maxInputLineLength\" , 4096 ) self . _useCharRefs = kwargs . get ( \"useCharRefs\" , True ) self . __logFilePath = None self . _debug = kwargs . get ( \"debug\" , False ) self . _timing = kwargs . get ( \"timing\" , False ) self . _verbose = kwargs . get ( \"verbose\" , True ) self . _readEncodingErrors = kwargs . get ( \"readEncodingErrors\" , \"ignore\" ) def readFile ( self , * args , ** kwargs ): \"\"\"Read file method. (abstract) Args: inputFilePath (string): Input file path/uri kw: optional key-value arguments Returns: list of DataContainer Objects: list of data or definition container objects \"\"\" raise NotImplementedError ( \"To be implemented in subclass\" ) def writeFile ( self , outputFilePath , containerList , ** kwargs ): \"\"\"Write file method - (abstract) Args: outputFilePath (string): output file path containerList (list of DataContainer objects): list of data or definition containers objects for output Returns: bool: Completion status \"\"\" raise NotImplementedError ( \"To be implemented in subclass\" ) def getReadDiags ( self ): \"\"\"Return any diagnostics from the last read operation. (abstract)\"\"\" raise NotImplementedError ( \"To be implemented in subclass\" ) def _setContainerProperties ( self , containerList , ** kwargs ): try : for container in containerList : for kw in kwargs : container . setProp ( kw , kwargs [ kw ]) except Exception : return False def _getTimeStamp ( self ): utcnow = datetime . datetime . utcnow () ts = utcnow . strftime ( \"%Y-%m- %d :%H:%M:%S\" ) return ts def _getCategoryNameList ( self , container , lastInOrder = None , selectOrder = None ): \"\"\"Return an ordered list of categories in the input container subject to input category name lists. Args: container (DataContainer object): Input DataContainer object lastInOrder (list): names of categories to be shifted to the end of the container. selectOrder (list): preferred order of category names Returns: catNameList: list: augmented category list or full list (default) \"\"\" catNameList = [] if lastInOrder : objNameList = container . getObjNameList () lastList = [] for nm in objNameList : if nm in lastInOrder : lastList . append ( nm ) continue catNameList . append ( nm ) catNameList . extend ( lastList ) elif selectOrder : for nm in selectOrder : if container . exists ( nm ): catNameList . append ( nm ) else : catNameList = container . getObjNameList () return catNameList def _setLogFilePath ( self , filePath ): \"\"\"Set the log file path.\"\"\" self . __logFilePath = filePath def _getLogFilePath ( self ): \"\"\"Return current log file path.\"\"\" return self . __logFilePath def _appendToLog ( self , stList ): \"\"\"Append input string list to the current log file -\"\"\" if not self . __logFilePath : return False try : with open ( self . __logFilePath , \"a\" ) as ofh : ofh . write ( \" %s \\n \" % \" \\n \" . join ( stList )) return True except Exception as e : logger . debug ( \"Failing with %s \" , str ( e )) return True def _logError ( self , msg ): \"\"\"Convenience method to log error messages and optionally raise general exceptions (PdbxError).\"\"\" self . _appendToLog ([ msg ]) if self . _raiseExceptions : raise PdbxError ( msg ) else : logger . error ( msg ) def _readLogRecords ( self ): \"\"\"Return the contents of the current log file as list of strings.\"\"\" diagL = [] try : with open ( self . __logFilePath , \"r\" ) as ifh : for line in ifh : diagL . append ( line [: - 1 ]) except Exception as e : msg = \"No logfile found %s ( %s )\" % ( self . __logFilePath , str ( e )) diagL . append ( msg ) logger . debug ( msg ) return diagL def __getDiscriminator ( self ): \"\"\"Internal method returning a string which can discriminate among default file names -\"\"\" return str ( time . time () * 10000 ) . replace ( \".\" , \"_\" ) def _chooseTemporaryPath ( self , filePath , outDirPath = None ): \"\"\"Select a path for temporary files in the priority order outDirpath, directory containing the input filePath, current working directory, dynamically created temporary directory. These choices harmonize various legacy api behaviors. \"\"\" if outDirPath : return outDirPath # for oPath in [ os . path . dirname ( filePath ), \".\" , tempfile . gettempdir ()]: if os . access ( oPath , os . W_OK ): return oPath def _getDefaultFileName ( self , filePath , fileType = \"cif-parser\" , fileExt = \"log\" , outDirPath = None , verify = True ): \"\"\"Return default file path for the target input file subject to input attributes and the output path.\"\"\" returnFilePath = None try : _ , fn = os . path . split ( filePath ) bn , _ = os . path . splitext ( fn ) # ft = fileType if fileType else \"temp\" fex = fileExt if fileExt else \"tmp\" # sf = \"_\" + ft + \"_P\" + self . __getDiscriminator () + \".\" + fex # # pth = outDirPath if outDirPath else '.' pth = self . _chooseTemporaryPath ( filePath , outDirPath = outDirPath ) # if verify : # test if pth is actually writable ? Throw exception otherwise - # testfile = tempfile . TemporaryFile ( dir = pth ) testfile . close () # returnFilePath = os . path . join ( pth , bn + sf ) except Exception as e : if self . _raiseExceptions : raise e else : logger . error ( \"Failed creating default filename for %s type %s with %s \" , filePath , fileType , str ( e )) return returnFilePath def _fileExists ( self , filePath ): \"\"\"Verify that input file path exists and is readable.\"\"\" try : if not os . access ( filePath , os . R_OK ): msg = \"Missing file %r \" % filePath self . _appendToLog ([ msg ]) logger . error ( msg ) # if self . _raiseExceptions : raise PdbxError ( msg ) return False else : logger . debug ( \"Reading from file path %s \" , filePath ) return True except Exception as e : msg = \"File check error for %r with %s \" % ( filePath , str ( e )) self . _appendToLog ([ msg ]) if self . _raiseExceptions : raise PdbxError ( msg ) else : logger . error ( msg ) return False def _cleanupFile ( self , test , filePath ): \"\"\"Remove the input file path subject to the input test condition.\"\"\" try : if test : os . remove ( filePath ) except Exception : pass def _toAscii ( self , inputFilePath , outputFilePath , chunkSize = 5000 , encodingErrors = \"ignore\" , readEncodingErrors = \"ignore\" ): \"\"\"Encode input file to Ascii and write this to the target output file. Handle encoding errors according to the input settting ('ignore', 'escape', 'xmlcharrefreplace'). \"\"\" try : startTime = time . time () chunk = [] with io . open ( inputFilePath , \"r\" , encoding = \"utf-8\" , errors = readEncodingErrors ) as ifh , io . open ( outputFilePath , \"w\" , encoding = \"ascii\" ) as ofh : for line in ifh : # chunk.append(line.encode('ascii', 'xmlcharrefreplace').decode('ascii')) chunk . append ( line . encode ( \"ascii\" , encodingErrors ) . decode ( \"ascii\" )) if len ( chunk ) == chunkSize : ofh . writelines ( chunk ) chunk = [] ofh . writelines ( chunk ) if self . _timing : stepTime1 = time . time () logger . info ( \"Timing text file %s encoded to as ascii in %.4f seconds\" , inputFilePath , stepTime1 - startTime ) return True except Exception as e : msg = \"Failing text ascii encoding for %s with %s \" % ( inputFilePath , str ( e )) self . _appendToLog ([ msg ]) logger . error ( msg ) if self . _raiseExceptions : raise PdbxError ( msg ) # return False def _uncompress ( self , inputFilePath , outputDir ): \"\"\"Uncompress the input file if the path name has a recognized compression type file extension.file Return the file name of the uncompressed file (in outDir) or the original input file path. \"\"\" try : startTime = time . time () _ , fn = os . path . split ( inputFilePath ) bn , _ = os . path . splitext ( fn ) outputFilePath = os . path . join ( outputDir , bn ) if inputFilePath . endswith ( \".gz\" ): with gzip . open ( inputFilePath , mode = \"rb\" ) as inpF : with io . open ( outputFilePath , \"wb\" ) as outF : shutil . copyfileobj ( inpF , outF ) elif inputFilePath . endswith ( \".bz2\" ): with bz2 . open ( inputFilePath , mode = \"rb\" ) as inpF : with io . open ( outputFilePath , \"wb\" ) as outF : shutil . copyfileobj ( inpF , outF ) # elif inputFilePath.endswith(\".xz\"): # with lzma.open(inputFilePath, mode=\"rb\") as inpF: # with io.open(outputFilePath, \"wb\") as outF: # shutil.copyfileobj(inpF, outF) elif inputFilePath . endswith ( \".zip\" ): with zipfile . ZipFile ( inputFilePath , mode = \"rb\" ) as inpF : with io . open ( outputFilePath , \"wb\" ) as outF : shutil . copyfileobj ( inpF , outF ) else : outputFilePath = inputFilePath if self . _timing : stepTime1 = time . time () logger . info ( \"Timing text file %s uncompressed in %.4f seconds\" , inputFilePath , stepTime1 - startTime ) # except Exception as e : msg = \"Failing uncompress for file %s with %s \" % ( inputFilePath , str ( e )) self . _appendToLog ([ msg ]) logger . exception ( msg ) if self . _raiseExceptions : raise PdbxError ( msg ) logger . debug ( \"Returning file path %r \" , outputFilePath ) return outputFilePath Methods __init__ ( self , * args , ** kwargs ) special General options controlling I/O method operations: Parameters: Name Type Description Default raiseExceptions bool Flag to indicate that API errors should generate exceptions (True) or catch and log errors (default=False) required maxInputLineLength int Default maximum input line length (default=4096) required useCharRefs bool Replace non-ascii characters with XML Character References (default=True) required readEncodingErrors str treatment of encoding errors at read time (default='ignore') required timing bool log timing details for parsing and processing steps (default=False) required verbose bool,optional log verbose output from wrapped libraries required Source code in mmcif/io/IoAdapterBase.py def __init__ ( self , * args , ** kwargs ): \"\"\"General options controlling I/O method operations: Args: raiseExceptions (bool, optional): Flag to indicate that API errors should generate exceptions (True) or catch and log errors (default=False) maxInputLineLength (int, optional): Default maximum input line length (default=4096) useCharRefs (bool, optional): Replace non-ascii characters with XML Character References (default=True) readEncodingErrors (str, optional): treatment of encoding errors at read time (default='ignore') timing (bool, optional): log timing details for parsing and processing steps (default=False) verbose (bool,optional): log verbose output from wrapped libraries \"\"\" _ = args self . _raiseExceptions = kwargs . get ( \"raiseExceptions\" , False ) self . _maxInputLineLength = kwargs . get ( \"maxInputLineLength\" , 4096 ) self . _useCharRefs = kwargs . get ( \"useCharRefs\" , True ) self . __logFilePath = None self . _debug = kwargs . get ( \"debug\" , False ) self . _timing = kwargs . get ( \"timing\" , False ) self . _verbose = kwargs . get ( \"verbose\" , True ) self . _readEncodingErrors = kwargs . get ( \"readEncodingErrors\" , \"ignore\" ) getReadDiags ( self ) Return any diagnostics from the last read operation. (abstract) Source code in mmcif/io/IoAdapterBase.py def getReadDiags ( self ): \"\"\"Return any diagnostics from the last read operation. (abstract)\"\"\" raise NotImplementedError ( \"To be implemented in subclass\" ) readFile ( self , * args , ** kwargs ) Read file method. (abstract) Args: inputFilePath (string): Input file path/uri kw: optional key-value arguments Returns: Type Description list of DataContainer Objects list of data or definition container objects Source code in mmcif/io/IoAdapterBase.py def readFile ( self , * args , ** kwargs ): \"\"\"Read file method. (abstract) Args: inputFilePath (string): Input file path/uri kw: optional key-value arguments Returns: list of DataContainer Objects: list of data or definition container objects \"\"\" raise NotImplementedError ( \"To be implemented in subclass\" ) writeFile ( self , outputFilePath , containerList , ** kwargs ) Write file method - (abstract) Parameters: Name Type Description Default outputFilePath string output file path required containerList list of DataContainer objects list of data or definition containers objects for output required Returns: Type Description bool Completion status Source code in mmcif/io/IoAdapterBase.py def writeFile ( self , outputFilePath , containerList , ** kwargs ): \"\"\"Write file method - (abstract) Args: outputFilePath (string): output file path containerList (list of DataContainer objects): list of data or definition containers objects for output Returns: bool: Completion status \"\"\" raise NotImplementedError ( \"To be implemented in subclass\" )","title":"IoAdapterBase"},{"location":"api_reference/IoAdapterBase/#mmcif.io.IoAdapterBase.IoAdapterBase","text":"Base class presenting essential mmCIF I/O methods. Source code in mmcif/io/IoAdapterBase.py class IoAdapterBase ( object ): \"\"\"Base class presenting essential mmCIF I/O methods.\"\"\" def __init__ ( self , * args , ** kwargs ): \"\"\"General options controlling I/O method operations: Args: raiseExceptions (bool, optional): Flag to indicate that API errors should generate exceptions (True) or catch and log errors (default=False) maxInputLineLength (int, optional): Default maximum input line length (default=4096) useCharRefs (bool, optional): Replace non-ascii characters with XML Character References (default=True) readEncodingErrors (str, optional): treatment of encoding errors at read time (default='ignore') timing (bool, optional): log timing details for parsing and processing steps (default=False) verbose (bool,optional): log verbose output from wrapped libraries \"\"\" _ = args self . _raiseExceptions = kwargs . get ( \"raiseExceptions\" , False ) self . _maxInputLineLength = kwargs . get ( \"maxInputLineLength\" , 4096 ) self . _useCharRefs = kwargs . get ( \"useCharRefs\" , True ) self . __logFilePath = None self . _debug = kwargs . get ( \"debug\" , False ) self . _timing = kwargs . get ( \"timing\" , False ) self . _verbose = kwargs . get ( \"verbose\" , True ) self . _readEncodingErrors = kwargs . get ( \"readEncodingErrors\" , \"ignore\" ) def readFile ( self , * args , ** kwargs ): \"\"\"Read file method. (abstract) Args: inputFilePath (string): Input file path/uri kw: optional key-value arguments Returns: list of DataContainer Objects: list of data or definition container objects \"\"\" raise NotImplementedError ( \"To be implemented in subclass\" ) def writeFile ( self , outputFilePath , containerList , ** kwargs ): \"\"\"Write file method - (abstract) Args: outputFilePath (string): output file path containerList (list of DataContainer objects): list of data or definition containers objects for output Returns: bool: Completion status \"\"\" raise NotImplementedError ( \"To be implemented in subclass\" ) def getReadDiags ( self ): \"\"\"Return any diagnostics from the last read operation. (abstract)\"\"\" raise NotImplementedError ( \"To be implemented in subclass\" ) def _setContainerProperties ( self , containerList , ** kwargs ): try : for container in containerList : for kw in kwargs : container . setProp ( kw , kwargs [ kw ]) except Exception : return False def _getTimeStamp ( self ): utcnow = datetime . datetime . utcnow () ts = utcnow . strftime ( \"%Y-%m- %d :%H:%M:%S\" ) return ts def _getCategoryNameList ( self , container , lastInOrder = None , selectOrder = None ): \"\"\"Return an ordered list of categories in the input container subject to input category name lists. Args: container (DataContainer object): Input DataContainer object lastInOrder (list): names of categories to be shifted to the end of the container. selectOrder (list): preferred order of category names Returns: catNameList: list: augmented category list or full list (default) \"\"\" catNameList = [] if lastInOrder : objNameList = container . getObjNameList () lastList = [] for nm in objNameList : if nm in lastInOrder : lastList . append ( nm ) continue catNameList . append ( nm ) catNameList . extend ( lastList ) elif selectOrder : for nm in selectOrder : if container . exists ( nm ): catNameList . append ( nm ) else : catNameList = container . getObjNameList () return catNameList def _setLogFilePath ( self , filePath ): \"\"\"Set the log file path.\"\"\" self . __logFilePath = filePath def _getLogFilePath ( self ): \"\"\"Return current log file path.\"\"\" return self . __logFilePath def _appendToLog ( self , stList ): \"\"\"Append input string list to the current log file -\"\"\" if not self . __logFilePath : return False try : with open ( self . __logFilePath , \"a\" ) as ofh : ofh . write ( \" %s \\n \" % \" \\n \" . join ( stList )) return True except Exception as e : logger . debug ( \"Failing with %s \" , str ( e )) return True def _logError ( self , msg ): \"\"\"Convenience method to log error messages and optionally raise general exceptions (PdbxError).\"\"\" self . _appendToLog ([ msg ]) if self . _raiseExceptions : raise PdbxError ( msg ) else : logger . error ( msg ) def _readLogRecords ( self ): \"\"\"Return the contents of the current log file as list of strings.\"\"\" diagL = [] try : with open ( self . __logFilePath , \"r\" ) as ifh : for line in ifh : diagL . append ( line [: - 1 ]) except Exception as e : msg = \"No logfile found %s ( %s )\" % ( self . __logFilePath , str ( e )) diagL . append ( msg ) logger . debug ( msg ) return diagL def __getDiscriminator ( self ): \"\"\"Internal method returning a string which can discriminate among default file names -\"\"\" return str ( time . time () * 10000 ) . replace ( \".\" , \"_\" ) def _chooseTemporaryPath ( self , filePath , outDirPath = None ): \"\"\"Select a path for temporary files in the priority order outDirpath, directory containing the input filePath, current working directory, dynamically created temporary directory. These choices harmonize various legacy api behaviors. \"\"\" if outDirPath : return outDirPath # for oPath in [ os . path . dirname ( filePath ), \".\" , tempfile . gettempdir ()]: if os . access ( oPath , os . W_OK ): return oPath def _getDefaultFileName ( self , filePath , fileType = \"cif-parser\" , fileExt = \"log\" , outDirPath = None , verify = True ): \"\"\"Return default file path for the target input file subject to input attributes and the output path.\"\"\" returnFilePath = None try : _ , fn = os . path . split ( filePath ) bn , _ = os . path . splitext ( fn ) # ft = fileType if fileType else \"temp\" fex = fileExt if fileExt else \"tmp\" # sf = \"_\" + ft + \"_P\" + self . __getDiscriminator () + \".\" + fex # # pth = outDirPath if outDirPath else '.' pth = self . _chooseTemporaryPath ( filePath , outDirPath = outDirPath ) # if verify : # test if pth is actually writable ? Throw exception otherwise - # testfile = tempfile . TemporaryFile ( dir = pth ) testfile . close () # returnFilePath = os . path . join ( pth , bn + sf ) except Exception as e : if self . _raiseExceptions : raise e else : logger . error ( \"Failed creating default filename for %s type %s with %s \" , filePath , fileType , str ( e )) return returnFilePath def _fileExists ( self , filePath ): \"\"\"Verify that input file path exists and is readable.\"\"\" try : if not os . access ( filePath , os . R_OK ): msg = \"Missing file %r \" % filePath self . _appendToLog ([ msg ]) logger . error ( msg ) # if self . _raiseExceptions : raise PdbxError ( msg ) return False else : logger . debug ( \"Reading from file path %s \" , filePath ) return True except Exception as e : msg = \"File check error for %r with %s \" % ( filePath , str ( e )) self . _appendToLog ([ msg ]) if self . _raiseExceptions : raise PdbxError ( msg ) else : logger . error ( msg ) return False def _cleanupFile ( self , test , filePath ): \"\"\"Remove the input file path subject to the input test condition.\"\"\" try : if test : os . remove ( filePath ) except Exception : pass def _toAscii ( self , inputFilePath , outputFilePath , chunkSize = 5000 , encodingErrors = \"ignore\" , readEncodingErrors = \"ignore\" ): \"\"\"Encode input file to Ascii and write this to the target output file. Handle encoding errors according to the input settting ('ignore', 'escape', 'xmlcharrefreplace'). \"\"\" try : startTime = time . time () chunk = [] with io . open ( inputFilePath , \"r\" , encoding = \"utf-8\" , errors = readEncodingErrors ) as ifh , io . open ( outputFilePath , \"w\" , encoding = \"ascii\" ) as ofh : for line in ifh : # chunk.append(line.encode('ascii', 'xmlcharrefreplace').decode('ascii')) chunk . append ( line . encode ( \"ascii\" , encodingErrors ) . decode ( \"ascii\" )) if len ( chunk ) == chunkSize : ofh . writelines ( chunk ) chunk = [] ofh . writelines ( chunk ) if self . _timing : stepTime1 = time . time () logger . info ( \"Timing text file %s encoded to as ascii in %.4f seconds\" , inputFilePath , stepTime1 - startTime ) return True except Exception as e : msg = \"Failing text ascii encoding for %s with %s \" % ( inputFilePath , str ( e )) self . _appendToLog ([ msg ]) logger . error ( msg ) if self . _raiseExceptions : raise PdbxError ( msg ) # return False def _uncompress ( self , inputFilePath , outputDir ): \"\"\"Uncompress the input file if the path name has a recognized compression type file extension.file Return the file name of the uncompressed file (in outDir) or the original input file path. \"\"\" try : startTime = time . time () _ , fn = os . path . split ( inputFilePath ) bn , _ = os . path . splitext ( fn ) outputFilePath = os . path . join ( outputDir , bn ) if inputFilePath . endswith ( \".gz\" ): with gzip . open ( inputFilePath , mode = \"rb\" ) as inpF : with io . open ( outputFilePath , \"wb\" ) as outF : shutil . copyfileobj ( inpF , outF ) elif inputFilePath . endswith ( \".bz2\" ): with bz2 . open ( inputFilePath , mode = \"rb\" ) as inpF : with io . open ( outputFilePath , \"wb\" ) as outF : shutil . copyfileobj ( inpF , outF ) # elif inputFilePath.endswith(\".xz\"): # with lzma.open(inputFilePath, mode=\"rb\") as inpF: # with io.open(outputFilePath, \"wb\") as outF: # shutil.copyfileobj(inpF, outF) elif inputFilePath . endswith ( \".zip\" ): with zipfile . ZipFile ( inputFilePath , mode = \"rb\" ) as inpF : with io . open ( outputFilePath , \"wb\" ) as outF : shutil . copyfileobj ( inpF , outF ) else : outputFilePath = inputFilePath if self . _timing : stepTime1 = time . time () logger . info ( \"Timing text file %s uncompressed in %.4f seconds\" , inputFilePath , stepTime1 - startTime ) # except Exception as e : msg = \"Failing uncompress for file %s with %s \" % ( inputFilePath , str ( e )) self . _appendToLog ([ msg ]) logger . exception ( msg ) if self . _raiseExceptions : raise PdbxError ( msg ) logger . debug ( \"Returning file path %r \" , outputFilePath ) return outputFilePath","title":"IoAdapterBase"},{"location":"api_reference/IoAdapterBase/#mmcif.io.IoAdapterBase.IoAdapterBase-methods","text":"","title":"Methods"},{"location":"api_reference/IoAdapterBase/#mmcif.io.IoAdapterBase.IoAdapterBase.__init__","text":"General options controlling I/O method operations: Parameters: Name Type Description Default raiseExceptions bool Flag to indicate that API errors should generate exceptions (True) or catch and log errors (default=False) required maxInputLineLength int Default maximum input line length (default=4096) required useCharRefs bool Replace non-ascii characters with XML Character References (default=True) required readEncodingErrors str treatment of encoding errors at read time (default='ignore') required timing bool log timing details for parsing and processing steps (default=False) required verbose bool,optional log verbose output from wrapped libraries required Source code in mmcif/io/IoAdapterBase.py def __init__ ( self , * args , ** kwargs ): \"\"\"General options controlling I/O method operations: Args: raiseExceptions (bool, optional): Flag to indicate that API errors should generate exceptions (True) or catch and log errors (default=False) maxInputLineLength (int, optional): Default maximum input line length (default=4096) useCharRefs (bool, optional): Replace non-ascii characters with XML Character References (default=True) readEncodingErrors (str, optional): treatment of encoding errors at read time (default='ignore') timing (bool, optional): log timing details for parsing and processing steps (default=False) verbose (bool,optional): log verbose output from wrapped libraries \"\"\" _ = args self . _raiseExceptions = kwargs . get ( \"raiseExceptions\" , False ) self . _maxInputLineLength = kwargs . get ( \"maxInputLineLength\" , 4096 ) self . _useCharRefs = kwargs . get ( \"useCharRefs\" , True ) self . __logFilePath = None self . _debug = kwargs . get ( \"debug\" , False ) self . _timing = kwargs . get ( \"timing\" , False ) self . _verbose = kwargs . get ( \"verbose\" , True ) self . _readEncodingErrors = kwargs . get ( \"readEncodingErrors\" , \"ignore\" )","title":"__init__()"},{"location":"api_reference/IoAdapterBase/#mmcif.io.IoAdapterBase.IoAdapterBase.getReadDiags","text":"Return any diagnostics from the last read operation. (abstract) Source code in mmcif/io/IoAdapterBase.py def getReadDiags ( self ): \"\"\"Return any diagnostics from the last read operation. (abstract)\"\"\" raise NotImplementedError ( \"To be implemented in subclass\" )","title":"getReadDiags()"},{"location":"api_reference/IoAdapterBase/#mmcif.io.IoAdapterBase.IoAdapterBase.readFile","text":"Read file method. (abstract) Args: inputFilePath (string): Input file path/uri kw: optional key-value arguments Returns: Type Description list of DataContainer Objects list of data or definition container objects Source code in mmcif/io/IoAdapterBase.py def readFile ( self , * args , ** kwargs ): \"\"\"Read file method. (abstract) Args: inputFilePath (string): Input file path/uri kw: optional key-value arguments Returns: list of DataContainer Objects: list of data or definition container objects \"\"\" raise NotImplementedError ( \"To be implemented in subclass\" )","title":"readFile()"},{"location":"api_reference/IoAdapterBase/#mmcif.io.IoAdapterBase.IoAdapterBase.writeFile","text":"Write file method - (abstract) Parameters: Name Type Description Default outputFilePath string output file path required containerList list of DataContainer objects list of data or definition containers objects for output required Returns: Type Description bool Completion status Source code in mmcif/io/IoAdapterBase.py def writeFile ( self , outputFilePath , containerList , ** kwargs ): \"\"\"Write file method - (abstract) Args: outputFilePath (string): output file path containerList (list of DataContainer objects): list of data or definition containers objects for output Returns: bool: Completion status \"\"\" raise NotImplementedError ( \"To be implemented in subclass\" )","title":"writeFile()"},{"location":"api_reference/IoAdapterCore/","text":"mmcif.io.IoAdapterCore.IoAdapterCore ( IoAdapterBase ) Adapter between Python mmCIF API and Pybind11 wrappers for the PDB C++ Core mmCIF Library. Source code in mmcif/io/IoAdapterCore.py class IoAdapterCore ( IoAdapterBase ): \"\"\"Adapter between Python mmCIF API and Pybind11 wrappers for the PDB C++ Core mmCIF Library.\"\"\" # def __init__(self, *args, **kwargs): # super(IoAdapterCore, self).__init__(*args, **kwargs) # pylint: disable=arguments-differ def readFile ( self , inputFilePath , enforceAscii = True , selectList = None , excludeFlag = False , logFilePath = None , outDirPath = None , cleanUp = True , ** kwargs ): \"\"\"Parse the data blocks in the input mmCIF format data file into list of DataContainers(). The data category content within each data block is stored a collection of DataCategory objects within each DataContainer. Args: inputFilePath (string): Input file path enforceAscii (bool, optional): Flag to requiring pre-filtering operation to convert input file to ASCII encoding. See encoding error options. selectList (List, optional): List of data category names to be extracted or excluded from the input file (default: select/extract) excludeFlag (bool, optional): Flag to indicate selectList should be treated as an exclusion list logFilePath (string, optional): Log file path (if not provided this will be derived from the input file.) outDirPath (string, optional): Path for translated/reencoded files and default logfiles. cleanUp (bool, optional): Flag to automatically remove logs and temporary files on exit. **kwargs: Placeholder for missing keyword arguments. Returns: List of DataContainers: Contents of input file parsed into a list of DataContainer objects. \"\"\" if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) asciiFilePath = None filePath = str ( inputFilePath ) # oPath = outDirPath if outDirPath else '.' oPath = self . _chooseTemporaryPath ( inputFilePath , outDirPath = outDirPath ) try : # lPath = logFilePath if not lPath : lPath = self . _getDefaultFileName ( filePath , fileType = \"cif-parser-log\" , outDirPath = oPath ) # self . _setLogFilePath ( lPath ) # if not self . _fileExists ( filePath ): return [] # filePath = self . _uncompress ( filePath , oPath ) tPath = filePath if enforceAscii : asciiFilePath = self . _getDefaultFileName ( filePath , fileType = \"cif-parser-ascii\" , fileExt = \"cif\" , outDirPath = oPath ) encodingErrors = \"xmlcharrefreplace\" if self . _useCharRefs else \"ignore\" logger . debug ( \"Filtering input file to %s using encoding errors as %s \" , asciiFilePath , encodingErrors ) ok = self . _toAscii ( filePath , asciiFilePath , chunkSize = 5000 , encodingErrors = encodingErrors , readEncodingErrors = self . _readEncodingErrors ) if ok : tPath = asciiFilePath # readDef = None if selectList is not None and selectList : readDef = self . __getSelectionDef ( selectList , excludeFlag ) # containerL , _ = self . __readData ( tPath , readDef = readDef , cleanUp = cleanUp , logFilePath = lPath , maxLineLength = self . _maxInputLineLength ) # if cleanUp : self . _cleanupFile ( asciiFilePath , asciiFilePath ) self . _cleanupFile ( filePath != str ( inputFilePath ), filePath ) self . _setContainerProperties ( containerL , locator = str ( inputFilePath ), load_date = self . _getTimeStamp (), uid = uuid . uuid4 () . hex ) # return containerL except ( PdbxError , PdbxSyntaxError ) as ex : self . _cleanupFile ( asciiFilePath and cleanUp , asciiFilePath ) if self . _raiseExceptions : raise_from ( ex , None ) # raise ex from None except Exception as e : self . _cleanupFile ( asciiFilePath and cleanUp , asciiFilePath ) msg = \"Failing read for %s with %s \" % ( filePath , str ( e )) self . _logError ( msg ) return [] def getReadDiags ( self ): \"\"\"Recover the diagnostics for the previous readFile() operation.readFile Returns: list of strings: List of parsing and processing diagnostics from last readFile() operation \"\"\" return self . _readLogRecords () def __getSelectionDef ( self , selectList , excludeFlag ): \"\"\"Internal method to package selection/exclusion list for the C++ parser library. Returns: CifFileReadDef() object: object prepared for parsing library \"\"\" try : readDef = CifFileReadDef () if excludeFlag : readDef . SetCategoryList ( selectList , PdbxType . D ) else : readDef . SetCategoryList ( selectList , PdbxType . A ) return readDef except Exception as e : msg = \"Failing read selection with %s \" % str ( e ) self . _logError ( msg ) return None def __processReadLogFile ( self , inputFilePath ): \"\"\"Internal method to process logfiles and either log errors or raise exceptions (See: Class PdbxExceptions). The behavior is controlled by the class attribute _raiseExcetions. Returns: list of strings: List of records in the input log file \"\"\" diagL = self . _readLogRecords () # if diagL : numErrors = 0 numSyntaxErrors = 0 numWarnings = 0 for diag in diagL : if \"ERROR\" in diag : numErrors += 1 if \"WARN\" in diag : numWarnings += 1 if \"syntax\" in diag . lower (): numSyntaxErrors += 1 # logger . debug ( \" %s syntax errors %d warnings %d all errors %d \" , inputFilePath , numSyntaxErrors , numWarnings , numErrors ) # if numSyntaxErrors and self . _raiseExceptions : raise PdbxSyntaxError ( \" %s syntax errors %d all errors %d \" % ( inputFilePath , numSyntaxErrors , numErrors )) elif numErrors and self . _raiseExceptions : raise PdbxError ( \" %s error count is %d \" % ( inputFilePath , numErrors )) elif numErrors : logger . error ( \" %s syntax errors %d all errors %d \" , inputFilePath , numSyntaxErrors , numErrors ) if numWarnings : logger . warning ( \" %s warnings %d \" , inputFilePath , numWarnings ) return diagL def __processContent ( self , cifFileObj ): \"\"\"Internal method to transfer parsed data from the wrapped input C++ CifFile object into the list of Python DataContainer objects. Args: cifFileObj (wrapped CifFile object): Wrapped input C++ CifFile object Returns: list of DataContainer objects: List of Python DataContainer objects \"\"\" containerList = [] containerNameList = [] try : # ----- Repackage the data content ---- # containerList = [] containerNameList = [] containerNameList = list ( cifFileObj . GetBlockNames ( containerNameList )) for containerName in containerNameList : # aContainer = DataContainer ( containerName ) # block = cifFileObj . GetBlock ( containerName ) tableNameList = [] tableNameList = list ( block . GetTableNames ( tableNameList )) for tableName in tableNameList : table = block . GetTable ( tableName ) attributeNameList = list ( table . GetColumnNames ()) numRows = table . GetNumRows () rowList = [] for iRow in range ( 0 , numRows ): row = table . GetRow ( iRow ) # row = table.GetRow(iRow).decode('unicode_escape').encode('utf-8') # row = [p.encode('ascii', 'xmlcharrefreplace') for p in table.GetRow(iRow)] rowList . append ( list ( row )) aCategory = DataCategory ( tableName , attributeNameList , rowList , copyInputData = False , raiseExceptions = self . _raiseExceptions ) aContainer . append ( aCategory ) containerList . append ( aContainer ) except Exception as e : msg = \"Failing packaging with %s \" % str ( e ) self . _logError ( msg ) return containerList def __readData ( self , inputFilePath , readDef = None , maxLineLength = 1024 , logFilePath = None , cleanUp = False ): \"\"\"Internal method to read input file and return data as a list of DataContainer objects. readDef optionally contains a selection of data categories to be returned. Diagnostics will be written to logFilePath (persisted if cleanuUp=False). Args: inputFilePath (string): input file path readDef (CifFileReadDef object, optional): wrapped CifFileReadDef() object maxLineLength (int, optional): Maximum supported line length on input logFilePath (string, optional): Log file path cleanUp (bool, optional): Flag to remove temporary files on exit Returns: Tuple of lists : DataContainer List, Diagnostics (string) List \"\"\" # startTime = time . time () containerList = [] diagL = [] try : if readDef : cifFileObj = ParseCifSelective ( inputFilePath , readDef , verbose = self . _verbose , intCaseSense = 0 , maxLineLength = maxLineLength , nullValue = \"?\" , parseLogFileName = logFilePath ) else : cifFileObj = ParseCifSimple ( inputFilePath , verbose = self . _verbose , intCaseSense = 0 , maxLineLength = maxLineLength , nullValue = \"?\" , parseLogFileName = logFilePath ) # # --- Process/Handle read errors ---- # diagL = self . __processReadLogFile ( inputFilePath ) logger . debug ( \"Diagnostic count %d values %r \" , len ( diagL ), diagL ) # if self . _timing : stepTime1 = time . time () logger . info ( \"Timing parsed %r in %.4f seconds\" , inputFilePath , stepTime1 - startTime ) # containerList = self . __processContent ( cifFileObj ) # self . _cleanupFile ( cleanUp , logFilePath ) if self . _timing : stepTime2 = time . time () logger . info ( \"Timing api load in %.4f seconds read time %.4f seconds\" , stepTime2 - stepTime1 , stepTime2 - startTime ) # return containerList , diagL except ( PdbxError , PdbxSyntaxError ) as ex : self . _cleanupFile ( cleanUp , logFilePath ) if self . _raiseExceptions : raise_from ( ex , None ) except Exception as e : self . _cleanupFile ( cleanUp , logFilePath ) msg = \"Failing read for %s with %s \" % ( inputFilePath , str ( e )) self . _logError ( msg ) return containerList , diagL def writeFile ( self , outputFilePath , containerList = None , maxLineLength = 900 , enforceAscii = True , lastInOrder = None , selectOrder = None , ** kwargs ): \"\"\"Write input list of data containers to the specified output file path in mmCIF format. Args: outputFilePath (string): output file path containerList (list DataContainer objects, optional): maxLineLength (int, optional): Maximum length of output line (content is wrapped beyond this length) enforceAscii (bool, optional): Filter output (not implemented - content must be ascii compatible on input) lastInOrder (list of category names, optional): Move data categories in this list to end of each data block selectOrder (list of category names, optional): Write only data categories on this list. **kwargs: Placeholder for unsupported key value pairs Returns: bool: Completion status \"\"\" _ = enforceAscii lastInOrder = lastInOrder if lastInOrder else [ \"pdbx_nonpoly_scheme\" , \"pdbx_poly_seq_scheme\" , \"atom_site\" , \"atom_site_anisotrop\" ] containerL = containerList if containerList else [] if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) try : startTime = time . time () logger . debug ( \"write container length %d \" , len ( containerL )) # (CifFile args: placeholder, verbose: bool, caseSense: Char::eCompareType, maxLineLength: int, nullValue: str) cF = CifFile ( True , self . _verbose , 0 , maxLineLength , \"?\" ) for container in containerL : containerName = container . getName () logger . debug ( \"writing container %s \" , containerName ) cF . AddBlock ( containerName ) block = cF . GetBlock ( containerName ) # # objNameList = container.getObjNameList() # logger.debug(\"write category length %d\\n\" % len(objNameList)) # # Reorder/Filter - container object list- objNameList = container . filterObjectNameList ( lastInOrder = lastInOrder , selectOrder = selectOrder ) logger . debug ( \"write category names %r \" , objNameList ) # for objName in objNameList : name , attributeNameList , rowList = container . getObj ( objName ) . get () table = block . AddTable ( name ) for attributeName in attributeNameList : table . AddColumn ( attributeName ) try : rLen = len ( attributeNameList ) for ii , row in enumerate ( rowList ): table . AddRow () table . FillRow ( ii , [ str ( row [ jj ]) if row [ jj ] is not None else \"?\" for jj in range ( 0 , rLen )]) except Exception as e : logger . error ( \"Exception for %s preparing category %r ( %d ) attributes %r for writing %s \" , outputFilePath , name , len ( rowList ), attributeNameList , str ( e )) # block . WriteTable ( table ) # if self . _timing : stepTime1 = time . time () logger . info ( \"Timing %d container(s) api loaded in %.4f seconds\" , len ( containerL ), stepTime1 - startTime ) if self . _debug : self . __dumpBlocks ( cF ) cF . Write ( str ( outputFilePath )) if self . _timing : stepTime2 = time . time () logger . info ( \"Timing %d container(s) written in %.4f seconds total time %.4f \" , len ( containerList ), stepTime2 - stepTime1 , stepTime2 - startTime ) return True except Exception as e : msg = \"Write failing for file %s with %s \" % ( outputFilePath , str ( e )) self . _logError ( msg ) return False def __dumpBlocks ( self , cf ): \"\"\"Internal method to log the contents of the input wrapped CifFile object. Args: cf (CifFile object): wrapped CifFile object. \"\"\" try : logger . info ( \"cif file %r \" , cf ) blockNameList = [] blockNameList = cf . GetBlockNames ( blockNameList ) # logger . info ( \" block name list %r \" , repr ( blockNameList )) for blockName in blockNameList : # block = cf . GetBlock ( blockName ) tableNameList = [] tableNameList = list ( block . GetTableNames ( tableNameList )) logger . info ( \"tables name list %r \" , repr ( tableNameList )) for tableName in tableNameList : logger . info ( \"table name %r \" , tableName ) ok = block . IsTablePresent ( tableName ) logger . info ( \"table present %r \" , ok ) table = block . GetTable ( tableName ) attributeNameList = list ( table . GetColumnNames ()) logger . info ( \"Attribute name list %r \" , repr ( attributeNameList )) numRows = table . GetNumRows () logger . info ( \"row length %r \" , numRows ) for iRow in range ( 0 , numRows ): row = table . GetRow ( iRow ) logger . info ( \"Attribute name list %r \" , row ) except Exception as e : logger . exception ( \"dump failing with %s \" , str ( e )) Methods getReadDiags ( self ) Recover the diagnostics for the previous readFile() operation.readFile Returns: Type Description list of strings List of parsing and processing diagnostics from last readFile() operation Source code in mmcif/io/IoAdapterCore.py def getReadDiags ( self ): \"\"\"Recover the diagnostics for the previous readFile() operation.readFile Returns: list of strings: List of parsing and processing diagnostics from last readFile() operation \"\"\" return self . _readLogRecords () readFile ( self , inputFilePath , enforceAscii = True , selectList = None , excludeFlag = False , logFilePath = None , outDirPath = None , cleanUp = True , ** kwargs ) Parse the data blocks in the input mmCIF format data file into list of DataContainers(). The data category content within each data block is stored a collection of DataCategory objects within each DataContainer. Parameters: Name Type Description Default inputFilePath string Input file path required enforceAscii bool Flag to requiring pre-filtering operation to convert input file to ASCII encoding. See encoding error options. True selectList List List of data category names to be extracted or excluded from the input file (default: select/extract) None excludeFlag bool Flag to indicate selectList should be treated as an exclusion list False logFilePath string Log file path (if not provided this will be derived from the input file.) None outDirPath string Path for translated/reencoded files and default logfiles. None cleanUp bool Flag to automatically remove logs and temporary files on exit. True **kwargs Placeholder for missing keyword arguments. {} Returns: Type Description List of DataContainers Contents of input file parsed into a list of DataContainer objects. Source code in mmcif/io/IoAdapterCore.py def readFile ( self , inputFilePath , enforceAscii = True , selectList = None , excludeFlag = False , logFilePath = None , outDirPath = None , cleanUp = True , ** kwargs ): \"\"\"Parse the data blocks in the input mmCIF format data file into list of DataContainers(). The data category content within each data block is stored a collection of DataCategory objects within each DataContainer. Args: inputFilePath (string): Input file path enforceAscii (bool, optional): Flag to requiring pre-filtering operation to convert input file to ASCII encoding. See encoding error options. selectList (List, optional): List of data category names to be extracted or excluded from the input file (default: select/extract) excludeFlag (bool, optional): Flag to indicate selectList should be treated as an exclusion list logFilePath (string, optional): Log file path (if not provided this will be derived from the input file.) outDirPath (string, optional): Path for translated/reencoded files and default logfiles. cleanUp (bool, optional): Flag to automatically remove logs and temporary files on exit. **kwargs: Placeholder for missing keyword arguments. Returns: List of DataContainers: Contents of input file parsed into a list of DataContainer objects. \"\"\" if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) asciiFilePath = None filePath = str ( inputFilePath ) # oPath = outDirPath if outDirPath else '.' oPath = self . _chooseTemporaryPath ( inputFilePath , outDirPath = outDirPath ) try : # lPath = logFilePath if not lPath : lPath = self . _getDefaultFileName ( filePath , fileType = \"cif-parser-log\" , outDirPath = oPath ) # self . _setLogFilePath ( lPath ) # if not self . _fileExists ( filePath ): return [] # filePath = self . _uncompress ( filePath , oPath ) tPath = filePath if enforceAscii : asciiFilePath = self . _getDefaultFileName ( filePath , fileType = \"cif-parser-ascii\" , fileExt = \"cif\" , outDirPath = oPath ) encodingErrors = \"xmlcharrefreplace\" if self . _useCharRefs else \"ignore\" logger . debug ( \"Filtering input file to %s using encoding errors as %s \" , asciiFilePath , encodingErrors ) ok = self . _toAscii ( filePath , asciiFilePath , chunkSize = 5000 , encodingErrors = encodingErrors , readEncodingErrors = self . _readEncodingErrors ) if ok : tPath = asciiFilePath # readDef = None if selectList is not None and selectList : readDef = self . __getSelectionDef ( selectList , excludeFlag ) # containerL , _ = self . __readData ( tPath , readDef = readDef , cleanUp = cleanUp , logFilePath = lPath , maxLineLength = self . _maxInputLineLength ) # if cleanUp : self . _cleanupFile ( asciiFilePath , asciiFilePath ) self . _cleanupFile ( filePath != str ( inputFilePath ), filePath ) self . _setContainerProperties ( containerL , locator = str ( inputFilePath ), load_date = self . _getTimeStamp (), uid = uuid . uuid4 () . hex ) # return containerL except ( PdbxError , PdbxSyntaxError ) as ex : self . _cleanupFile ( asciiFilePath and cleanUp , asciiFilePath ) if self . _raiseExceptions : raise_from ( ex , None ) # raise ex from None except Exception as e : self . _cleanupFile ( asciiFilePath and cleanUp , asciiFilePath ) msg = \"Failing read for %s with %s \" % ( filePath , str ( e )) self . _logError ( msg ) return [] writeFile ( self , outputFilePath , containerList = None , maxLineLength = 900 , enforceAscii = True , lastInOrder = None , selectOrder = None , ** kwargs ) Write input list of data containers to the specified output file path in mmCIF format. Parameters: Name Type Description Default outputFilePath string output file path required containerList list DataContainer objects None maxLineLength int Maximum length of output line (content is wrapped beyond this length) 900 enforceAscii bool Filter output (not implemented - content must be ascii compatible on input) True lastInOrder list of category names Move data categories in this list to end of each data block None selectOrder list of category names Write only data categories on this list. None **kwargs Placeholder for unsupported key value pairs {} Returns: Type Description bool Completion status Source code in mmcif/io/IoAdapterCore.py def writeFile ( self , outputFilePath , containerList = None , maxLineLength = 900 , enforceAscii = True , lastInOrder = None , selectOrder = None , ** kwargs ): \"\"\"Write input list of data containers to the specified output file path in mmCIF format. Args: outputFilePath (string): output file path containerList (list DataContainer objects, optional): maxLineLength (int, optional): Maximum length of output line (content is wrapped beyond this length) enforceAscii (bool, optional): Filter output (not implemented - content must be ascii compatible on input) lastInOrder (list of category names, optional): Move data categories in this list to end of each data block selectOrder (list of category names, optional): Write only data categories on this list. **kwargs: Placeholder for unsupported key value pairs Returns: bool: Completion status \"\"\" _ = enforceAscii lastInOrder = lastInOrder if lastInOrder else [ \"pdbx_nonpoly_scheme\" , \"pdbx_poly_seq_scheme\" , \"atom_site\" , \"atom_site_anisotrop\" ] containerL = containerList if containerList else [] if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) try : startTime = time . time () logger . debug ( \"write container length %d \" , len ( containerL )) # (CifFile args: placeholder, verbose: bool, caseSense: Char::eCompareType, maxLineLength: int, nullValue: str) cF = CifFile ( True , self . _verbose , 0 , maxLineLength , \"?\" ) for container in containerL : containerName = container . getName () logger . debug ( \"writing container %s \" , containerName ) cF . AddBlock ( containerName ) block = cF . GetBlock ( containerName ) # # objNameList = container.getObjNameList() # logger.debug(\"write category length %d\\n\" % len(objNameList)) # # Reorder/Filter - container object list- objNameList = container . filterObjectNameList ( lastInOrder = lastInOrder , selectOrder = selectOrder ) logger . debug ( \"write category names %r \" , objNameList ) # for objName in objNameList : name , attributeNameList , rowList = container . getObj ( objName ) . get () table = block . AddTable ( name ) for attributeName in attributeNameList : table . AddColumn ( attributeName ) try : rLen = len ( attributeNameList ) for ii , row in enumerate ( rowList ): table . AddRow () table . FillRow ( ii , [ str ( row [ jj ]) if row [ jj ] is not None else \"?\" for jj in range ( 0 , rLen )]) except Exception as e : logger . error ( \"Exception for %s preparing category %r ( %d ) attributes %r for writing %s \" , outputFilePath , name , len ( rowList ), attributeNameList , str ( e )) # block . WriteTable ( table ) # if self . _timing : stepTime1 = time . time () logger . info ( \"Timing %d container(s) api loaded in %.4f seconds\" , len ( containerL ), stepTime1 - startTime ) if self . _debug : self . __dumpBlocks ( cF ) cF . Write ( str ( outputFilePath )) if self . _timing : stepTime2 = time . time () logger . info ( \"Timing %d container(s) written in %.4f seconds total time %.4f \" , len ( containerList ), stepTime2 - stepTime1 , stepTime2 - startTime ) return True except Exception as e : msg = \"Write failing for file %s with %s \" % ( outputFilePath , str ( e )) self . _logError ( msg ) return False","title":"IoAdapterCore"},{"location":"api_reference/IoAdapterCore/#mmcif.io.IoAdapterCore.IoAdapterCore","text":"Adapter between Python mmCIF API and Pybind11 wrappers for the PDB C++ Core mmCIF Library. Source code in mmcif/io/IoAdapterCore.py class IoAdapterCore ( IoAdapterBase ): \"\"\"Adapter between Python mmCIF API and Pybind11 wrappers for the PDB C++ Core mmCIF Library.\"\"\" # def __init__(self, *args, **kwargs): # super(IoAdapterCore, self).__init__(*args, **kwargs) # pylint: disable=arguments-differ def readFile ( self , inputFilePath , enforceAscii = True , selectList = None , excludeFlag = False , logFilePath = None , outDirPath = None , cleanUp = True , ** kwargs ): \"\"\"Parse the data blocks in the input mmCIF format data file into list of DataContainers(). The data category content within each data block is stored a collection of DataCategory objects within each DataContainer. Args: inputFilePath (string): Input file path enforceAscii (bool, optional): Flag to requiring pre-filtering operation to convert input file to ASCII encoding. See encoding error options. selectList (List, optional): List of data category names to be extracted or excluded from the input file (default: select/extract) excludeFlag (bool, optional): Flag to indicate selectList should be treated as an exclusion list logFilePath (string, optional): Log file path (if not provided this will be derived from the input file.) outDirPath (string, optional): Path for translated/reencoded files and default logfiles. cleanUp (bool, optional): Flag to automatically remove logs and temporary files on exit. **kwargs: Placeholder for missing keyword arguments. Returns: List of DataContainers: Contents of input file parsed into a list of DataContainer objects. \"\"\" if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) asciiFilePath = None filePath = str ( inputFilePath ) # oPath = outDirPath if outDirPath else '.' oPath = self . _chooseTemporaryPath ( inputFilePath , outDirPath = outDirPath ) try : # lPath = logFilePath if not lPath : lPath = self . _getDefaultFileName ( filePath , fileType = \"cif-parser-log\" , outDirPath = oPath ) # self . _setLogFilePath ( lPath ) # if not self . _fileExists ( filePath ): return [] # filePath = self . _uncompress ( filePath , oPath ) tPath = filePath if enforceAscii : asciiFilePath = self . _getDefaultFileName ( filePath , fileType = \"cif-parser-ascii\" , fileExt = \"cif\" , outDirPath = oPath ) encodingErrors = \"xmlcharrefreplace\" if self . _useCharRefs else \"ignore\" logger . debug ( \"Filtering input file to %s using encoding errors as %s \" , asciiFilePath , encodingErrors ) ok = self . _toAscii ( filePath , asciiFilePath , chunkSize = 5000 , encodingErrors = encodingErrors , readEncodingErrors = self . _readEncodingErrors ) if ok : tPath = asciiFilePath # readDef = None if selectList is not None and selectList : readDef = self . __getSelectionDef ( selectList , excludeFlag ) # containerL , _ = self . __readData ( tPath , readDef = readDef , cleanUp = cleanUp , logFilePath = lPath , maxLineLength = self . _maxInputLineLength ) # if cleanUp : self . _cleanupFile ( asciiFilePath , asciiFilePath ) self . _cleanupFile ( filePath != str ( inputFilePath ), filePath ) self . _setContainerProperties ( containerL , locator = str ( inputFilePath ), load_date = self . _getTimeStamp (), uid = uuid . uuid4 () . hex ) # return containerL except ( PdbxError , PdbxSyntaxError ) as ex : self . _cleanupFile ( asciiFilePath and cleanUp , asciiFilePath ) if self . _raiseExceptions : raise_from ( ex , None ) # raise ex from None except Exception as e : self . _cleanupFile ( asciiFilePath and cleanUp , asciiFilePath ) msg = \"Failing read for %s with %s \" % ( filePath , str ( e )) self . _logError ( msg ) return [] def getReadDiags ( self ): \"\"\"Recover the diagnostics for the previous readFile() operation.readFile Returns: list of strings: List of parsing and processing diagnostics from last readFile() operation \"\"\" return self . _readLogRecords () def __getSelectionDef ( self , selectList , excludeFlag ): \"\"\"Internal method to package selection/exclusion list for the C++ parser library. Returns: CifFileReadDef() object: object prepared for parsing library \"\"\" try : readDef = CifFileReadDef () if excludeFlag : readDef . SetCategoryList ( selectList , PdbxType . D ) else : readDef . SetCategoryList ( selectList , PdbxType . A ) return readDef except Exception as e : msg = \"Failing read selection with %s \" % str ( e ) self . _logError ( msg ) return None def __processReadLogFile ( self , inputFilePath ): \"\"\"Internal method to process logfiles and either log errors or raise exceptions (See: Class PdbxExceptions). The behavior is controlled by the class attribute _raiseExcetions. Returns: list of strings: List of records in the input log file \"\"\" diagL = self . _readLogRecords () # if diagL : numErrors = 0 numSyntaxErrors = 0 numWarnings = 0 for diag in diagL : if \"ERROR\" in diag : numErrors += 1 if \"WARN\" in diag : numWarnings += 1 if \"syntax\" in diag . lower (): numSyntaxErrors += 1 # logger . debug ( \" %s syntax errors %d warnings %d all errors %d \" , inputFilePath , numSyntaxErrors , numWarnings , numErrors ) # if numSyntaxErrors and self . _raiseExceptions : raise PdbxSyntaxError ( \" %s syntax errors %d all errors %d \" % ( inputFilePath , numSyntaxErrors , numErrors )) elif numErrors and self . _raiseExceptions : raise PdbxError ( \" %s error count is %d \" % ( inputFilePath , numErrors )) elif numErrors : logger . error ( \" %s syntax errors %d all errors %d \" , inputFilePath , numSyntaxErrors , numErrors ) if numWarnings : logger . warning ( \" %s warnings %d \" , inputFilePath , numWarnings ) return diagL def __processContent ( self , cifFileObj ): \"\"\"Internal method to transfer parsed data from the wrapped input C++ CifFile object into the list of Python DataContainer objects. Args: cifFileObj (wrapped CifFile object): Wrapped input C++ CifFile object Returns: list of DataContainer objects: List of Python DataContainer objects \"\"\" containerList = [] containerNameList = [] try : # ----- Repackage the data content ---- # containerList = [] containerNameList = [] containerNameList = list ( cifFileObj . GetBlockNames ( containerNameList )) for containerName in containerNameList : # aContainer = DataContainer ( containerName ) # block = cifFileObj . GetBlock ( containerName ) tableNameList = [] tableNameList = list ( block . GetTableNames ( tableNameList )) for tableName in tableNameList : table = block . GetTable ( tableName ) attributeNameList = list ( table . GetColumnNames ()) numRows = table . GetNumRows () rowList = [] for iRow in range ( 0 , numRows ): row = table . GetRow ( iRow ) # row = table.GetRow(iRow).decode('unicode_escape').encode('utf-8') # row = [p.encode('ascii', 'xmlcharrefreplace') for p in table.GetRow(iRow)] rowList . append ( list ( row )) aCategory = DataCategory ( tableName , attributeNameList , rowList , copyInputData = False , raiseExceptions = self . _raiseExceptions ) aContainer . append ( aCategory ) containerList . append ( aContainer ) except Exception as e : msg = \"Failing packaging with %s \" % str ( e ) self . _logError ( msg ) return containerList def __readData ( self , inputFilePath , readDef = None , maxLineLength = 1024 , logFilePath = None , cleanUp = False ): \"\"\"Internal method to read input file and return data as a list of DataContainer objects. readDef optionally contains a selection of data categories to be returned. Diagnostics will be written to logFilePath (persisted if cleanuUp=False). Args: inputFilePath (string): input file path readDef (CifFileReadDef object, optional): wrapped CifFileReadDef() object maxLineLength (int, optional): Maximum supported line length on input logFilePath (string, optional): Log file path cleanUp (bool, optional): Flag to remove temporary files on exit Returns: Tuple of lists : DataContainer List, Diagnostics (string) List \"\"\" # startTime = time . time () containerList = [] diagL = [] try : if readDef : cifFileObj = ParseCifSelective ( inputFilePath , readDef , verbose = self . _verbose , intCaseSense = 0 , maxLineLength = maxLineLength , nullValue = \"?\" , parseLogFileName = logFilePath ) else : cifFileObj = ParseCifSimple ( inputFilePath , verbose = self . _verbose , intCaseSense = 0 , maxLineLength = maxLineLength , nullValue = \"?\" , parseLogFileName = logFilePath ) # # --- Process/Handle read errors ---- # diagL = self . __processReadLogFile ( inputFilePath ) logger . debug ( \"Diagnostic count %d values %r \" , len ( diagL ), diagL ) # if self . _timing : stepTime1 = time . time () logger . info ( \"Timing parsed %r in %.4f seconds\" , inputFilePath , stepTime1 - startTime ) # containerList = self . __processContent ( cifFileObj ) # self . _cleanupFile ( cleanUp , logFilePath ) if self . _timing : stepTime2 = time . time () logger . info ( \"Timing api load in %.4f seconds read time %.4f seconds\" , stepTime2 - stepTime1 , stepTime2 - startTime ) # return containerList , diagL except ( PdbxError , PdbxSyntaxError ) as ex : self . _cleanupFile ( cleanUp , logFilePath ) if self . _raiseExceptions : raise_from ( ex , None ) except Exception as e : self . _cleanupFile ( cleanUp , logFilePath ) msg = \"Failing read for %s with %s \" % ( inputFilePath , str ( e )) self . _logError ( msg ) return containerList , diagL def writeFile ( self , outputFilePath , containerList = None , maxLineLength = 900 , enforceAscii = True , lastInOrder = None , selectOrder = None , ** kwargs ): \"\"\"Write input list of data containers to the specified output file path in mmCIF format. Args: outputFilePath (string): output file path containerList (list DataContainer objects, optional): maxLineLength (int, optional): Maximum length of output line (content is wrapped beyond this length) enforceAscii (bool, optional): Filter output (not implemented - content must be ascii compatible on input) lastInOrder (list of category names, optional): Move data categories in this list to end of each data block selectOrder (list of category names, optional): Write only data categories on this list. **kwargs: Placeholder for unsupported key value pairs Returns: bool: Completion status \"\"\" _ = enforceAscii lastInOrder = lastInOrder if lastInOrder else [ \"pdbx_nonpoly_scheme\" , \"pdbx_poly_seq_scheme\" , \"atom_site\" , \"atom_site_anisotrop\" ] containerL = containerList if containerList else [] if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) try : startTime = time . time () logger . debug ( \"write container length %d \" , len ( containerL )) # (CifFile args: placeholder, verbose: bool, caseSense: Char::eCompareType, maxLineLength: int, nullValue: str) cF = CifFile ( True , self . _verbose , 0 , maxLineLength , \"?\" ) for container in containerL : containerName = container . getName () logger . debug ( \"writing container %s \" , containerName ) cF . AddBlock ( containerName ) block = cF . GetBlock ( containerName ) # # objNameList = container.getObjNameList() # logger.debug(\"write category length %d\\n\" % len(objNameList)) # # Reorder/Filter - container object list- objNameList = container . filterObjectNameList ( lastInOrder = lastInOrder , selectOrder = selectOrder ) logger . debug ( \"write category names %r \" , objNameList ) # for objName in objNameList : name , attributeNameList , rowList = container . getObj ( objName ) . get () table = block . AddTable ( name ) for attributeName in attributeNameList : table . AddColumn ( attributeName ) try : rLen = len ( attributeNameList ) for ii , row in enumerate ( rowList ): table . AddRow () table . FillRow ( ii , [ str ( row [ jj ]) if row [ jj ] is not None else \"?\" for jj in range ( 0 , rLen )]) except Exception as e : logger . error ( \"Exception for %s preparing category %r ( %d ) attributes %r for writing %s \" , outputFilePath , name , len ( rowList ), attributeNameList , str ( e )) # block . WriteTable ( table ) # if self . _timing : stepTime1 = time . time () logger . info ( \"Timing %d container(s) api loaded in %.4f seconds\" , len ( containerL ), stepTime1 - startTime ) if self . _debug : self . __dumpBlocks ( cF ) cF . Write ( str ( outputFilePath )) if self . _timing : stepTime2 = time . time () logger . info ( \"Timing %d container(s) written in %.4f seconds total time %.4f \" , len ( containerList ), stepTime2 - stepTime1 , stepTime2 - startTime ) return True except Exception as e : msg = \"Write failing for file %s with %s \" % ( outputFilePath , str ( e )) self . _logError ( msg ) return False def __dumpBlocks ( self , cf ): \"\"\"Internal method to log the contents of the input wrapped CifFile object. Args: cf (CifFile object): wrapped CifFile object. \"\"\" try : logger . info ( \"cif file %r \" , cf ) blockNameList = [] blockNameList = cf . GetBlockNames ( blockNameList ) # logger . info ( \" block name list %r \" , repr ( blockNameList )) for blockName in blockNameList : # block = cf . GetBlock ( blockName ) tableNameList = [] tableNameList = list ( block . GetTableNames ( tableNameList )) logger . info ( \"tables name list %r \" , repr ( tableNameList )) for tableName in tableNameList : logger . info ( \"table name %r \" , tableName ) ok = block . IsTablePresent ( tableName ) logger . info ( \"table present %r \" , ok ) table = block . GetTable ( tableName ) attributeNameList = list ( table . GetColumnNames ()) logger . info ( \"Attribute name list %r \" , repr ( attributeNameList )) numRows = table . GetNumRows () logger . info ( \"row length %r \" , numRows ) for iRow in range ( 0 , numRows ): row = table . GetRow ( iRow ) logger . info ( \"Attribute name list %r \" , row ) except Exception as e : logger . exception ( \"dump failing with %s \" , str ( e ))","title":"IoAdapterCore"},{"location":"api_reference/IoAdapterCore/#mmcif.io.IoAdapterCore.IoAdapterCore-methods","text":"","title":"Methods"},{"location":"api_reference/IoAdapterCore/#mmcif.io.IoAdapterCore.IoAdapterCore.getReadDiags","text":"Recover the diagnostics for the previous readFile() operation.readFile Returns: Type Description list of strings List of parsing and processing diagnostics from last readFile() operation Source code in mmcif/io/IoAdapterCore.py def getReadDiags ( self ): \"\"\"Recover the diagnostics for the previous readFile() operation.readFile Returns: list of strings: List of parsing and processing diagnostics from last readFile() operation \"\"\" return self . _readLogRecords ()","title":"getReadDiags()"},{"location":"api_reference/IoAdapterCore/#mmcif.io.IoAdapterCore.IoAdapterCore.readFile","text":"Parse the data blocks in the input mmCIF format data file into list of DataContainers(). The data category content within each data block is stored a collection of DataCategory objects within each DataContainer. Parameters: Name Type Description Default inputFilePath string Input file path required enforceAscii bool Flag to requiring pre-filtering operation to convert input file to ASCII encoding. See encoding error options. True selectList List List of data category names to be extracted or excluded from the input file (default: select/extract) None excludeFlag bool Flag to indicate selectList should be treated as an exclusion list False logFilePath string Log file path (if not provided this will be derived from the input file.) None outDirPath string Path for translated/reencoded files and default logfiles. None cleanUp bool Flag to automatically remove logs and temporary files on exit. True **kwargs Placeholder for missing keyword arguments. {} Returns: Type Description List of DataContainers Contents of input file parsed into a list of DataContainer objects. Source code in mmcif/io/IoAdapterCore.py def readFile ( self , inputFilePath , enforceAscii = True , selectList = None , excludeFlag = False , logFilePath = None , outDirPath = None , cleanUp = True , ** kwargs ): \"\"\"Parse the data blocks in the input mmCIF format data file into list of DataContainers(). The data category content within each data block is stored a collection of DataCategory objects within each DataContainer. Args: inputFilePath (string): Input file path enforceAscii (bool, optional): Flag to requiring pre-filtering operation to convert input file to ASCII encoding. See encoding error options. selectList (List, optional): List of data category names to be extracted or excluded from the input file (default: select/extract) excludeFlag (bool, optional): Flag to indicate selectList should be treated as an exclusion list logFilePath (string, optional): Log file path (if not provided this will be derived from the input file.) outDirPath (string, optional): Path for translated/reencoded files and default logfiles. cleanUp (bool, optional): Flag to automatically remove logs and temporary files on exit. **kwargs: Placeholder for missing keyword arguments. Returns: List of DataContainers: Contents of input file parsed into a list of DataContainer objects. \"\"\" if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) asciiFilePath = None filePath = str ( inputFilePath ) # oPath = outDirPath if outDirPath else '.' oPath = self . _chooseTemporaryPath ( inputFilePath , outDirPath = outDirPath ) try : # lPath = logFilePath if not lPath : lPath = self . _getDefaultFileName ( filePath , fileType = \"cif-parser-log\" , outDirPath = oPath ) # self . _setLogFilePath ( lPath ) # if not self . _fileExists ( filePath ): return [] # filePath = self . _uncompress ( filePath , oPath ) tPath = filePath if enforceAscii : asciiFilePath = self . _getDefaultFileName ( filePath , fileType = \"cif-parser-ascii\" , fileExt = \"cif\" , outDirPath = oPath ) encodingErrors = \"xmlcharrefreplace\" if self . _useCharRefs else \"ignore\" logger . debug ( \"Filtering input file to %s using encoding errors as %s \" , asciiFilePath , encodingErrors ) ok = self . _toAscii ( filePath , asciiFilePath , chunkSize = 5000 , encodingErrors = encodingErrors , readEncodingErrors = self . _readEncodingErrors ) if ok : tPath = asciiFilePath # readDef = None if selectList is not None and selectList : readDef = self . __getSelectionDef ( selectList , excludeFlag ) # containerL , _ = self . __readData ( tPath , readDef = readDef , cleanUp = cleanUp , logFilePath = lPath , maxLineLength = self . _maxInputLineLength ) # if cleanUp : self . _cleanupFile ( asciiFilePath , asciiFilePath ) self . _cleanupFile ( filePath != str ( inputFilePath ), filePath ) self . _setContainerProperties ( containerL , locator = str ( inputFilePath ), load_date = self . _getTimeStamp (), uid = uuid . uuid4 () . hex ) # return containerL except ( PdbxError , PdbxSyntaxError ) as ex : self . _cleanupFile ( asciiFilePath and cleanUp , asciiFilePath ) if self . _raiseExceptions : raise_from ( ex , None ) # raise ex from None except Exception as e : self . _cleanupFile ( asciiFilePath and cleanUp , asciiFilePath ) msg = \"Failing read for %s with %s \" % ( filePath , str ( e )) self . _logError ( msg ) return []","title":"readFile()"},{"location":"api_reference/IoAdapterCore/#mmcif.io.IoAdapterCore.IoAdapterCore.writeFile","text":"Write input list of data containers to the specified output file path in mmCIF format. Parameters: Name Type Description Default outputFilePath string output file path required containerList list DataContainer objects None maxLineLength int Maximum length of output line (content is wrapped beyond this length) 900 enforceAscii bool Filter output (not implemented - content must be ascii compatible on input) True lastInOrder list of category names Move data categories in this list to end of each data block None selectOrder list of category names Write only data categories on this list. None **kwargs Placeholder for unsupported key value pairs {} Returns: Type Description bool Completion status Source code in mmcif/io/IoAdapterCore.py def writeFile ( self , outputFilePath , containerList = None , maxLineLength = 900 , enforceAscii = True , lastInOrder = None , selectOrder = None , ** kwargs ): \"\"\"Write input list of data containers to the specified output file path in mmCIF format. Args: outputFilePath (string): output file path containerList (list DataContainer objects, optional): maxLineLength (int, optional): Maximum length of output line (content is wrapped beyond this length) enforceAscii (bool, optional): Filter output (not implemented - content must be ascii compatible on input) lastInOrder (list of category names, optional): Move data categories in this list to end of each data block selectOrder (list of category names, optional): Write only data categories on this list. **kwargs: Placeholder for unsupported key value pairs Returns: bool: Completion status \"\"\" _ = enforceAscii lastInOrder = lastInOrder if lastInOrder else [ \"pdbx_nonpoly_scheme\" , \"pdbx_poly_seq_scheme\" , \"atom_site\" , \"atom_site_anisotrop\" ] containerL = containerList if containerList else [] if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) try : startTime = time . time () logger . debug ( \"write container length %d \" , len ( containerL )) # (CifFile args: placeholder, verbose: bool, caseSense: Char::eCompareType, maxLineLength: int, nullValue: str) cF = CifFile ( True , self . _verbose , 0 , maxLineLength , \"?\" ) for container in containerL : containerName = container . getName () logger . debug ( \"writing container %s \" , containerName ) cF . AddBlock ( containerName ) block = cF . GetBlock ( containerName ) # # objNameList = container.getObjNameList() # logger.debug(\"write category length %d\\n\" % len(objNameList)) # # Reorder/Filter - container object list- objNameList = container . filterObjectNameList ( lastInOrder = lastInOrder , selectOrder = selectOrder ) logger . debug ( \"write category names %r \" , objNameList ) # for objName in objNameList : name , attributeNameList , rowList = container . getObj ( objName ) . get () table = block . AddTable ( name ) for attributeName in attributeNameList : table . AddColumn ( attributeName ) try : rLen = len ( attributeNameList ) for ii , row in enumerate ( rowList ): table . AddRow () table . FillRow ( ii , [ str ( row [ jj ]) if row [ jj ] is not None else \"?\" for jj in range ( 0 , rLen )]) except Exception as e : logger . error ( \"Exception for %s preparing category %r ( %d ) attributes %r for writing %s \" , outputFilePath , name , len ( rowList ), attributeNameList , str ( e )) # block . WriteTable ( table ) # if self . _timing : stepTime1 = time . time () logger . info ( \"Timing %d container(s) api loaded in %.4f seconds\" , len ( containerL ), stepTime1 - startTime ) if self . _debug : self . __dumpBlocks ( cF ) cF . Write ( str ( outputFilePath )) if self . _timing : stepTime2 = time . time () logger . info ( \"Timing %d container(s) written in %.4f seconds total time %.4f \" , len ( containerList ), stepTime2 - stepTime1 , stepTime2 - startTime ) return True except Exception as e : msg = \"Write failing for file %s with %s \" % ( outputFilePath , str ( e )) self . _logError ( msg ) return False","title":"writeFile()"},{"location":"api_reference/IoAdapterPy/","text":"mmcif.io.IoAdapterPy.IoAdapterPy ( IoAdapterBase ) Python implementation of IoAdapterBase class providing essential read and write methods for mmCIF data files - Source code in mmcif/io/IoAdapterPy.py class IoAdapterPy ( IoAdapterBase ): \"\"\"Python implementation of IoAdapterBase class providing essential read and write methods for mmCIF data files -\"\"\" # def __init__(self, *args, **kwargs): # super(IoAdapterPy, self).__init__(*args, **kwargs) # pylint: disable=arguments-differ def readFile ( self , inputFilePath , enforceAscii = False , selectList = None , excludeFlag = False , logFilePath = None , outDirPath = None , cleanUp = False , ** kwargs ): \"\"\"Parse the data blocks in the input mmCIF format data file into list of data or definition containers. The data category content within each data block is stored a collection of DataCategory objects within each container. Args: inputFilePath (string): Input file path enforceAscii (bool, optional): Flag to requiring ASCII encoding. See encoding error options. selectList (List, optional): List of data category names to be extracted or excluded from the input file (default: select/extract) excludeFlag (bool, optional): Flag to indicate selectList should be treated as an exclusion list logFilePath (string, optional): Log file path (if not provided this will be derived from the input file.) outDirPath (string, optional): Path for translated/re-encoded files and default logfiles. cleanUp (bool, optional): Flag to automatically remove logs and temporary files on exit. **kwargs: Placeholder for missing keyword arguments. Returns: List of DataContainers: Contents of input file parsed into a list of DataContainer objects. \"\"\" if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) filePath = str ( inputFilePath ) # oPath = outDirPath if outDirPath else '.' oPath = self . _chooseTemporaryPath ( inputFilePath , outDirPath = outDirPath ) containerList = [] if enforceAscii : encoding = \"ascii\" else : encoding = \"utf-8\" try : # lPath = logFilePath if not lPath : lPath = self . _getDefaultFileName ( filePath , fileType = \"cif-parser-log\" , outDirPath = oPath ) # self . _setLogFilePath ( lPath ) # --- if self . __isLocal ( filePath ) and not self . _fileExists ( filePath ): return [] # if sys . version_info [ 0 ] > 2 : if self . __isLocal ( filePath ): filePath = self . _uncompress ( filePath , oPath ) with open ( filePath , \"r\" , encoding = encoding , errors = self . _readEncodingErrors ) as ifh : pRd = PdbxReader ( ifh ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : if filePath . endswith ( \".gz\" ): customHeader = { \"Accept-Encoding\" : \"gzip\" } with closing ( requests . get ( filePath , headers = customHeader )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () gzit = gzip . GzipFile ( fileobj = io . BytesIO ( ifh . content )) it = ( line . decode ( encoding , \"ignore\" ) for line in gzit ) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : with closing ( requests . get ( filePath )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () it = ( line . decode ( encoding , \"ignore\" ) + \" \\n \" for line in ifh . iter_lines ()) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : if self . __isLocal ( filePath ): filePath = self . _uncompress ( filePath , oPath ) if enforceAscii : with io . open ( filePath , \"r\" , encoding = encoding , errors = self . _readEncodingErrors ) as ifh : pRd = PdbxReader ( ifh ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : with open ( filePath , \"r\" ) as ifh : pRd = PdbxReader ( ifh ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : if filePath . endswith ( \".gz\" ): customHeader = { \"Accept-Encoding\" : \"gzip\" } with closing ( requests . get ( filePath , headers = customHeader )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () gzit = gzip . GzipFile ( fileobj = io . BytesIO ( ifh . content )) it = ( line . decode ( encoding , \"ignore\" ) for line in gzit ) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : with closing ( requests . get ( filePath )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () it = ( line . decode ( encoding , \"ignore\" ) + \" \\n \" for line in ifh . iter_lines ()) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) if cleanUp : self . _cleanupFile ( lPath , lPath ) self . _cleanupFile ( filePath != str ( inputFilePath ), filePath ) self . _setContainerProperties ( containerList , locator = str ( inputFilePath ), load_date = self . _getTimeStamp (), uid = uuid . uuid4 () . hex ) except ( PdbxError , PdbxSyntaxError ) as ex : msg = \"File %r with %s \" % ( filePath , str ( ex )) self . _appendToLog ([ msg ]) self . _cleanupFile ( lPath and cleanUp , lPath ) if self . _raiseExceptions : raise_from ( ex , None ) # raise ex from None except Exception as e : msg = \"File %r with %s \" % ( filePath , str ( e )) self . _appendToLog ([ msg ]) self . _cleanupFile ( lPath and cleanUp , lPath ) if self . _raiseExceptions : raise e else : logger . error ( \"Failing read for %s with %s \" , filePath , str ( e )) return containerList def getReadDiags ( self ): \"\"\"Return diagnostics from last readFile operation. This will NOT be an exhaustive list but rather the particular failure that raised a parsing exception. \"\"\" return self . _readLogRecords () def writeFile ( self , outputFilePath , containerList , maxLineLength = 900 , enforceAscii = True , lastInOrder = None , selectOrder = None , columnAlignFlag = True , useStopTokens = False , formattingStep = None , ** kwargs ): \"\"\"Write input list of data containers to the specified output file path in mmCIF format. Args: outputFilePath (string): output file path containerList (list DataContainer objects, optional) maxLineLength (int, optional): Maximum length of output line (content is wrapped beyond this length) enforceAscii (bool, optional): Filter output (not implemented - content must be ascii compatible on input) lastInOrder (list of category names, optional): Move data categories in this list to end of each data block selectOrder (list of category names, optional): Write only data categories on this list. columnAlignFlag (bool, optional): Format the output in aligned columns (default=True) (Native Python Only) useStopTokens (bool, optional): Include terminating 'stop_' tokens at the end of mmCIF categories (loop_'s) (Native Python only) formattingStep (int, optional): The number row samples within each category used to estimate maximum column width for data alignment (Native Python only) **kwargs: Placeholder for unsupported key value pairs Returns: bool: Completion status \"\"\" lastInOrder = lastInOrder if lastInOrder else [ \"pdbx_nonpoly_scheme\" , \"pdbx_poly_seq_scheme\" , \"atom_site\" , \"atom_site_anisotrop\" ] if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) try : if enforceAscii : encoding = \"ascii\" else : encoding = \"utf-8\" # if sys . version_info [ 0 ] > 2 : with open ( outputFilePath , \"w\" , encoding = encoding ) as ofh : self . __writeFile ( ofh , containerList , maxLineLength = maxLineLength , columnAlignFlag = columnAlignFlag , lastInOrder = lastInOrder , selectOrder = selectOrder , useStopTokens = useStopTokens , formattingStep = formattingStep , enforceAscii = enforceAscii , cnvCharRefs = self . _useCharRefs , ) else : if enforceAscii : with io . open ( outputFilePath , \"w\" , encoding = encoding ) as ofh : self . __writeFile ( ofh , containerList , maxLineLength = maxLineLength , columnAlignFlag = columnAlignFlag , lastInOrder = lastInOrder , selectOrder = selectOrder , useStopTokens = useStopTokens , formattingStep = formattingStep , enforceAscii = enforceAscii , cnvCharRefs = self . _useCharRefs , ) else : with open ( outputFilePath , \"wb\" ) as ofh : self . __writeFile ( ofh , containerList , maxLineLength = maxLineLength , columnAlignFlag = columnAlignFlag , lastInOrder = lastInOrder , selectOrder = selectOrder , useStopTokens = useStopTokens , formattingStep = formattingStep , enforceAscii = enforceAscii , cnvCharRefs = self . _useCharRefs , ) return True except Exception as ex : if self . _raiseExceptions : raise_from ( ex , None ) else : logger . exception ( \"Failing write for %s with %s \" , outputFilePath , str ( ex )) logger . error ( \"Failing write for %s with %s \" , outputFilePath , str ( ex )) return False def __writeFile ( self , ofh , containerList , maxLineLength = 900 , columnAlignFlag = True , lastInOrder = None , selectOrder = None , useStopTokens = False , formattingStep = None , enforceAscii = False , cnvCharRefs = False , ): \"\"\"Internal method mapping arguments to PDBxWriter API.\"\"\" # pdbxW = PdbxWriter ( ofh ) pdbxW . setUseStopTokens ( flag = useStopTokens ) pdbxW . setMaxLineLength ( numChars = maxLineLength ) pdbxW . setAlignmentFlag ( flag = columnAlignFlag ) pdbxW . setRowPartition ( numParts = formattingStep ) pdbxW . setConvertCharRefs ( flag = cnvCharRefs ) pdbxW . setSetEnforceAscii ( enforceAscii ) pdbxW . write ( containerList , lastInOrder = lastInOrder , selectOrder = selectOrder ) def __isLocal ( self , locator ): try : locSp = urlsplit ( locator ) return locSp . scheme in [ \"\" , \"file\" ] except Exception as e : logger . exception ( \"For locator %r failing with %s \" , locator , str ( e )) return None Methods getReadDiags ( self ) Return diagnostics from last readFile operation. This will NOT be an exhaustive list but rather the particular failure that raised a parsing exception. Source code in mmcif/io/IoAdapterPy.py def getReadDiags ( self ): \"\"\"Return diagnostics from last readFile operation. This will NOT be an exhaustive list but rather the particular failure that raised a parsing exception. \"\"\" return self . _readLogRecords () readFile ( self , inputFilePath , enforceAscii = False , selectList = None , excludeFlag = False , logFilePath = None , outDirPath = None , cleanUp = False , ** kwargs ) Parse the data blocks in the input mmCIF format data file into list of data or definition containers. The data category content within each data block is stored a collection of DataCategory objects within each container. Parameters: Name Type Description Default inputFilePath string Input file path required enforceAscii bool Flag to requiring ASCII encoding. See encoding error options. False selectList List List of data category names to be extracted or excluded from the input file (default: select/extract) None excludeFlag bool Flag to indicate selectList should be treated as an exclusion list False logFilePath string Log file path (if not provided this will be derived from the input file.) None outDirPath string Path for translated/re-encoded files and default logfiles. None cleanUp bool Flag to automatically remove logs and temporary files on exit. False **kwargs Placeholder for missing keyword arguments. {} Returns: Type Description List of DataContainers Contents of input file parsed into a list of DataContainer objects. Source code in mmcif/io/IoAdapterPy.py def readFile ( self , inputFilePath , enforceAscii = False , selectList = None , excludeFlag = False , logFilePath = None , outDirPath = None , cleanUp = False , ** kwargs ): \"\"\"Parse the data blocks in the input mmCIF format data file into list of data or definition containers. The data category content within each data block is stored a collection of DataCategory objects within each container. Args: inputFilePath (string): Input file path enforceAscii (bool, optional): Flag to requiring ASCII encoding. See encoding error options. selectList (List, optional): List of data category names to be extracted or excluded from the input file (default: select/extract) excludeFlag (bool, optional): Flag to indicate selectList should be treated as an exclusion list logFilePath (string, optional): Log file path (if not provided this will be derived from the input file.) outDirPath (string, optional): Path for translated/re-encoded files and default logfiles. cleanUp (bool, optional): Flag to automatically remove logs and temporary files on exit. **kwargs: Placeholder for missing keyword arguments. Returns: List of DataContainers: Contents of input file parsed into a list of DataContainer objects. \"\"\" if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) filePath = str ( inputFilePath ) # oPath = outDirPath if outDirPath else '.' oPath = self . _chooseTemporaryPath ( inputFilePath , outDirPath = outDirPath ) containerList = [] if enforceAscii : encoding = \"ascii\" else : encoding = \"utf-8\" try : # lPath = logFilePath if not lPath : lPath = self . _getDefaultFileName ( filePath , fileType = \"cif-parser-log\" , outDirPath = oPath ) # self . _setLogFilePath ( lPath ) # --- if self . __isLocal ( filePath ) and not self . _fileExists ( filePath ): return [] # if sys . version_info [ 0 ] > 2 : if self . __isLocal ( filePath ): filePath = self . _uncompress ( filePath , oPath ) with open ( filePath , \"r\" , encoding = encoding , errors = self . _readEncodingErrors ) as ifh : pRd = PdbxReader ( ifh ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : if filePath . endswith ( \".gz\" ): customHeader = { \"Accept-Encoding\" : \"gzip\" } with closing ( requests . get ( filePath , headers = customHeader )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () gzit = gzip . GzipFile ( fileobj = io . BytesIO ( ifh . content )) it = ( line . decode ( encoding , \"ignore\" ) for line in gzit ) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : with closing ( requests . get ( filePath )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () it = ( line . decode ( encoding , \"ignore\" ) + \" \\n \" for line in ifh . iter_lines ()) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : if self . __isLocal ( filePath ): filePath = self . _uncompress ( filePath , oPath ) if enforceAscii : with io . open ( filePath , \"r\" , encoding = encoding , errors = self . _readEncodingErrors ) as ifh : pRd = PdbxReader ( ifh ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : with open ( filePath , \"r\" ) as ifh : pRd = PdbxReader ( ifh ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : if filePath . endswith ( \".gz\" ): customHeader = { \"Accept-Encoding\" : \"gzip\" } with closing ( requests . get ( filePath , headers = customHeader )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () gzit = gzip . GzipFile ( fileobj = io . BytesIO ( ifh . content )) it = ( line . decode ( encoding , \"ignore\" ) for line in gzit ) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : with closing ( requests . get ( filePath )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () it = ( line . decode ( encoding , \"ignore\" ) + \" \\n \" for line in ifh . iter_lines ()) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) if cleanUp : self . _cleanupFile ( lPath , lPath ) self . _cleanupFile ( filePath != str ( inputFilePath ), filePath ) self . _setContainerProperties ( containerList , locator = str ( inputFilePath ), load_date = self . _getTimeStamp (), uid = uuid . uuid4 () . hex ) except ( PdbxError , PdbxSyntaxError ) as ex : msg = \"File %r with %s \" % ( filePath , str ( ex )) self . _appendToLog ([ msg ]) self . _cleanupFile ( lPath and cleanUp , lPath ) if self . _raiseExceptions : raise_from ( ex , None ) # raise ex from None except Exception as e : msg = \"File %r with %s \" % ( filePath , str ( e )) self . _appendToLog ([ msg ]) self . _cleanupFile ( lPath and cleanUp , lPath ) if self . _raiseExceptions : raise e else : logger . error ( \"Failing read for %s with %s \" , filePath , str ( e )) return containerList writeFile ( self , outputFilePath , containerList , maxLineLength = 900 , enforceAscii = True , lastInOrder = None , selectOrder = None , columnAlignFlag = True , useStopTokens = False , formattingStep = None , ** kwargs ) Write input list of data containers to the specified output file path in mmCIF format. Parameters: Name Type Description Default outputFilePath string output file path required maxLineLength int Maximum length of output line (content is wrapped beyond this length) 900 enforceAscii bool Filter output (not implemented - content must be ascii compatible on input) True lastInOrder list of category names Move data categories in this list to end of each data block None selectOrder list of category names Write only data categories on this list. None columnAlignFlag bool Format the output in aligned columns (default=True) (Native Python Only) True useStopTokens bool Include terminating 'stop_' tokens at the end of mmCIF categories (loop_'s) (Native Python only) False formattingStep int The number row samples within each category used to estimate maximum column width for data alignment (Native Python only) None **kwargs Placeholder for unsupported key value pairs {} Returns: Type Description bool Completion status Source code in mmcif/io/IoAdapterPy.py def writeFile ( self , outputFilePath , containerList , maxLineLength = 900 , enforceAscii = True , lastInOrder = None , selectOrder = None , columnAlignFlag = True , useStopTokens = False , formattingStep = None , ** kwargs ): \"\"\"Write input list of data containers to the specified output file path in mmCIF format. Args: outputFilePath (string): output file path containerList (list DataContainer objects, optional) maxLineLength (int, optional): Maximum length of output line (content is wrapped beyond this length) enforceAscii (bool, optional): Filter output (not implemented - content must be ascii compatible on input) lastInOrder (list of category names, optional): Move data categories in this list to end of each data block selectOrder (list of category names, optional): Write only data categories on this list. columnAlignFlag (bool, optional): Format the output in aligned columns (default=True) (Native Python Only) useStopTokens (bool, optional): Include terminating 'stop_' tokens at the end of mmCIF categories (loop_'s) (Native Python only) formattingStep (int, optional): The number row samples within each category used to estimate maximum column width for data alignment (Native Python only) **kwargs: Placeholder for unsupported key value pairs Returns: bool: Completion status \"\"\" lastInOrder = lastInOrder if lastInOrder else [ \"pdbx_nonpoly_scheme\" , \"pdbx_poly_seq_scheme\" , \"atom_site\" , \"atom_site_anisotrop\" ] if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) try : if enforceAscii : encoding = \"ascii\" else : encoding = \"utf-8\" # if sys . version_info [ 0 ] > 2 : with open ( outputFilePath , \"w\" , encoding = encoding ) as ofh : self . __writeFile ( ofh , containerList , maxLineLength = maxLineLength , columnAlignFlag = columnAlignFlag , lastInOrder = lastInOrder , selectOrder = selectOrder , useStopTokens = useStopTokens , formattingStep = formattingStep , enforceAscii = enforceAscii , cnvCharRefs = self . _useCharRefs , ) else : if enforceAscii : with io . open ( outputFilePath , \"w\" , encoding = encoding ) as ofh : self . __writeFile ( ofh , containerList , maxLineLength = maxLineLength , columnAlignFlag = columnAlignFlag , lastInOrder = lastInOrder , selectOrder = selectOrder , useStopTokens = useStopTokens , formattingStep = formattingStep , enforceAscii = enforceAscii , cnvCharRefs = self . _useCharRefs , ) else : with open ( outputFilePath , \"wb\" ) as ofh : self . __writeFile ( ofh , containerList , maxLineLength = maxLineLength , columnAlignFlag = columnAlignFlag , lastInOrder = lastInOrder , selectOrder = selectOrder , useStopTokens = useStopTokens , formattingStep = formattingStep , enforceAscii = enforceAscii , cnvCharRefs = self . _useCharRefs , ) return True except Exception as ex : if self . _raiseExceptions : raise_from ( ex , None ) else : logger . exception ( \"Failing write for %s with %s \" , outputFilePath , str ( ex )) logger . error ( \"Failing write for %s with %s \" , outputFilePath , str ( ex )) return False","title":"IoAdapterPy"},{"location":"api_reference/IoAdapterPy/#mmcif.io.IoAdapterPy.IoAdapterPy","text":"Python implementation of IoAdapterBase class providing essential read and write methods for mmCIF data files - Source code in mmcif/io/IoAdapterPy.py class IoAdapterPy ( IoAdapterBase ): \"\"\"Python implementation of IoAdapterBase class providing essential read and write methods for mmCIF data files -\"\"\" # def __init__(self, *args, **kwargs): # super(IoAdapterPy, self).__init__(*args, **kwargs) # pylint: disable=arguments-differ def readFile ( self , inputFilePath , enforceAscii = False , selectList = None , excludeFlag = False , logFilePath = None , outDirPath = None , cleanUp = False , ** kwargs ): \"\"\"Parse the data blocks in the input mmCIF format data file into list of data or definition containers. The data category content within each data block is stored a collection of DataCategory objects within each container. Args: inputFilePath (string): Input file path enforceAscii (bool, optional): Flag to requiring ASCII encoding. See encoding error options. selectList (List, optional): List of data category names to be extracted or excluded from the input file (default: select/extract) excludeFlag (bool, optional): Flag to indicate selectList should be treated as an exclusion list logFilePath (string, optional): Log file path (if not provided this will be derived from the input file.) outDirPath (string, optional): Path for translated/re-encoded files and default logfiles. cleanUp (bool, optional): Flag to automatically remove logs and temporary files on exit. **kwargs: Placeholder for missing keyword arguments. Returns: List of DataContainers: Contents of input file parsed into a list of DataContainer objects. \"\"\" if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) filePath = str ( inputFilePath ) # oPath = outDirPath if outDirPath else '.' oPath = self . _chooseTemporaryPath ( inputFilePath , outDirPath = outDirPath ) containerList = [] if enforceAscii : encoding = \"ascii\" else : encoding = \"utf-8\" try : # lPath = logFilePath if not lPath : lPath = self . _getDefaultFileName ( filePath , fileType = \"cif-parser-log\" , outDirPath = oPath ) # self . _setLogFilePath ( lPath ) # --- if self . __isLocal ( filePath ) and not self . _fileExists ( filePath ): return [] # if sys . version_info [ 0 ] > 2 : if self . __isLocal ( filePath ): filePath = self . _uncompress ( filePath , oPath ) with open ( filePath , \"r\" , encoding = encoding , errors = self . _readEncodingErrors ) as ifh : pRd = PdbxReader ( ifh ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : if filePath . endswith ( \".gz\" ): customHeader = { \"Accept-Encoding\" : \"gzip\" } with closing ( requests . get ( filePath , headers = customHeader )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () gzit = gzip . GzipFile ( fileobj = io . BytesIO ( ifh . content )) it = ( line . decode ( encoding , \"ignore\" ) for line in gzit ) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : with closing ( requests . get ( filePath )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () it = ( line . decode ( encoding , \"ignore\" ) + \" \\n \" for line in ifh . iter_lines ()) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : if self . __isLocal ( filePath ): filePath = self . _uncompress ( filePath , oPath ) if enforceAscii : with io . open ( filePath , \"r\" , encoding = encoding , errors = self . _readEncodingErrors ) as ifh : pRd = PdbxReader ( ifh ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : with open ( filePath , \"r\" ) as ifh : pRd = PdbxReader ( ifh ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : if filePath . endswith ( \".gz\" ): customHeader = { \"Accept-Encoding\" : \"gzip\" } with closing ( requests . get ( filePath , headers = customHeader )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () gzit = gzip . GzipFile ( fileobj = io . BytesIO ( ifh . content )) it = ( line . decode ( encoding , \"ignore\" ) for line in gzit ) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : with closing ( requests . get ( filePath )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () it = ( line . decode ( encoding , \"ignore\" ) + \" \\n \" for line in ifh . iter_lines ()) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) if cleanUp : self . _cleanupFile ( lPath , lPath ) self . _cleanupFile ( filePath != str ( inputFilePath ), filePath ) self . _setContainerProperties ( containerList , locator = str ( inputFilePath ), load_date = self . _getTimeStamp (), uid = uuid . uuid4 () . hex ) except ( PdbxError , PdbxSyntaxError ) as ex : msg = \"File %r with %s \" % ( filePath , str ( ex )) self . _appendToLog ([ msg ]) self . _cleanupFile ( lPath and cleanUp , lPath ) if self . _raiseExceptions : raise_from ( ex , None ) # raise ex from None except Exception as e : msg = \"File %r with %s \" % ( filePath , str ( e )) self . _appendToLog ([ msg ]) self . _cleanupFile ( lPath and cleanUp , lPath ) if self . _raiseExceptions : raise e else : logger . error ( \"Failing read for %s with %s \" , filePath , str ( e )) return containerList def getReadDiags ( self ): \"\"\"Return diagnostics from last readFile operation. This will NOT be an exhaustive list but rather the particular failure that raised a parsing exception. \"\"\" return self . _readLogRecords () def writeFile ( self , outputFilePath , containerList , maxLineLength = 900 , enforceAscii = True , lastInOrder = None , selectOrder = None , columnAlignFlag = True , useStopTokens = False , formattingStep = None , ** kwargs ): \"\"\"Write input list of data containers to the specified output file path in mmCIF format. Args: outputFilePath (string): output file path containerList (list DataContainer objects, optional) maxLineLength (int, optional): Maximum length of output line (content is wrapped beyond this length) enforceAscii (bool, optional): Filter output (not implemented - content must be ascii compatible on input) lastInOrder (list of category names, optional): Move data categories in this list to end of each data block selectOrder (list of category names, optional): Write only data categories on this list. columnAlignFlag (bool, optional): Format the output in aligned columns (default=True) (Native Python Only) useStopTokens (bool, optional): Include terminating 'stop_' tokens at the end of mmCIF categories (loop_'s) (Native Python only) formattingStep (int, optional): The number row samples within each category used to estimate maximum column width for data alignment (Native Python only) **kwargs: Placeholder for unsupported key value pairs Returns: bool: Completion status \"\"\" lastInOrder = lastInOrder if lastInOrder else [ \"pdbx_nonpoly_scheme\" , \"pdbx_poly_seq_scheme\" , \"atom_site\" , \"atom_site_anisotrop\" ] if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) try : if enforceAscii : encoding = \"ascii\" else : encoding = \"utf-8\" # if sys . version_info [ 0 ] > 2 : with open ( outputFilePath , \"w\" , encoding = encoding ) as ofh : self . __writeFile ( ofh , containerList , maxLineLength = maxLineLength , columnAlignFlag = columnAlignFlag , lastInOrder = lastInOrder , selectOrder = selectOrder , useStopTokens = useStopTokens , formattingStep = formattingStep , enforceAscii = enforceAscii , cnvCharRefs = self . _useCharRefs , ) else : if enforceAscii : with io . open ( outputFilePath , \"w\" , encoding = encoding ) as ofh : self . __writeFile ( ofh , containerList , maxLineLength = maxLineLength , columnAlignFlag = columnAlignFlag , lastInOrder = lastInOrder , selectOrder = selectOrder , useStopTokens = useStopTokens , formattingStep = formattingStep , enforceAscii = enforceAscii , cnvCharRefs = self . _useCharRefs , ) else : with open ( outputFilePath , \"wb\" ) as ofh : self . __writeFile ( ofh , containerList , maxLineLength = maxLineLength , columnAlignFlag = columnAlignFlag , lastInOrder = lastInOrder , selectOrder = selectOrder , useStopTokens = useStopTokens , formattingStep = formattingStep , enforceAscii = enforceAscii , cnvCharRefs = self . _useCharRefs , ) return True except Exception as ex : if self . _raiseExceptions : raise_from ( ex , None ) else : logger . exception ( \"Failing write for %s with %s \" , outputFilePath , str ( ex )) logger . error ( \"Failing write for %s with %s \" , outputFilePath , str ( ex )) return False def __writeFile ( self , ofh , containerList , maxLineLength = 900 , columnAlignFlag = True , lastInOrder = None , selectOrder = None , useStopTokens = False , formattingStep = None , enforceAscii = False , cnvCharRefs = False , ): \"\"\"Internal method mapping arguments to PDBxWriter API.\"\"\" # pdbxW = PdbxWriter ( ofh ) pdbxW . setUseStopTokens ( flag = useStopTokens ) pdbxW . setMaxLineLength ( numChars = maxLineLength ) pdbxW . setAlignmentFlag ( flag = columnAlignFlag ) pdbxW . setRowPartition ( numParts = formattingStep ) pdbxW . setConvertCharRefs ( flag = cnvCharRefs ) pdbxW . setSetEnforceAscii ( enforceAscii ) pdbxW . write ( containerList , lastInOrder = lastInOrder , selectOrder = selectOrder ) def __isLocal ( self , locator ): try : locSp = urlsplit ( locator ) return locSp . scheme in [ \"\" , \"file\" ] except Exception as e : logger . exception ( \"For locator %r failing with %s \" , locator , str ( e )) return None","title":"IoAdapterPy"},{"location":"api_reference/IoAdapterPy/#mmcif.io.IoAdapterPy.IoAdapterPy-methods","text":"","title":"Methods"},{"location":"api_reference/IoAdapterPy/#mmcif.io.IoAdapterPy.IoAdapterPy.getReadDiags","text":"Return diagnostics from last readFile operation. This will NOT be an exhaustive list but rather the particular failure that raised a parsing exception. Source code in mmcif/io/IoAdapterPy.py def getReadDiags ( self ): \"\"\"Return diagnostics from last readFile operation. This will NOT be an exhaustive list but rather the particular failure that raised a parsing exception. \"\"\" return self . _readLogRecords ()","title":"getReadDiags()"},{"location":"api_reference/IoAdapterPy/#mmcif.io.IoAdapterPy.IoAdapterPy.readFile","text":"Parse the data blocks in the input mmCIF format data file into list of data or definition containers. The data category content within each data block is stored a collection of DataCategory objects within each container. Parameters: Name Type Description Default inputFilePath string Input file path required enforceAscii bool Flag to requiring ASCII encoding. See encoding error options. False selectList List List of data category names to be extracted or excluded from the input file (default: select/extract) None excludeFlag bool Flag to indicate selectList should be treated as an exclusion list False logFilePath string Log file path (if not provided this will be derived from the input file.) None outDirPath string Path for translated/re-encoded files and default logfiles. None cleanUp bool Flag to automatically remove logs and temporary files on exit. False **kwargs Placeholder for missing keyword arguments. {} Returns: Type Description List of DataContainers Contents of input file parsed into a list of DataContainer objects. Source code in mmcif/io/IoAdapterPy.py def readFile ( self , inputFilePath , enforceAscii = False , selectList = None , excludeFlag = False , logFilePath = None , outDirPath = None , cleanUp = False , ** kwargs ): \"\"\"Parse the data blocks in the input mmCIF format data file into list of data or definition containers. The data category content within each data block is stored a collection of DataCategory objects within each container. Args: inputFilePath (string): Input file path enforceAscii (bool, optional): Flag to requiring ASCII encoding. See encoding error options. selectList (List, optional): List of data category names to be extracted or excluded from the input file (default: select/extract) excludeFlag (bool, optional): Flag to indicate selectList should be treated as an exclusion list logFilePath (string, optional): Log file path (if not provided this will be derived from the input file.) outDirPath (string, optional): Path for translated/re-encoded files and default logfiles. cleanUp (bool, optional): Flag to automatically remove logs and temporary files on exit. **kwargs: Placeholder for missing keyword arguments. Returns: List of DataContainers: Contents of input file parsed into a list of DataContainer objects. \"\"\" if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) filePath = str ( inputFilePath ) # oPath = outDirPath if outDirPath else '.' oPath = self . _chooseTemporaryPath ( inputFilePath , outDirPath = outDirPath ) containerList = [] if enforceAscii : encoding = \"ascii\" else : encoding = \"utf-8\" try : # lPath = logFilePath if not lPath : lPath = self . _getDefaultFileName ( filePath , fileType = \"cif-parser-log\" , outDirPath = oPath ) # self . _setLogFilePath ( lPath ) # --- if self . __isLocal ( filePath ) and not self . _fileExists ( filePath ): return [] # if sys . version_info [ 0 ] > 2 : if self . __isLocal ( filePath ): filePath = self . _uncompress ( filePath , oPath ) with open ( filePath , \"r\" , encoding = encoding , errors = self . _readEncodingErrors ) as ifh : pRd = PdbxReader ( ifh ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : if filePath . endswith ( \".gz\" ): customHeader = { \"Accept-Encoding\" : \"gzip\" } with closing ( requests . get ( filePath , headers = customHeader )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () gzit = gzip . GzipFile ( fileobj = io . BytesIO ( ifh . content )) it = ( line . decode ( encoding , \"ignore\" ) for line in gzit ) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : with closing ( requests . get ( filePath )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () it = ( line . decode ( encoding , \"ignore\" ) + \" \\n \" for line in ifh . iter_lines ()) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : if self . __isLocal ( filePath ): filePath = self . _uncompress ( filePath , oPath ) if enforceAscii : with io . open ( filePath , \"r\" , encoding = encoding , errors = self . _readEncodingErrors ) as ifh : pRd = PdbxReader ( ifh ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : with open ( filePath , \"r\" ) as ifh : pRd = PdbxReader ( ifh ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : if filePath . endswith ( \".gz\" ): customHeader = { \"Accept-Encoding\" : \"gzip\" } with closing ( requests . get ( filePath , headers = customHeader )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () gzit = gzip . GzipFile ( fileobj = io . BytesIO ( ifh . content )) it = ( line . decode ( encoding , \"ignore\" ) for line in gzit ) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) else : with closing ( requests . get ( filePath )) as ifh : if self . _raiseExceptions : ifh . raise_for_status () it = ( line . decode ( encoding , \"ignore\" ) + \" \\n \" for line in ifh . iter_lines ()) pRd = PdbxReader ( it ) pRd . read ( containerList , selectList , excludeFlag = excludeFlag ) if cleanUp : self . _cleanupFile ( lPath , lPath ) self . _cleanupFile ( filePath != str ( inputFilePath ), filePath ) self . _setContainerProperties ( containerList , locator = str ( inputFilePath ), load_date = self . _getTimeStamp (), uid = uuid . uuid4 () . hex ) except ( PdbxError , PdbxSyntaxError ) as ex : msg = \"File %r with %s \" % ( filePath , str ( ex )) self . _appendToLog ([ msg ]) self . _cleanupFile ( lPath and cleanUp , lPath ) if self . _raiseExceptions : raise_from ( ex , None ) # raise ex from None except Exception as e : msg = \"File %r with %s \" % ( filePath , str ( e )) self . _appendToLog ([ msg ]) self . _cleanupFile ( lPath and cleanUp , lPath ) if self . _raiseExceptions : raise e else : logger . error ( \"Failing read for %s with %s \" , filePath , str ( e )) return containerList","title":"readFile()"},{"location":"api_reference/IoAdapterPy/#mmcif.io.IoAdapterPy.IoAdapterPy.writeFile","text":"Write input list of data containers to the specified output file path in mmCIF format. Parameters: Name Type Description Default outputFilePath string output file path required maxLineLength int Maximum length of output line (content is wrapped beyond this length) 900 enforceAscii bool Filter output (not implemented - content must be ascii compatible on input) True lastInOrder list of category names Move data categories in this list to end of each data block None selectOrder list of category names Write only data categories on this list. None columnAlignFlag bool Format the output in aligned columns (default=True) (Native Python Only) True useStopTokens bool Include terminating 'stop_' tokens at the end of mmCIF categories (loop_'s) (Native Python only) False formattingStep int The number row samples within each category used to estimate maximum column width for data alignment (Native Python only) None **kwargs Placeholder for unsupported key value pairs {} Returns: Type Description bool Completion status Source code in mmcif/io/IoAdapterPy.py def writeFile ( self , outputFilePath , containerList , maxLineLength = 900 , enforceAscii = True , lastInOrder = None , selectOrder = None , columnAlignFlag = True , useStopTokens = False , formattingStep = None , ** kwargs ): \"\"\"Write input list of data containers to the specified output file path in mmCIF format. Args: outputFilePath (string): output file path containerList (list DataContainer objects, optional) maxLineLength (int, optional): Maximum length of output line (content is wrapped beyond this length) enforceAscii (bool, optional): Filter output (not implemented - content must be ascii compatible on input) lastInOrder (list of category names, optional): Move data categories in this list to end of each data block selectOrder (list of category names, optional): Write only data categories on this list. columnAlignFlag (bool, optional): Format the output in aligned columns (default=True) (Native Python Only) useStopTokens (bool, optional): Include terminating 'stop_' tokens at the end of mmCIF categories (loop_'s) (Native Python only) formattingStep (int, optional): The number row samples within each category used to estimate maximum column width for data alignment (Native Python only) **kwargs: Placeholder for unsupported key value pairs Returns: bool: Completion status \"\"\" lastInOrder = lastInOrder if lastInOrder else [ \"pdbx_nonpoly_scheme\" , \"pdbx_poly_seq_scheme\" , \"atom_site\" , \"atom_site_anisotrop\" ] if kwargs : logger . warning ( \"Unsupported keyword arguments %s \" , kwargs . keys ()) try : if enforceAscii : encoding = \"ascii\" else : encoding = \"utf-8\" # if sys . version_info [ 0 ] > 2 : with open ( outputFilePath , \"w\" , encoding = encoding ) as ofh : self . __writeFile ( ofh , containerList , maxLineLength = maxLineLength , columnAlignFlag = columnAlignFlag , lastInOrder = lastInOrder , selectOrder = selectOrder , useStopTokens = useStopTokens , formattingStep = formattingStep , enforceAscii = enforceAscii , cnvCharRefs = self . _useCharRefs , ) else : if enforceAscii : with io . open ( outputFilePath , \"w\" , encoding = encoding ) as ofh : self . __writeFile ( ofh , containerList , maxLineLength = maxLineLength , columnAlignFlag = columnAlignFlag , lastInOrder = lastInOrder , selectOrder = selectOrder , useStopTokens = useStopTokens , formattingStep = formattingStep , enforceAscii = enforceAscii , cnvCharRefs = self . _useCharRefs , ) else : with open ( outputFilePath , \"wb\" ) as ofh : self . __writeFile ( ofh , containerList , maxLineLength = maxLineLength , columnAlignFlag = columnAlignFlag , lastInOrder = lastInOrder , selectOrder = selectOrder , useStopTokens = useStopTokens , formattingStep = formattingStep , enforceAscii = enforceAscii , cnvCharRefs = self . _useCharRefs , ) return True except Exception as ex : if self . _raiseExceptions : raise_from ( ex , None ) else : logger . exception ( \"Failing write for %s with %s \" , outputFilePath , str ( ex )) logger . error ( \"Failing write for %s with %s \" , outputFilePath , str ( ex )) return False","title":"writeFile()"},{"location":"api_reference/Method/","text":"mmcif.api.Method.MethodDefinition Source code in mmcif/api/Method.py class MethodDefinition ( object ): def __init__ ( self , methodId , code = \"calculate\" , language = \"Python\" , inline = None , priority = None , implementation = None , implementationSource = \"inline\" ): self . methodId = methodId self . language = language self . code = code self . inline = inline self . priority = priority if priority else 1 self . implementationSource = implementationSource self . implementation = implementation def getId ( self ): return self . methodId def getLanguage ( self ): return self . language def getCode ( self ): return self . code def getInline ( self ): return self . inline def getImplementation ( self ): return self . implementation def getImplementationSource ( self ): return self . implementationSource def getPriority ( self ): return self . priority def printIt ( self , fh = sys . stdout ): fh . write ( \"------------- Method definition ------------- \\n \" ) fh . write ( \"Id: %s \\n \" % self . methodId ) fh . write ( \"Code: %s \\n \" % self . code ) fh . write ( \"Language: %s \\n \" % str ( self . language )) fh . write ( \"Inline text: %s \\n \" % str ( self . inline )) fh . write ( \"Implementation: %s \\n \" % str ( self . implementation )) fh . write ( \"Implementation source: %s \\n \" % str ( self . implementationSource )) fh . write ( \"Priority: %d \\n \" % self . priority ) def __repr__ ( self ): oL = [] oL . append ( \" \\n ------------- Method definition -------------\" ) oL . append ( \"Id: %s \" % self . methodId ) oL . append ( \"Code: %s \" % self . code ) oL . append ( \"Language: %s \" % str ( self . language )) oL . append ( \"Inline text: %s \" % str ( self . inline )) oL . append ( \"Implementation: %s \" % str ( self . implementation )) oL . append ( \"Implementation source: %s \" % str ( self . implementationSource )) oL . append ( \"Priority: %d \" % self . priority ) return \" \\n \" . join ( oL ) __init__ ( self , methodId , code = 'calculate' , language = 'Python' , inline = None , priority = None , implementation = None , implementationSource = 'inline' ) special Source code in mmcif/api/Method.py def __init__ ( self , methodId , code = \"calculate\" , language = \"Python\" , inline = None , priority = None , implementation = None , implementationSource = \"inline\" ): self . methodId = methodId self . language = language self . code = code self . inline = inline self . priority = priority if priority else 1 self . implementationSource = implementationSource self . implementation = implementation __repr__ ( self ) special Source code in mmcif/api/Method.py def __repr__ ( self ): oL = [] oL . append ( \" \\n ------------- Method definition -------------\" ) oL . append ( \"Id: %s \" % self . methodId ) oL . append ( \"Code: %s \" % self . code ) oL . append ( \"Language: %s \" % str ( self . language )) oL . append ( \"Inline text: %s \" % str ( self . inline )) oL . append ( \"Implementation: %s \" % str ( self . implementation )) oL . append ( \"Implementation source: %s \" % str ( self . implementationSource )) oL . append ( \"Priority: %d \" % self . priority ) return \" \\n \" . join ( oL ) getCode ( self ) Source code in mmcif/api/Method.py def getCode ( self ): return self . code getId ( self ) Source code in mmcif/api/Method.py def getId ( self ): return self . methodId getImplementation ( self ) Source code in mmcif/api/Method.py def getImplementation ( self ): return self . implementation getImplementationSource ( self ) Source code in mmcif/api/Method.py def getImplementationSource ( self ): return self . implementationSource getInline ( self ) Source code in mmcif/api/Method.py def getInline ( self ): return self . inline getLanguage ( self ) Source code in mmcif/api/Method.py def getLanguage ( self ): return self . language getPriority ( self ) Source code in mmcif/api/Method.py def getPriority ( self ): return self . priority printIt ( self , fh =< _io . StringIO object at 0x106b4dc10 > ) Source code in mmcif/api/Method.py def printIt ( self , fh = sys . stdout ): fh . write ( \"------------- Method definition ------------- \\n \" ) fh . write ( \"Id: %s \\n \" % self . methodId ) fh . write ( \"Code: %s \\n \" % self . code ) fh . write ( \"Language: %s \\n \" % str ( self . language )) fh . write ( \"Inline text: %s \\n \" % str ( self . inline )) fh . write ( \"Implementation: %s \\n \" % str ( self . implementation )) fh . write ( \"Implementation source: %s \\n \" % str ( self . implementationSource )) fh . write ( \"Priority: %d \\n \" % self . priority ) mmcif.api.Method.MethodReference Source code in mmcif/api/Method.py class MethodReference ( object ): def __init__ ( self , methodId , mType = \"attribute\" , category = None , attribute = None ): self . methodId = methodId self . type = mType self . categoryName = category self . attributeName = attribute def getId ( self ): return self . methodId def getType ( self ): return self . type def getCategoryName ( self ): return self . categoryName def getAttributeName ( self ): return self . attributeName def printIt ( self , fh = sys . stdout ): fh . write ( \"--------------- Method Reference ----------------- \\n \" ) fh . write ( \"Id: %s \\n \" % self . methodId ) fh . write ( \"Type: %s \\n \" % self . type ) fh . write ( \"Category name: %s \\n \" % str ( self . categoryName )) fh . write ( \"Attribute name: %s \\n \" % str ( self . attributeName )) def __repr__ ( self ): oL = [] oL . append ( \"--------------- Method Reference -----------------\" ) oL . append ( \"Id: %s \" % self . methodId ) oL . append ( \"Type: %s \" % self . type ) oL . append ( \"Category name: %s \" % str ( self . categoryName )) oL . append ( \"Attribute name: %s \" % str ( self . attributeName )) return \" \\n \" . join ( oL ) __init__ ( self , methodId , mType = 'attribute' , category = None , attribute = None ) special Source code in mmcif/api/Method.py def __init__ ( self , methodId , mType = \"attribute\" , category = None , attribute = None ): self . methodId = methodId self . type = mType self . categoryName = category self . attributeName = attribute __repr__ ( self ) special Source code in mmcif/api/Method.py def __repr__ ( self ): oL = [] oL . append ( \"--------------- Method Reference -----------------\" ) oL . append ( \"Id: %s \" % self . methodId ) oL . append ( \"Type: %s \" % self . type ) oL . append ( \"Category name: %s \" % str ( self . categoryName )) oL . append ( \"Attribute name: %s \" % str ( self . attributeName )) return \" \\n \" . join ( oL ) getAttributeName ( self ) Source code in mmcif/api/Method.py def getAttributeName ( self ): return self . attributeName getCategoryName ( self ) Source code in mmcif/api/Method.py def getCategoryName ( self ): return self . categoryName getId ( self ) Source code in mmcif/api/Method.py def getId ( self ): return self . methodId getType ( self ) Source code in mmcif/api/Method.py def getType ( self ): return self . type printIt ( self , fh =< _io . StringIO object at 0x106b4dc10 > ) Source code in mmcif/api/Method.py def printIt ( self , fh = sys . stdout ): fh . write ( \"--------------- Method Reference ----------------- \\n \" ) fh . write ( \"Id: %s \\n \" % self . methodId ) fh . write ( \"Type: %s \\n \" % self . type ) fh . write ( \"Category name: %s \\n \" % str ( self . categoryName )) fh . write ( \"Attribute name: %s \\n \" % str ( self . attributeName ))","title":"Method"},{"location":"api_reference/Method/#mmcif.api.Method.MethodDefinition","text":"Source code in mmcif/api/Method.py class MethodDefinition ( object ): def __init__ ( self , methodId , code = \"calculate\" , language = \"Python\" , inline = None , priority = None , implementation = None , implementationSource = \"inline\" ): self . methodId = methodId self . language = language self . code = code self . inline = inline self . priority = priority if priority else 1 self . implementationSource = implementationSource self . implementation = implementation def getId ( self ): return self . methodId def getLanguage ( self ): return self . language def getCode ( self ): return self . code def getInline ( self ): return self . inline def getImplementation ( self ): return self . implementation def getImplementationSource ( self ): return self . implementationSource def getPriority ( self ): return self . priority def printIt ( self , fh = sys . stdout ): fh . write ( \"------------- Method definition ------------- \\n \" ) fh . write ( \"Id: %s \\n \" % self . methodId ) fh . write ( \"Code: %s \\n \" % self . code ) fh . write ( \"Language: %s \\n \" % str ( self . language )) fh . write ( \"Inline text: %s \\n \" % str ( self . inline )) fh . write ( \"Implementation: %s \\n \" % str ( self . implementation )) fh . write ( \"Implementation source: %s \\n \" % str ( self . implementationSource )) fh . write ( \"Priority: %d \\n \" % self . priority ) def __repr__ ( self ): oL = [] oL . append ( \" \\n ------------- Method definition -------------\" ) oL . append ( \"Id: %s \" % self . methodId ) oL . append ( \"Code: %s \" % self . code ) oL . append ( \"Language: %s \" % str ( self . language )) oL . append ( \"Inline text: %s \" % str ( self . inline )) oL . append ( \"Implementation: %s \" % str ( self . implementation )) oL . append ( \"Implementation source: %s \" % str ( self . implementationSource )) oL . append ( \"Priority: %d \" % self . priority ) return \" \\n \" . join ( oL )","title":"MethodDefinition"},{"location":"api_reference/Method/#mmcif.api.Method.MethodDefinition.__init__","text":"Source code in mmcif/api/Method.py def __init__ ( self , methodId , code = \"calculate\" , language = \"Python\" , inline = None , priority = None , implementation = None , implementationSource = \"inline\" ): self . methodId = methodId self . language = language self . code = code self . inline = inline self . priority = priority if priority else 1 self . implementationSource = implementationSource self . implementation = implementation","title":"__init__()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodDefinition.__repr__","text":"Source code in mmcif/api/Method.py def __repr__ ( self ): oL = [] oL . append ( \" \\n ------------- Method definition -------------\" ) oL . append ( \"Id: %s \" % self . methodId ) oL . append ( \"Code: %s \" % self . code ) oL . append ( \"Language: %s \" % str ( self . language )) oL . append ( \"Inline text: %s \" % str ( self . inline )) oL . append ( \"Implementation: %s \" % str ( self . implementation )) oL . append ( \"Implementation source: %s \" % str ( self . implementationSource )) oL . append ( \"Priority: %d \" % self . priority ) return \" \\n \" . join ( oL )","title":"__repr__()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodDefinition.getCode","text":"Source code in mmcif/api/Method.py def getCode ( self ): return self . code","title":"getCode()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodDefinition.getId","text":"Source code in mmcif/api/Method.py def getId ( self ): return self . methodId","title":"getId()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodDefinition.getImplementation","text":"Source code in mmcif/api/Method.py def getImplementation ( self ): return self . implementation","title":"getImplementation()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodDefinition.getImplementationSource","text":"Source code in mmcif/api/Method.py def getImplementationSource ( self ): return self . implementationSource","title":"getImplementationSource()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodDefinition.getInline","text":"Source code in mmcif/api/Method.py def getInline ( self ): return self . inline","title":"getInline()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodDefinition.getLanguage","text":"Source code in mmcif/api/Method.py def getLanguage ( self ): return self . language","title":"getLanguage()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodDefinition.getPriority","text":"Source code in mmcif/api/Method.py def getPriority ( self ): return self . priority","title":"getPriority()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodDefinition.printIt","text":"Source code in mmcif/api/Method.py def printIt ( self , fh = sys . stdout ): fh . write ( \"------------- Method definition ------------- \\n \" ) fh . write ( \"Id: %s \\n \" % self . methodId ) fh . write ( \"Code: %s \\n \" % self . code ) fh . write ( \"Language: %s \\n \" % str ( self . language )) fh . write ( \"Inline text: %s \\n \" % str ( self . inline )) fh . write ( \"Implementation: %s \\n \" % str ( self . implementation )) fh . write ( \"Implementation source: %s \\n \" % str ( self . implementationSource )) fh . write ( \"Priority: %d \\n \" % self . priority )","title":"printIt()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodReference","text":"Source code in mmcif/api/Method.py class MethodReference ( object ): def __init__ ( self , methodId , mType = \"attribute\" , category = None , attribute = None ): self . methodId = methodId self . type = mType self . categoryName = category self . attributeName = attribute def getId ( self ): return self . methodId def getType ( self ): return self . type def getCategoryName ( self ): return self . categoryName def getAttributeName ( self ): return self . attributeName def printIt ( self , fh = sys . stdout ): fh . write ( \"--------------- Method Reference ----------------- \\n \" ) fh . write ( \"Id: %s \\n \" % self . methodId ) fh . write ( \"Type: %s \\n \" % self . type ) fh . write ( \"Category name: %s \\n \" % str ( self . categoryName )) fh . write ( \"Attribute name: %s \\n \" % str ( self . attributeName )) def __repr__ ( self ): oL = [] oL . append ( \"--------------- Method Reference -----------------\" ) oL . append ( \"Id: %s \" % self . methodId ) oL . append ( \"Type: %s \" % self . type ) oL . append ( \"Category name: %s \" % str ( self . categoryName )) oL . append ( \"Attribute name: %s \" % str ( self . attributeName )) return \" \\n \" . join ( oL )","title":"MethodReference"},{"location":"api_reference/Method/#mmcif.api.Method.MethodReference.__init__","text":"Source code in mmcif/api/Method.py def __init__ ( self , methodId , mType = \"attribute\" , category = None , attribute = None ): self . methodId = methodId self . type = mType self . categoryName = category self . attributeName = attribute","title":"__init__()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodReference.__repr__","text":"Source code in mmcif/api/Method.py def __repr__ ( self ): oL = [] oL . append ( \"--------------- Method Reference -----------------\" ) oL . append ( \"Id: %s \" % self . methodId ) oL . append ( \"Type: %s \" % self . type ) oL . append ( \"Category name: %s \" % str ( self . categoryName )) oL . append ( \"Attribute name: %s \" % str ( self . attributeName )) return \" \\n \" . join ( oL )","title":"__repr__()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodReference.getAttributeName","text":"Source code in mmcif/api/Method.py def getAttributeName ( self ): return self . attributeName","title":"getAttributeName()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodReference.getCategoryName","text":"Source code in mmcif/api/Method.py def getCategoryName ( self ): return self . categoryName","title":"getCategoryName()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodReference.getId","text":"Source code in mmcif/api/Method.py def getId ( self ): return self . methodId","title":"getId()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodReference.getType","text":"Source code in mmcif/api/Method.py def getType ( self ): return self . type","title":"getType()"},{"location":"api_reference/Method/#mmcif.api.Method.MethodReference.printIt","text":"Source code in mmcif/api/Method.py def printIt ( self , fh = sys . stdout ): fh . write ( \"--------------- Method Reference ----------------- \\n \" ) fh . write ( \"Id: %s \\n \" % self . methodId ) fh . write ( \"Type: %s \\n \" % self . type ) fh . write ( \"Category name: %s \\n \" % str ( self . categoryName )) fh . write ( \"Attribute name: %s \\n \" % str ( self . attributeName ))","title":"printIt()"},{"location":"api_reference/MethodUtils/","text":"mmcif.api.MethodUtils.MethodUtils Source code in mmcif/api/MethodUtils.py class MethodUtils ( object ): def __init__ ( self , dictContainerList , verbose = False ): # self . __verbose = verbose # list of dictionary data & definition containers self . __dictContainerList = dictContainerList self . __dApi = DictionaryApi ( containerList = self . __dictContainerList , consolidate = True , verbose = self . __verbose ) # # Target data container list self . __dataContainerList = [] # def setDataContainerList ( self , dataContainerList ): self . __dataContainerList = dataContainerList def getDataContainerList ( self ): return self . __dataContainerList def getDictionary ( self ): return self . __dApi def getMethods ( self ): return self . __dApi . getMethodIndex () def getMethod ( self , mId ): return self . __dApi . getMethod ( mId ) def invokeMethods ( self , fh = sys . stdout ): _ = fh mI = self . __dApi . getMethodIndex () lenD = len ( mI ) i = 0 for k , mRefL in mI . items (): for mRef in mRefL : i += 1 mId = mRef . getId () mType = mRef . getType () categoryName = mRef . getCategoryName () attributeName = mRef . getAttributeName () # logger . debug ( \" \\n \" ) logger . debug ( \"++++++++++++++++++-------------------- \\n \" ) logger . debug ( \"Invoking dictionary method on file object: %s ( %d / %d )\" , k , i , lenD ) logger . debug ( \" + Method id: %s \" , mId ) logger . debug ( \" + Type: %s \" , mType ) logger . debug ( \" + Category: %s \" , categoryName ) logger . debug ( \" + Attribute: %s \" , attributeName ) # if mType == \"datablock\" : logger . debug ( \"Invoke datablock method %s \" , mId ) # self.invokeDataBlockMethod(type,self.__dApi.getMethod(id)) # continue # for db in self . __dataContainerList : if mType == \"category\" : if not db . exists ( categoryName ): dc = DataCategory ( categoryName ) db . append ( dc ) dObj = db . getObj ( categoryName ) dObj . invokeCategoryMethod ( mType , self . __dApi . getMethod ( mId ), db ) elif mType == \"attribute\" : if not db . exists ( categoryName ): dc = DataCategory ( categoryName ) db . append ( dc ) dObj = db . getObj ( categoryName ) # logger.debug(\"invoke - %r %r %r %r\" % (attributeName, type, self.__dApi.getMethod(id), db)) dObj . invokeAttributeMethod ( attributeName , mType , self . __dApi . getMethod ( mId ), db ) elif mType == \"datablock\" : logger . debug ( \"Invoke datablock method %s \" , mId ) db . invokeDataBlockMethod ( mType , self . __dApi . getMethod ( mId ), db ) else : pass def dumpMethods ( self , fh = sys . stdout ): self . __dApi . dumpMethods ( fh ) def dumpDictionary ( self , fh = sys . stdout ): lenD = len ( self . __dictContainerList ) fh . write ( \" \\n -------------------------------------------- \\n \" ) fh . write ( \" \\n -----------DUMP DICTIONARY------------------ \\n \" ) fh . write ( \"Dictionary object list length is: %d \\n \" % lenD ) i = 1 for dObj in self . __dictContainerList : if dObj . getName (): fh . write ( \" \\n \" ) fh . write ( \"++++++++++++++++++-------------------- \\n \" ) fh . write ( \"Dumping dictionary object named: %s ( %d / %d ) \\n \" % ( dObj . getName (), i , lenD )) dObj . printIt ( fh ) i += 1 # def dumpDataFile ( self , fh = sys . stdout ): lenD = len ( self . __dataContainerList ) fh . write ( \" \\n -------------------------------------------- \\n \" ) fh . write ( \" \\n -----------DUMP DATAFILE-------------------- \\n \" ) fh . write ( \"Data object list length is: %d \\n \" % lenD ) i = 1 for dObj in self . __dataContainerList : fh . write ( \" \\n \" ) fh . write ( \"++++++++++++++++++-------------------- \\n \" ) fh . write ( \"Dumping data file object named: %s ( %d / %d ) \\n \" % ( dObj . getName (), i , lenD )) dObj . printIt ( fh ) i += 1 __init__ ( self , dictContainerList , verbose = False ) special Source code in mmcif/api/MethodUtils.py def __init__ ( self , dictContainerList , verbose = False ): # self . __verbose = verbose # list of dictionary data & definition containers self . __dictContainerList = dictContainerList self . __dApi = DictionaryApi ( containerList = self . __dictContainerList , consolidate = True , verbose = self . __verbose ) # # Target data container list self . __dataContainerList = [] # dumpDataFile ( self , fh =< _io . StringIO object at 0x106dea5e0 > ) Source code in mmcif/api/MethodUtils.py def dumpDataFile ( self , fh = sys . stdout ): lenD = len ( self . __dataContainerList ) fh . write ( \" \\n -------------------------------------------- \\n \" ) fh . write ( \" \\n -----------DUMP DATAFILE-------------------- \\n \" ) fh . write ( \"Data object list length is: %d \\n \" % lenD ) i = 1 for dObj in self . __dataContainerList : fh . write ( \" \\n \" ) fh . write ( \"++++++++++++++++++-------------------- \\n \" ) fh . write ( \"Dumping data file object named: %s ( %d / %d ) \\n \" % ( dObj . getName (), i , lenD )) dObj . printIt ( fh ) i += 1 dumpDictionary ( self , fh =< _io . StringIO object at 0x106dea5e0 > ) Source code in mmcif/api/MethodUtils.py def dumpDictionary ( self , fh = sys . stdout ): lenD = len ( self . __dictContainerList ) fh . write ( \" \\n -------------------------------------------- \\n \" ) fh . write ( \" \\n -----------DUMP DICTIONARY------------------ \\n \" ) fh . write ( \"Dictionary object list length is: %d \\n \" % lenD ) i = 1 for dObj in self . __dictContainerList : if dObj . getName (): fh . write ( \" \\n \" ) fh . write ( \"++++++++++++++++++-------------------- \\n \" ) fh . write ( \"Dumping dictionary object named: %s ( %d / %d ) \\n \" % ( dObj . getName (), i , lenD )) dObj . printIt ( fh ) i += 1 dumpMethods ( self , fh =< _io . StringIO object at 0x106dea5e0 > ) Source code in mmcif/api/MethodUtils.py def dumpMethods ( self , fh = sys . stdout ): self . __dApi . dumpMethods ( fh ) getDataContainerList ( self ) Source code in mmcif/api/MethodUtils.py def getDataContainerList ( self ): return self . __dataContainerList getDictionary ( self ) Source code in mmcif/api/MethodUtils.py def getDictionary ( self ): return self . __dApi getMethod ( self , mId ) Source code in mmcif/api/MethodUtils.py def getMethod ( self , mId ): return self . __dApi . getMethod ( mId ) getMethods ( self ) Source code in mmcif/api/MethodUtils.py def getMethods ( self ): return self . __dApi . getMethodIndex () invokeMethods ( self , fh =< _io . StringIO object at 0x106dea5e0 > ) Source code in mmcif/api/MethodUtils.py def invokeMethods ( self , fh = sys . stdout ): _ = fh mI = self . __dApi . getMethodIndex () lenD = len ( mI ) i = 0 for k , mRefL in mI . items (): for mRef in mRefL : i += 1 mId = mRef . getId () mType = mRef . getType () categoryName = mRef . getCategoryName () attributeName = mRef . getAttributeName () # logger . debug ( \" \\n \" ) logger . debug ( \"++++++++++++++++++-------------------- \\n \" ) logger . debug ( \"Invoking dictionary method on file object: %s ( %d / %d )\" , k , i , lenD ) logger . debug ( \" + Method id: %s \" , mId ) logger . debug ( \" + Type: %s \" , mType ) logger . debug ( \" + Category: %s \" , categoryName ) logger . debug ( \" + Attribute: %s \" , attributeName ) # if mType == \"datablock\" : logger . debug ( \"Invoke datablock method %s \" , mId ) # self.invokeDataBlockMethod(type,self.__dApi.getMethod(id)) # continue # for db in self . __dataContainerList : if mType == \"category\" : if not db . exists ( categoryName ): dc = DataCategory ( categoryName ) db . append ( dc ) dObj = db . getObj ( categoryName ) dObj . invokeCategoryMethod ( mType , self . __dApi . getMethod ( mId ), db ) elif mType == \"attribute\" : if not db . exists ( categoryName ): dc = DataCategory ( categoryName ) db . append ( dc ) dObj = db . getObj ( categoryName ) # logger.debug(\"invoke - %r %r %r %r\" % (attributeName, type, self.__dApi.getMethod(id), db)) dObj . invokeAttributeMethod ( attributeName , mType , self . __dApi . getMethod ( mId ), db ) elif mType == \"datablock\" : logger . debug ( \"Invoke datablock method %s \" , mId ) db . invokeDataBlockMethod ( mType , self . __dApi . getMethod ( mId ), db ) else : pass setDataContainerList ( self , dataContainerList ) Source code in mmcif/api/MethodUtils.py def setDataContainerList ( self , dataContainerList ): self . __dataContainerList = dataContainerList","title":"MethodUtils"},{"location":"api_reference/MethodUtils/#mmcif.api.MethodUtils.MethodUtils","text":"Source code in mmcif/api/MethodUtils.py class MethodUtils ( object ): def __init__ ( self , dictContainerList , verbose = False ): # self . __verbose = verbose # list of dictionary data & definition containers self . __dictContainerList = dictContainerList self . __dApi = DictionaryApi ( containerList = self . __dictContainerList , consolidate = True , verbose = self . __verbose ) # # Target data container list self . __dataContainerList = [] # def setDataContainerList ( self , dataContainerList ): self . __dataContainerList = dataContainerList def getDataContainerList ( self ): return self . __dataContainerList def getDictionary ( self ): return self . __dApi def getMethods ( self ): return self . __dApi . getMethodIndex () def getMethod ( self , mId ): return self . __dApi . getMethod ( mId ) def invokeMethods ( self , fh = sys . stdout ): _ = fh mI = self . __dApi . getMethodIndex () lenD = len ( mI ) i = 0 for k , mRefL in mI . items (): for mRef in mRefL : i += 1 mId = mRef . getId () mType = mRef . getType () categoryName = mRef . getCategoryName () attributeName = mRef . getAttributeName () # logger . debug ( \" \\n \" ) logger . debug ( \"++++++++++++++++++-------------------- \\n \" ) logger . debug ( \"Invoking dictionary method on file object: %s ( %d / %d )\" , k , i , lenD ) logger . debug ( \" + Method id: %s \" , mId ) logger . debug ( \" + Type: %s \" , mType ) logger . debug ( \" + Category: %s \" , categoryName ) logger . debug ( \" + Attribute: %s \" , attributeName ) # if mType == \"datablock\" : logger . debug ( \"Invoke datablock method %s \" , mId ) # self.invokeDataBlockMethod(type,self.__dApi.getMethod(id)) # continue # for db in self . __dataContainerList : if mType == \"category\" : if not db . exists ( categoryName ): dc = DataCategory ( categoryName ) db . append ( dc ) dObj = db . getObj ( categoryName ) dObj . invokeCategoryMethod ( mType , self . __dApi . getMethod ( mId ), db ) elif mType == \"attribute\" : if not db . exists ( categoryName ): dc = DataCategory ( categoryName ) db . append ( dc ) dObj = db . getObj ( categoryName ) # logger.debug(\"invoke - %r %r %r %r\" % (attributeName, type, self.__dApi.getMethod(id), db)) dObj . invokeAttributeMethod ( attributeName , mType , self . __dApi . getMethod ( mId ), db ) elif mType == \"datablock\" : logger . debug ( \"Invoke datablock method %s \" , mId ) db . invokeDataBlockMethod ( mType , self . __dApi . getMethod ( mId ), db ) else : pass def dumpMethods ( self , fh = sys . stdout ): self . __dApi . dumpMethods ( fh ) def dumpDictionary ( self , fh = sys . stdout ): lenD = len ( self . __dictContainerList ) fh . write ( \" \\n -------------------------------------------- \\n \" ) fh . write ( \" \\n -----------DUMP DICTIONARY------------------ \\n \" ) fh . write ( \"Dictionary object list length is: %d \\n \" % lenD ) i = 1 for dObj in self . __dictContainerList : if dObj . getName (): fh . write ( \" \\n \" ) fh . write ( \"++++++++++++++++++-------------------- \\n \" ) fh . write ( \"Dumping dictionary object named: %s ( %d / %d ) \\n \" % ( dObj . getName (), i , lenD )) dObj . printIt ( fh ) i += 1 # def dumpDataFile ( self , fh = sys . stdout ): lenD = len ( self . __dataContainerList ) fh . write ( \" \\n -------------------------------------------- \\n \" ) fh . write ( \" \\n -----------DUMP DATAFILE-------------------- \\n \" ) fh . write ( \"Data object list length is: %d \\n \" % lenD ) i = 1 for dObj in self . __dataContainerList : fh . write ( \" \\n \" ) fh . write ( \"++++++++++++++++++-------------------- \\n \" ) fh . write ( \"Dumping data file object named: %s ( %d / %d ) \\n \" % ( dObj . getName (), i , lenD )) dObj . printIt ( fh ) i += 1","title":"MethodUtils"},{"location":"api_reference/MethodUtils/#mmcif.api.MethodUtils.MethodUtils.__init__","text":"Source code in mmcif/api/MethodUtils.py def __init__ ( self , dictContainerList , verbose = False ): # self . __verbose = verbose # list of dictionary data & definition containers self . __dictContainerList = dictContainerList self . __dApi = DictionaryApi ( containerList = self . __dictContainerList , consolidate = True , verbose = self . __verbose ) # # Target data container list self . __dataContainerList = [] #","title":"__init__()"},{"location":"api_reference/MethodUtils/#mmcif.api.MethodUtils.MethodUtils.dumpDataFile","text":"Source code in mmcif/api/MethodUtils.py def dumpDataFile ( self , fh = sys . stdout ): lenD = len ( self . __dataContainerList ) fh . write ( \" \\n -------------------------------------------- \\n \" ) fh . write ( \" \\n -----------DUMP DATAFILE-------------------- \\n \" ) fh . write ( \"Data object list length is: %d \\n \" % lenD ) i = 1 for dObj in self . __dataContainerList : fh . write ( \" \\n \" ) fh . write ( \"++++++++++++++++++-------------------- \\n \" ) fh . write ( \"Dumping data file object named: %s ( %d / %d ) \\n \" % ( dObj . getName (), i , lenD )) dObj . printIt ( fh ) i += 1","title":"dumpDataFile()"},{"location":"api_reference/MethodUtils/#mmcif.api.MethodUtils.MethodUtils.dumpDictionary","text":"Source code in mmcif/api/MethodUtils.py def dumpDictionary ( self , fh = sys . stdout ): lenD = len ( self . __dictContainerList ) fh . write ( \" \\n -------------------------------------------- \\n \" ) fh . write ( \" \\n -----------DUMP DICTIONARY------------------ \\n \" ) fh . write ( \"Dictionary object list length is: %d \\n \" % lenD ) i = 1 for dObj in self . __dictContainerList : if dObj . getName (): fh . write ( \" \\n \" ) fh . write ( \"++++++++++++++++++-------------------- \\n \" ) fh . write ( \"Dumping dictionary object named: %s ( %d / %d ) \\n \" % ( dObj . getName (), i , lenD )) dObj . printIt ( fh ) i += 1","title":"dumpDictionary()"},{"location":"api_reference/MethodUtils/#mmcif.api.MethodUtils.MethodUtils.dumpMethods","text":"Source code in mmcif/api/MethodUtils.py def dumpMethods ( self , fh = sys . stdout ): self . __dApi . dumpMethods ( fh )","title":"dumpMethods()"},{"location":"api_reference/MethodUtils/#mmcif.api.MethodUtils.MethodUtils.getDataContainerList","text":"Source code in mmcif/api/MethodUtils.py def getDataContainerList ( self ): return self . __dataContainerList","title":"getDataContainerList()"},{"location":"api_reference/MethodUtils/#mmcif.api.MethodUtils.MethodUtils.getDictionary","text":"Source code in mmcif/api/MethodUtils.py def getDictionary ( self ): return self . __dApi","title":"getDictionary()"},{"location":"api_reference/MethodUtils/#mmcif.api.MethodUtils.MethodUtils.getMethod","text":"Source code in mmcif/api/MethodUtils.py def getMethod ( self , mId ): return self . __dApi . getMethod ( mId )","title":"getMethod()"},{"location":"api_reference/MethodUtils/#mmcif.api.MethodUtils.MethodUtils.getMethods","text":"Source code in mmcif/api/MethodUtils.py def getMethods ( self ): return self . __dApi . getMethodIndex ()","title":"getMethods()"},{"location":"api_reference/MethodUtils/#mmcif.api.MethodUtils.MethodUtils.invokeMethods","text":"Source code in mmcif/api/MethodUtils.py def invokeMethods ( self , fh = sys . stdout ): _ = fh mI = self . __dApi . getMethodIndex () lenD = len ( mI ) i = 0 for k , mRefL in mI . items (): for mRef in mRefL : i += 1 mId = mRef . getId () mType = mRef . getType () categoryName = mRef . getCategoryName () attributeName = mRef . getAttributeName () # logger . debug ( \" \\n \" ) logger . debug ( \"++++++++++++++++++-------------------- \\n \" ) logger . debug ( \"Invoking dictionary method on file object: %s ( %d / %d )\" , k , i , lenD ) logger . debug ( \" + Method id: %s \" , mId ) logger . debug ( \" + Type: %s \" , mType ) logger . debug ( \" + Category: %s \" , categoryName ) logger . debug ( \" + Attribute: %s \" , attributeName ) # if mType == \"datablock\" : logger . debug ( \"Invoke datablock method %s \" , mId ) # self.invokeDataBlockMethod(type,self.__dApi.getMethod(id)) # continue # for db in self . __dataContainerList : if mType == \"category\" : if not db . exists ( categoryName ): dc = DataCategory ( categoryName ) db . append ( dc ) dObj = db . getObj ( categoryName ) dObj . invokeCategoryMethod ( mType , self . __dApi . getMethod ( mId ), db ) elif mType == \"attribute\" : if not db . exists ( categoryName ): dc = DataCategory ( categoryName ) db . append ( dc ) dObj = db . getObj ( categoryName ) # logger.debug(\"invoke - %r %r %r %r\" % (attributeName, type, self.__dApi.getMethod(id), db)) dObj . invokeAttributeMethod ( attributeName , mType , self . __dApi . getMethod ( mId ), db ) elif mType == \"datablock\" : logger . debug ( \"Invoke datablock method %s \" , mId ) db . invokeDataBlockMethod ( mType , self . __dApi . getMethod ( mId ), db ) else : pass","title":"invokeMethods()"},{"location":"api_reference/MethodUtils/#mmcif.api.MethodUtils.MethodUtils.setDataContainerList","text":"Source code in mmcif/api/MethodUtils.py def setDataContainerList ( self , dataContainerList ): self . __dataContainerList = dataContainerList","title":"setDataContainerList()"},{"location":"api_reference/PdbxContainers/","text":"mmcif.api.PdbxContainers.ContainerBase Container base class for data and definition objects. Source code in mmcif/api/PdbxContainers.py class ContainerBase ( object ): \"\"\"Container base class for data and definition objects.\"\"\" def __init__ ( self , name ): # The enclosing scope of the data container (e.g. data_/save_) self . __name = name # List of category names within this container - self . __objNameList = [] # dictionary of DataCategory objects keyed by category name. self . __objCatalog = {} # dictionary for properties of the container self . __propCatalog = {} self . __type = None def __eq__ ( self , other ): if not isinstance ( other , type ( self )): return NotImplemented return ( self . __name == other . getName () and self . __objNameList == other . getObjNameList () and self . __objCatalog == other . getObjCatalog () and self . __type == other . getType () and self . __propCatalog == other . getPropCatalog () ) def __hash__ ( self ): return hash (( self . __name , tuple ( self . __objNameList ), self . __type , tuple ( self . __objCatalog . items ()), tuple ( self . __propCatalog . items ()))) def getObjCatalog ( self ): return self . __objCatalog def getPropCatalog ( self ): return self . __propCatalog def setProp ( self , propName , value ): try : self . __propCatalog [ propName ] = value return True except Exception : return False def getProp ( self , propName ): try : return self . __propCatalog [ propName ] except Exception : return None def getType ( self ): return self . __type def setType ( self , cType ): self . __type = cType def getName ( self ): return self . __name def setName ( self , name ): self . __name = name def exists ( self , name ): if name in self . __objCatalog : return True else : return False def getObj ( self , name ): if name in self . __objCatalog : return self . __objCatalog [ name ] else : return None def getObjNameList ( self ): return self . __objNameList def append ( self , obj ): \"\"\"Add the input object to the current object catalog. An existing object of the same name will be overwritten. \"\"\" if obj . getName () is not None : if obj . getName () not in self . __objCatalog : # self.__objNameList is keeping track of object order here -- self . __objNameList . append ( obj . getName ()) self . __objCatalog [ obj . getName ()] = obj def replace ( self , obj ): \"\"\"Replace an existing object with the input object\"\"\" if ( obj . getName () is not None ) and ( obj . getName () in self . __objCatalog ): self . __objCatalog [ obj . getName ()] = obj def printIt ( self , fh = sys . stdout , pType = \"brief\" ): fh . write ( \"+ %s container: %30s contains %4d categories \\n \" % ( self . getType (), self . getName (), len ( self . __objNameList ))) for nm in self . __objNameList : fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \"Data category: %s \\n \" % nm ) if pType == \"brief\" : self . __objCatalog [ nm ] . printIt ( fh ) else : self . __objCatalog [ nm ] . dumpIt ( fh ) def rename ( self , curName , newName ): \"\"\"Change the name of an object in place -\"\"\" try : i = self . __objNameList . index ( curName ) self . __objNameList [ i ] = newName self . __objCatalog [ newName ] = self . __objCatalog [ curName ] self . __objCatalog [ newName ] . setName ( newName ) return True except Exception : return False def remove ( self , curName ): \"\"\"Remove object by name. Return True on success or False otherwise.\"\"\" try : if curName in self . __objCatalog : del self . __objCatalog [ curName ] i = self . __objNameList . index ( curName ) del self . __objNameList [ i ] return True else : return False except Exception : pass return False def merge ( self , container ): \"\"\"Merge the contents of the input container with the contents of the current container.\"\"\" try : objNameList = container . getObjNameList () for objName in objNameList : self . append ( container . getObj ( objName )) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return False return True def filterObjectNameList ( self , lastInOrder = None , selectOrder = None ): \"\"\"Return an ordered list of categories in the input container subject to input - lastInOrder: list: categories to be shifted to the end of the container. selectOrder: list: ordered selection of container categories returns: filNameList: list: augmented category list or full list (default) \"\"\" filNameList = [] if lastInOrder : objNameList = self . __objNameList lastList = [] for nm in objNameList : if nm in lastInOrder : lastList . append ( nm ) continue filNameList . append ( nm ) filNameList . extend ( lastList ) elif selectOrder : for nm in selectOrder : if self . exists ( nm ): filNameList . append ( nm ) else : filNameList = self . __objNameList return filNameList def toJSON ( self ): return self . __objCatalog Methods __eq__ ( self , other ) special Source code in mmcif/api/PdbxContainers.py def __eq__ ( self , other ): if not isinstance ( other , type ( self )): return NotImplemented return ( self . __name == other . getName () and self . __objNameList == other . getObjNameList () and self . __objCatalog == other . getObjCatalog () and self . __type == other . getType () and self . __propCatalog == other . getPropCatalog () ) __hash__ ( self ) special Source code in mmcif/api/PdbxContainers.py def __hash__ ( self ): return hash (( self . __name , tuple ( self . __objNameList ), self . __type , tuple ( self . __objCatalog . items ()), tuple ( self . __propCatalog . items ()))) __init__ ( self , name ) special Source code in mmcif/api/PdbxContainers.py def __init__ ( self , name ): # The enclosing scope of the data container (e.g. data_/save_) self . __name = name # List of category names within this container - self . __objNameList = [] # dictionary of DataCategory objects keyed by category name. self . __objCatalog = {} # dictionary for properties of the container self . __propCatalog = {} self . __type = None append ( self , obj ) Add the input object to the current object catalog. An existing object of the same name will be overwritten. Source code in mmcif/api/PdbxContainers.py def append ( self , obj ): \"\"\"Add the input object to the current object catalog. An existing object of the same name will be overwritten. \"\"\" if obj . getName () is not None : if obj . getName () not in self . __objCatalog : # self.__objNameList is keeping track of object order here -- self . __objNameList . append ( obj . getName ()) self . __objCatalog [ obj . getName ()] = obj exists ( self , name ) Source code in mmcif/api/PdbxContainers.py def exists ( self , name ): if name in self . __objCatalog : return True else : return False filterObjectNameList ( self , lastInOrder = None , selectOrder = None ) Return an ordered list of categories in the input container subject to input - lastInOrder: list: categories to be shifted to the end of the container. selectOrder: list: ordered selection of container categories Returns: Type Description filNameList list: augmented category list or full list (default) Source code in mmcif/api/PdbxContainers.py def filterObjectNameList ( self , lastInOrder = None , selectOrder = None ): \"\"\"Return an ordered list of categories in the input container subject to input - lastInOrder: list: categories to be shifted to the end of the container. selectOrder: list: ordered selection of container categories returns: filNameList: list: augmented category list or full list (default) \"\"\" filNameList = [] if lastInOrder : objNameList = self . __objNameList lastList = [] for nm in objNameList : if nm in lastInOrder : lastList . append ( nm ) continue filNameList . append ( nm ) filNameList . extend ( lastList ) elif selectOrder : for nm in selectOrder : if self . exists ( nm ): filNameList . append ( nm ) else : filNameList = self . __objNameList return filNameList getName ( self ) Source code in mmcif/api/PdbxContainers.py def getName ( self ): return self . __name getObj ( self , name ) Source code in mmcif/api/PdbxContainers.py def getObj ( self , name ): if name in self . __objCatalog : return self . __objCatalog [ name ] else : return None getObjCatalog ( self ) Source code in mmcif/api/PdbxContainers.py def getObjCatalog ( self ): return self . __objCatalog getObjNameList ( self ) Source code in mmcif/api/PdbxContainers.py def getObjNameList ( self ): return self . __objNameList getProp ( self , propName ) Source code in mmcif/api/PdbxContainers.py def getProp ( self , propName ): try : return self . __propCatalog [ propName ] except Exception : return None getPropCatalog ( self ) Source code in mmcif/api/PdbxContainers.py def getPropCatalog ( self ): return self . __propCatalog getType ( self ) Source code in mmcif/api/PdbxContainers.py def getType ( self ): return self . __type merge ( self , container ) Merge the contents of the input container with the contents of the current container. Source code in mmcif/api/PdbxContainers.py def merge ( self , container ): \"\"\"Merge the contents of the input container with the contents of the current container.\"\"\" try : objNameList = container . getObjNameList () for objName in objNameList : self . append ( container . getObj ( objName )) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return False return True printIt ( self , fh =< _io . StringIO object at 0x106062280 > , pType = 'brief' ) Source code in mmcif/api/PdbxContainers.py def printIt ( self , fh = sys . stdout , pType = \"brief\" ): fh . write ( \"+ %s container: %30s contains %4d categories \\n \" % ( self . getType (), self . getName (), len ( self . __objNameList ))) for nm in self . __objNameList : fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \"Data category: %s \\n \" % nm ) if pType == \"brief\" : self . __objCatalog [ nm ] . printIt ( fh ) else : self . __objCatalog [ nm ] . dumpIt ( fh ) remove ( self , curName ) Remove object by name. Return True on success or False otherwise. Source code in mmcif/api/PdbxContainers.py def remove ( self , curName ): \"\"\"Remove object by name. Return True on success or False otherwise.\"\"\" try : if curName in self . __objCatalog : del self . __objCatalog [ curName ] i = self . __objNameList . index ( curName ) del self . __objNameList [ i ] return True else : return False except Exception : pass return False rename ( self , curName , newName ) Change the name of an object in place - Source code in mmcif/api/PdbxContainers.py def rename ( self , curName , newName ): \"\"\"Change the name of an object in place -\"\"\" try : i = self . __objNameList . index ( curName ) self . __objNameList [ i ] = newName self . __objCatalog [ newName ] = self . __objCatalog [ curName ] self . __objCatalog [ newName ] . setName ( newName ) return True except Exception : return False replace ( self , obj ) Replace an existing object with the input object Source code in mmcif/api/PdbxContainers.py def replace ( self , obj ): \"\"\"Replace an existing object with the input object\"\"\" if ( obj . getName () is not None ) and ( obj . getName () in self . __objCatalog ): self . __objCatalog [ obj . getName ()] = obj setName ( self , name ) Source code in mmcif/api/PdbxContainers.py def setName ( self , name ): self . __name = name setProp ( self , propName , value ) Source code in mmcif/api/PdbxContainers.py def setProp ( self , propName , value ): try : self . __propCatalog [ propName ] = value return True except Exception : return False setType ( self , cType ) Source code in mmcif/api/PdbxContainers.py def setType ( self , cType ): self . __type = cType toJSON ( self ) Source code in mmcif/api/PdbxContainers.py def toJSON ( self ): return self . __objCatalog mmcif.api.PdbxContainers.DefinitionContainer ( ContainerBase ) Source code in mmcif/api/PdbxContainers.py class DefinitionContainer ( ContainerBase ): def __init__ ( self , name ): super ( DefinitionContainer , self ) . __init__ ( name ) self . setType ( \"definition\" ) self . __globalFlag = False def isCategory ( self ): if self . exists ( \"category\" ): return True return False def isAttribute ( self ): if self . exists ( \"item\" ): return True return False def getGlobal ( self ): return self . __globalFlag def printIt ( self , fh = sys . stdout , pType = \"brief\" ): fh . write ( \"Definition container: %30s contains %4d categories \\n \" % ( self . getName (), len ( self . getObjNameList ()))) if self . isCategory (): fh . write ( \"Definition type: category \\n \" ) elif self . isAttribute (): fh . write ( \"Definition type: item \\n \" ) else : fh . write ( \"Definition type: undefined \\n \" ) for nm in self . getObjNameList (): fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \"Definition category: %s \\n \" % nm ) if pType == \"brief\" : self . getObj ( nm ) . printIt ( fh ) else : self . getObj ( nm ) . dumpId ( fh ) __init__ ( self , name ) special Source code in mmcif/api/PdbxContainers.py def __init__ ( self , name ): super ( DefinitionContainer , self ) . __init__ ( name ) self . setType ( \"definition\" ) self . __globalFlag = False getGlobal ( self ) Source code in mmcif/api/PdbxContainers.py def getGlobal ( self ): return self . __globalFlag isAttribute ( self ) Source code in mmcif/api/PdbxContainers.py def isAttribute ( self ): if self . exists ( \"item\" ): return True return False isCategory ( self ) Source code in mmcif/api/PdbxContainers.py def isCategory ( self ): if self . exists ( \"category\" ): return True return False printIt ( self , fh =< _io . StringIO object at 0x106062280 > , pType = 'brief' ) Source code in mmcif/api/PdbxContainers.py def printIt ( self , fh = sys . stdout , pType = \"brief\" ): fh . write ( \"Definition container: %30s contains %4d categories \\n \" % ( self . getName (), len ( self . getObjNameList ()))) if self . isCategory (): fh . write ( \"Definition type: category \\n \" ) elif self . isAttribute (): fh . write ( \"Definition type: item \\n \" ) else : fh . write ( \"Definition type: undefined \\n \" ) for nm in self . getObjNameList (): fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \"Definition category: %s \\n \" % nm ) if pType == \"brief\" : self . getObj ( nm ) . printIt ( fh ) else : self . getObj ( nm ) . dumpId ( fh ) mmcif.api.PdbxContainers.DataContainer ( ContainerBase ) Container class for DataCategory objects. Source code in mmcif/api/PdbxContainers.py class DataContainer ( ContainerBase ): \"\"\"Container class for DataCategory objects.\"\"\" def __init__ ( self , name ): super ( DataContainer , self ) . __init__ ( name ) self . setType ( \"data\" ) self . __globalFlag = False def invokeDataBlockMethod ( self , mType , method , db ): _ = mType _ = db # self.__currentRow = 1 exec ( method . getInline (), globals (), locals ()) # pylint: disable=exec-used def setGlobal ( self ): self . __globalFlag = True def getGlobal ( self ): return self . __globalFlag __init__ ( self , name ) special Source code in mmcif/api/PdbxContainers.py def __init__ ( self , name ): super ( DataContainer , self ) . __init__ ( name ) self . setType ( \"data\" ) self . __globalFlag = False getGlobal ( self ) Source code in mmcif/api/PdbxContainers.py def getGlobal ( self ): return self . __globalFlag invokeDataBlockMethod ( self , mType , method , db ) Source code in mmcif/api/PdbxContainers.py def invokeDataBlockMethod ( self , mType , method , db ): _ = mType _ = db # self.__currentRow = 1 exec ( method . getInline (), globals (), locals ()) # pylint: disable=exec-used setGlobal ( self ) Source code in mmcif/api/PdbxContainers.py def setGlobal ( self ): self . __globalFlag = True mmcif.api.PdbxContainers.SaveFrameContainer ( ContainerBase ) Source code in mmcif/api/PdbxContainers.py class SaveFrameContainer ( ContainerBase ): def __init__ ( self , name ): super ( SaveFrameContainer , self ) . __init__ ( name ) self . setType ( \"definition\" ) __init__ ( self , name ) special Source code in mmcif/api/PdbxContainers.py def __init__ ( self , name ): super ( SaveFrameContainer , self ) . __init__ ( name ) self . setType ( \"definition\" ) mmcif.api.PdbxContainers.CifName Class of utilities for CIF-style data names - Source code in mmcif/api/PdbxContainers.py class CifName ( object ): \"\"\"Class of utilities for CIF-style data names -\"\"\" def __init__ ( self ): pass @staticmethod def categoryPart ( name ): tname = \"\" try : if name . startswith ( \"_\" ): tname = name [ 1 :] else : tname = name i = tname . find ( \".\" ) if i == - 1 : return tname else : return tname [: i ] except Exception : return tname @staticmethod def attributePart ( name ): try : i = name . find ( \".\" ) if i == - 1 : return None else : return name [ i + 1 :] except Exception : return None @staticmethod def itemName ( categoryName , attributeName ): try : return \"_\" + str ( categoryName ) + \".\" + str ( attributeName ) except Exception : return None __init__ ( self ) special Source code in mmcif/api/PdbxContainers.py def __init__ ( self ): pass attributePart ( name ) staticmethod Source code in mmcif/api/PdbxContainers.py @staticmethod def attributePart ( name ): try : i = name . find ( \".\" ) if i == - 1 : return None else : return name [ i + 1 :] except Exception : return None categoryPart ( name ) staticmethod Source code in mmcif/api/PdbxContainers.py @staticmethod def categoryPart ( name ): tname = \"\" try : if name . startswith ( \"_\" ): tname = name [ 1 :] else : tname = name i = tname . find ( \".\" ) if i == - 1 : return tname else : return tname [: i ] except Exception : return tname itemName ( categoryName , attributeName ) staticmethod Source code in mmcif/api/PdbxContainers.py @staticmethod def itemName ( categoryName , attributeName ): try : return \"_\" + str ( categoryName ) + \".\" + str ( attributeName ) except Exception : return None","title":"PdbxContainers"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase","text":"Container base class for data and definition objects. Source code in mmcif/api/PdbxContainers.py class ContainerBase ( object ): \"\"\"Container base class for data and definition objects.\"\"\" def __init__ ( self , name ): # The enclosing scope of the data container (e.g. data_/save_) self . __name = name # List of category names within this container - self . __objNameList = [] # dictionary of DataCategory objects keyed by category name. self . __objCatalog = {} # dictionary for properties of the container self . __propCatalog = {} self . __type = None def __eq__ ( self , other ): if not isinstance ( other , type ( self )): return NotImplemented return ( self . __name == other . getName () and self . __objNameList == other . getObjNameList () and self . __objCatalog == other . getObjCatalog () and self . __type == other . getType () and self . __propCatalog == other . getPropCatalog () ) def __hash__ ( self ): return hash (( self . __name , tuple ( self . __objNameList ), self . __type , tuple ( self . __objCatalog . items ()), tuple ( self . __propCatalog . items ()))) def getObjCatalog ( self ): return self . __objCatalog def getPropCatalog ( self ): return self . __propCatalog def setProp ( self , propName , value ): try : self . __propCatalog [ propName ] = value return True except Exception : return False def getProp ( self , propName ): try : return self . __propCatalog [ propName ] except Exception : return None def getType ( self ): return self . __type def setType ( self , cType ): self . __type = cType def getName ( self ): return self . __name def setName ( self , name ): self . __name = name def exists ( self , name ): if name in self . __objCatalog : return True else : return False def getObj ( self , name ): if name in self . __objCatalog : return self . __objCatalog [ name ] else : return None def getObjNameList ( self ): return self . __objNameList def append ( self , obj ): \"\"\"Add the input object to the current object catalog. An existing object of the same name will be overwritten. \"\"\" if obj . getName () is not None : if obj . getName () not in self . __objCatalog : # self.__objNameList is keeping track of object order here -- self . __objNameList . append ( obj . getName ()) self . __objCatalog [ obj . getName ()] = obj def replace ( self , obj ): \"\"\"Replace an existing object with the input object\"\"\" if ( obj . getName () is not None ) and ( obj . getName () in self . __objCatalog ): self . __objCatalog [ obj . getName ()] = obj def printIt ( self , fh = sys . stdout , pType = \"brief\" ): fh . write ( \"+ %s container: %30s contains %4d categories \\n \" % ( self . getType (), self . getName (), len ( self . __objNameList ))) for nm in self . __objNameList : fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \"Data category: %s \\n \" % nm ) if pType == \"brief\" : self . __objCatalog [ nm ] . printIt ( fh ) else : self . __objCatalog [ nm ] . dumpIt ( fh ) def rename ( self , curName , newName ): \"\"\"Change the name of an object in place -\"\"\" try : i = self . __objNameList . index ( curName ) self . __objNameList [ i ] = newName self . __objCatalog [ newName ] = self . __objCatalog [ curName ] self . __objCatalog [ newName ] . setName ( newName ) return True except Exception : return False def remove ( self , curName ): \"\"\"Remove object by name. Return True on success or False otherwise.\"\"\" try : if curName in self . __objCatalog : del self . __objCatalog [ curName ] i = self . __objNameList . index ( curName ) del self . __objNameList [ i ] return True else : return False except Exception : pass return False def merge ( self , container ): \"\"\"Merge the contents of the input container with the contents of the current container.\"\"\" try : objNameList = container . getObjNameList () for objName in objNameList : self . append ( container . getObj ( objName )) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return False return True def filterObjectNameList ( self , lastInOrder = None , selectOrder = None ): \"\"\"Return an ordered list of categories in the input container subject to input - lastInOrder: list: categories to be shifted to the end of the container. selectOrder: list: ordered selection of container categories returns: filNameList: list: augmented category list or full list (default) \"\"\" filNameList = [] if lastInOrder : objNameList = self . __objNameList lastList = [] for nm in objNameList : if nm in lastInOrder : lastList . append ( nm ) continue filNameList . append ( nm ) filNameList . extend ( lastList ) elif selectOrder : for nm in selectOrder : if self . exists ( nm ): filNameList . append ( nm ) else : filNameList = self . __objNameList return filNameList def toJSON ( self ): return self . __objCatalog","title":"ContainerBase"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase-methods","text":"","title":"Methods"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.__eq__","text":"Source code in mmcif/api/PdbxContainers.py def __eq__ ( self , other ): if not isinstance ( other , type ( self )): return NotImplemented return ( self . __name == other . getName () and self . __objNameList == other . getObjNameList () and self . __objCatalog == other . getObjCatalog () and self . __type == other . getType () and self . __propCatalog == other . getPropCatalog () )","title":"__eq__()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.__hash__","text":"Source code in mmcif/api/PdbxContainers.py def __hash__ ( self ): return hash (( self . __name , tuple ( self . __objNameList ), self . __type , tuple ( self . __objCatalog . items ()), tuple ( self . __propCatalog . items ())))","title":"__hash__()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.__init__","text":"Source code in mmcif/api/PdbxContainers.py def __init__ ( self , name ): # The enclosing scope of the data container (e.g. data_/save_) self . __name = name # List of category names within this container - self . __objNameList = [] # dictionary of DataCategory objects keyed by category name. self . __objCatalog = {} # dictionary for properties of the container self . __propCatalog = {} self . __type = None","title":"__init__()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.append","text":"Add the input object to the current object catalog. An existing object of the same name will be overwritten. Source code in mmcif/api/PdbxContainers.py def append ( self , obj ): \"\"\"Add the input object to the current object catalog. An existing object of the same name will be overwritten. \"\"\" if obj . getName () is not None : if obj . getName () not in self . __objCatalog : # self.__objNameList is keeping track of object order here -- self . __objNameList . append ( obj . getName ()) self . __objCatalog [ obj . getName ()] = obj","title":"append()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.exists","text":"Source code in mmcif/api/PdbxContainers.py def exists ( self , name ): if name in self . __objCatalog : return True else : return False","title":"exists()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.filterObjectNameList","text":"Return an ordered list of categories in the input container subject to input - lastInOrder: list: categories to be shifted to the end of the container. selectOrder: list: ordered selection of container categories Returns: Type Description filNameList list: augmented category list or full list (default) Source code in mmcif/api/PdbxContainers.py def filterObjectNameList ( self , lastInOrder = None , selectOrder = None ): \"\"\"Return an ordered list of categories in the input container subject to input - lastInOrder: list: categories to be shifted to the end of the container. selectOrder: list: ordered selection of container categories returns: filNameList: list: augmented category list or full list (default) \"\"\" filNameList = [] if lastInOrder : objNameList = self . __objNameList lastList = [] for nm in objNameList : if nm in lastInOrder : lastList . append ( nm ) continue filNameList . append ( nm ) filNameList . extend ( lastList ) elif selectOrder : for nm in selectOrder : if self . exists ( nm ): filNameList . append ( nm ) else : filNameList = self . __objNameList return filNameList","title":"filterObjectNameList()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.getName","text":"Source code in mmcif/api/PdbxContainers.py def getName ( self ): return self . __name","title":"getName()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.getObj","text":"Source code in mmcif/api/PdbxContainers.py def getObj ( self , name ): if name in self . __objCatalog : return self . __objCatalog [ name ] else : return None","title":"getObj()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.getObjCatalog","text":"Source code in mmcif/api/PdbxContainers.py def getObjCatalog ( self ): return self . __objCatalog","title":"getObjCatalog()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.getObjNameList","text":"Source code in mmcif/api/PdbxContainers.py def getObjNameList ( self ): return self . __objNameList","title":"getObjNameList()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.getProp","text":"Source code in mmcif/api/PdbxContainers.py def getProp ( self , propName ): try : return self . __propCatalog [ propName ] except Exception : return None","title":"getProp()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.getPropCatalog","text":"Source code in mmcif/api/PdbxContainers.py def getPropCatalog ( self ): return self . __propCatalog","title":"getPropCatalog()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.getType","text":"Source code in mmcif/api/PdbxContainers.py def getType ( self ): return self . __type","title":"getType()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.merge","text":"Merge the contents of the input container with the contents of the current container. Source code in mmcif/api/PdbxContainers.py def merge ( self , container ): \"\"\"Merge the contents of the input container with the contents of the current container.\"\"\" try : objNameList = container . getObjNameList () for objName in objNameList : self . append ( container . getObj ( objName )) except Exception as e : logger . exception ( \"Failing with %s \" , str ( e )) return False return True","title":"merge()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.printIt","text":"Source code in mmcif/api/PdbxContainers.py def printIt ( self , fh = sys . stdout , pType = \"brief\" ): fh . write ( \"+ %s container: %30s contains %4d categories \\n \" % ( self . getType (), self . getName (), len ( self . __objNameList ))) for nm in self . __objNameList : fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \"Data category: %s \\n \" % nm ) if pType == \"brief\" : self . __objCatalog [ nm ] . printIt ( fh ) else : self . __objCatalog [ nm ] . dumpIt ( fh )","title":"printIt()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.remove","text":"Remove object by name. Return True on success or False otherwise. Source code in mmcif/api/PdbxContainers.py def remove ( self , curName ): \"\"\"Remove object by name. Return True on success or False otherwise.\"\"\" try : if curName in self . __objCatalog : del self . __objCatalog [ curName ] i = self . __objNameList . index ( curName ) del self . __objNameList [ i ] return True else : return False except Exception : pass return False","title":"remove()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.rename","text":"Change the name of an object in place - Source code in mmcif/api/PdbxContainers.py def rename ( self , curName , newName ): \"\"\"Change the name of an object in place -\"\"\" try : i = self . __objNameList . index ( curName ) self . __objNameList [ i ] = newName self . __objCatalog [ newName ] = self . __objCatalog [ curName ] self . __objCatalog [ newName ] . setName ( newName ) return True except Exception : return False","title":"rename()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.replace","text":"Replace an existing object with the input object Source code in mmcif/api/PdbxContainers.py def replace ( self , obj ): \"\"\"Replace an existing object with the input object\"\"\" if ( obj . getName () is not None ) and ( obj . getName () in self . __objCatalog ): self . __objCatalog [ obj . getName ()] = obj","title":"replace()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.setName","text":"Source code in mmcif/api/PdbxContainers.py def setName ( self , name ): self . __name = name","title":"setName()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.setProp","text":"Source code in mmcif/api/PdbxContainers.py def setProp ( self , propName , value ): try : self . __propCatalog [ propName ] = value return True except Exception : return False","title":"setProp()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.setType","text":"Source code in mmcif/api/PdbxContainers.py def setType ( self , cType ): self . __type = cType","title":"setType()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.ContainerBase.toJSON","text":"Source code in mmcif/api/PdbxContainers.py def toJSON ( self ): return self . __objCatalog","title":"toJSON()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.DefinitionContainer","text":"Source code in mmcif/api/PdbxContainers.py class DefinitionContainer ( ContainerBase ): def __init__ ( self , name ): super ( DefinitionContainer , self ) . __init__ ( name ) self . setType ( \"definition\" ) self . __globalFlag = False def isCategory ( self ): if self . exists ( \"category\" ): return True return False def isAttribute ( self ): if self . exists ( \"item\" ): return True return False def getGlobal ( self ): return self . __globalFlag def printIt ( self , fh = sys . stdout , pType = \"brief\" ): fh . write ( \"Definition container: %30s contains %4d categories \\n \" % ( self . getName (), len ( self . getObjNameList ()))) if self . isCategory (): fh . write ( \"Definition type: category \\n \" ) elif self . isAttribute (): fh . write ( \"Definition type: item \\n \" ) else : fh . write ( \"Definition type: undefined \\n \" ) for nm in self . getObjNameList (): fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \"Definition category: %s \\n \" % nm ) if pType == \"brief\" : self . getObj ( nm ) . printIt ( fh ) else : self . getObj ( nm ) . dumpId ( fh )","title":"DefinitionContainer"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.DefinitionContainer.__init__","text":"Source code in mmcif/api/PdbxContainers.py def __init__ ( self , name ): super ( DefinitionContainer , self ) . __init__ ( name ) self . setType ( \"definition\" ) self . __globalFlag = False","title":"__init__()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.DefinitionContainer.getGlobal","text":"Source code in mmcif/api/PdbxContainers.py def getGlobal ( self ): return self . __globalFlag","title":"getGlobal()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.DefinitionContainer.isAttribute","text":"Source code in mmcif/api/PdbxContainers.py def isAttribute ( self ): if self . exists ( \"item\" ): return True return False","title":"isAttribute()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.DefinitionContainer.isCategory","text":"Source code in mmcif/api/PdbxContainers.py def isCategory ( self ): if self . exists ( \"category\" ): return True return False","title":"isCategory()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.DefinitionContainer.printIt","text":"Source code in mmcif/api/PdbxContainers.py def printIt ( self , fh = sys . stdout , pType = \"brief\" ): fh . write ( \"Definition container: %30s contains %4d categories \\n \" % ( self . getName (), len ( self . getObjNameList ()))) if self . isCategory (): fh . write ( \"Definition type: category \\n \" ) elif self . isAttribute (): fh . write ( \"Definition type: item \\n \" ) else : fh . write ( \"Definition type: undefined \\n \" ) for nm in self . getObjNameList (): fh . write ( \"-------------------------------------------- \\n \" ) fh . write ( \"Definition category: %s \\n \" % nm ) if pType == \"brief\" : self . getObj ( nm ) . printIt ( fh ) else : self . getObj ( nm ) . dumpId ( fh )","title":"printIt()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.DataContainer","text":"Container class for DataCategory objects. Source code in mmcif/api/PdbxContainers.py class DataContainer ( ContainerBase ): \"\"\"Container class for DataCategory objects.\"\"\" def __init__ ( self , name ): super ( DataContainer , self ) . __init__ ( name ) self . setType ( \"data\" ) self . __globalFlag = False def invokeDataBlockMethod ( self , mType , method , db ): _ = mType _ = db # self.__currentRow = 1 exec ( method . getInline (), globals (), locals ()) # pylint: disable=exec-used def setGlobal ( self ): self . __globalFlag = True def getGlobal ( self ): return self . __globalFlag","title":"DataContainer"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.DataContainer.__init__","text":"Source code in mmcif/api/PdbxContainers.py def __init__ ( self , name ): super ( DataContainer , self ) . __init__ ( name ) self . setType ( \"data\" ) self . __globalFlag = False","title":"__init__()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.DataContainer.getGlobal","text":"Source code in mmcif/api/PdbxContainers.py def getGlobal ( self ): return self . __globalFlag","title":"getGlobal()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.DataContainer.invokeDataBlockMethod","text":"Source code in mmcif/api/PdbxContainers.py def invokeDataBlockMethod ( self , mType , method , db ): _ = mType _ = db # self.__currentRow = 1 exec ( method . getInline (), globals (), locals ()) # pylint: disable=exec-used","title":"invokeDataBlockMethod()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.DataContainer.setGlobal","text":"Source code in mmcif/api/PdbxContainers.py def setGlobal ( self ): self . __globalFlag = True","title":"setGlobal()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.SaveFrameContainer","text":"Source code in mmcif/api/PdbxContainers.py class SaveFrameContainer ( ContainerBase ): def __init__ ( self , name ): super ( SaveFrameContainer , self ) . __init__ ( name ) self . setType ( \"definition\" )","title":"SaveFrameContainer"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.SaveFrameContainer.__init__","text":"Source code in mmcif/api/PdbxContainers.py def __init__ ( self , name ): super ( SaveFrameContainer , self ) . __init__ ( name ) self . setType ( \"definition\" )","title":"__init__()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.CifName","text":"Class of utilities for CIF-style data names - Source code in mmcif/api/PdbxContainers.py class CifName ( object ): \"\"\"Class of utilities for CIF-style data names -\"\"\" def __init__ ( self ): pass @staticmethod def categoryPart ( name ): tname = \"\" try : if name . startswith ( \"_\" ): tname = name [ 1 :] else : tname = name i = tname . find ( \".\" ) if i == - 1 : return tname else : return tname [: i ] except Exception : return tname @staticmethod def attributePart ( name ): try : i = name . find ( \".\" ) if i == - 1 : return None else : return name [ i + 1 :] except Exception : return None @staticmethod def itemName ( categoryName , attributeName ): try : return \"_\" + str ( categoryName ) + \".\" + str ( attributeName ) except Exception : return None","title":"CifName"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.CifName.__init__","text":"Source code in mmcif/api/PdbxContainers.py def __init__ ( self ): pass","title":"__init__()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.CifName.attributePart","text":"Source code in mmcif/api/PdbxContainers.py @staticmethod def attributePart ( name ): try : i = name . find ( \".\" ) if i == - 1 : return None else : return name [ i + 1 :] except Exception : return None","title":"attributePart()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.CifName.categoryPart","text":"Source code in mmcif/api/PdbxContainers.py @staticmethod def categoryPart ( name ): tname = \"\" try : if name . startswith ( \"_\" ): tname = name [ 1 :] else : tname = name i = tname . find ( \".\" ) if i == - 1 : return tname else : return tname [: i ] except Exception : return tname","title":"categoryPart()"},{"location":"api_reference/PdbxContainers/#mmcif.api.PdbxContainers.CifName.itemName","text":"Source code in mmcif/api/PdbxContainers.py @staticmethod def itemName ( categoryName , attributeName ): try : return \"_\" + str ( categoryName ) + \".\" + str ( attributeName ) except Exception : return None","title":"itemName()"},{"location":"api_reference/PdbxExceptions/","text":"mmcif.io.PdbxExceptions.PdbxError ( Exception ) Class for catch general errors Source code in mmcif/io/PdbxExceptions.py class PdbxError ( Exception ): \"\"\"Class for catch general errors\"\"\" mmcif.io.PdbxExceptions.PdbxSyntaxError ( Exception ) Class for catching syntax errors Source code in mmcif/io/PdbxExceptions.py class PdbxSyntaxError ( Exception ): \"\"\"Class for catching syntax errors\"\"\"","title":"PdbxExceptions"},{"location":"api_reference/PdbxExceptions/#mmcif.io.PdbxExceptions.PdbxError","text":"Class for catch general errors Source code in mmcif/io/PdbxExceptions.py class PdbxError ( Exception ): \"\"\"Class for catch general errors\"\"\"","title":"PdbxError"},{"location":"api_reference/PdbxExceptions/#mmcif.io.PdbxExceptions.PdbxSyntaxError","text":"Class for catching syntax errors Source code in mmcif/io/PdbxExceptions.py class PdbxSyntaxError ( Exception ): \"\"\"Class for catching syntax errors\"\"\"","title":"PdbxSyntaxError"},{"location":"api_reference/PdbxReader/","text":"mmcif.io.PdbxReader.PdbxReader Utilities for reading mmCIF for data files and dictionaries. Source code in mmcif/io/PdbxReader.py class PdbxReader ( object ): \"\"\"Utilities for reading mmCIF for data files and dictionaries.\"\"\" def __init__ ( self , ifh ): \"\"\"ifh - input file handle returned by open()\"\"\" # self . __curLineNumber = 0 self . __ifh = ifh self . __stateDict = { \"data\" : \"ST_DATA_CONTAINER\" , \"loop\" : \"ST_TABLE\" , \"global\" : \"ST_GLOBAL_CONTAINER\" , \"save\" : \"ST_DEFINITION\" , \"stop\" : \"ST_STOP\" } def read ( self , containerList , selectList = None , excludeFlag = False ): \"\"\" Appends to input list of definition and data containers. return \"\"\" sL = selectList if selectList else [] catSelectD = { k : k for k in sL } self . __curLineNumber = 0 try : self . __parser ( self . __tokenizer ( self . __ifh ), containerList , categorySelectionD = catSelectD , excludeFlag = excludeFlag ) except RuntimeError as e : # will be raised at the end of token iterator - not an error - logger . debug ( \"Normal termination after reading %d lines with %s \" , self . __curLineNumber , str ( e )) except StopIteration : # will be raised at the end of token iterator - not an error - logger . debug ( \"Normal termination after reading %d lines\" , self . __curLineNumber ) except PdbxSyntaxError as e : logger . debug ( \"Caught syntax exception at %d \" , self . __curLineNumber ) raise e except UnicodeDecodeError as e : logger . debug ( \"Caught character encoding exception at %d with %s \" , self . __curLineNumber , str ( e )) raise PdbxError ( \"Character encoding error at line %d \" % self . __curLineNumber ) except Exception as e : raise PdbxError ( \"Failing at line %d with %s \" % ( self . __curLineNumber , str ( e ))) else : raise PdbxError ( \"Miscellaneous parsing error at line %d \" % self . __curLineNumber ) def __allSelected ( self , container , catSelectD ): \"\"\"Test the input container for completeness relative to the input category selection dictionary.\"\"\" nl = - 1 if catSelectD : try : nl = container . getObjNameList () if len ( nl ) <= len ( catSelectD ): ok = False else : ok = True logger . debug ( \"nl %d length catSelectD %d returning %r \" , len ( nl ), len ( catSelectD ), ok ) except Exception : ok = False else : ok = False return ok def __syntaxError ( self , errText ): msg = \" [Line: %d ] %s \" % ( self . __curLineNumber , errText ) raise PdbxSyntaxError ( msg ) def __getContainerName ( self , inWord ): \"\"\"Returns the name of the data block or saveframe container\"\"\" return str ( inWord [ 5 :]) . strip () def __getState ( self , inWord ): \"\"\"Identifies reserved syntax elements and assigns an associated state. on return: (reserved word, state) where - reserved word - is one of CIF syntax elements: data, loop, global, save, or stop state - the parser state required to process this next section. \"\"\" i = inWord . find ( \"_\" ) if i == - 1 : return None , \"ST_UNKNOWN\" try : rWord = inWord [: i ] . lower () return rWord , self . __stateDict [ rWord ] except Exception : return None , \"ST_UNKNOWN\" def __parser ( self , tokenizer , containerList , categorySelectionD = None , excludeFlag = False ): \"\"\"Parser for PDBx data files and dictionaries. Input - tokenizer() reentrant method recognizing data item names (_category.attribute) quoted strings (single, double and multi-line semi-colon delimited), and unquoted strings. containerList - list-type container for data and definition objects parsed from from the input file. On return: The input containerList is appended with data and definition objects - \"\"\" catSelectD = categorySelectionD if categorySelectionD is not None else {} logger . debug ( \"Exclude Flag %r Category selection %r \" , excludeFlag , catSelectD ) # Working container - data or definition curContainer = None # the last container of type data - previousDataContainer = None # # Working category container categoryIndex = {} curCategory = None # curRow = None state = None # Find the first reserved word and begin capturing data. # while True : curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) if curWord is None : continue reservedWord , state = self . __getState ( curWord ) if reservedWord is not None : break while True : # # Set the current state - # # At this point in the processing cycle we are expecting a token containing # either a '_category.attribute' or a reserved word. # if curCatName is not None : state = \"ST_KEY_VALUE_PAIR\" elif curWord is not None : reservedWord , state = self . __getState ( curWord ) else : self . __syntaxError ( \"Miscellaneous syntax error\" ) return # # Process _category.attribute value assignments # if state == \"ST_KEY_VALUE_PAIR\" : try : curCategory = categoryIndex [ curCatName ] except KeyError : # A new category is encountered - create a container and add a row curCategory = categoryIndex [ curCatName ] = DataCategory ( curCatName ) # # check if we have all of the selection if not excludeFlag and self . __allSelected ( curContainer , catSelectD ): return try : if catSelectD : if not excludeFlag and curCatName in catSelectD : curContainer . append ( curCategory ) elif excludeFlag and curCatName not in catSelectD : curContainer . append ( curCategory ) else : logger . debug ( \"Skipped unselected/excluded category %s \" , curCatName ) else : curContainer . append ( curCategory ) except AttributeError : self . __syntaxError ( \"Category cannot be added to data_ block\" ) return curRow = [] curCategory . append ( curRow ) else : # Recover the existing row from the category try : # curRow = curCategory[0] curRow = curCategory . getRow ( 0 ) except IndexError : self . __syntaxError ( \"Internal index error accessing category data\" ) return # Check for duplicate attributes and add attribute to table. if curAttName in curCategory . getAttributeList (): self . __syntaxError ( \"Duplicate attribute encountered in category\" ) return else : curCategory . appendAttribute ( curAttName ) # Get the data for this attribute from the next token tCat , _ , curQuotedString , curWord = next ( tokenizer ) if tCat is not None or ( curQuotedString is None and curWord is None ): self . __syntaxError ( \"Missing data for item _ %s . %s \" % ( curCatName , curAttName )) if curWord is not None : # # Validation check token for misplaced reserved words - # reservedWord , state = self . __getState ( curWord ) if reservedWord is not None : self . __syntaxError ( \"Unexpected reserved word: %s \" % ( reservedWord )) curRow . append ( curWord ) elif curQuotedString is not None : curRow . append ( curQuotedString ) else : self . __syntaxError ( \"Missing value in item-value pair\" ) curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) continue # # Process a loop_ declaration and associated data - # elif state == \"ST_TABLE\" : # The category name in the next curCatName,curAttName pair # defines the name of the category container. curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) if curCatName is None or curAttName is None : self . __syntaxError ( \"Unexpected token in loop_ declaration\" ) return # Check for a previous category declaration. if curCatName in categoryIndex : self . __syntaxError ( \"Duplicate category declaration in loop_\" ) return curCategory = DataCategory ( curCatName ) # # check if we have all of the selection if not excludeFlag and self . __allSelected ( curContainer , catSelectD ): return try : if catSelectD : if not excludeFlag and curCatName in catSelectD : curContainer . append ( curCategory ) elif excludeFlag and curCatName not in catSelectD : curContainer . append ( curCategory ) else : logger . debug ( \"Skipped unselected/excluded category %s \" , curCatName ) else : curContainer . append ( curCategory ) except AttributeError : self . __syntaxError ( \"loop_ declaration outside of data_ block or save_ frame\" ) return curCategory . appendAttribute ( curAttName ) # Read the rest of the loop_ declaration while True : curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) if curCatName is None : break if curCatName != curCategory . getName (): self . __syntaxError ( \"Changed category name in loop_ declaration\" ) return curCategory . appendAttribute ( curAttName ) # If the next token is a 'word', check it for any reserved words - if curWord is not None : reservedWord , state = self . __getState ( curWord ) if reservedWord is not None : if reservedWord == \"stop\" : return else : self . __syntaxError ( \"Unexpected reserved word after loop declaration: %s \" % ( reservedWord )) # Read the table of data for this loop_ - while True : curRow = [] curCategory . append ( curRow ) for _ in curCategory . getAttributeList (): if curWord is not None : curRow . append ( curWord ) elif curQuotedString is not None : curRow . append ( curQuotedString ) curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) # loop_ data processing ends if - # A new _category.attribute is encountered if curCatName is not None : break # A reserved word is encountered if curWord is not None : reservedWord , state = self . __getState ( curWord ) if reservedWord is not None : break continue elif state == \"ST_DEFINITION\" : # Ignore trailing unnamed saveframe delimiters e.g. 'save' sName = self . __getContainerName ( curWord ) if sName : curContainer = DefinitionContainer ( sName ) containerList . append ( curContainer ) categoryIndex = {} curCategory = None else : # reset current container to the last data container curContainer = previousDataContainer curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) elif state == \"ST_DATA_CONTAINER\" : # dName = self . __getContainerName ( curWord ) if not dName : dName = \"unidentified\" curContainer = DataContainer ( dName ) containerList . append ( curContainer ) categoryIndex = {} curCategory = None previousDataContainer = curContainer curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) elif state == \"ST_STOP\" : ### # curCatName, curAttName, curQuotedString, curWord = tokenizer.next() continue elif state == \"ST_GLOBAL\" : curContainer = DataContainer ( \"blank-global\" ) curContainer . setGlobal () containerList . append ( curContainer ) categoryIndex = {} curCategory = None curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) elif state == \"ST_UNKNOWN\" : self . __syntaxError ( \"Unrecognized syntax element: \" + str ( curWord )) return def __tokenizer ( self , ifh ): \"\"\"Tokenizer method for the mmCIF syntax file - Each return/yield from this method returns information about the next token in the form of a tuple with the following structure. (category name, attribute name, quoted strings, words w/o quotes or white space) \"\"\" # # Regex definition for mmCIF syntax - semi-colon delimited strings are handled # outside of this regex. # Differentiated the regular expression to the better handle embedded quotes. # mmcifRe = re . compile ( r \"(?:\" r \"(?:_(.+?)[.](\\S+))\" r \"|\" # _category.attribute r \"(?:['](.*?)(?:[']\\s|[']$))\" r \"|\" # single quoted strings r '(?:[\"](.*?)(?:[\"]\\s|[\"]$))' r \"|\" # double quoted strings r \"(?:\\s*#.*$)\" r \"|\" # comments (dumped) r \"(\\S+)\" # unquoted words r \")\" ) fileIter = iter ( ifh ) # Tokenizer loop begins here --- while True : try : line = next ( fileIter ) self . __curLineNumber += 1 # Dump comments if line . startswith ( \"#\" ): continue # Gobble up the entire semi-colon/multi-line delimited string and # and stuff this into the string slot in the return tuple # if line . startswith ( \";\" ): mlString = [ line [ 1 :]] while True : line = next ( fileIter ) self . __curLineNumber += 1 if line . startswith ( \";\" ): break mlString . append ( line ) # remove trailing new-line that is part of the \\n; delimiter mlString [ - 1 ] = mlString [ - 1 ] . rstrip () # yield ( None , None , \"\" . join ( mlString ), None ) # # Need to process the remainder of the current line - line = line [ 1 :] # continue # Apply regex to the current line consolidate the single/double # quoted within the quoted string category for it in mmcifRe . finditer ( line ): tgroups = it . groups () # if tgroups [ 4 ] is not None and tgroups [ 4 ] . lower () == \"stop_\" : continue if tgroups != ( None , None , None , None , None ): if tgroups [ 2 ] is not None : qs = tgroups [ 2 ] elif tgroups [ 3 ] is not None : qs = tgroups [ 3 ] else : qs = None groups = ( tgroups [ 0 ], tgroups [ 1 ], qs , tgroups [ 4 ]) yield groups except StopIteration : return Methods __init__ ( self , ifh ) special ifh - input file handle returned by open() Source code in mmcif/io/PdbxReader.py def __init__ ( self , ifh ): \"\"\"ifh - input file handle returned by open()\"\"\" # self . __curLineNumber = 0 self . __ifh = ifh self . __stateDict = { \"data\" : \"ST_DATA_CONTAINER\" , \"loop\" : \"ST_TABLE\" , \"global\" : \"ST_GLOBAL_CONTAINER\" , \"save\" : \"ST_DEFINITION\" , \"stop\" : \"ST_STOP\" } read ( self , containerList , selectList = None , excludeFlag = False ) Appends to input list of definition and data containers. return Source code in mmcif/io/PdbxReader.py def read ( self , containerList , selectList = None , excludeFlag = False ): \"\"\" Appends to input list of definition and data containers. return \"\"\" sL = selectList if selectList else [] catSelectD = { k : k for k in sL } self . __curLineNumber = 0 try : self . __parser ( self . __tokenizer ( self . __ifh ), containerList , categorySelectionD = catSelectD , excludeFlag = excludeFlag ) except RuntimeError as e : # will be raised at the end of token iterator - not an error - logger . debug ( \"Normal termination after reading %d lines with %s \" , self . __curLineNumber , str ( e )) except StopIteration : # will be raised at the end of token iterator - not an error - logger . debug ( \"Normal termination after reading %d lines\" , self . __curLineNumber ) except PdbxSyntaxError as e : logger . debug ( \"Caught syntax exception at %d \" , self . __curLineNumber ) raise e except UnicodeDecodeError as e : logger . debug ( \"Caught character encoding exception at %d with %s \" , self . __curLineNumber , str ( e )) raise PdbxError ( \"Character encoding error at line %d \" % self . __curLineNumber ) except Exception as e : raise PdbxError ( \"Failing at line %d with %s \" % ( self . __curLineNumber , str ( e ))) else : raise PdbxError ( \"Miscellaneous parsing error at line %d \" % self . __curLineNumber )","title":"PdbxReader"},{"location":"api_reference/PdbxReader/#mmcif.io.PdbxReader.PdbxReader","text":"Utilities for reading mmCIF for data files and dictionaries. Source code in mmcif/io/PdbxReader.py class PdbxReader ( object ): \"\"\"Utilities for reading mmCIF for data files and dictionaries.\"\"\" def __init__ ( self , ifh ): \"\"\"ifh - input file handle returned by open()\"\"\" # self . __curLineNumber = 0 self . __ifh = ifh self . __stateDict = { \"data\" : \"ST_DATA_CONTAINER\" , \"loop\" : \"ST_TABLE\" , \"global\" : \"ST_GLOBAL_CONTAINER\" , \"save\" : \"ST_DEFINITION\" , \"stop\" : \"ST_STOP\" } def read ( self , containerList , selectList = None , excludeFlag = False ): \"\"\" Appends to input list of definition and data containers. return \"\"\" sL = selectList if selectList else [] catSelectD = { k : k for k in sL } self . __curLineNumber = 0 try : self . __parser ( self . __tokenizer ( self . __ifh ), containerList , categorySelectionD = catSelectD , excludeFlag = excludeFlag ) except RuntimeError as e : # will be raised at the end of token iterator - not an error - logger . debug ( \"Normal termination after reading %d lines with %s \" , self . __curLineNumber , str ( e )) except StopIteration : # will be raised at the end of token iterator - not an error - logger . debug ( \"Normal termination after reading %d lines\" , self . __curLineNumber ) except PdbxSyntaxError as e : logger . debug ( \"Caught syntax exception at %d \" , self . __curLineNumber ) raise e except UnicodeDecodeError as e : logger . debug ( \"Caught character encoding exception at %d with %s \" , self . __curLineNumber , str ( e )) raise PdbxError ( \"Character encoding error at line %d \" % self . __curLineNumber ) except Exception as e : raise PdbxError ( \"Failing at line %d with %s \" % ( self . __curLineNumber , str ( e ))) else : raise PdbxError ( \"Miscellaneous parsing error at line %d \" % self . __curLineNumber ) def __allSelected ( self , container , catSelectD ): \"\"\"Test the input container for completeness relative to the input category selection dictionary.\"\"\" nl = - 1 if catSelectD : try : nl = container . getObjNameList () if len ( nl ) <= len ( catSelectD ): ok = False else : ok = True logger . debug ( \"nl %d length catSelectD %d returning %r \" , len ( nl ), len ( catSelectD ), ok ) except Exception : ok = False else : ok = False return ok def __syntaxError ( self , errText ): msg = \" [Line: %d ] %s \" % ( self . __curLineNumber , errText ) raise PdbxSyntaxError ( msg ) def __getContainerName ( self , inWord ): \"\"\"Returns the name of the data block or saveframe container\"\"\" return str ( inWord [ 5 :]) . strip () def __getState ( self , inWord ): \"\"\"Identifies reserved syntax elements and assigns an associated state. on return: (reserved word, state) where - reserved word - is one of CIF syntax elements: data, loop, global, save, or stop state - the parser state required to process this next section. \"\"\" i = inWord . find ( \"_\" ) if i == - 1 : return None , \"ST_UNKNOWN\" try : rWord = inWord [: i ] . lower () return rWord , self . __stateDict [ rWord ] except Exception : return None , \"ST_UNKNOWN\" def __parser ( self , tokenizer , containerList , categorySelectionD = None , excludeFlag = False ): \"\"\"Parser for PDBx data files and dictionaries. Input - tokenizer() reentrant method recognizing data item names (_category.attribute) quoted strings (single, double and multi-line semi-colon delimited), and unquoted strings. containerList - list-type container for data and definition objects parsed from from the input file. On return: The input containerList is appended with data and definition objects - \"\"\" catSelectD = categorySelectionD if categorySelectionD is not None else {} logger . debug ( \"Exclude Flag %r Category selection %r \" , excludeFlag , catSelectD ) # Working container - data or definition curContainer = None # the last container of type data - previousDataContainer = None # # Working category container categoryIndex = {} curCategory = None # curRow = None state = None # Find the first reserved word and begin capturing data. # while True : curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) if curWord is None : continue reservedWord , state = self . __getState ( curWord ) if reservedWord is not None : break while True : # # Set the current state - # # At this point in the processing cycle we are expecting a token containing # either a '_category.attribute' or a reserved word. # if curCatName is not None : state = \"ST_KEY_VALUE_PAIR\" elif curWord is not None : reservedWord , state = self . __getState ( curWord ) else : self . __syntaxError ( \"Miscellaneous syntax error\" ) return # # Process _category.attribute value assignments # if state == \"ST_KEY_VALUE_PAIR\" : try : curCategory = categoryIndex [ curCatName ] except KeyError : # A new category is encountered - create a container and add a row curCategory = categoryIndex [ curCatName ] = DataCategory ( curCatName ) # # check if we have all of the selection if not excludeFlag and self . __allSelected ( curContainer , catSelectD ): return try : if catSelectD : if not excludeFlag and curCatName in catSelectD : curContainer . append ( curCategory ) elif excludeFlag and curCatName not in catSelectD : curContainer . append ( curCategory ) else : logger . debug ( \"Skipped unselected/excluded category %s \" , curCatName ) else : curContainer . append ( curCategory ) except AttributeError : self . __syntaxError ( \"Category cannot be added to data_ block\" ) return curRow = [] curCategory . append ( curRow ) else : # Recover the existing row from the category try : # curRow = curCategory[0] curRow = curCategory . getRow ( 0 ) except IndexError : self . __syntaxError ( \"Internal index error accessing category data\" ) return # Check for duplicate attributes and add attribute to table. if curAttName in curCategory . getAttributeList (): self . __syntaxError ( \"Duplicate attribute encountered in category\" ) return else : curCategory . appendAttribute ( curAttName ) # Get the data for this attribute from the next token tCat , _ , curQuotedString , curWord = next ( tokenizer ) if tCat is not None or ( curQuotedString is None and curWord is None ): self . __syntaxError ( \"Missing data for item _ %s . %s \" % ( curCatName , curAttName )) if curWord is not None : # # Validation check token for misplaced reserved words - # reservedWord , state = self . __getState ( curWord ) if reservedWord is not None : self . __syntaxError ( \"Unexpected reserved word: %s \" % ( reservedWord )) curRow . append ( curWord ) elif curQuotedString is not None : curRow . append ( curQuotedString ) else : self . __syntaxError ( \"Missing value in item-value pair\" ) curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) continue # # Process a loop_ declaration and associated data - # elif state == \"ST_TABLE\" : # The category name in the next curCatName,curAttName pair # defines the name of the category container. curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) if curCatName is None or curAttName is None : self . __syntaxError ( \"Unexpected token in loop_ declaration\" ) return # Check for a previous category declaration. if curCatName in categoryIndex : self . __syntaxError ( \"Duplicate category declaration in loop_\" ) return curCategory = DataCategory ( curCatName ) # # check if we have all of the selection if not excludeFlag and self . __allSelected ( curContainer , catSelectD ): return try : if catSelectD : if not excludeFlag and curCatName in catSelectD : curContainer . append ( curCategory ) elif excludeFlag and curCatName not in catSelectD : curContainer . append ( curCategory ) else : logger . debug ( \"Skipped unselected/excluded category %s \" , curCatName ) else : curContainer . append ( curCategory ) except AttributeError : self . __syntaxError ( \"loop_ declaration outside of data_ block or save_ frame\" ) return curCategory . appendAttribute ( curAttName ) # Read the rest of the loop_ declaration while True : curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) if curCatName is None : break if curCatName != curCategory . getName (): self . __syntaxError ( \"Changed category name in loop_ declaration\" ) return curCategory . appendAttribute ( curAttName ) # If the next token is a 'word', check it for any reserved words - if curWord is not None : reservedWord , state = self . __getState ( curWord ) if reservedWord is not None : if reservedWord == \"stop\" : return else : self . __syntaxError ( \"Unexpected reserved word after loop declaration: %s \" % ( reservedWord )) # Read the table of data for this loop_ - while True : curRow = [] curCategory . append ( curRow ) for _ in curCategory . getAttributeList (): if curWord is not None : curRow . append ( curWord ) elif curQuotedString is not None : curRow . append ( curQuotedString ) curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) # loop_ data processing ends if - # A new _category.attribute is encountered if curCatName is not None : break # A reserved word is encountered if curWord is not None : reservedWord , state = self . __getState ( curWord ) if reservedWord is not None : break continue elif state == \"ST_DEFINITION\" : # Ignore trailing unnamed saveframe delimiters e.g. 'save' sName = self . __getContainerName ( curWord ) if sName : curContainer = DefinitionContainer ( sName ) containerList . append ( curContainer ) categoryIndex = {} curCategory = None else : # reset current container to the last data container curContainer = previousDataContainer curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) elif state == \"ST_DATA_CONTAINER\" : # dName = self . __getContainerName ( curWord ) if not dName : dName = \"unidentified\" curContainer = DataContainer ( dName ) containerList . append ( curContainer ) categoryIndex = {} curCategory = None previousDataContainer = curContainer curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) elif state == \"ST_STOP\" : ### # curCatName, curAttName, curQuotedString, curWord = tokenizer.next() continue elif state == \"ST_GLOBAL\" : curContainer = DataContainer ( \"blank-global\" ) curContainer . setGlobal () containerList . append ( curContainer ) categoryIndex = {} curCategory = None curCatName , curAttName , curQuotedString , curWord = next ( tokenizer ) elif state == \"ST_UNKNOWN\" : self . __syntaxError ( \"Unrecognized syntax element: \" + str ( curWord )) return def __tokenizer ( self , ifh ): \"\"\"Tokenizer method for the mmCIF syntax file - Each return/yield from this method returns information about the next token in the form of a tuple with the following structure. (category name, attribute name, quoted strings, words w/o quotes or white space) \"\"\" # # Regex definition for mmCIF syntax - semi-colon delimited strings are handled # outside of this regex. # Differentiated the regular expression to the better handle embedded quotes. # mmcifRe = re . compile ( r \"(?:\" r \"(?:_(.+?)[.](\\S+))\" r \"|\" # _category.attribute r \"(?:['](.*?)(?:[']\\s|[']$))\" r \"|\" # single quoted strings r '(?:[\"](.*?)(?:[\"]\\s|[\"]$))' r \"|\" # double quoted strings r \"(?:\\s*#.*$)\" r \"|\" # comments (dumped) r \"(\\S+)\" # unquoted words r \")\" ) fileIter = iter ( ifh ) # Tokenizer loop begins here --- while True : try : line = next ( fileIter ) self . __curLineNumber += 1 # Dump comments if line . startswith ( \"#\" ): continue # Gobble up the entire semi-colon/multi-line delimited string and # and stuff this into the string slot in the return tuple # if line . startswith ( \";\" ): mlString = [ line [ 1 :]] while True : line = next ( fileIter ) self . __curLineNumber += 1 if line . startswith ( \";\" ): break mlString . append ( line ) # remove trailing new-line that is part of the \\n; delimiter mlString [ - 1 ] = mlString [ - 1 ] . rstrip () # yield ( None , None , \"\" . join ( mlString ), None ) # # Need to process the remainder of the current line - line = line [ 1 :] # continue # Apply regex to the current line consolidate the single/double # quoted within the quoted string category for it in mmcifRe . finditer ( line ): tgroups = it . groups () # if tgroups [ 4 ] is not None and tgroups [ 4 ] . lower () == \"stop_\" : continue if tgroups != ( None , None , None , None , None ): if tgroups [ 2 ] is not None : qs = tgroups [ 2 ] elif tgroups [ 3 ] is not None : qs = tgroups [ 3 ] else : qs = None groups = ( tgroups [ 0 ], tgroups [ 1 ], qs , tgroups [ 4 ]) yield groups except StopIteration : return","title":"PdbxReader"},{"location":"api_reference/PdbxReader/#mmcif.io.PdbxReader.PdbxReader-methods","text":"","title":"Methods"},{"location":"api_reference/PdbxReader/#mmcif.io.PdbxReader.PdbxReader.__init__","text":"ifh - input file handle returned by open() Source code in mmcif/io/PdbxReader.py def __init__ ( self , ifh ): \"\"\"ifh - input file handle returned by open()\"\"\" # self . __curLineNumber = 0 self . __ifh = ifh self . __stateDict = { \"data\" : \"ST_DATA_CONTAINER\" , \"loop\" : \"ST_TABLE\" , \"global\" : \"ST_GLOBAL_CONTAINER\" , \"save\" : \"ST_DEFINITION\" , \"stop\" : \"ST_STOP\" }","title":"__init__()"},{"location":"api_reference/PdbxReader/#mmcif.io.PdbxReader.PdbxReader.read","text":"Appends to input list of definition and data containers. return Source code in mmcif/io/PdbxReader.py def read ( self , containerList , selectList = None , excludeFlag = False ): \"\"\" Appends to input list of definition and data containers. return \"\"\" sL = selectList if selectList else [] catSelectD = { k : k for k in sL } self . __curLineNumber = 0 try : self . __parser ( self . __tokenizer ( self . __ifh ), containerList , categorySelectionD = catSelectD , excludeFlag = excludeFlag ) except RuntimeError as e : # will be raised at the end of token iterator - not an error - logger . debug ( \"Normal termination after reading %d lines with %s \" , self . __curLineNumber , str ( e )) except StopIteration : # will be raised at the end of token iterator - not an error - logger . debug ( \"Normal termination after reading %d lines\" , self . __curLineNumber ) except PdbxSyntaxError as e : logger . debug ( \"Caught syntax exception at %d \" , self . __curLineNumber ) raise e except UnicodeDecodeError as e : logger . debug ( \"Caught character encoding exception at %d with %s \" , self . __curLineNumber , str ( e )) raise PdbxError ( \"Character encoding error at line %d \" % self . __curLineNumber ) except Exception as e : raise PdbxError ( \"Failing at line %d with %s \" % ( self . __curLineNumber , str ( e ))) else : raise PdbxError ( \"Miscellaneous parsing error at line %d \" % self . __curLineNumber )","title":"read()"},{"location":"api_reference/PdbxWriter/","text":"mmcif.io.PdbxWriter.PdbxWriter Write mmCIF data files or dictionaries using the input container or container list. Source code in mmcif/io/PdbxWriter.py class PdbxWriter ( object ): \"\"\"Write mmCIF data files or dictionaries using the input container or container list.\"\"\" def __init__ ( self , ofh = sys . stdout ): self . __ofh = ofh self . __containerList = [] self . __maximumLineLength = 2048 self . __spacing = 2 self . __indentDefinition = 3 self . __indentSpace = \" \" * self . __indentDefinition self . __doDefinitionIndent = False # Maximum number of rows checked for value length and format self . __rowPartition = None # Defaults to double quoting preference - self . __preferDoubleQuotes = True self . __useAlignedColumns = True self . __useStopTokens = False self . __cnvCharRefs = False # self . __enforceAscii = False self . __isPy3 = sys . version_info [ 0 ] == 3 # if self.__isPy3: # self.__string_types = str # else: # self.__string_types = basestring def setSetEnforceAscii ( self , boolVal ): self . __enforceAscii = boolVal def setConvertCharRefs ( self , flag ): self . __cnvCharRefs = flag def setUseStopTokens ( self , flag ): self . __useStopTokens = flag def setMaxLineLength ( self , numChars ): self . __maximumLineLength = numChars def setAlignmentFlag ( self , flag = True ): self . __useAlignedColumns = flag def setPreferSingleQuotes ( self ): self . __preferDoubleQuotes = False def setPreferDoubleQuotes ( self ): self . __preferDoubleQuotes = True def setRowPartition ( self , numParts ): \"\"\"Maximum number of partitions used to format value length for column alignment\"\"\" self . __rowPartition = numParts def write ( self , containerList , lastInOrder = None , selectOrder = None ): self . __containerList = containerList for container in self . __containerList : self . writeContainer ( container , lastInOrder = lastInOrder , selectOrder = selectOrder ) def writeContainer ( self , container , lastInOrder = None , selectOrder = None ): indS = \" \" * self . __indentDefinition if container . getType () == \"definition\" : self . __write ( \"save_ %s \" % container . getName ()) # self.__write(\"save_%s\\n\" % container.getName()) self . __doDefinitionIndent = True # self.__write(indS + \"#\\n\") elif container . getType () == \"data\" : if container . getGlobal (): self . __write ( \"global_ \\n \" ) self . __doDefinitionIndent = False self . __write ( \" \\n \" ) else : self . __write ( \"data_ %s \\n \" % container . getName ()) self . __doDefinitionIndent = False # self.__write(\"#\\n\") nmL = container . filterObjectNameList ( lastInOrder = lastInOrder , selectOrder = selectOrder ) for nm in nmL : obj = container . getObj ( nm ) objL = obj . getRowList () # Skip empty objects if not objL : continue # Item - value formattting elif len ( objL ) == 1 : self . __writeItemValueFormat ( obj ) # Table formatting - elif objL and obj . getAttributeList (): if self . __useAlignedColumns : self . __writeTableFormat ( obj ) else : self . __writeTable ( obj ) else : raise PdbxError ( \"\" ) if self . __doDefinitionIndent : self . __write ( indS + \"#\" ) else : self . __write ( \"#\" ) # Add a trailing saveframe reserved word if container . getType () == \"definition\" : self . __write ( \" \\n save_ \\n \" ) self . __write ( \"# \\n \" ) def __write ( self , st ): try : if self . __cnvCharRefs : self . __ofh . write ( st . encode ( \"ascii\" , \"xmlcharrefreplace\" ) . decode ( \"ascii\" )) elif not self . __isPy3 : if self . __enforceAscii : self . __ofh . write ( st . decode ( \"ascii\" )) else : self . __ofh . write ( st ) # self.__ofh.write(st.encode('utf-8').decode('utf-8')) else : self . __ofh . write ( st ) except Exception as e : logger . exception ( \"write fails with %s for %r \" , str ( e ), st ) def __writeItemValueFormat ( self , categoryObj ): # indS = \" \" * self.__INDENT_DEFINITION myCategory = DataCategoryFormatted ( categoryObj , preferDoubleQuotes = self . __preferDoubleQuotes ) # Compute the maximum item name length within this category - attributeNameLengthMax = 0 for attributeName in myCategory . getAttributeList (): attributeNameLengthMax = max ( attributeNameLengthMax , len ( attributeName )) itemNameLengthMax = self . __spacing + len ( myCategory . getName ()) + attributeNameLengthMax + 2 # lineList = [] # lineList.append(indS+\"#\\n\") lineList . append ( \" \\n \" ) for attributeName , _ in myCategory . getAttributeListWithOrder (): if self . __doDefinitionIndent : # - add indent -- lineList . append ( self . __indentSpace ) itemName = \"_ %s . %s \" % ( myCategory . getName (), attributeName ) lineList . append ( itemName . ljust ( itemNameLengthMax )) lineList . append ( myCategory . getValueFormatted ( attributeName , 0 )) lineList . append ( \" \\n \" ) self . __write ( \"\" . join ( lineList )) def __writeTableFormat ( self , categoryObj ): # indS = \" \" * self.__INDENT_DEFINITION myCategory = DataCategoryFormatted ( categoryObj , preferDoubleQuotes = self . __preferDoubleQuotes ) # Write the declaration of the loop_ # lineList = [] # lineList.append(indS + '#\\n') lineList . append ( \" \\n \" ) if self . __doDefinitionIndent : lineList . append ( self . __indentSpace ) lineList . append ( \"loop_\" ) for attributeName in myCategory . getAttributeList (): lineList . append ( \" \\n \" ) if self . __doDefinitionIndent : lineList . append ( self . __indentSpace ) itemName = \"_ %s . %s \" % ( myCategory . getName (), attributeName ) lineList . append ( itemName ) self . __write ( \"\" . join ( lineList )) # # Write the data in tabular format - # # print myCategory.getName() # print myCategory.getAttributeList() # For speed make the following evaluation on a portion of the table if self . __rowPartition is not None : numSteps = max ( 1 , myCategory . getRowCount () // self . __rowPartition ) else : numSteps = 1 formatTypeList , _ = myCategory . getFormatTypeList ( steps = numSteps ) maxLengthList = myCategory . getAttributeValueMaxLengthList ( steps = numSteps ) spacing = \" \" * self . __spacing # # print formatTypeList # print dataTypeList # print maxLengthList # for iRow in range ( myCategory . getRowCount ()): lineList = [] lineList . append ( \" \\n \" ) if self . __doDefinitionIndent : lineList . append ( self . __indentSpace + \" \" ) for iAt in range ( myCategory . getAttributeCount ()): formatType = formatTypeList [ iAt ] maxLength = maxLengthList [ iAt ] if formatType == \"FT_UNQUOTED_STRING\" or formatType == \"FT_NULL_VALUE\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val . ljust ( maxLength )) elif formatType == \"FT_NUMBER\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val . rjust ( maxLength )) elif formatType == \"FT_QUOTED_STRING\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) # don't pad the last item in row condition if iAt == myCategory . getAttributeCount () - 1 : lineList . append ( val . ljust ( len ( val ))) else : lineList . append ( val . ljust ( maxLength + 2 )) elif formatType == \"FT_MULTI_LINE_STRING\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val ) lineList . append ( spacing ) self . __write ( \"\" . join ( lineList )) self . __write ( \" \\n \" ) if self . __useStopTokens : self . __write ( \"stop_ \\n \" ) def __writeTable ( self , categoryObj , numSteps = 5 ): indS = \" \" * self . __indentDefinition myCategory = DataCategoryFormatted ( categoryObj , preferDoubleQuotes = self . __preferDoubleQuotes ) # Write the declaration of the loop_ # lineList = [] lineList . append ( indS + \"# \\n \" ) if self . __doDefinitionIndent : lineList . append ( self . __indentSpace ) lineList . append ( \"loop_\" ) for attributeName in myCategory . getAttributeList (): lineList . append ( \" \\n \" ) if self . __doDefinitionIndent : lineList . append ( self . __indentSpace ) itemName = \"_ %s . %s \" % ( myCategory . getName (), attributeName ) lineList . append ( itemName ) self . __write ( \"\" . join ( lineList )) # formatTypeList , _ = myCategory . getFormatTypeList ( steps = numSteps ) spacing = \" \" * self . __spacing # for iRow in range ( myCategory . getRowCount ()): lineList = [] lineList . append ( \" \\n \" ) if self . __doDefinitionIndent : lineList . append ( self . __indentSpace + \" \" ) for iAt in range ( myCategory . getAttributeCount ()): formatType = formatTypeList [ iAt ] if formatType == \"FT_UNQUOTED_STRING\" or formatType == \"FT_NULL_VALUE\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val ) elif formatType == \"FT_NUMBER\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val ) elif formatType == \"FT_QUOTED_STRING\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val ) elif formatType == \"FT_MULTI_LINE_STRING\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val ) lineList . append ( spacing ) self . __write ( \"\" . join ( lineList )) self . __write ( \" \\n \" ) if self . __useStopTokens : self . __write ( \"stop_ \\n \" ) Methods __init__ ( self , ofh =< _io . StringIO object at 0x106c17ca0 > ) special Source code in mmcif/io/PdbxWriter.py def __init__ ( self , ofh = sys . stdout ): self . __ofh = ofh self . __containerList = [] self . __maximumLineLength = 2048 self . __spacing = 2 self . __indentDefinition = 3 self . __indentSpace = \" \" * self . __indentDefinition self . __doDefinitionIndent = False # Maximum number of rows checked for value length and format self . __rowPartition = None # Defaults to double quoting preference - self . __preferDoubleQuotes = True self . __useAlignedColumns = True self . __useStopTokens = False self . __cnvCharRefs = False # self . __enforceAscii = False self . __isPy3 = sys . version_info [ 0 ] == 3 # if self.__isPy3: # self.__string_types = str # else: # self.__string_types = basestring setAlignmentFlag ( self , flag = True ) Source code in mmcif/io/PdbxWriter.py def setAlignmentFlag ( self , flag = True ): self . __useAlignedColumns = flag setConvertCharRefs ( self , flag ) Source code in mmcif/io/PdbxWriter.py def setConvertCharRefs ( self , flag ): self . __cnvCharRefs = flag setMaxLineLength ( self , numChars ) Source code in mmcif/io/PdbxWriter.py def setMaxLineLength ( self , numChars ): self . __maximumLineLength = numChars setPreferDoubleQuotes ( self ) Source code in mmcif/io/PdbxWriter.py def setPreferDoubleQuotes ( self ): self . __preferDoubleQuotes = True setPreferSingleQuotes ( self ) Source code in mmcif/io/PdbxWriter.py def setPreferSingleQuotes ( self ): self . __preferDoubleQuotes = False setRowPartition ( self , numParts ) Maximum number of partitions used to format value length for column alignment Source code in mmcif/io/PdbxWriter.py def setRowPartition ( self , numParts ): \"\"\"Maximum number of partitions used to format value length for column alignment\"\"\" self . __rowPartition = numParts setSetEnforceAscii ( self , boolVal ) Source code in mmcif/io/PdbxWriter.py def setSetEnforceAscii ( self , boolVal ): self . __enforceAscii = boolVal setUseStopTokens ( self , flag ) Source code in mmcif/io/PdbxWriter.py def setUseStopTokens ( self , flag ): self . __useStopTokens = flag write ( self , containerList , lastInOrder = None , selectOrder = None ) Source code in mmcif/io/PdbxWriter.py def write ( self , containerList , lastInOrder = None , selectOrder = None ): self . __containerList = containerList for container in self . __containerList : self . writeContainer ( container , lastInOrder = lastInOrder , selectOrder = selectOrder ) writeContainer ( self , container , lastInOrder = None , selectOrder = None ) Source code in mmcif/io/PdbxWriter.py def writeContainer ( self , container , lastInOrder = None , selectOrder = None ): indS = \" \" * self . __indentDefinition if container . getType () == \"definition\" : self . __write ( \"save_ %s \" % container . getName ()) # self.__write(\"save_%s\\n\" % container.getName()) self . __doDefinitionIndent = True # self.__write(indS + \"#\\n\") elif container . getType () == \"data\" : if container . getGlobal (): self . __write ( \"global_ \\n \" ) self . __doDefinitionIndent = False self . __write ( \" \\n \" ) else : self . __write ( \"data_ %s \\n \" % container . getName ()) self . __doDefinitionIndent = False # self.__write(\"#\\n\") nmL = container . filterObjectNameList ( lastInOrder = lastInOrder , selectOrder = selectOrder ) for nm in nmL : obj = container . getObj ( nm ) objL = obj . getRowList () # Skip empty objects if not objL : continue # Item - value formattting elif len ( objL ) == 1 : self . __writeItemValueFormat ( obj ) # Table formatting - elif objL and obj . getAttributeList (): if self . __useAlignedColumns : self . __writeTableFormat ( obj ) else : self . __writeTable ( obj ) else : raise PdbxError ( \"\" ) if self . __doDefinitionIndent : self . __write ( indS + \"#\" ) else : self . __write ( \"#\" ) # Add a trailing saveframe reserved word if container . getType () == \"definition\" : self . __write ( \" \\n save_ \\n \" ) self . __write ( \"# \\n \" )","title":"PdbxWriter"},{"location":"api_reference/PdbxWriter/#mmcif.io.PdbxWriter.PdbxWriter","text":"Write mmCIF data files or dictionaries using the input container or container list. Source code in mmcif/io/PdbxWriter.py class PdbxWriter ( object ): \"\"\"Write mmCIF data files or dictionaries using the input container or container list.\"\"\" def __init__ ( self , ofh = sys . stdout ): self . __ofh = ofh self . __containerList = [] self . __maximumLineLength = 2048 self . __spacing = 2 self . __indentDefinition = 3 self . __indentSpace = \" \" * self . __indentDefinition self . __doDefinitionIndent = False # Maximum number of rows checked for value length and format self . __rowPartition = None # Defaults to double quoting preference - self . __preferDoubleQuotes = True self . __useAlignedColumns = True self . __useStopTokens = False self . __cnvCharRefs = False # self . __enforceAscii = False self . __isPy3 = sys . version_info [ 0 ] == 3 # if self.__isPy3: # self.__string_types = str # else: # self.__string_types = basestring def setSetEnforceAscii ( self , boolVal ): self . __enforceAscii = boolVal def setConvertCharRefs ( self , flag ): self . __cnvCharRefs = flag def setUseStopTokens ( self , flag ): self . __useStopTokens = flag def setMaxLineLength ( self , numChars ): self . __maximumLineLength = numChars def setAlignmentFlag ( self , flag = True ): self . __useAlignedColumns = flag def setPreferSingleQuotes ( self ): self . __preferDoubleQuotes = False def setPreferDoubleQuotes ( self ): self . __preferDoubleQuotes = True def setRowPartition ( self , numParts ): \"\"\"Maximum number of partitions used to format value length for column alignment\"\"\" self . __rowPartition = numParts def write ( self , containerList , lastInOrder = None , selectOrder = None ): self . __containerList = containerList for container in self . __containerList : self . writeContainer ( container , lastInOrder = lastInOrder , selectOrder = selectOrder ) def writeContainer ( self , container , lastInOrder = None , selectOrder = None ): indS = \" \" * self . __indentDefinition if container . getType () == \"definition\" : self . __write ( \"save_ %s \" % container . getName ()) # self.__write(\"save_%s\\n\" % container.getName()) self . __doDefinitionIndent = True # self.__write(indS + \"#\\n\") elif container . getType () == \"data\" : if container . getGlobal (): self . __write ( \"global_ \\n \" ) self . __doDefinitionIndent = False self . __write ( \" \\n \" ) else : self . __write ( \"data_ %s \\n \" % container . getName ()) self . __doDefinitionIndent = False # self.__write(\"#\\n\") nmL = container . filterObjectNameList ( lastInOrder = lastInOrder , selectOrder = selectOrder ) for nm in nmL : obj = container . getObj ( nm ) objL = obj . getRowList () # Skip empty objects if not objL : continue # Item - value formattting elif len ( objL ) == 1 : self . __writeItemValueFormat ( obj ) # Table formatting - elif objL and obj . getAttributeList (): if self . __useAlignedColumns : self . __writeTableFormat ( obj ) else : self . __writeTable ( obj ) else : raise PdbxError ( \"\" ) if self . __doDefinitionIndent : self . __write ( indS + \"#\" ) else : self . __write ( \"#\" ) # Add a trailing saveframe reserved word if container . getType () == \"definition\" : self . __write ( \" \\n save_ \\n \" ) self . __write ( \"# \\n \" ) def __write ( self , st ): try : if self . __cnvCharRefs : self . __ofh . write ( st . encode ( \"ascii\" , \"xmlcharrefreplace\" ) . decode ( \"ascii\" )) elif not self . __isPy3 : if self . __enforceAscii : self . __ofh . write ( st . decode ( \"ascii\" )) else : self . __ofh . write ( st ) # self.__ofh.write(st.encode('utf-8').decode('utf-8')) else : self . __ofh . write ( st ) except Exception as e : logger . exception ( \"write fails with %s for %r \" , str ( e ), st ) def __writeItemValueFormat ( self , categoryObj ): # indS = \" \" * self.__INDENT_DEFINITION myCategory = DataCategoryFormatted ( categoryObj , preferDoubleQuotes = self . __preferDoubleQuotes ) # Compute the maximum item name length within this category - attributeNameLengthMax = 0 for attributeName in myCategory . getAttributeList (): attributeNameLengthMax = max ( attributeNameLengthMax , len ( attributeName )) itemNameLengthMax = self . __spacing + len ( myCategory . getName ()) + attributeNameLengthMax + 2 # lineList = [] # lineList.append(indS+\"#\\n\") lineList . append ( \" \\n \" ) for attributeName , _ in myCategory . getAttributeListWithOrder (): if self . __doDefinitionIndent : # - add indent -- lineList . append ( self . __indentSpace ) itemName = \"_ %s . %s \" % ( myCategory . getName (), attributeName ) lineList . append ( itemName . ljust ( itemNameLengthMax )) lineList . append ( myCategory . getValueFormatted ( attributeName , 0 )) lineList . append ( \" \\n \" ) self . __write ( \"\" . join ( lineList )) def __writeTableFormat ( self , categoryObj ): # indS = \" \" * self.__INDENT_DEFINITION myCategory = DataCategoryFormatted ( categoryObj , preferDoubleQuotes = self . __preferDoubleQuotes ) # Write the declaration of the loop_ # lineList = [] # lineList.append(indS + '#\\n') lineList . append ( \" \\n \" ) if self . __doDefinitionIndent : lineList . append ( self . __indentSpace ) lineList . append ( \"loop_\" ) for attributeName in myCategory . getAttributeList (): lineList . append ( \" \\n \" ) if self . __doDefinitionIndent : lineList . append ( self . __indentSpace ) itemName = \"_ %s . %s \" % ( myCategory . getName (), attributeName ) lineList . append ( itemName ) self . __write ( \"\" . join ( lineList )) # # Write the data in tabular format - # # print myCategory.getName() # print myCategory.getAttributeList() # For speed make the following evaluation on a portion of the table if self . __rowPartition is not None : numSteps = max ( 1 , myCategory . getRowCount () // self . __rowPartition ) else : numSteps = 1 formatTypeList , _ = myCategory . getFormatTypeList ( steps = numSteps ) maxLengthList = myCategory . getAttributeValueMaxLengthList ( steps = numSteps ) spacing = \" \" * self . __spacing # # print formatTypeList # print dataTypeList # print maxLengthList # for iRow in range ( myCategory . getRowCount ()): lineList = [] lineList . append ( \" \\n \" ) if self . __doDefinitionIndent : lineList . append ( self . __indentSpace + \" \" ) for iAt in range ( myCategory . getAttributeCount ()): formatType = formatTypeList [ iAt ] maxLength = maxLengthList [ iAt ] if formatType == \"FT_UNQUOTED_STRING\" or formatType == \"FT_NULL_VALUE\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val . ljust ( maxLength )) elif formatType == \"FT_NUMBER\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val . rjust ( maxLength )) elif formatType == \"FT_QUOTED_STRING\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) # don't pad the last item in row condition if iAt == myCategory . getAttributeCount () - 1 : lineList . append ( val . ljust ( len ( val ))) else : lineList . append ( val . ljust ( maxLength + 2 )) elif formatType == \"FT_MULTI_LINE_STRING\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val ) lineList . append ( spacing ) self . __write ( \"\" . join ( lineList )) self . __write ( \" \\n \" ) if self . __useStopTokens : self . __write ( \"stop_ \\n \" ) def __writeTable ( self , categoryObj , numSteps = 5 ): indS = \" \" * self . __indentDefinition myCategory = DataCategoryFormatted ( categoryObj , preferDoubleQuotes = self . __preferDoubleQuotes ) # Write the declaration of the loop_ # lineList = [] lineList . append ( indS + \"# \\n \" ) if self . __doDefinitionIndent : lineList . append ( self . __indentSpace ) lineList . append ( \"loop_\" ) for attributeName in myCategory . getAttributeList (): lineList . append ( \" \\n \" ) if self . __doDefinitionIndent : lineList . append ( self . __indentSpace ) itemName = \"_ %s . %s \" % ( myCategory . getName (), attributeName ) lineList . append ( itemName ) self . __write ( \"\" . join ( lineList )) # formatTypeList , _ = myCategory . getFormatTypeList ( steps = numSteps ) spacing = \" \" * self . __spacing # for iRow in range ( myCategory . getRowCount ()): lineList = [] lineList . append ( \" \\n \" ) if self . __doDefinitionIndent : lineList . append ( self . __indentSpace + \" \" ) for iAt in range ( myCategory . getAttributeCount ()): formatType = formatTypeList [ iAt ] if formatType == \"FT_UNQUOTED_STRING\" or formatType == \"FT_NULL_VALUE\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val ) elif formatType == \"FT_NUMBER\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val ) elif formatType == \"FT_QUOTED_STRING\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val ) elif formatType == \"FT_MULTI_LINE_STRING\" : val = myCategory . getValueFormattedByIndex ( iAt , iRow ) lineList . append ( val ) lineList . append ( spacing ) self . __write ( \"\" . join ( lineList )) self . __write ( \" \\n \" ) if self . __useStopTokens : self . __write ( \"stop_ \\n \" )","title":"PdbxWriter"},{"location":"api_reference/PdbxWriter/#mmcif.io.PdbxWriter.PdbxWriter-methods","text":"","title":"Methods"},{"location":"api_reference/PdbxWriter/#mmcif.io.PdbxWriter.PdbxWriter.__init__","text":"Source code in mmcif/io/PdbxWriter.py def __init__ ( self , ofh = sys . stdout ): self . __ofh = ofh self . __containerList = [] self . __maximumLineLength = 2048 self . __spacing = 2 self . __indentDefinition = 3 self . __indentSpace = \" \" * self . __indentDefinition self . __doDefinitionIndent = False # Maximum number of rows checked for value length and format self . __rowPartition = None # Defaults to double quoting preference - self . __preferDoubleQuotes = True self . __useAlignedColumns = True self . __useStopTokens = False self . __cnvCharRefs = False # self . __enforceAscii = False self . __isPy3 = sys . version_info [ 0 ] == 3 # if self.__isPy3: # self.__string_types = str # else: # self.__string_types = basestring","title":"__init__()"},{"location":"api_reference/PdbxWriter/#mmcif.io.PdbxWriter.PdbxWriter.setAlignmentFlag","text":"Source code in mmcif/io/PdbxWriter.py def setAlignmentFlag ( self , flag = True ): self . __useAlignedColumns = flag","title":"setAlignmentFlag()"},{"location":"api_reference/PdbxWriter/#mmcif.io.PdbxWriter.PdbxWriter.setConvertCharRefs","text":"Source code in mmcif/io/PdbxWriter.py def setConvertCharRefs ( self , flag ): self . __cnvCharRefs = flag","title":"setConvertCharRefs()"},{"location":"api_reference/PdbxWriter/#mmcif.io.PdbxWriter.PdbxWriter.setMaxLineLength","text":"Source code in mmcif/io/PdbxWriter.py def setMaxLineLength ( self , numChars ): self . __maximumLineLength = numChars","title":"setMaxLineLength()"},{"location":"api_reference/PdbxWriter/#mmcif.io.PdbxWriter.PdbxWriter.setPreferDoubleQuotes","text":"Source code in mmcif/io/PdbxWriter.py def setPreferDoubleQuotes ( self ): self . __preferDoubleQuotes = True","title":"setPreferDoubleQuotes()"},{"location":"api_reference/PdbxWriter/#mmcif.io.PdbxWriter.PdbxWriter.setPreferSingleQuotes","text":"Source code in mmcif/io/PdbxWriter.py def setPreferSingleQuotes ( self ): self . __preferDoubleQuotes = False","title":"setPreferSingleQuotes()"},{"location":"api_reference/PdbxWriter/#mmcif.io.PdbxWriter.PdbxWriter.setRowPartition","text":"Maximum number of partitions used to format value length for column alignment Source code in mmcif/io/PdbxWriter.py def setRowPartition ( self , numParts ): \"\"\"Maximum number of partitions used to format value length for column alignment\"\"\" self . __rowPartition = numParts","title":"setRowPartition()"},{"location":"api_reference/PdbxWriter/#mmcif.io.PdbxWriter.PdbxWriter.setSetEnforceAscii","text":"Source code in mmcif/io/PdbxWriter.py def setSetEnforceAscii ( self , boolVal ): self . __enforceAscii = boolVal","title":"setSetEnforceAscii()"},{"location":"api_reference/PdbxWriter/#mmcif.io.PdbxWriter.PdbxWriter.setUseStopTokens","text":"Source code in mmcif/io/PdbxWriter.py def setUseStopTokens ( self , flag ): self . __useStopTokens = flag","title":"setUseStopTokens()"},{"location":"api_reference/PdbxWriter/#mmcif.io.PdbxWriter.PdbxWriter.write","text":"Source code in mmcif/io/PdbxWriter.py def write ( self , containerList , lastInOrder = None , selectOrder = None ): self . __containerList = containerList for container in self . __containerList : self . writeContainer ( container , lastInOrder = lastInOrder , selectOrder = selectOrder )","title":"write()"},{"location":"api_reference/PdbxWriter/#mmcif.io.PdbxWriter.PdbxWriter.writeContainer","text":"Source code in mmcif/io/PdbxWriter.py def writeContainer ( self , container , lastInOrder = None , selectOrder = None ): indS = \" \" * self . __indentDefinition if container . getType () == \"definition\" : self . __write ( \"save_ %s \" % container . getName ()) # self.__write(\"save_%s\\n\" % container.getName()) self . __doDefinitionIndent = True # self.__write(indS + \"#\\n\") elif container . getType () == \"data\" : if container . getGlobal (): self . __write ( \"global_ \\n \" ) self . __doDefinitionIndent = False self . __write ( \" \\n \" ) else : self . __write ( \"data_ %s \\n \" % container . getName ()) self . __doDefinitionIndent = False # self.__write(\"#\\n\") nmL = container . filterObjectNameList ( lastInOrder = lastInOrder , selectOrder = selectOrder ) for nm in nmL : obj = container . getObj ( nm ) objL = obj . getRowList () # Skip empty objects if not objL : continue # Item - value formattting elif len ( objL ) == 1 : self . __writeItemValueFormat ( obj ) # Table formatting - elif objL and obj . getAttributeList (): if self . __useAlignedColumns : self . __writeTableFormat ( obj ) else : self . __writeTable ( obj ) else : raise PdbxError ( \"\" ) if self . __doDefinitionIndent : self . __write ( indS + \"#\" ) else : self . __write ( \"#\" ) # Add a trailing saveframe reserved word if container . getType () == \"definition\" : self . __write ( \" \\n save_ \\n \" ) self . __write ( \"# \\n \" )","title":"writeContainer()"}]}